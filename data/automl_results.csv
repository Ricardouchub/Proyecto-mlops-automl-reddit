brand,text,sentiment
Intel,"Nice, I like this approach, stops the end user who isn't an expert when reading specs from getting screwed over by slow ram killing their igpu performance. If you see the Arc B branding on the laptop you can be rest assured you're getting the right setup",Positive
Intel,"It is really impressive what Intel were able to achieve with Arc B390, using a traditional 128-bit memory bus.  Nova Lake (2027) is rumoured to keep the same memory setup same (perhaps bump up to 10700 MT/s), while [bringing a modest 25% improvement](https://www.reddit.com/r/hardware/comments/1qmk1e9/intel_nova_lake_xe3p_igpus_could_be_25_more/).  Razer Lake (2028) could be the next big leap forward, if it adopts LPDDR6.",Positive
Intel,I'm guessing lpCAMM2 would work as it can reach that 7467 MT/s no?,Neutral
Intel,"so 7467 MT/s or you lose the Arc badge, kinda savage lol",Negative
Intel,"how about.  Quad channel for consumers  Crazy idea, I know.",Neutral
Intel,I assume they also need 2 DIMMs to get the Arc branding?,Neutral
Intel,"imo yeah man, cost always gets us lol maybe someday they'll make it more affordable for everyone",Neutral
Intel,Can someone with that special kind of mental situation explain the 140T vs b390 vs Iris Xe to me,Neutral
Intel,They don't sell them with on-package memory?,Neutral
Intel,"Man it's tragic that the CEO that saved the company, pat gelsinger created this product and got fired before he could see his projects come to fruition because the board was only concerned with short term profits and building chips is a long term endeavor. Now they are going to ruin the company again",Negative
Intel,Nobody seems to be talking about how Panther Lake is going to be more expensive than Gorgon Point,Negative
Intel,"So yeah, as I assumed, these will be closer to Strix Halo pricing than Strix Point.",Neutral
Intel,"Hello Forsaken_Arm5698! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
Intel,"This isnâ€™t entirely new, I think with the first generation of Arc iGPUs you had to have some minimum bandwidth to get to call it â€œArcâ€, otherwise it was the same generic â€œIntel graphicsâ€ listed here. _Might_ even date back before Arc with â€œIrisâ€ graphics branding?",Neutral
Intel,Or CPU performance. Single channel RAM cripples CPUs in almost every workload with its 50% bandwidth cut.,Negative
Intel,"> Razer Lake (2028) could be the next big leap forward, if it adopts LPDDR6.  Razor Lake won't. They'll just reuse the NVL construction. Titan Lake (2029?) would be the next big step assuming they don't go for a 3rd reuse, though there are rumors about it sticking with Xe3p. Xe4 should be a big leap though, assuming it's timely enough.",Neutral
Intel,It should work fine based on their documentation.,Positive
Intel,"Yeah, it's called Strix Halo and you do not see it anywhere because of cost.",Neutral
Intel,It raises costs a lot for a mainstream platform. Intel seems to have struck a good balance for the target market.,Positive
Intel,We used to have triple channel with Intel Nehalem.,Neutral
Intel,"256 bit memory bus you mean, which is technically 16 channels of LPDDR.",Neutral
Intel,"Unfortunately only way such chips will get quad channels is if RAM will get into SoC. Like in Apple M series, ~~AMD's Strix Halo~~ or Intel Lunar Lake. Or wide bus soldered RAM with APUs like AMD's Strix Halo.   But that comes with no upgradeability/fixability and higher cost in general.  edit: correction as u/bazhvn pointed out",Negative
Intel,wouldnt that make echo issues worse? the current board manufacturers are already doing everything possible to not invest a single cent into fixing this.,Negative
Intel,Stick two DIMMs on the PCIE bus and dedicate them to the iGPU.,Neutral
Intel,8 ram pieces per laptop? thats a lotta ram,Neutral
Intel,The problem is they're doing better in the sector that isn't making any money these days. All the money is in AI currently and they're not getting any of it.,Negative
Intel,"The guy who turned Intel around got fired lol. They were mad that Intel wasn't doing well but they didn't give enough time for the dudes projects to come to fruition. I.g. he was CEO for a few years but new chips take 5 years to build. Intel is going to have a short golden period while pat gelsigners projects come to fruition and then after like 3 years they are gonna be back to shit. The new CEO seems like the same as the ones before pat, just cares about next quarters profit and nothing else.",Negative
Intel,Not the kind of being on fire you want though. Let's be honest.,Negative
Intel,"Given Intel only advertises LPDDR5x with the 12Xe tile regardless of the memory controller, I think it's safe to say they will not allow OEMs to use DIMMs with it.",Neutral
Intel,"doesn't matter, can't get SODIMM LPPDR5X. and CAMM2 modules are dual channel",Negative
Intel,"Iris Xe was Intel's more premium iGPUs for a while. Then Lunar Lake launched with a ~~140T~~ 140V iGPU that was their first actually competitive iGPU.  Now Panther Lake has a B390 iGPU option. Intel has finally, with the launch of Panther Lake, decided to give their premium iGPUs the same naming scheme as their dGPU line, because ~~""140T""~~ 140V made no sense, but ""B390"" does (for the most part)  Edit: Case and Point: Got 140V and 140T mixed up",Neutral
Intel,"You have a CPU that costs $150 for you to make that you sell to OEMs for $300. This gets you a 50% margin.  You have a CPU that costs $150 to make, then you add $50 of RAM on the package, so total is $200. OEMs aren't gonna like you taking a profit on RAM as a middleman when taking profit on RAM is one of their key revenue sources on laptop upsells. So you sell the RAM for cost, meaning you charge $350 for the SoC.  Yes, you've made the same nominal profit of $150, but your margin % dropped from 50% to ~43% *and* this simple math example doesn't take into account that there is a cost involved with having to source the memory yourself (i.e pay staff to manage contracts, make and track orders, receive shipments, package the RAM, etc.)  That's why it's very difficult for on-package memory to gain traction in the Windows PC world: Most CPU makers don't want to take the margin hit, and most OEMs would prefer to just handle memory quantity and product tiering themselves.",Neutral
Intel,"Nope, that's why lunar lake is a one time thing, it's too expensive and has little flexibility",Negative
Intel,"I donâ€™t think that concern for short term profits was unfounded in this case, Intel was having crisis levels of cash flow problems and radical measures needed to be taken to shore up investors. Intel was on the verge of being a failed business and frankly they are not out of the woods yet",Negative
Intel,"> the CEO that saved the company  How did he save the company? His legacy is the fabs, which are still a dumpster fire.",Negative
Intel,"Because unless someone can provide the figures, then what's there to discuss? Whats the cost of a PTL-H SoC? How much more does it cost than Gorgon Point? And how does the cost of RAM/SSDs impact that overall total cost between the two when factoring in the total laptop BOM?",Neutral
Intel,"PTL being a better product prob helps justify a higher price tag.   Though how much higher is kinda hard to tell, with the whole component shortages due to the AI boom prob also playing a part.",Positive
Intel,Does not seem to be the case based on newly released laptop prices. Remember when full die strix point laptops started at $1600 back in July 2024?,Neutral
Intel,"If your laptop only has 1 stick of RAM, it'll show up as Intel UHD graphics and a few of the execution units are disabled. Slapping in another stick changes it to Iris Xe and unlocks all the EU.",Neutral
Intel,Xe4? When does nvidia come into the picture?,Neutral
Intel,> Razer Lake  Bloated batteries after 1 year will be a requirement for laptop manufacturers to use this./s,Neutral
Intel,The power of a 4060 for the cost of a 4080!,Positive
Intel,"A better compromise for gaming handhelds would probably be 192 bit bus, running ~16 XE3 cores. Wider and slower can work very nicely for power efficiency but cost is an important consideration too. Ofc the real killer is economies of scale - nobody's going to do a bulk order of 5 million of these things to make it worth their while.",Neutral
Intel,"Intrinsically, 4ch is not *that* much more expensive. And even considering the CPU config STX-H has more than just product cost being reflected in its pricing.",Neutral
Intel,highkey lol right? high-end specs always come with a crazy price tag. it'd be awesome if they made it affordable tho,Neutral
Intel,> Intel seems to have struck a good balance for the target market.  Technology and market-awareness... both are important,Positive
Intel,"But this has like 150GB/s of memory bandwidth, even at 7467. Maybe even closer to 120GB/s. Which is pathetic for a GPU.",Negative
Intel,Shout out to my sweet i7-920 and 6GB of Dominator DDR3,Positive
Intel,quad channel on X79/X99,Neutral
Intel,On consumer boards?,Neutral
Intel,5 different sticks running single channel was perfectly fine ever more further back :),Positive
Intel,"256=32*8, and also ddr5 channels being 32-bit is superficial",Negative
Intel,Eh Strix Halo doesnâ€™t employ DRAM on package.,Neutral
Intel,"No. lpcamm modules are dual-channel per module. So quad-channel would be 2 modules or 'sticks',  just like current so-dimm dual-channel laptops.",Neutral
Intel,"Yes, the sector does only 12 billion in revenue, completely nothing.",Negative
Intel,">The guy who turned Intel around got fired lol.  Intel isn't even turned around yet.   >They were mad that Intel wasn't doing well but they didn't give enough time for the dudes projects to come to fruition  The problem was that, if external customers would have ended up using their fabs, they would have known before hand, since the contracts have to be inked and it takes a year or two at least to even just port IP over.   >Intel is going to have a short golden period while pat gelsigners projects come to fruition and then after like 3 years they are gonna be back to shit.  Why do you expect Intel to have a short golden period soon?",Negative
Intel,what I meant was that there would be 2 memory modules. A laptop with only one gets half the memory bandwidth,Neutral
Intel,"Correction, Lunar Lake had the 140V iGPU, which was based on Xe2, or Battlemage.     Arrow Lake was the one that got 140T, which was basically a A380 (Meteor Lake got an A380 but without XMX).",Neutral
Intel,"There is one possible out, however. If someone can figure out how to design the package such that OEMs can own the memory attach.",Neutral
Intel,"There is some humor in how their necessary front-loading of LNL packages mitigated needing to source more LPDDR5x after it spiked in cost. They sort of lucked into that one, with LNL able to simply clear out existing stock at its own natural pace during the transition to PTL.  \[Edited a weird sentence\]",Neutral
Intel,It's not expensive. The challenge is with the margins of Intel reselling memory to OEMs.,Neutral
Intel,Even QC is only doing on package memory for 1 SKU (now 2 but same),Neutral
Intel,"> Though how much higher is kinda hard to tell, with the whole component shortages due to the AI boom prob also playing a part.  Ye, people comparing launch prices of today vs previously launched products. Are up for a rough awakening of what those previously launched products will cost in 6+ months from now when the DRAM apocalypse catches up to them and current stock is depleted.",Negative
Intel,You can buy mini pc's with Strix Point for $600 now though. I doubt they're ever going to sell devices with this iGPU for a price that low with those requirements. Not with the way RAM prices are now.  It's going to be closer to Strix Halo pricing than Strix Point.,Negative
Intel,"If they ever use Nvidia, it'll be for Strix Halo tier chips. Intel isn't getting rid of their GPU department entirely.",Neutral
Intel,Hopefully never at this point.,Negative
Intel,No idea. I *am* working on talk from before that announcement.,Neutral
Intel,I think those will be very AI-centered products.,Positive
Intel,"And overhauling the BIOS every 6 months, with a new BIOS X+1.",Neutral
Intel,"idk man, it has a 16c32t zen5 CPU attached to it... so...",Neutral
Intel,More like mid range performance (5060 at BEST) for high end pricing.,Neutral
Intel,"But think of what range the Panther Lake platform covers. The B390 is the top end. You have essentially the same platform support down to the 4Xe entry GPU. So yeah, maybe dual channel is not quite ideal at the far end of the distribution, but you need to compromise somewhere.Â    If they went for 256b, they'd really need a significantly bigger GPU to justify it. Something like Strix Halo or the cancelled NVL-AX.",Neutral
Intel,"Yes, though it has tons of cache to service it (16 MB GPU L2, 8 MB SLC).  Whatever the means, the end result is what matters. In that regard, it's as good as a 4050. â€‹",Positive
Intel,"oh boy, this brings back memories, my second ever PC build was this exact setup!",Positive
Intel,My 7900x Intel at 5ghz all core still running today.,Neutral
Intel,"Yup, I used a Intel i7 920 with my Asus P6T motherboard and had 3x2GB memory.",Neutral
Intel,"Strix Halo has 16x16b LPDDR5X, not DDR5. And it's not superficial, they function exactly like separate channels always have.  It's just a convention to normalise to 64b channels when discussing components to make it clearer what the total bus width is, independent of differing channel widths.",Neutral
Intel,Yeap. Thanks. I've made correction.,Positive
Intel,He means by comparison duuh,Neutral
Intel,it'd be fabulously stupid to have half-populated soldered memory.  lpddr = soldered.  dimms are slow and power hungry.,Negative
Intel,"> (Meteor Lake got an A380 but without XMX)  This was such a bizarre omission, I don't understand it.",Negative
Intel,"Interesting. So chipmaker (such as Intel or Qualcomm), solders the SoC on package, then sends it off to the device OEMs, for them to solder their choice of RAM on the package.?",Neutral
Intel,In what world is DRAM not expensive rn brother,Negative
Intel,"Why would the ram affect this but not strix point?Â   It doesnâ€™t say it canâ€™t support SODIMM to ship barebone mini pcs without ram. It just says it wonâ€™t be badged â€œB390â€.Â   Again why are you using 1.5 year old product pricing vs launch pricing in the first place? Like I said, do July 2024 pricing. If you canâ€™t, then i canâ€™t help you with current pricing.Â    https://www.lenovo.com/gb/en/configurator/cto/index.html?bundleId=83RWCTO1WWGB1   https://www.lenovo.com/gb/en/configurator/cto/index.html?bundleId=83Q6CTO1WWGB2   Hereâ€™s identical Legion 5 laptops with Panther vs Gorgon. Very similar pricing. Anything else?",Neutral
Intel,Intel would have already been very familiar with how the B390 was going to perform when they signed that deal.,Neutral
Intel,"I would've been more interested in a Strix Halo machine if it had FSR4.  I'll be waiting for the next version of it, cause that would make for an amazing gaming tablet on the go, and a great workstation connected to a dock on the desk.",Positive
Intel,In a power envelope where it can't be used correctly.Â  It loses in a bunch of benchmarks to M4 Pro that only has 10P coresÂ    That's why it is mini pc only,Negative
Intel,Well the 4Xe3 nearly at level of 8Xe2 in LNL if you look at game benchmarks that alone is a achievement https://www.ultrabookreview.com/74624-intel-panther-lake-laptops/,Positive
Intel,Since when is nvlax cancelled?,Negative
Intel,Itâ€™s an improper consumer convention to normalize 64b as a channel*,Negative
Intel,"On the topic, SOCAMM would be a rather nice solution repairability wise whilst not trading much real estate since 256bit requires only 2 modules. Not quite thin and light orientated but mobility is not out of question.",Positive
Intel,"Fabulously stupid, but not without precedent. Iâ€™m pretty sure â€œNuclear Laptopsâ€ has covered at least one laptop that supported dual channel but the manufacturer only soldered a single channel without even an empty DIMM slot for the other channel. Granted, the premise of those videos are theyâ€™re cheap, ~$300 laptops that are all terrible in one way or another, probably not the _most_ likely to happen to top end Panther Lake.",Negative
Intel,"> lpddr = soldered  Not with LPCAMM, but they haven't yet proposed a single channel module. Definitely not impossible though, and may even be likely.",Neutral
Intel,"Yes, that would be the ideal. The current process has both the memory and SoC attached at once. If you could separate out those two steps, then you could have the customer source the memory, and problem solved.  And this isn't some pie-in-the-sky fantasy either. Would require some packaging innovation, sure, but I don't think anyone seriously questions the feasibility at a conceptual level. The problem is that the overlap between both ""can"" and ""want to"" has been pretty low.",Neutral
Intel,It was removed before the DRAM crisis because managing so many SKUs is a nightmare for Intel.,Negative
Intel,Having it be on package isn't more expensive then on the motherboard.,Neutral
Intel,"The Intel version of that laptop only has either a 356H or 386H, those SoCs only have 4 Xe cores so they wouldn't have the B390 or B370 branding regardless (that's only on the models ending in --8H)  Soldered RAM is mandatory for the --8H SKUs, the Intel product pages for them only mention LPDDR5X  [IntelÂ® Coreâ„¢ Ultra X9 Processor 388H](https://www.intel.com/content/www/us/en/products/sku/245526/intel-core-ultra-x9-processor-388h-18m-cache-up-to-5-10-ghz/specifications.html)  Other SKUs mention both LPDDR5X and DDR5  [IntelÂ® Coreâ„¢ Ultra 9 Processor 386H](https://www.intel.com/content/www/us/en/products/sku/245529/intel-core-ultra-9-processor-386h-18m-cache-up-to-4-90-ghz/specifications.html)",Neutral
Intel,">Why would the ram affect this but not strix point?   Because Strix Point doesn't have a 7467 MT/s RAM requirement like this one does to be called a B390 iGPU product.  That's the whole point of the article, for it to actually be a B390 it needs to have 7467 MT7s RAM or better. Which will make it very expensive.  >Again why are you using 1.5 year old product pricing vs launch pricing in the first place?   You skipped my point, again. This chip (in the configuration which makes it ""B390"") will never be as cheap as Strix Point. The B390 going to be a premium priced product closer to Strix Halo than to Strix Point. Yet Intel compares its performance to Strix Point and not Strix Halo.  >Hereâ€™s identical Legion 5 laptops with Panther vs Gorgon. Very similar pricing. Anything else?  None of your examples are B390 certified.",Negative
Intel,"Intel was also not really in a position to turn down a $5B investment. And the deal adds native NVLink support for Xeon, which benefits Intel more than any potential Nvidia deal for iGPUs may hurt them",Neutral
Intel,"I had an HP G1A with 128GB RAM on release in checkout when I found out it was RDNA 3.5, I rubbed my eyes in disbelief but the spec list didn't change. It was the saddest tab closure of my days  That literally more than halved the value proposition of an already obscene price in an instant.",Negative
Intel,"X86 loses in single threaded performance at every power range for consumers. As for the 10P cores. E cores are known to boost multi threaded performance by a lot. The M4 pro has 10 of them. Yes, it'll beat it in some benchmarks.",Positive
Intel,What? Your link is showing the full LNL config being roughly 1/3rd better.,Neutral
Intel,"There've been rumors about its cancellation for a while, and with Intel marketing just saying they have no plans for such a product, think it's safe to say it's dead.",Negative
Intel,"Yea, i hope that CAMM2/LPCAMM2 will succeed both on laptops and on PCs.   While CPU dont need typically wide bus with high bandwith, higher MT/s is helpful and CAMM helps with that and thats pain point on PCs.   While simultaneously can have wide bus for iGPU as You say.  Unfortunately with current RAM shortage getting any kind of ram is pain :/.",Positive
Intel,"No, it's primarily the margin issue. Intel isn't shy about SKUs.",Neutral
Intel,">Â Because Strix Point doesn't have a 7467 MT/s RAM requirement like this one does to be called a B390 iGPU product.  It does not need to be called B390 to obliterate the 890m. 890m isnâ€™t as fast when using DDR5-5600 as with 7500 (promo material used during the original strix point presentation), either.Â   >Â You skipped my point, again. This chip (in the configuration which makes it ""B390) will never be as cheap as Strix Point. It's going to be a premium priced product closer to Strix Halo than to Strix Point.  >Â You skipped my point, again. This chip (in the configuration which makes it ""B390) will never be as cheap as Strix Point. It's going to be a premium priced product closer to Strix Halo than to Strix Point.  Strix halo is 256 bit memory and a significantly bigger die. Why would just the mere fact that Panther B390 requires soldered LPDDR ram mean it will be comparable to Halo? Does soldered memory automatically make strix point expensive like Halo?Â   >Â None of your examples are B390 certified.  It is sufficient to demonstrate that with equalised ramÂ itâ€™sÂ not more expensive than Gorgon.",Neutral
Intel,"Also an NVIDIA deal for iGPUs really doesn't hurt them, because it allows them to  develop a Strix Halo level APU competitor for laptops without having to take a risk on trying to compete with NVIDIA's mindshare or technology.     They are still perfectly free to pursue developing lower end iGPUs, which they most likely will be.",Positive
Intel,No? Have you checked the correct table it's not 1/3 better in game s,Negative
Intel,With the DRAM shortages Intel could sell more chips with the supply it would eat   Doesn't make sense in current environment sadly,Negative
Intel,"But we're talking about the B390. And that's what Intel is using in its presentations. I'm making the point that according to this article, the B390 will most likely be priced closer to Strix Halo than Strix Point.  7467MT/s RAM (and above) is expensive. RAM is much more expensive than it used to be, cutting edge RAM speeds even more so.  >It is sufficient to demonstrate that with equalised ram itâ€™s not more expensive than Gorgon.  We're talking about the B390. The one Intel is using in its presentations. None of your examples are B390. The article is about the B-series. We shouldn't use the B390's performance numbers to compare to Strix Point, but only use the prices of the non B-series. They are irrelevant for this discussion.",Neutral
Intel,"Ah, you're right. Was scrolling on mobile and stopped at the synthetics. Well, good showing then, and also good to see more a focus on actual game performance.",Positive
Intel,"What do you mean? If anything, the current environment would favor such a system.",Neutral
Intel,MSI Prestige 14 Flip with B390 is up for $1300. The cheapest upcoming Strix Halo laptop is ASUS TUF A14 $1800. Other laptops with Strix Halo are over $2000. Intel Panther Lake is closer to Strix Point in price,Neutral
Intel,No problem seeing 4Xe3 performance so well feels like 12Xe3 is starving for more memory bandwidth,Positive
Intel,OEM's can't buy enough DRAM   Intel can sell panther lake in 16GB laptopsÂ    While all the halo stuff is 32GB and mini pcs are 128GB,Neutral
Intel,"Yeah, I feared PTL-U is going to be a significant regression from LNL, where the GPU is concerned. Well, I see that's not the case.â€‹",Negative
Intel,"Problem is that dGPU systems would have to source VRAM in addition to DRAM, whereas a large APU only has to source slightly more DRAM.",Neutral
Intel,"TLDR:    ""The performance advantage over the previous Arc Graphics 140T/140V iGPUs is around 70%. The advantage over the smaller Radeon 800 series iGPUs of AMD Zen 5 is also considerably high (between 50-80% depending on the benchmark).   Although the Strix Halo GPUs are even faster (but not more efficient), they operate at higher power limits. There are only a handful of corresponding devices on the market, which then are also quite expensive.""",Positive
Intel,"This will be nasty on handhelds, because a 4050 at 720p runs just as fast as a 3070 at 1440p.",Negative
Intel,What does this mean for handhelds.,Neutral
Intel,"As much as its nice to see it competing with low powered 4050. The 4050 and even  full powered 5050 and 5060 laptops are significantly cheaper than the B390 laptops.  You can get 5070 to 5070 ti laptops for the price of of laptops using the b390  On Best Buy  Dells XPS 14 is 2249 with the X9 388H with 32 GB ram  https://www.bestbuy.com/product/dell-xps-14-copilot-pc-14-2-8k-oled-touchscreen-laptop-intel-core-ultra-x9-388h-2026-32gb-memory-1tb-storage-graphite/J3K4L6QWVR   The G14 is 2399 with a Ryzen AI 9 hx with 32 GB ram AND A RTX 5070 Ti  https://www.bestbuy.com/product/asus-rog-zephyrus-g14-14-3k-oled-120hz-gaming-laptop-copilot-pc-amd-ryzen-ai-9-hx-32gb-ram-nvidia-rtx-5070-ti-1tb-platinum-white/JJGGLHJXQ9/sku/6613954  And that's a premium G14. The Acer 16S with Ultra 9 288H, 32 GB ram and 5070 ti is currently 1699  https://www.bestbuy.com/product/acer-predator-helios-neo-16s-ai-gaming-laptop-16-oled-240hz-intel-core-ultra-9-nvidia-geforce-rtx-5070ti-32gb-1tb-obsidian-black/JJ8V8H38XT  Intel needs to get pricing to RTX 5050 levels or below to be actually competitive.",Positive
Intel,">and the two render slices each consist of six Xe cores.  I assumed it was 3 slices, of 4 cores each. Is there a benefit to doing it this way, or does it not matter?",Neutral
Intel,"Intel is back, it will be at 1 trillion market cap in next 18-24 months",Positive
Intel,"Hello Antonis_32! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
Intel,"Stop with these fake benchmarks.  You will see when the benchmarks are not cherry picked, it will be no where near a 4050 lol. They had to gimp the poor 4050 all the way down to 30w, which I donâ€™t even know how it even operates as such low wattages for the b390 to have a chance.  The full wattage 4050 (100w+) is about as fast as a 3060 desktop, this tiny iGPU in real world gaming tests will be at most best case scenario as fast as a full powered 3050, which is still  a massive 50-60% slower than a 4050 laptop.",Negative
Intel,"Digital foundry did a video where they ran a strix halo at the same tdp as panther lake and it was notably faster, albeit with a much larger die size.",Positive
Intel,It means the next MSI Claw will be sweet,Positive
Intel,For now nothing but they're in development of a handheld version and when that comes out handhelds are gonna be a lot better. Right now the only strix halo handheld is the gpd 5 and it's expensive the ultra 9 CPUs are going to be more affordable so we might see more options,Positive
Intel,"[MSai Prestige 14 Flip AI](https://www.bhphotovideo.com/c/product/1939343-REG/msi_prestige_14_flip_ai_d3mtg_001us_prestige_14_flip_ai.html) $1299, 358H, 32GB/1TB.",Neutral
Intel,"You must have no idea how having to deal with only the iGPU in a laptop simplifies things in terms of drivers on Linux, and especially compared to something like a 4050 which only has 6GB of VRAM.   Not to mention having no need to lug around a 300+ W power brick for a gaming laptop.",Negative
Intel,"> Intel needs to get pricing to RTX 5050 levels or below to be actually competitive.  Not really. They offer a product that fits in small form factor and gives very good battery life while also providing with graphics that can play pretty much any game on steam if you know how to navigate the options menu. If you are a student and need a device that is light/portable, has good battery life but also plays games it is a perfect fit.",Positive
Intel,the MSI Prestige 14 is like 1300 iirc,Neutral
Intel,Itâ€™s waaaaaay too early to compare prices. Give it 6 months time and manufacturing ramping up to see what the b390 laptops are actually priced at. Itâ€™s the same for any new shiny device,Neutral
Intel,"Do they? It's not marketed as a gaming laptop in the first place, it was never meant to compete with a 5070 Ti laptop.  We will also have to see prices in a few weeks once more models drop and see how X7 models pricing looks.",Negative
Intel,"Intel could maybe possibily drop pricesâ€¦but they donâ€™t have to. These new devices are targeted for people who dont necessarily care about perf/$. Students, office, devs, travelers, creators   â€œDoes it last all day, is it decent and not sound like a jet?â€  And theyâ€™ll pay extra for that. Its basically M series   But at least with apple the laptops are made to last...but Intel comptiability is advantagous & people are used to windows.",Neutral
Intel,That's a good price for a Helios you linked... don't expect the 2026 refresh of it to be priced the same when it replaces that model in a few months.   XPS 14 *is* very expensive. But that's always been the case for the XPS. They've always been expensive given their performance level. But you do get some of the best build quality available on a Windows machine in exchange.,Positive
Intel,"This is just how the Windows laptop market is. MSRP on new laptops are high, while last gen are on sale, it's always like this I'm guessing you forget that AMD once marketed Mendocino as being in up to $700 laptops.. B390 laptops will start at around $1100, but I expect that to decrease after companies get their premium lineups out and then do more budget models.  Like you can find Lunar Lake for $500-$600 new these days if you wait for sales and aren't picky about other aspects.  Anyways, yes you can get a stronger GPU laptop for not much more, but those dGPU laptops will eat through battery like no other, so I wouldn't even consider them a direct competition.",Neutral
Intel,People aren't buying these for price alone.,Neutral
Intel,"I saw this yesterday as well... The edge is dead on arrival at these prices. At those prices, I'd rather get HP zbook with strix halo.",Negative
Intel,"It means less of the fixed function units in the render slice, which IIRC is rasterisers and ROPs. Compared to 3x4 it'll be less performant, but also smaller and less power hungry. More generally the ratio of compute to fixed function depends on the complexity of the shading - coarsely, low settings at high resolution would prefer more fixed function, high settings at lower resolution prefer more compute",Neutral
Intel,"It pretty much matches 60w version of 4050 which is good result for an iGPU, it gets beaten handily by 90w but considering the form factor of devices B390 can be used in, the most relevant comparison is to the 60 and 30w version.",Positive
Intel,"It depends on the TDP chosen, as we see in other reviews as at around 35W it's even and under that Strix Halo chokes itself. No point putting Strix Halo in most laptops or handhelds at its cost and power curve. Desktop replacements/workstation, absolutely but if you want to play games on battery you might as well just use PTL.",Neutral
Intel,What's that supposed to prove? Obviously a chip with way more transistors is going to perform better.,Neutral
Intel,"That's significantly better pricing but by a 65w charger suggests, its a lower-powered X7 chip. Not the full power used in the XPS 14, which comes with 100w charger  Probably 25w tdp. Instead of 45 tdp.",Neutral
Intel,"To be completely fair: 4050 laptops don't use 300W power bricks. It's a 50W GPU typically, I think the very highest power limit I have seen for one of those is 65W.  It's fair criticism though, you can absolutely squeeze this type of GPU into most ultrabooks if desired though and a 50 tier chip used to be a common inclusion in ultrabook machines with reasonable power requirements.",Neutral
Intel,Why do people think the G14 is some chonky laptop? It's similar to a MacBook Pro is terms of weight and size.  And it has all day battery life as well.,Neutral
Intel,"Different classes of machines each putting their budgets into different things. XPS 14 is basically the most expensive Windows Thin and Light, but it's also *the* standard (on Windows). That budget is going into materials and build quality. You'll always be able to find more performance for your dollar if you're willing to get a thicker, heavier laptop with a plastic chassis",Neutral
Intel,Its need to drop to like $1000 to be competitive with rtx 5050,Neutral
Intel,">These new devices are targeted for people who dont necessarily care about perf/$. Students,  Ah students, famously wealthy and like to splash their cash ðŸ˜€ /s",Neutral
Intel,The G14 pretty much lasts all day without sounding like a jet,Neutral
Intel,"> B390 laptops will start at around $1100, but I expect that to decrease after companies get their premium lineups out and then do more budget models.  Not sure how many budget models with B390 will be there, and price might as well go up (for basically every laptop) due to RAM and SSD becoming significantly more expensive over the year.",Neutral
Intel,Thereâ€™s a 1300 MSI model. The other models pricing is likely because theyâ€™re extra premium laptops that OEMs typically ship new chips in first to jack up prices,Neutral
Intel,"It does not lol LMAO.   It will get no where close to a 60w 4050, with its puny 12 low powered xe3 cores, the 8060s with its massive gpu die and high tdp is still 13% slower than a 4060 laptop in 20+ game average tested by Jarrodâ€™s tech.    Watch when the real gaming benchmarks come, itâ€™s good for an iGPU but no where close to a 4050.",Negative
Intel,Also looking at Geekerwan's testing I would be veeeery interested in seeing how this thing does in a handheld with like 15w for the full SoC. The numbers they were getting at 10w on the GPU were kind of insane.,Positive
Intel,"XPS 14 is likely using the 100W charger for faster charging times, not to accommodate higher TDPs.",Neutral
Intel,"Ptl doesn't need more than 45w at most, perf gains after 30w are low. The difference is just core count, GPU is the same. I'd argue more cores for a regular person doesn't matter much.",Neutral
Intel,"Probably, but that's what PTL is specified at. 25W TDP and 65-80W power cap. The B390 that everyone wants out of these should perform basically the same here. You don't need a 388H to have that GPU. One thing I'll admit I didn't notice before, and that may hurt it slightly, is that the RAM is running at 8533 instead of the full 9600mt/s.",Neutral
Intel,No that seems to be just about enough power considering that the full power draw of a CES display unit used to test games by reviewers drew 60 watts.,Neutral
Intel,"65W seems right, they noted 60W total system draw when testing it in games at CES on one machine.   The X9 only seems to have +100MHz clock speed over the X7, everything else seems the same.",Neutral
Intel,Funny thing is a lot of laptops now come with power bricks much stronger than the laptop actually needs and this is because its used for fast charging.,Neutral
Intel,"What will you do when you run out of 6GB VRAM though? Not to mention that when gaming, a laptop with it will typically have to dissipate twice as much power as Panther Lake.  Either way, the 300 W power brick comes with the 5070 Ti Laptops that the OP is comparing against.",Neutral
Intel,"Well that thing is also expensive, only a bit less than the Dell XPS. We are talking about devices like the MSI Prestige that is like $1300.",Negative
Intel,"It definitely doesnâ€™t have all day battery life, and I doubt the PTL+dGPU model wonâ€™t have drawbacks the normal PTL models donâ€™t in battery life",Negative
Intel,Walk into an office or university and see how many people pay $1400+ for gtx 1050 perf.   Not everyone wants the performance if they can get other things.,Negative
Intel,So you want it to be sold for 400 dollars?,Neutral
Intel,"You're comparing an iGPU to a dGPU. These are in completely different categories and they do not compete directly with each other. These devices are literally in different classes and are aimed at different customers.  Panther Lake can be paired with a dGPU too, but for anyone who does not want that, this iGPU is simply phenomenal.",Neutral
Intel,How is battery life on those ~$1k 5050 laptops and how much do they weight?,Neutral
Intel,"Students are extremely likely to make poor financial decisions, yes. Theres a reason so many predatory loan agencies have offices on campuses.",Negative
Intel,"Depends on the college. I find my university to be basically just that, though itâ€™s typically less students being strapped and more parents being strapped with cash",Neutral
Intel,Dude go to uni or office and see the laptops people using. G14 is not it. Too big and fat,Negative
Intel,What are you on about? there are gaming benchmarks in that review... difference between B390 and 4050 60w is 9%,Negative
Intel,The real gaming benchmarks are saying exactly this: that itâ€™s only slightly behind a 60 watt 4050,Neutral
Intel,The 8060s is much slower than this iGPU.,Negative
Intel,"The G14 is 1.57 KG and a 1.59 \~ 1.83 cm  Are you like studying with kids?  For reference, the MacBook Pro 16 is 2.14 KG and 1.68 cm thick and Macbook Pro 14 is 1.55-1.62 KG and 1.55 cm thick",Neutral
Intel,"Guy did an actual test.   https://youtu.be/jrygnUnBRNI  Skip to 12:40  Performs like a full wattage 3050, LIKE I SAID BEFORE. Or a heavily gimped 30w 4050, but anything remotely close to a full wattage 4050 it is majorly behind.",Neutral
Intel,"The 8060s is MUCH FASTER than the b390 lol, what are you on about, some people are so confident in being wrong.",Negative
Intel,"Whatever you're right, Intel should drop pantherlake to 1k. G14 is a slim & sleek design. Honestly dont even know why its not more widly used in offices & univerties",Neutral
Intel,"B390 laptops will start at around $1100, but I expect that to decrease after companies get their premium lineups out and then do more budget models.  Can you give me a link (review will be fine) to ~3lb/sub 1.5kg laptop with full, +100W 4050 that performs on par with desktop 3060?",Neutral
Intel,">Â Intel should drop pantherlake to 1k.  Intel isn't making the laptops, they're making the chips.  OEMs have decided to debut them in their premium, thin and light flag ships + a price increase from RAM shortage",Neutral
Intel,"4050 is 3 years old now, thereâ€™s not many laptops with that gpu anymore on sale.   But the 4050 at max wattage was only around 10% slower  than a 3060 12gb desktop gpu, which is also reflected in their benchmark scores.   Theres now Lenovoâ€™s yoga pro 9i with a full wattage 5050, which is even faster than the 4050 and performs slightly slower than a 4060 desktop, itâ€™s a thin and light premium laptop lol, is light years faster than a b390 iGPU.",Neutral
Intel,It makes sense to debut in premium models for oems. Cant complain if there's consumers willing to buy them.,Positive
Intel,"> Theres now Lenovoâ€™s yoga pro 9i with a full wattage 5050 [...] itâ€™s a thin and light premium laptop lol  In what world is 4.5lbs light compared to 2.5-3lbs laptops with PTL? That's not even including power brick, which adds at least 1lb.  You could've chosen something like ASUS Tuf A14, but in most cases battery life will be significantly worse, despite bigger battery. Oh, and it will be loud under load.  It's also just under $2k now, so pretty big difference.  It might be a surprise for you, but what many people want from those igpus is the most performance at certain form factor while at the same time being efficient enough to last whole day (or like 7-8 hours) not having to go to every battery saving setting possible.",Neutral
Intel,"it's very cool how optimized that game will be i think, especially for 2026 with all the components shortages",Positive
Intel,Every gaming dev should target the B390 as the 1080p 60fps on medium/low tbh,Neutral
Intel,It seems odd that the Arc B390 was listed as the minimum required IGPU when the much weaker discrete Arc A380 is also on there. I'm sure most of the last generation IGPUs like the Radeon 880M or 890M are also powerful enough (considering they are faster than the Arc A380).  We've always known that the Forza Horizon games are very well optimized and are able to run on IGPUs just fine. Keep in mind that Forza Horizon 5 runs just fine on the Vega 3 IGPU in the 7 year old AMD Athlon 3000G.  The article is presenting the trivial fact that the B390 is listed as the minimum spec for the upcoming Forza Horizon 6 as somehow being a huge win for Intel. That's not very good journalism. It was going to run on IGPUs regardless of whether or not the B390 existed.,Neutral
Intel,Wonder how many wafer starts per month Fab 52 is up to now. Seems 18A parts are going to sell well and they have several more coming. Hope they can keep up.,Positive
Intel,"Pricing is not one of those ""victories""",Negative
Intel,"Unfortunately it's likely the B390 will be priced closer to Strix Halo than to Strix Point. Which is awkward since Intel only compares it to Strix Point if their presentations, not to Strix Halo.",Negative
Intel,Any game that has to run on a Series S will consequently have very low minimum system requirements.,Negative
Intel,Low minimum system requirements were never a guarantee that a game would perform decently. Especially when they don't even list the resolution and framerate they're targeting.,Negative
Intel,"Gives me hope that the Fable reboot will be well optimized. Just hoping playground games nails the story, gameplay and charm that we love with the series.",Positive
Intel,Do you all forget how raw Forza Horizon 5 seemed when it came out despite having relatively low system requirements? Low system requirements != good optimisation.,Neutral
Intel,"except you, unreal engine",Negative
Intel,"Yeah, it feels a bit like marketing and there have been a few of those.  Right now pretty much any computer with the X9 or X7 is expensive. You can find 5050 laptops for the same price. This chipset isnâ€™t going to do that well unless it can be found at a decent price.   Also buyers should be careful because not every laptop presented has the power and thermals set to permit full power sustained boosting at the wattages tested in the reviews.   Those laptops should get cheaper and so on of course. Right now we donâ€™t know. A Dell XPS costs more than a new mid-range MacBook Pro though, that is steep.",Negative
Intel,"Sometimes even big developers put surprisingly little work into assessing system requirements. Assassin's Creed Unity lists the GTX 680 as the minimum spec GPU and the GTX 780 (same architecture, more cores) as the recommended GPU.",Neutral
Intel,"A380 is \~140% raster performance of 890M based on Steel Nomad scores, doesn't seem faster than 890M at least at the wattages those are ran at",Negative
Intel,"tbf the base requirement for Microsoft is probably the Series S, a case the B390 is probably competitive with.",Neutral
Intel,"At the same time, it seemed to run at 30fps on the series X. So Iâ€™ll assume itâ€™ll be pretty CPU heavy.",Neutral
Intel,UE5 is the ultimate benchmark for this GPU.,Positive
Intel,"> You can find 5050 laptops for the same price.   For now, I wouldn't hold on and wait for better prices. Panther Lake laptops are being priced in the post RAM hike world. Older laptops are still floating around and being priced of DDR prices from 6 months ago.  If that 5050 laptop launched today, it would have to deal with $100+ dollars in extra manufacturing cost.  Also the initial launch models for new Intel CPUs always come at a premium. Budget models will come and also prices will be slashed from launch prices. Something that has already happened with older generations.",Neutral
Intel,Shouldn't the base line be the new Xbox handheld?,Neutral
Intel,"If you're talking about the ROG Ally, then no.",Neutral
Intel,"No, I'm talking about the Xbox Ally X.",Neutral
Intel,"Okay, so same thing. No, that is not Microsoft's baseline.",Neutral
Intel,"Why not? Microsoft announced it like it's an official console, shouldn't their first party studios support it then?",Neutral
Intel,"Probably two main reasons off the top of my head: the Xbox Ally released quite late in this console cycle and it's very weak. There already exists a large library of games that would not be playable and Microsoft suddenly (drastically) lowering the minimum target would be messy for devs. Even the Series S can barely do raytracing effects, for example. [Microsoft maintains a compatibility list](https://www.xbox.com/en-US/handhelds/handheld-compatibility) much like Valve with the Steam Deck.  Maybe things change with the next gen if Microsoft brings out a first party handheld, but for now it's just a bonus if runs on the Ally.",Negative
Intel,"What purpose is going to be achieved by supporting superficial gimmicks like ray tracing? Four generations of NVidia, three generations of AMD in, it's still incredibly difficult to find a game where the ray tracing is visible without a side-by-side screenshot comparison AND where it doesn't make the game look worse. And forcing that setting to ""on"" with certain presets doesn't exactly fix that in any way. Sure, I can continue to waste power and processing cycles on it, but it doesn't change how I still have yet to find enough games to tick BOTH of those boxes to run out of fingers on the two hands. Even after padding out the list with Quake 2 and crap Minecraft variant.",Negative
Intel,">Both Arc Pro B70 and Pro B65 are based on the BMG-G31 GPU, which is now confirmed. The memory configuration is also the same. Both cards are said to feature 32GB of GDDR6 on a 256-bit bus. The main difference is GPU core configuration. [...]  >Based on conversations we have had, it appears Intel has put the gaming variant on hold, possibly to see how the memory market develops. This does not look promising for anyone expecting a near-term launch. The longer the delay, the less sense a release makes.",Neutral
Intel,"Another day, another exclusive BMG-G31 leakâ€¦",Neutral
Intel,"Hello PorchettaM! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
Intel,Hoenstly B770 with Xe2 at this point makes no sense. Rather if they'd do a Xe3P dGPU release late 2027 especially if memory prices collapse.,Negative
Intel,I wonder how different Xe3P is to Xe3. Xe3P could be further along than we expect.,Neutral
Intel,Rumour suggests Xe3P has 20-25% architecture improvement over Xe3.,Neutral
Intel,I mean in terms of release.,Neutral
Intel,"that amt of hair in a clean room, steve should wear a hooded rain coat lol.",Neutral
Intel,I thought that was Denis lol,Neutral
Intel,"Yeah this is a really surprisingly open factory tour, at least compared to when Sapphire took Linus and Alex along. It feels unprecedented to see this much access and insight, but that's the goodwill nurtured by Steve paying off in spades. The lament about AMD and Nvidia ditching the sub-250 side is real, so having Arc actually be a usable option down here is going to be significant later on.",Positive
Intel,"Pretty good video with a lot of detail I haven't seen in previous factory tours. I probably still won't use an Intel GPU for gaming, but for a media server it's probably sufficient.  Side note: It's funny how whenever a GN video gets posted, the same cast of characters comes out and writes essays criticizing the video, apparently without watching it. I guess that's what it means to ""make it"".",Positive
Intel,"**GN:** NVIDIA and AMD abandoned this segment!  #Reality:  **B580:** $249 USD  **9060 XT 8GB:** $299 USD  **9060 non-XT:** $259 USD  **5060:** $299 USD  **5050:** $249 USD  I wouldn't say this is abandoned. I will say though the actual factory tour is cool, great content. But a dumb headline/title for the video.",Negative
Intel,"Amazing video, GN is so good with content like this",Positive
Intel,"rtx 5050 149 mmÂ² 128bit has similar performance to B580 272 mmÂ² 192bit. Selling for same msrp, winning by not ""trying"". Love how 5050 is actually at msrp now cheapest b580 is $349+  ""intel's gpu division seems like the only place in tech right now where the customers arent getting shafted these days""  People just want their Nvidia gpus cheaper  Nvidia crashouts making people hype an even worse product at current prices lol  [https://imgur.com/a/8iRI87Q](https://imgur.com/a/8iRI87Q)",Positive
Intel,"Love the Sparkle heatsink aesthetic, just wish there were some higher end card offerings from them instead of just Intel's lower midrange GPUs.",Positive
Intel,He probably just single handedly killed 6 wafers worth of intel GPUs.,Negative
Intel,AKA 'NVIDIA and AMD are going where the real money is.',Neutral
Intel,Finally a video that isnâ€™t â€œAI badâ€ or â€œcompany X badâ€,Negative
Intel,"Woah, a GN video that is actually interesting and informative for once instead of just ranting about the fact hardware companies exist to make money, not please gamers.",Positive
Intel,That hat is so useful,Positive
Intel,Making them isn't important selling them is.  The reality is that this segment doesn't actually exist it has no buyers in it.  Seems intel is truly doomed trying to win segments that if they even exist aren't big enough to pay back their R&D even if the dominate them.,Negative
Intel,"To be fair this is not a clean room, just SMT assembly. Basically, soldering components. A lose hair might be a bit of a problem (kind of like in any factory), but his hair is tied and doesn't seem to be an issue.  At an actual clean room (where the actual silicon is processed and etched), the standards can become very crazy. Some parts of it aren't even accessible to humans, just automated lines to avoid contamination.",Neutral
Intel,"Gaming Jesus could walk on wafers without corrupting a single tile, His body is that pure.",Positive
Intel,"same thought, just feels disrespectful",Negative
Intel,"He desperately needs to learn how to take care of his hair. I have no idea why nerds think a dry, frizzy mess of hair is some kind of enviable quality.   I feel like I'm walking into friday night magic every time he pops up.",Negative
Intel,"Intel hired him on the spot when they saw the ""Live, Laugh, Liao"" sign",Neutral
Intel,"who knew he can into GPU manufacturing? I thought he was a video editor and first real ""why are you employed"" guy on LTT.",Neutral
Intel,I'm pretty sure Denis has neither long hair nor beard. Though to be fair I haven't seen him recently.,Neutral
Intel,"Itâ€™s crazy. I think Steve and GN are doing the lords work with their nonstop, accurate coverage of the absolute shit state of the computer component markets and the megacorps that perpetuate it. And their seemingly endless support and advocacy for *consumers*.   But then I come in this sub and see people are actuallyâ€¦ against this? I donâ€™t understand it. Probably the same mfs that bought MKBHDâ€™s wallpaper app lmfao",Negative
Intel,"Wasn't that the B310? That was supposed to be the $100 bracket. To be fair that's an almost useless tier nowadays because iGPUs are capable of similar performance or even outperforming the cards in those brackets. Like the GT710 make no sense nowadays (their last attempt was what, the GeForce GTX 1630?), even though they sold like hotcakes for offices and for people who just wanted HDMI outs.",Negative
Intel,"They're talking about the A310 and A380, of which Nvidia doesn't have anything made in this decade to compete with and AMD has the 6400 that came out 5 years ago.  The only cards with modern features in that price segment that consumers can directly buy are the A310 and A380.",Neutral
Intel,He(Lucas) stated $100 was the market that was abandoned.  10:37  > Steve: So why still making A310?  > Lucas: Because what's the competitor have? Nvidia? like... GT710? GT1030? (laughs) No way. So literally Nvidia AMD already give up the segment of this like... $100 price card.,Neutral
Intel,This guy was talking about the A310 which is a $100 GPU. Basically said that the only other options at that price bracket are either a GT 710 or a GT 1030. And from AMD you can still get an old RX 550. The A310 may be slow but it beats those two gpu's by a mile.,Neutral
Intel,> 9060 non-XT: $259 USD >  >   LOL. Good luck finding it. It's OEM exclusive,Positive
Intel,The title is a literal quote from Lucas,Neutral
Intel,The title is in quotes. That is from Sparkle.,Neutral
Intel,Now do SR-IOV and 16GB RAM for under $400.,Neutral
Intel,B580 has 12gb of vram though,Neutral
Intel,"Sad that all of those are 8gb cards. Even if comparable or faster than the B580 aside from that, the lack of vram makes them far inferior products imo.",Negative
Intel,I just wish all of those options were more compelling tbh. I think what Steve was trying to say was that AMD and Nvidia have just half assed that market segment at the expense of the consumer. All these being 8gb cards for $250-$300 is kinda ridiculous in 2026. Iâ€™ll take a b580 over a 9060xt 8gb or 5060 any day of the week.,Negative
Intel,Go to r/PCMasterrace and they will downvote you into oblivion for even MENTIONING the possibility of gaming on a 5060 let alone 5050 XD,Negative
Intel,The title is just playing the YouTube algorithm game. It's stupid but they have to do it.,Negative
Intel,"> Love how 5050 is actually at msrp now cheapest b580 is $349+  Just an FYI but B&H has the [Acer Nitro B580 for $249.99](https://www.bhphotovideo.com/c/product/1874395-REG/acer_dp_z4bww_p01_nitro_oc_arc_b580.html) and the [Intel Limited Edition model for $259.99](https://www.bhphotovideo.com/c/product/1869297-REG/intel_31p06hb0ba_arc_b580_limited_edition.html). So you can get B580 for MSRP, but for how long who knows.",Positive
Intel,"die area is not the only cost indicator. B580 actually uses N5 fab, which is likely cheaper than N4, used by 5050. In reality, B580 only has about ~15% more transistors and if we assume N5 is cheaper per transistor and N5 has higher yields (by being more mature) i'd say their die cost might be very similar.  While yes, it has wider memory, the chips are clocked lower, so they can buy slower bins, reducing per chip cost.   B580 has more power draw, which in turn costs more for power delivery and cooling.  All in all, AIB manufacturer likely has lower margin per card as it stands, so i wouldn't be surprised if intel is taking a lower margin on the gpu/gddr combo to get more market share.  Nvidia on the other hand optimized their cost REALLY well, as they have been doing GPUs for almost 30 years.",Neutral
Intel,"Nvidia is getting such good performance out of such a small die because they're the best. Simple as. They've been doing GPU's for decades. It's not unexpected that at this stage Intel needs to use a larger die to match the performance - it would be incredibly surprising if that wasn't the case.  But a small *part* of that die size advantage comes from that narrow 128bit bus, and *part* of B580's appeal is its wider bus and subsequently more VRAM.",Positive
Intel,"I see b580 for â‚¬ 260. That's VAT included. rtx5050 is similarly priced.     And i found $300 lot on US amazon.  Considering other post, maybe search better than 1 place or something.",Neutral
Intel,"Isn't the title pretty much ""AMD & NVidia bad""?",Negative
Intel,Although even then the thumbnail is framed negatively.   But I much prefer these to Steves endless negativity ragebait.,Negative
Intel,> finally a company that isnt bad   ftfy,Neutral
Intel,"GN makes videos like these all the time, you just aren't watching them.",Neutral
Intel,"Did you even watch the video? they are selling, and they are selling out, so much so that they want to ramp up production so they can push out more.",Neutral
Intel,I do not know if the numbering scheme from my workplace is common across the industry but the smt assembly would be in a class 5 or 6 clean room and the fabrication itself would be a 1 or 2 class clean room,Neutral
Intel,"I think it still matters to a certain point, thats why everyone in the factory is wearing a hat. The Factory boss decided to roll RNG dice and say *""Fck it, that small hat is fine, even tho wearing it is pointless now; I'll just pray nothing bad happen*"". lol  What hilarious is when you think about what going through uninformed factory-employee's head, after they saw some guy(Steve) walk-into the factory like that. Definitely a lot of ""WTF"" moment going through their mind lmao.",Neutral
Intel,"The factory boss told me not to bother tying my hair (""ä¸ç”¨ä¸ç”¨ä¸ç”¨, æ²¡äº‹å„¿æ²¡äº‹å„¿æ²¡äº‹å„¿. è¿™æ ·å¯ä»¥çš„"") when I started to put it under the hat... and after asking for a larger hat or hairnet.",Neutral
Intel,"> same thought, just feels disrespectful  It's a good thing you were there to personally witness the interaction so that we'd all know exactly how disrespectful Steve was being before holding everyone at gunpoint to force them to let him shoot the video without first fixing his hair.",Negative
Intel,Nothing really surprises me with regards to gamers nexus at this point.  Edit: Downvote me all youâ€™d like. Theyâ€™ve been leaning incredibly hard into the rage bait type content of late.,Negative
Intel,I'm sure getting beauty tips from random redditors who have never left the basement is of utmost importance to Steve.,Neutral
Intel,"So, pray tell, who declared you the holder of absolute truth in terms of hair? What authority do you hold that allows you to determine what other people should do with the hair on their body?",Neutral
Intel,The other guy.,Neutral
Intel,This sub is genuinely weird. They complain about PCMR when the level of discourse here is much worse and a lot more mean spirited.,Negative
Intel,"They are truly rage baiting drama mongers sadly. The fact that the causes they support happen to be semi legit and consumer friendly in nature does not take away from the fact that they are essentially drama and negativity for profit at this point, and often out of touch with reality. You can be positive, polite, and have reporting standards while still calling out shitty behavior and ripping bad practices to pieces.   Companies are not your friend. That includes GN. They stoke hardware enthusiast anger for their own gain. Personally i think the harm they do to the space/peoples mentality is farm more than the amount of good most (key word most, fire risks and stuff deserve prompt drama) of their coverage does.   Even this title takes a topic and very educational opportunity to provide actual hardware coverage and immediatly tryâ€™s to stoke negative furry about some aspect of the hardware industry. Its just non stop with them. I dont think its healthy for anyone to watch then honestly, which is sad as i used to enjoy their review/news. I hope for their sake they are not actually so perpetually angry and they are doing what they do to knowingly manipulate their audience for increased views/engagement. I cant imagine living life so constantly angry at every possible point over computer hardware, as much as i am saddened by the current state hardware and love gaming.   As tough as it is with rising prices and such and sad to think of what we could have instead, modern hardware, gaming, and such is in a nearly historic good state (realistic cost to perf is probably lowest in history other than brief periods such as the 30 series launch), and is a very cost effective hobby compared with other ones for the time you get out of it. Many great games launch all the time (even if big name traditional games have largely went to trash). They are easier to run with hardware (like the ARC gpu) being quite cheap and capable. People, like GN, need to temper their overexagerated frustration with a dose of real world perspective and objectivity.",Negative
Intel,"Might be just the thing for older machines and a GNU Linux (or BSD like) migration. Or as a pass through GPU to Jellyfin, Emby, or Plex for media transcoding. Edit: or Small form computing tied together with a iGPU enhancing game performance...",Neutral
Intel,yeah there is a reason the a310 cards they are making are 4 hdmi out.  Gotta know your market,Neutral
Intel,I assume those are being marketed to OEMs who make digital billboard systems or something. No idea why else you would want 4 HDMI ports on a card.,Neutral
Intel,"> Wasn't that the B310? That was supposed to be the $100 bracket.  It's the A310, which is Alchemist and it's pretty much dogwater for anything beyond being a 'display out' card. The claim that NVIDIA has abandoned that segment is stupid... They've had offerings in this segment for years, plus anyone smart will just go buy a used GPU, your money goes way further. For example, the GTX 1650 performs basically 10-15% better, has better drivers, better encoding and generally is better supported. It's older, but I mean Alchemist wasn't exactly impressive either when it released and pretty much Intel has moved onto Battlemage and Celestial driver optimisations instead.   Plus let's be real here I went and searched and I found only weird places tend sell the brand new A310, the only local computer shop I found selling it in Australia for instance is a big one which is good surprisingly, but they had it for $189 AUD, a total rip tbh. A used 1650 is like $100 AUD and a used 1650 SUPER is like $120 AUD. No reason to buy an A310 tbh, pocket the cash and move on. Or if you're really intent on spending around that much buying a used RTX 2060 for like $20 AUD more, so a total of $200-210 AUD is better. Then on the AMD side you have the RX 6400 which had an MSRP of $159 USD and it's again a solid 10-15% faster, but much better off buying a used 6500 XT or 6600. Neither company has abandoned the segment, they had offerings for years and the used market basically obliterated any point to buying a brand new card like this.  >  To be fair that's an almost useless tier nowadays because iGPUs are capable of outperforming the cards in those brackets.  Yep this too. Honestly, I mean it's cool they're showing how they make cards on this factory tour, but to be like ""NVIDIA and AMD abandoned this segment"" is stupid when it comes to the A310. Almost anything these days is better than an A310.  >  Like the GT710 make no sense nowadays (their last attempt was what, the GeForce GTX 1630?), even though they sold like hotcakes for offices and for people who just wanted HDMI outs.  GT710 hasn't made sense for like 8 years at least, even when it was relevant people laughed at it, but it did the job for 'display out' and such which was all that mattered. GTX 1630 was okay but it was supposed to be $149 USD MSRP and it came out for like $200 USD in most stores due to GPU shortage at the time, not much NVIDIA could really do about that.",Neutral
Intel,They haven't made anything because the market has moved on. Intel might be making these but are they selling them?,Neutral
Intel,"[Is it in reference to this moment in the video?](https://youtu.be/YwrUxG26ulk?t=648) If so, he doesn't say that as a literal quote, he says ""give up the segment"". Unless there's another quote somewhere else which I missed which may be possible or maybe it was edited out or cut from the video? I can't remember everything he said tbh but there was a lot of good information in this video and I think the title is better off without it. If it was called ""Intel Arc GPU Factory Tour with Sparkle"" I would have insta-clicked to watch anyways.",Neutral
Intel,You know what you're doing with the title... It's honestly unnecessary to use it on a factory tour video tbh.,Negative
Intel,Stop defending your clickbait.,Negative
Intel,do you wanna address this then? Its kinda cringe ignoring the rest of the post  >**GN:**Â NVIDIA and AMD abandoned this segment!     >**B580:**Â $249 USD  >**9060 XT 8GB:**Â $299 USD  >**9060 non-XT:**Â $259 USD  >**5060:**Â $299 USD  >**5050:**Â $249 USD  Why include that in the title then too?,Negative
Intel,"Obligatory ""lol stupid pcmr amirite"" comment.",Negative
Intel,"The RTX 50 and 40 series are using the TSMC 4N node which is a custom version of the N5 node for NVIDIA. But anyway the N5, N5P, N4, N4P, N4X are all 5 nm class node, so have around the same price for the wafer. And I wouldn't be suprised that NVIDIA is paying less for these considering the volume compared to Intel orders.",Neutral
Intel,Well their gpus are much more expensive than amd & nvidia who arent even trying. When they try Intel wouldnt even have a chance  Nvidia increasing their entry gpu volume  [https://videocardz.com/newz/nvidia-reportedly-shifts-rtx-50-supply-toward-rtx-5060-and-5060-ti-8gb-in-2026](https://videocardz.com/newz/nvidia-reportedly-shifts-rtx-50-supply-toward-rtx-5060-and-5060-ti-8gb-in-2026),Negative
Intel,Take a positive factory tour video. How can we spin it to make outrage?,Neutral
Intel,Yep,Positive
Intel,Baby steps.,Positive
Intel,Recently he's been making far more rants and less informative videos.,Negative
Intel,those number grades are an ISO standard (14644) so they are indeed common.,Neutral
Intel,Thanks Steve,Positive
Intel,But you still didn't to say hi to me at PAX West 2016 in front of the LEGO USS Missouri battleship...,Neutral
Intel,"makes sense, I coulda been more charitable in the way I said it",Neutral
Intel,"relax dude, steve already replied, no need to whiteknight",Neutral
Intel,"he replied in a comment to me to say that he was told to leave it alone, I guess assembly isn't as careful as the initial production is.",Negative
Intel,"Given the impeccable, spotless, damn near saint-like moral & ethical code of Steve & GN, and their recent consumer advocacy and stepping on some very powerful toes, your comment sounds an ***awful*** lot like an astroturfing smear campaign meant to breed sentiments against Steve & GN.",Neutral
Intel,Imagine defending the hair of a guy who looks like he judges anime conventions in his spare time.,Negative
Intel,"I get it, for those with old boxes. But intel has great transcoding according to self hosters, and the powr consumption is much better vs old i5 pairing with those dedicated cards.",Positive
Intel,day traders love having a zillion stock tickers running.  i'm sure there's more applications where a heap of monitors is useful.,Positive
Intel,A lot of digital displays make use of DP MST to avoid the use of home run cabling.,Neutral
Intel,The a310 and a380 are fantastical for a media server!,Positive
Intel,Your wasting a lot of words defending a company about to rerelease a 4 year old GPU (3060) because they canâ€™t get memory for the current model.,Negative
Intel,The A310 was released in 2022. Do your think Sparkle would still be producing them in 2025 if they didn't sell?,Neutral
Intel,"Sure it was paraphrased for the title, but that's just semantics.   AMD and Nvidia ""giving up"" vs. ""abandoning"" the segment mean the same thing either way, given Lucas' intention behind the statement.",Neutral
Intel,He is ignoring the post because the poster didn't watch the video and is spreading BS. The segment they are talking about is $100 cards.,Negative
Intel,"maybe the cost for the raw wafer, but that's not all TSMC will charge nvidia for. You also need to account for yields, which could be different depending on the type of node.",Neutral
Intel,"Lately there's been a lot of bad shit happening in the industry and a lot less good tech to talk about. Shocking, right?",Negative
Intel,Thanks you ðŸ˜Š,Positive
Intel,But then I won't earn my free toaster after the 11th white knight attempt.,Negative
Intel,"> Given the impeccable, spotless, damn near saint-like moral & ethical code of Steve & GN  You have to be joking, right?",Positive
Intel,Yeah. Iâ€™m definitely an astroturfing bot account. You got me. My profile certainly *reeks* of botting / astroturfing ðŸ˜‚,Neutral
Intel,This has to be sarcasm.,Negative
Intel,"Imagine being as shallow are you are while still posting on reddit behind an anonymous username.  Let's see how your hair looks, mate. You're giving off pure incel vibes here.",Negative
Intel,"You know I also talked about AMD right? Not just NVIDIA. Regardless, you think Intel isn't also going to have memory issues soon? They might just divert all memory they have to the SKUs that are selling.",Neutral
Intel,>  a literal quote from Lucas  Does not line up with  > paraphrased,Negative
Intel,Yields wouldn't meaningfully differ within the same family. Certainly not by enough to remotely cover for the die size difference.,Neutral
Intel,I'm starting to think that r/hardware is the circlejerk sub and I just haven't yet found the actual hardware sub that it's parodying,Neutral
Intel,Intel B570/580 already use GDDR6 which is what Nvidia is trying to achieve with the 3060 release. Intel presumably won't be effected.,Neutral
Intel,"...Yes, that's why I said it's a semantics issue.  The meaning is the same: The paraphrased quote isn't a statement made by GN like u/KARMAAACS implies.   What makes it worse is that Lucas said that in response to Steve's question about ~$100 A310 cards and why they're still producing them (adding that they see a healthy demand for them from their customers).   It's like he didn't watch the video and just reacted to the title.",Negative
Intel,"Solid product, nice foundation. Improve ST and intel will comfortably keep their mobile market",Positive
Intel,"I think the ideal would be to get to a point where the flagship ""mainstream"" iGPUs (-H series, for Intel) compete with Nvidia's contemporary x50 GPUs, and then have big iGPU chips (Strix Halo, NVL-AX?) to compete with x60+ level.",Neutral
Intel,"Strix halo is a commercial failure. Too expensive for any meaningful customer to adopt and have real mainstream products.Â    Intel couldn't care less about that, they just need to be better than 890M and the game is done.",Negative
Intel,Iâ€™d love to see its support outside of the approved games demo list. Intel has great hardware but their drivers and game support have always been the biggest question.  Whatâ€™s the point of hardware if you canâ€™t apply it to what you need.,Neutral
Intel,"If these chips end up cheap enough that they can replace the standard Intel CPU + 50/60 tier mobile Nvidia dGPU it will be very interesting.  I'm not sure they will be able to in the short term, Nvidia pricing on low end mobile dGPUs is very aggressive ($600 5050 laptops are the proof) but hopefully it isn't long before this type of powerful iGPU becomes a common thing.",Positive
Intel,"This is against a 50W TBP RTX 4050 Laptop (which should be more at ease around 90-100W)  Not saying it's bad, but you can't compare Laptop performances without including TDP configuration and behavior.",Neutral
Intel,"""taking on strix halo"" -> result 50% of strix halo performance, ok.",Neutral
Intel,"TWELVE efficiency cores?.... that's nuts.   Anywho, these results look good. Assuming CPU and battery life are comparable or better than Strix Point/Gorgon Point, Intel might have a nice little advantage.",Positive
Intel,Wtf is this article? Strix halo is another class product. Takes on strix halo being more than 50% slower?,Negative
Intel,"I'm sorry but nothing was more embarrassing than that guy from AMD the other day saying it doesn't matter because Strix Halo, a chip in so few devices that's an absolute behemoth, is still faster. Panther Lake is an absolute achievement for Intel. With the right drivers, they're going to have the perfect chip to forgo low end dGPUs.",Positive
Intel,I will need at die fast ultrabook with 12hrs+ battery  Its Not a gaming product,Negative
Intel,Website doesnâ€™t load with adblocker,Negative
Intel,"I'm hoping for a thin and light 16 inch laptop with Panther lake and a B390, as it'll be perfect for photo editing, as Adobe seems to prefer Intel over AMD graphics and a discrete GPU is overkill.",Positive
Intel,"Hello Balance-! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
Intel,I am more interested in next gen desktop APUs,Neutral
Intel,"Compared to my 890M based laptop, the 890M numbers here are about 15-20% lower than what I'm seeing at the same settings.  This is likely due to power targets?  Even if the uplift is just 60% instead of 80%, that's still an impressive achievement for the B390M.  It's a shame that AMD appears to have dropped the iGPU ball in 2026.  Relying on the Strix Halo is not an option here.  It's pretty much impossible to find a good laptops that use it.  The upcoming HX470, and still without FSR4, isn't going to close the apparent large gap.  It seems that AMD forgot to stay hungry and they'll end up losing whatever ground that they'd gained in the last few years.  Mind you, Intel is known to play pressure games with laptop makers too in order to limit AMD adoption, which just makes it even crazier that AMD isn't doing what's required to keep the pressure on.",Negative
Intel,"I think the B390 could be faster than even an RTX 5050 35W (As it could beat an RTX 4050 at 60W).       These thin and light laptops that Panther Lake is built for use way underpowered GPUs. Honestly, it makes sense why the Dell XPS 14 only has the B390 graphics. Before it used an RTX 4050, but it ran at just 30W of power.       Now that Integrated Graphics have beat the -50 Tier of GPUs I don't think we'll even see an RTX 6050 or RX 9050",Positive
Intel,"They've basically maxed out the 128-bit normal socket iGPU now.  For them to beat it they need more memory bandwidth - they can put in a bit more cache, but realistically they'll need a quad channel bus (or maybe they can wait for LPDDR6 at 14.4+).  They can probably have a bit more physical room in the next generation of sockets, but without more bandwidth it isn't *that* useful.",Neutral
Intel,"the 140v also got a 25% speed boost post launch, if something similar happens than this could be as good as a 5060 mobile... which is wild! I hope it dosen't cost as much as halo strix!",Positive
Intel,Needs a conroe vs fx62 moment. It doesn't look promising.,Negative
Intel,Why aren't they comparing the AMD 8060S in the current Strix Halo flagship to the Intel B390? Probably because it doesn't go intel's way... interesting.,Neutral
Intel,And yet maybe 5% of customers will buy this version because its absolutely irrelevant for them whether their laptop would have an Iris iGPU from 2014 or a 2500watt RTX 5090.,Negative
Intel,"Thats great. If you are nvidia making dedicated gpu, then better make something that is not shit. 4050 is a joke",Positive
Intel,"But how much does it cost? It mentions it having 16 cores so I'm guessing it's going to be overpriced if you don't need CPU performance, just like Strix Halo.",Negative
Intel,They need a 25% IPC increase to get back to the leading edge in CPU and honestly i don't see it with their current architecture. They need a new radical design   Edit: getting downvoted for what?. Currently Apple and QC have a very solid lead. Even ARM beats Intel and AMD in general CPU workloads and Intel/AMD have been very slow to update their uarch focusing on clock speed over efficiency and IPC,Negative
Intel,"AMD Ryzen AI Max+ 388 just dropped cheaper than the 395 with the same GPU, it will be cheaper than the panther lake.",Positive
Intel,"Depends on Intel's & amd power targets. I dont think its rly feesible for them to target cpu + gpu power usage, 100W combined at least?",Neutral
Intel,then we wouldnt have the 50 gpus anymore. The XX30 and XX40 GPUs died because of iGPUs competing with them.,Negative
Intel,> Too expensive for any meaningful customer to adopt and have real mainstream products.   So basically every decent APU ever made. Too expensive to the point it bumps into dGPU territory and not powerful enough to be a direct replacement.,Negative
Intel,> Strix halo is a commercial failure. Too expensive for any meaningful customer to adopt and have real mainstream products.Â  >  >   Story of AMD APUs.,Negative
Intel,"AMD aimed Strix Halo at AI users first and foremost, thinking those folks would pay the high premiums.   But of course anybody serious about AI would have an Nvidia GPU, and so many other AI users are still just using cloud-based services anyways.",Neutral
Intel,"AMD has always had lower supply compared to Intel and yet AMD client continues to grow. Strix Point at launch had little products (Asus being the only OEM per usual) and yet they still continue to grow, at a smaller scale relative to Intel. Strix Halo is still continuing to have designs made, it wouldn't be a 'failure' if we are still getting Strix Halo products at CES...  I wrote a [comment in a previous post](https://www.reddit.com/r/hardware/comments/1q7d67m/comment/nyhh23c/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) on the reality of the state of Intel and AMD in the mobile segment. Intel is really dependent on CCG, it is double in revenue to DCAI. They invest in what makes them money. Compared to AMD, client and DCAI is doing well, for client CPUs and GPUs are doing well, putting no pressure in mobile, in fact their strategy has remained the same in the past couple the years and even if marginally their % share is sufficient for them. Intel pushes a lot of supply for mobile, while AMD is smaller, it is all relative in the necessary investments they need to make in order to supply demand. Do I wish AMD stop stagnating in designs, yeah, RDNA3 needs to go, but these companies have motives in what they do.",Neutral
Intel,"We all saw it coming a mile away, when it came out in 2025 it was competing against discounted 4060 laptops as low as just $1000. Too little, too late, too expensive, dated on arrival with RDNA3.5, etc. But for some reason this sub and r / amd always have such a hard on at the concept of a ""big APU"" that in practice would never be economically sensible.",Negative
Intel,Arc 140T is already on par with the 890m for most tasks excluding games.,Neutral
Intel,Commercial failure indeed. Laptop with dGPUs at same price perform better. Laptops with solid CPU perf are much cheaper.,Neutral
Intel,AMD gave Strix Halo zero chance to compete by barely selling any of the lower end models. An 8 core with 32 CUs would be a great mini PC.,Negative
Intel,"I dunno Battlemage was a big step forward on driver compatibility and every month Intel improves all their Arc compatibility. I'd be honestly surprised if Xe3 was worse than their current offerings. I'm sure it still has shortcomings as all Intel GPUs will because they're simply starting fresh, but even my A750 is pretty good right now at playing anything I throw at it.  The only aspect Intel kind of messed up that annoys me is their video encoder, once it gets pegged to 100%, it absolutely tanks your performance on the capture to the point where it skips frames and lags. It never used to do that and the driver also used to include capture software, now they just offload it to people having to download OBS and removed the capture aspect of the driver. Kind of dumb when both NVIDIA and AMD include it as a driver option.",Negative
Intel,Driver support is better than ever and will continue to get better now that Intel has found its footing in the gaming GPU business (yes that includes igpus),Positive
Intel,"If TSMC does raise price on their node, Nvidia doesn't find another node for their lower-end bins and Intel can keep the price on their own node down low, we could see Nvidia simply slowly phasing out the -50 series like they used to do with the MX series.",Neutral
Intel,"The 4050 still has a sizeable memory bandwidth advantage, so it's still very surprising that the B390 comes so close.",Neutral
Intel,"oh damn, this should be a lot higher up! Most laptops have them clocked much higher so expecting 4050mobile performance is kinof a lie...",Negative
Intel,"I get the feeling everybody is still unsure where these PTL chips slot in to and what to compare these against actually. Once we get more info on pricing, power consumption, CPU performance etc. we will get some actually useful comparisons.",Neutral
Intel,I actually think they meant to say Strix Point in the headline there.,Neutral
Intel,"[HP ZBook Ultra G1a 14](https://www.notebookcheck.net/HP-ZBook-Ultra-G1a-14-review-Powerful-MacBook-Pro-alternative-for-work-and-game.994758.0.html) would've been a better test  Load average: 83.3W   Cyberpunk 2077 ultra \* 110.9W = 80.7fps  Baldur's gate 3: 99.4fps   B390 wattage?   If pantherlake is designed for battery, is it better if it loses performance?",Neutral
Intel,So how many sub 1000 dollar laptops we have with Strix Halo?,Neutral
Intel,It's definitely going to come down to pricing and availability,Neutral
Intel,The new MSI Prestige 16 looks nice.  They all seem to lack Thunderbolt 5 though.,Positive
Intel,"It seems the revived Dell XPS 16 will have the â€œB390â€ and no dGPU, as another option. LTTâ€™s video on it said Dell is quoting 27 hours of battery life in â€œgeneral tasksâ€ and 40 hours of video playback. Obviously remains to be seen how real those manufacturers claims are, but hereâ€™s hoping.",Neutral
Intel,"WÃ¼rde das Thinkpad X9 15p bevorzugen, hat einen SD-Karten Slot, super Lautsprecher und einen richtig groÃŸen Akku.",Neutral
Intel,"$1100 for a little MSI 13"" laptop with one. there are also quite a few CPU SKUs that have the B390.",Neutral
Intel,"Those 16 cores are 4 performance cores, 8 efficiency cores and 4 â€œLow Powerâ€ efficiency cores. This is only doubling the core count of Lunar Lake, by adding the two plain efficiency core clusters. Or keeping the same core count as ArrowLake mobileâ€™s 285H (not HX!), trading 2 performance cores for 2 â€œLow Powerâ€ efficiency cores.  Iâ€™m not 100% on this but I donâ€™t think Stryx Halo used AMDâ€™s C cores, so it basically had an entire 9950x attached to the iGPU.  Prices should be more normal, as this is more part of Intelâ€™s normal lineup.",Neutral
Intel,There's an Ultra 5 chip with the B370 (10 Xe cores instead of the 12). Shouldn't be too costly,Neutral
Intel,It's 16 cores but it's only comparable to Strix Point 12 cores and not Strix Halo.      The highest end Intel chip here only matches the number of P cores in the M5,Neutral
Intel,"I really don't think that is so important for mobile devices though.  All Intel needs to do is be ""good enough"" and the OEMs will use them in flagship models.",Neutral
Intel,I doubt anybody is going unseat Apple from the ST throne in the near future.,Negative
Intel,Well unified core is supposed to be happening in the next couple of gens. Frequencies also seem to have taken a hit on 18A but I'd expect that to improve with time as usual,Neutral
Intel,Not really. They just need to not completely bungle gaming and latency sensitive performance like with Arrow.,Neutral
Intel,"This is about mobile devices, and since a high performing IGPU is included, the question is no longer how well the CPU performs in a system with a 5090 (what most cpu benchmarks focus on) but how well this IGPU/CPU combination performs compared to other IGPU/CPU combinations. I am positive the CPU is not the limiting factor in this IGPU performance tier, so ""leading edge CPU performance"" is not really relevant.",Neutral
Intel,"Don't think it's completely absurd. Should get some efficiencies from less interconnect overhead and lower power memory, so not quite 1:1 with a dGPU. If we were to budget, say, 40W for the iGPU in gaming and 20W for the rest, should be perfectly in line with the higher end laptop SKUs.",Neutral
Intel,Intel Arrow Lake already uses 80W just on the CPU side in multicore,Neutral
Intel,"It would be viable if AMD released their own small PCs with it to cut the MSRP of products, but they aren't interested.",Neutral
Intel,And yet AMD managed it for the PS5... it's clearly possible.  Of course we don't know the cost breakdown there as far as PS5 pricing goes.,Neutral
Intel,They just need to make the next iteration cost less. Most of strix halo's issues were the sky high price.,Negative
Intel,"""Local LLM"" is such an incredibly niche thing I can't believe the tech nerd internet is so obsessed over it. Any real life business use case of AI is cloud based no question asked.",Neutral
Intel,well said,Positive
Intel,Too much listening to MLiD who has a boner for APUs,Negative
Intel,"Idk one can easily flip your statement. Panther lake coming in **2026** competing against continuing discounted 4050s prob less than 4060s. I don't dislike Panther Lake nor am I defending Strix Halo, but I wouldn't say your argument is a rather good one.",Neutral
Intel,https://m.youtube.com/watch?v=ymoiWv9BF7Q   It's already at least on par for reasonable power profiles unless you play stuck to the wall.,Neutral
Intel,"Huge step forward, I just wish the didnâ€™t struggle with older and brand new games. Itâ€™s a great card if you are willing to do troubleshooting and know computers but I wonâ€™t recommend them to family yet.",Positive
Intel,I hope they start supporting dx11 stuff. Thatâ€™s a ton of games.,Positive
Intel,Isn't TSMC planning to increase pricing on n2 by 20-30%,Neutral
Intel,Nvidia will find another cheap node to use. Samsung will gladly oblige,Positive
Intel,"153 GB/s vs 192 GB/s is not that ""sizeable""  And the comparison against ""HP OmniStudio X 32-c0077ng"" is weird, even in the linked test they have GPU-Z screenshot displaying 1375Mhz memory speed instead of 2000 Mhz on most other RTX 4050 Laptop Review.  I don't understand this comparison against an All-in-One, and I'll wait for more in depth reviews to draw some conclusion.",Negative
Intel,"PC World had power consumption tests under gaming loads. It pulled 60W through USBC with Cyberpunk, so probably 35-40W for the gpu. When they unplugged it, the benchmark numbers stayed the same. So it also pulls 60W on battery.  Unless the manufacturer actually configured the device to simultaneously pull energy from the cord and battery under full load.",Neutral
Intel,About as much as we have PTL laptops,Neutral
Intel,"TB5 isn't a big deal, although I don't like that they have a numpad keyboard, and usually MSI speakers are terrible.",Negative
Intel,But can't you get a laptop with a 5060-5070 at that price?,Neutral
Intel,"Damn, that's really good! it's pretty much macbook air pricing.",Positive
Intel,"> Iâ€™m not 100% on this but I donâ€™t think Stryx Halo used AMDâ€™s C cores, so it basically had an entire 9950x attached to the iGPU.  I have a Strix Halo.  What you wrote is exactly what it is.  It's essentially a 9950x (so all P-cores) with a fat iGPU attached, and with a 4 channel memory controller instead of 2-channel.",Neutral
Intel,"The biggest difference between the P and E cores is fMax. The larger the core count becomes, the lower the all core clocks become, the smaller the gap between P and E core performance becomes.   The IPC difference between the two is like ~10%  At a certain point along the wattage curve, given a certain number of cores, there will be a point where E core performance can potentially meet or exceed what you would've gotten has you had too many P cores.    Its also more than just trading 2 P cores for 2 lpE cores. The lpE cores in ARL-H were *so* weak, they were functionally useless. In practice, it'll be more like trading 2 P cores for 4 lpE cores  edit: to be more specific, In ARL-H, below 5W per core, E cores outperform P cores. If you have 16 cores and are running all core workloads, then at 60W, each core is receiving less than 4W.",Neutral
Intel,No it's firmly ahead of strix its right in between. Strix point uses 8 ecores too and it gets demolished in multithread benchmarks as expected,Neutral
Intel,"It affects their margins. The more competitive and better QC is, the less Intel can charge OEMs for their CPUs.     AMD made them lower margins for laptop chips because they weren't very competitive. If they want fat margins, they need to be the best",Neutral
Intel,Single Core is very important when Intel is doing these designs that lack P cores throughout. The cheapest X2 Elite has the same amount of P cores as the most expensive Panther Lake SKU,Neutral
Intel,"Qualcomm is already super close with Oryon V3...  Perf/Watt for that single thread isn't close I guess, but absolute performance is breathing down Apple's neck for sure.  Also, don't compare Geekbench scores on windows vs Linux/Apple/Android... Windows just does something negatively about it and the difference is 5-7% vs non-windows.",Neutral
Intel,>Well unified core is supposed to be happening in the next couple of gens.  I would be shocked if this has much to do with a large performance uplift. I imagine it would have to do more with rightsizing core area and power draw.,Negative
Intel,Chasing above 5Ghz is stupid on laptops. It only matters for desktops,Negative
Intel,You are overly focusing on gaming. I mean general CPU performance,Neutral
Intel,Rtx 5050 is 61% faster than B390. I doubt if they change the wattage configuration and stick to 60W they'll match it. Unless the 5050 is capped to more reasonable wattages like 60-80W. Plus the 60W budget for Intel/amd will be used for other compotents and the apu budget reduces.,Neutral
Intel,"I'm talking out of my knowledge base, but I think the switch from heat pipes to custom vapor chambers means we are less bottlenecked at power density / pulling heat from the chip and more constrained at what the radiator/fan system can push out of the system.",Neutral
Intel,"They announced a first party Strix Halo PC at CES, but it'll probably be really expensive.",Neutral
Intel,"> And yet AMD managed it for the PS5... it's clearly possible.  Well for two reasons:  1. Sony bankrolls the R&D of the APU and it's underlying architectures which allows AMD to make it for basically cost and have a low BOM on it. They didn't pay as much as they normally would for the R&D, tapeout, testing etc.  2. It's a console APU, it literally has to be cost effective to make sense, otherwise it becomes like Strix Halo and SONY goes out of business. Also most consoles are sold on launch for a small loss with SONY and Microsoft recouping those lost funds off game sales, online subscriptions and store revenue. Then over time they tend to shrink console APUs on newer nodes which makes it more power efficient and less expensive to produce as a smaller chip on a newer node typically has better yields, it also allows SONY or Microsoft to put in lower quality components like less heatpipes in a new revision or Slim console, for similar thermal headroom and save on BOM cost.   I mean there's a reason why they do not offer the PS5 APU as an off the shelf product, only the cutdown bad yields go onto being some cryptocurrency mining board or some Linux APU and with the performance being cut its usually worse value than buying off the shelf dGPU parts like a 5060 or something.  I don't know why you're seriously arguing that APUs for Desktop and Laptop PCs are a viable product. For one, they've never been viable, not once. Even Strix Halo which is honestly the best APU I've ever seen has been ruined by its high cost. Don't get me wrong, I like the idea of an APU, an all in one chip that does it all. But unless you're like Intel and you're willing to do a tile based design and or basically have a true chiplet where you can link lots of smaller dGPU tiles together it doesn't really work. You're just better off buying dedicated CPU and GPU parts for better price to performance. If you don't believe me, I can buy an [RTX 5070 Laptop right now for $1900 AUD](https://www.centrecom.com.au/msi-katana-15-hx-14xwgk-156-qhd-i7-16gb-ram-512gb-rtx-5070-gaming-laptop-black) and that will easily outperform Strix Halo which has less performance and typically costs over $4000 AUD... [Even a lowly 4060 laptop fairs better.](https://youtu.be/RycbWuyQHLY)  The only thing APUs excel in is this, if you want something relatively cheap but capable. i.e it can run a game at 30 FPS with medium settings at a low resolution. i.e something like Panther Lake or Apple's M series chips. But if you want true performance, just go out and buy an RTX X060 series laptop it's far better price to perf each generation.",Neutral
Intel,"What is possible? PS5 uses GDDR6 instead of DRAM. And consoles are heavily subsidized by digital purchases. I bet AMD makes good money on PS5 (and Xbox X/S), Sony & Microsoft just subsidize the shit out of it with their 30% cut from selling games. Even the Steam Deck is barely profitable for Valve. High-end APU is just a waste of sillicon.",Negative
Intel,Even their Ryzen 5 AI 340 laptop are too expensive and you can buy an older gen Ryzen 5 with Nvidia GPU laptop for same price or even lower with much better GPU performance.,Negative
Intel,Local AI (not just LLM) is universal on mobile and getting to be universal in corporate computers. You just dont see it. The background blurring in Teams meeting? 5x more battery efficient with AI. But its just going to be integrated into Teams and fire up if hardware supported without asking you.  >Any real life business use case of AI is cloud based no question asked.  All AI use cases at the place i work for is local due to confidentiality issues. We cannot and will never be able to use this on cloud. Unless the world completely flips its ideas about confidentiality i guess.,Neutral
Intel,"Panther Lake is a normal CPU, not some special ""big APU."" It doesn't make much sense to flip the argument the way you did.",Negative
Intel,"140T (Arrow Lake) isn't the same as 140v (Lunar Lake) though, the former is usually quite a bit weaker and inconsistent in games despite slaying all the synthetics.",Negative
Intel,"It is probably because the AIO was one of their most, if not the most recent RTX 4050 tested (March 17th 2025) which probably enabled them to compare in newer title like F1 25 in the article, as it has already been around for like 3 years while RTX 5050 was released last year and received more attention in its place overall. From their database, the next most recent thing with RTX 4050 they reviewed was the Yoga Pro 7 in January 2025 with a 60W RTX 4050 (45 watts + 15 watts Dynamic Boost), which scored 50.8fps in Cyberpunk 2077 at the same setting and thus a bit lower than the AIO, so I would say the AIO is at an okay spot for a RTX 4050 to be compared to this Arc B390.",Neutral
Intel,"> 153 GB/s vs 192 GB/s is not that ""sizeable""  25%? What's sizeable?",Neutral
Intel,"It would be easier to compare mobile parts if laptop OEMs didn't lock down their BIOS and EC registers, blocking anyone from actually tinkering with the (godawful) default configs for TDP, boost behaviours and fan curves on most common laptops  You can buy the bestest Intel Core Ultra 9 285h but if some engineer at HP thinks that 45Â°C idle is too warm it will either throttle to the point that you wish you were using the Nintendo DS browser or crank the fans to Mach 3...",Negative
Intel,had no idea Strix Halo is this popular.,Neutral
Intel,"the new Prestige 16 actually [doesnt use a numpad](https://www.notebookcheck.net/MSI-debuts-Prestige-16-AI-and-Prestige-16-Flip-AI-with-Panther-Lake-H-Core-Ultra-X9-388H-and-Arc-B390-graphics.1197009.0.html)!  and the flip version is especially intresting, they managed to tuck the stylus *under* the laptop with a slot that can also charge said stylus",Neutral
Intel,"Laptops with 5060 at sub- $1000 weren't launch event laptops at CES. They came later as fairly cost optimized, ""compromised"" laptops that cheaped out on most of the total laptop in order to fit that CPU/GPU in its budget.   PTL-X is PTL-H with a ~60mm GPU tile. A 4050 is a binned ~160mm chip. Edit: that *also* requires its own VRAM and cooling  Intel is also on record saying 18A cost structure is flat vs Intel 7. I imagine costs between PTL-X and RPL-H + dGPU are much more competitive than you think, with the only caveat being discounts on old excess inventory and not having to redesign a new laptop (although I imagine the RAM pricing increases makes the total price different between the two shrink even more)",Neutral
Intel,"5060 yes, but it's less power efficient",Negative
Intel,"5060 -5070 cannot be fitted into ultrabook or thin & light models. those item are power hungry and high temperature, need to fit it in bulky laptops which are bigger heatsink , more room space.",Negative
Intel,"technically, but it will be a shitbox in basically every other aspect (and stuck with 16/512)",Negative
Intel,i've been looking rn but have only seen those at $1400+,Neutral
Intel,"> It affects their margins. The more competitive and better QC is, the less Intel can charge OEMs for their CPUs.  Last year's leadership QC laptops had to be heavily discounted shortly after reaching market. Clearly there's more to it than IPC.",Neutral
Intel,"The X2 Elite *may* be an amazing CPU. But customers don't buy mobile CPUs. They buy full, complete laptops, and that includes all of WoA's issues. Customers have so far, by and large, mainly rejected WoA. The biggest demographic of people who research and care about strong CPU performance are people who'd also want to play games, and QC has yet to demonstrate that that's viable.",Negative
Intel,But this product has 4 P cores?,Neutral
Intel,Do we have 285H/HX370 scores on Linux for comparison?,Neutral
Intel,I was going to wait for this - but driver support comments basically said wait for it to mature.,Neutral
Intel,"it is presumably lead by the e core team that's doing a lot better so we'll see, but at the very least saving area from debloating p cores would allow a bit more cache that the cores would love.",Positive
Intel,Chasing 5GHz is only stupid if it costs more power than it'd save. The lower end panther lake SKUs clock their cores a lot lower compared to LNL so it's likely just a node thing,Negative
Intel,Apple and Qualcomm are both doing that right now though. It's cheaper than blowing up the area of the core to increase IPC.,Neutral
Intel,But for non -gaming tasks arrow beats zen5,Neutral
Intel,Gaming is the only segment where your previuos comment made sense though.  Everything else Intel is still leading edge.,Positive
Intel,"Yeah, I'm not talking about PTL. Clearly it's too far off. But clearly there's a lot of room left for Intel (and current AMD APUs) to catch up. Also worth noting that that 5050 is given 100W, which is particularly high for that chip. Gap obviously closes when the TDP is more reasonable.",Neutral
Intel,"it may not be this generation, but at the rate iGPU performance growing; pretty soon xx50 chips is no longer relevant. \*its not like Nvidia can make fat profit anyway.   Fyi, Nvidia has abandon their low profit margin xx30 line up, or Geforce MX series in laptop.",Negative
Intel,Nah. the price of Strix Halo is the cost of the PS5 itself. AMD has fat margins for laptops and desktops,Neutral
Intel,Laptops with dgpu always has poor battery life. Even tinkering with the best power optimizations. These ryzens have nearly double the real world battery life from my experience.,Negative
Intel,"Depends on what you consider to be â€œhigh end mobile gamingâ€, the laptop 4060 is currently the 2nd most popular gpu on steam, and thatâ€™s the level strix halo targeted",Positive
Intel,"What youâ€™re describing is just inference. Runs on a phone Soc. Minimal memory requirement. Like faceID on the original iPhone X over eight years ago. Strix halo provides no additional benefit over strix point or lunar lake. If there are business use cases that use outlook or Microsoft 365 or Teams, they are using cloud based copilot. Thatâ€™s the mainstream business use case at present.",Neutral
Intel,"The statement is directly comparable. 'Big APU' Strix Halo can literally be fit into a [handheld ](https://gpdstore.net/product/gpd-win-5/)and a [surface type tablet](https://www.ultrabookreview.com/71207-amd-strix-halo-asus-rog-flow-z13/). Regardless of the effective yields due to it's size, it is coming out another year later when compared to a 40 series gen, and a tier lower than the 4060. If you want to game, like many have argued with Strix Halo when it launched, just get a discounted RTX 40 dGPU laptop... Panther Lake has a great iGPU, don't get me wrong, but the argument isn't good.  A better one would be \~10-25W Panther Lake would be competitive than Strix Point/Halo and so on, not 'Strix Halo isn't economically sensible' because it's still on the market, with CES designs still being announced.  Some people in the sub think that if they aren't the ones the product is directed to (which is pretty much gamers), then they believe 'well it must've been a failure'.",Neutral
Intel,"Oh I'm blind lol, my bad.",Negative
Intel,Yeah I'm bewildered by this take that it's not sizeable.,Negative
Intel,Easily offset with a slightly bigger cache.,Neutral
Intel,"Don't worry, the engineer at HP also made sure you can never exceed 35W continuous power draw by giving it an undersized vrm and no vrm cooling",Neutral
Intel,"Oooo neat, close to perfect for me.",Positive
Intel,"> Intel is also on record saying 18A cost structure is flat vs Intel 7  The 12Xe GPU die is on N3E, not 18A. Though I still agree with the conclusion that PTL should still end up relatively affordable, and cheaper than an equivalent dGPU.",Neutral
Intel,"Power efficiency is a curve. There will exist points along that curve where the B390 is more efficient than the 5060.   Efficiency is more complicated than just ""perf/watt at specifically both chips maximum power draw""  edit: May have misunderstood your comment. Thought you were saying B390 was less efficient than a 5060",Neutral
Intel,Asus G14 would like a word.,Neutral
Intel,>(and stuck with 16/512)  Those typically have open ram and ssd slots. It's the premium thin models that have them soldered on.,Neutral
Intel,https://www.bestbuy.com/product/asus-tuf-gaming-a16-16-fhd-165hz-gaming-laptop-amd-ryzen-9-32gb-ram-nvidia-geforce-rtx-5070-1tb-ssd-jaegar-gray/JJGGLH8Y2Z  [Proof that the deal at least exists at the time of this comment](https://imgur.com/a/XYQm2fn),Neutral
Intel,"QC last year had a bad product.Â  It was competitive vs AMD and Intel but Qc was selling those for 50% less than Intel or AMD chips. OEMs at first decided to price these at Intel prices then it settled at Intel -100/200â‚¬   QC laptops still sold what QC and partners expected and OEMs are increasing new models for X2 (design wins went from 60 to 100+)   X2 has a 25% advantage vs Panther Lake and it will still be cheaper because QC is an underdog. If QC captures market share and reaches 10-15%, then Intel will start to sweat and then margins will be hit. I don't think QC gets anywhere near that till like 2028/2029. The laptop market is VERY slow to move. AMD had a better product for several generations and it only netted them +10%   While QC and Mediatek/Nvidia don't hit a bigger marketshare number. Intel and AMD won't need to lower prices",Negative
Intel,"[285H GB6 Windows \~2900](https://browser.geekbench.com/search?utf8=%E2%9C%93&q=core+285h+windows)   [285H GB6 Linux \~3050](https://browser.geekbench.com/search?utf8=%E2%9C%93&q=core+285h+linux)  [HX370 GB6 Windows \~3050](https://browser.geekbench.com/search?utf8=%E2%9C%93&q=ai+370+windows)   [HX370 GB6 Linux \~3000](https://browser.geekbench.com/search?utf8=%E2%9C%93&q=ai+370+linux)  I'm just eyeballing results on geekbench browser 1st page but surprised by the HX370 results. Intel is all over the place but that may make sense since Intel is actually found on tons of laptops compared to AMD shiny hunting experience.  There was one source i had found testing X Elite on Windows and WSL2 on the same machine that showed Geekbench performing higher on WSL2 than native on windows but it may have been a yt video. Perhaps i'm mistaken.  AFAIK , the Windows Tax is real for Geekbench. this particular search on HX370 showing otherwise is a fluke imo. You can search other chips too, like 285K 3350win vs 3500linux  Unfortunately, i cannot bother looking for more controlled setups that had the same exact setup with both Linux vs Windows compared to definitely prove this, but i have seen those in the past here and there.  EDIT:   I found a source that compares GB6 Windows vs Linux relatively recent   [AM5 W11 vs Linux Performance Comparison in GB3,5,6 - Ryzen AM5 - HWBOT Community Forums](https://community.hwbot.org/topic/236884-am5-w11-vs-linux-performance-comparison-in-gb356/)  The Windows tax is still real.  [Qualcomm Snapdragon X2 Elite Extreme X2E-96-100 Processor - Benchmarks and Specs - NotebookCheck.net Tech](https://www.notebookcheck.net/Qualcomm-Snapdragon-X2-Elite-Extreme-X2E-96-100-Processor-Benchmarks-and-Specs.1127282.0.html)  Idk what actual source notebookcheck used here, but if x2 Elite Extreme reaches 4080 in GB6 on windows then +4% for linux would be 4240... Whether that's comparable to Apple M5 or not i'm not gonna say more on the subject...       I'd say Qualcomm is gonna be within spitting distance to Apple... Sure SD2X Extreme is highest end unicorn SKU vs base M5, that's valid argument, but still... within 10% of Apple i consider within spitting distance.",Neutral
Intel,I hope somebody tests Panther Lake GB6 on both linux and windows.,Neutral
Intel,">Chasing 5GHz is only stupid if it costs more power than it'd save.Â   Chasing any GHz much above Vmin would cost more power than the performance it would bring, no?",Negative
Intel,"They are not. Like I said they are 25% behind Apple and Qualcomm in ST. Multicore the X2E can go up to 2x the performance of Arrow Lake and Panther Lake is just a refresh on 18A   Now there's more competitors.Â  They have 5 total. AMD, Nvidia, ARM, Qualcomm,Â  Apple",Neutral
Intel,3nm will give 6050 another 20%. Whatever changes amd/intel do at power limit needs to be impressive. Otherwise I still see cpu + gpu combo yielding better perf.   Not perf/W or maybe perf/$,Neutral
Intel,LPDDR6 coming hot with 50% bandwidth improvement...,Positive
Intel,"Obviuosly. all AI *usage* is inference. Inference requires plenty of memory btw, it all depends on the model you want to run.  No, that is not the business case use.",Neutral
Intel,"The Strix Halo was intended for local ai, the OpenAI OSS 120B fp4 model (or a 240B fp4 50% pruned like MiniMax 2.1) is run at 50 t/sec on a Strix Halo, or about 5 000 000 tokens day - 75$ if using Sonnet 4.5.  So in 20 days you get the money back (a 96GB RAM Strix Halo during 2024 has been sold for1480$ by a lot of OEMs and the 128 GB RAM - for 1600$-1700$), not to say you keep home your AI work",Neutral
Intel,"if only AMD released a 384 bit bus Strix Halo with support to LPDDR5X 10700 MT/s, that would double the bandwidth - from actual 260 GB/s to 520 GB/s, putting it in the M4 Max category, which Apple is selling at 4000$",Neutral
Intel,"They're completely different product classes. One is priced for mainstream and the other is decidedly not. One is purpose-built to go up against discrete GPUs, the other is not. That's why flipping that statement just doesn't work.",Negative
Intel,"Donâ€™t even get me started! My current HP laptop straight up doesnâ€™t support any type of fan control on Linuxâ€¦  So even if I throttle my CPU manually based on temps, the vrm WILL burn a hole in my desk during prolonged use  I even found the basic EC registers for fan speed, but there is some other magic register that keeps resetting them. And trying to find the magic register might involve frying the board if you hit a voltage-related EC",Negative
Intel,"ikr, im also heavily considering the Prestige 16 Flip atm (even tho I am an unhappy owner of a 8 year old MSI Thin...)",Negative
Intel,Not using LPDDR is part of what makes it a shitbox.,Negative
Intel,Screen is still dogshit,Negative
Intel,"It's not just Geekbench, Linux usually has higher performance",Neutral
Intel,"depends on the workload and the efficiency curve, but there is the race to sleep concept. Even assuming hanging around at low freq the voltage can sustain is always better power wise - which i don't think is true as you're dropping a lot of performance, you still have to power all the uncore around it  I saw someone run a couple tests on intel/amd for iirc a game server workload, and while intel peaked a lot higher from aggressive boosting, the amd cpu consumed more energy overall",Neutral
Intel,"Neither apple nor qualcomm are real competition in a sense that Apple has its own segregated market that does not crosscompete and qualcomm practically does not exist in segments Intel is in.  ARM is hurting them in servers, but not really relevant for a laptop discussion.",Negative
Intel,"> 3nm will give 6050 another 20%  But are Nvidia willing to use cutting edge nodes for their low end GPUs? If they don't move to N3 before Intel/AMD have an N2 GPU, a gap will remain. And of course LPDDR6 should be a big deal for bandwidth.   Obviously not treating this as a forgone conclusion, but doesn't seem like an unreasonable target for this part of the lineup.",Neutral
Intel,The only TRUE disable option on windows is to disable through bios for most laptops. Which becomes extremely tedious if you want to use the dGPU without constantly restarting.  I have never owned a laptop with a dGPU that didn't misbehave constantly and not fully idling.,Negative
Intel,"Plenty of ""daily use cases"" have very minimal hardware requirement, the original iPhone X FaceID ran on a device with 3GB ram and it was sufficient for FaceID purpose. And I don't know nor care your particular business use case, since you made zero specific clarifications I only had to bring up one mainstream example which is Microsoft 365 and its cloud based subscription based Copilot feature.",Neutral
Intel,Probably that's what gonna happen with medusa halo. On N2. It will actually match Apple M6 Max pricing.,Neutral
Intel,"I am not talking about product classes though? The original statement is trying to say that an **SoC can compete with dedicated iGPU** regardless if Strix Halo is bigger. They are trying to say that it was obvious it was **going to be a flop, when competing against a 4060 that at the time was being sold at a discount**. **Panther Lake is literally coming out another year later one tier below a 4060 and a gen old**.  Yes, they are different product classes, but Panther Lake SKUs that have 10-12 Xe3 cores will most definitely be >$1000 with laptops. ""Mainstream"" pricing is subjective in this class, unlike GPUs where there are 5060s and 5080s segments. At CES, there are surprisingly dGPUs still being paired with Panther Lake, heck, Strix Halo was designed purely for it's iGPU, even the engineers stand by this (PCIe slots are being released in miniPCs because that's what the market wants).  Also, this ""big APU"" argument is based on chiplets/tiles. Strix Halo isn't monolithic, same as Panther Lake. They both have the same design strategy that makes it economically viable to tape out in the first place.  I am not trying to say that STX-H is better than PTL, PTL was like the only thing I was looking forward to at CES, but this whole thread surrounding around how STX-H is a failure doesn't make sense at all.",Neutral
Intel,"I hadn't long bought a Zenbook S16, but if MSI can get a decent spec with the B390 under Â£2k then maybe.",Neutral
Intel,Their target audience is more likely to complain about upgradability.,Negative
Intel,New goalpost?,Neutral
Intel,"Race to sleep has value to a point. Does someone on battery want to, say, increase power consumption 4x to race to sleep 2x faster?",Neutral
Intel,> there is the race to sleep concept.  i hope we can excise this concept as soon as possible. It leads to worst design choices.,Negative
Intel,"I don't think amd ryzen will match M6 Max pricing (amd is selling them at 400$), as those miniPC are manufactured by a lot of noname companies, making a true competition  There are 37 such ryzen ai max 395+ products [https://www.techradar.com/pro/there-are-15-amd-ryzen-ai-max-395-mini-pcs-in-the-world-right-now-heres-where-you-can-buy-them](https://www.techradar.com/pro/there-are-15-amd-ryzen-ai-max-395-mini-pcs-in-the-world-right-now-heres-where-you-can-buy-them)  And there are also nvidia with their dgx project, Qualqom with their Snapgragon X Elite 2, a lot of RISC-V platforms like tenstorrent with 512 GB/s (but only 32 GB VRAM at 1399$), so even apple will need to double the bandwidth in their upcoming M5 pro/max in order to stay competitive with actual prices",Neutral
Intel,"I assume at least intel and amd do some research there for how much the cpu should boost if the oems don't, and also have to consider user impact from lower performance but I guess that's more fighting against windows getting slower.   Presumably with current nodes 5GHz is always beyond the point of being worth it but no reason that has to carry into future gens",Neutral
Intel,Medusa halo isnâ€™t strix halo if going by what you think it is going to be. It will be much bigger and on N2.,Neutral
Intel,Great.  Does this mean AMD will finaly stop pricing Strix Point as if it was made out of gold ?,Positive
Intel,"One of the biggest things the current AMD driven handhelds lack is a decent upscaling option, so getting native XeSS support on a fast GPU would be a HUGE performance boost.",Positive
Intel,"I think the LPE cores and them going at chiplets a second time after Meteor lake is paying off. This chip is more efficient than lunar lake, a chip that could do 0.62W idle lol.",Positive
Intel,"This is exciting. Hope some decently priced handhelds can drop, RAM prices notwithstanding.",Positive
Intel,am confused. this is battlemage too right? because its a B series. but its supposed to be all new. and the old gen was battlemage too on the 200V series. so what is going on here?. is this just a bigger GPU or is this Xe3 so that would be Celestial.,Neutral
Intel,brah they straight up claiming it's equivalent to a 4050 on stream >!(a 60W RTX 4050)!<,Neutral
Intel,"Even if that claim were overstated by 2x, would still be a colossal L for amd.",Negative
Intel,Xps is a huge seller for Dell and they are straight up using Panther Lake and XE3. They are exclusively going intel. Intel is 100% securing up there dominance in Labtops. In the process also taking business away from Nvidia.,Positive
Intel,I hesitate to trust Intel's charts. But I am interested if Intel will actually get companies to adopt panther lake for their handheld pc. They did not have much luck with lunar lake.,Negative
Intel,"Assuming intel also keeps those mobile CPUs a good price, this could be really good. Hopefully as well they add the B390 in their high power desktop CPUs, seeing a core ultra 5 with an iGPU like this would really mitigate the need for a dedicated GPU right away Mostly because iGPUs on other generations were bad, and only a select few Ryzen CPUs had the 890M. Budget systems could become much better for gaming on the low side for graphical intensive games",Positive
Intel,>Intel reference platform; Memory: 32GB LPDDR5 9600;  I wonder how much difference that makes and if we'll even see laptops with such RAM in this economy...,Positive
Intel,"I'd love to see benchmarks comparing it to lower end discrete GPUs (like 5050, B570, etc). Could be a boon for ultra low cost builds depending on what price point it lands at.",Positive
Intel,How many compute units does it have?,Neutral
Intel,XESS and native frame gen is going to make handhelds monsters with Panther Lake in them.,Neutral
Intel,I think people need to be ready for the fact that OEMs aren't going to use lpddr5x-9000,Neutral
Intel,"We'll see. Every year they claim they're faster, and every year they have been proven not to be",Neutral
Intel,NOTE: this might be because it has MFG (Multi-Frame-Generation).  We have to see reports to see if its true or not.,Neutral
Intel,"This ain't gonna matter. It's the sku with 50% more igpu cores compared to lunarlake, which already has an igpu that's larger than the hx 370, it's real expensive. Imagine a hx370 with 26cu instead of 16, that's the price range you're lookin at  Any system built with this is gonna need to run at extremely high mem speed to feed the really large igpu which in the current market with insane ram prices is gonna be priced out of most people's budget. Are ya prepared for a gaming handheld that costs north of $1500?  And since this is gonna compete against nvidia's entry level mobile gpus oems are gonna have to choose between nvidia and intel for the gaming brand on laptops. Amd learned this through the hard way that most oems would choose nvidia over a large igpu.",Negative
Intel,Haven't they been making similar claims for all their failed GPU's?,Negative
Intel,"I mean Intel has never fudged the numbers before when they were behind, or do something crazy like literally bribe people.... Oh wait.... Uh.... Oh.....   Jokes aside, with what the current and future state of the market looks like, people might have to get used to iGPU graphics.",Neutral
Intel,"To be fair it kind of is, the die size is huge, larger than an RTX 5070 die",Neutral
Intel,"Intel laptops were already better tbh, AMD had nothing to compete with Lunar Lake, and Arrow lake pretty much was better at high perf efficiency. Zen 6 better not be delayed or AMD will be buried under intel, qualcomm and apple all launching a real next gen shortly",Positive
Intel,"Nah, because it's an ""AI chip"" and AMD will market it as so. AI equals fancy even though the AI capability can't match a regular desktop computer for far less.  Intel is probably gonna strategically match AMD in price.",Neutral
Intel,"With how wide the memory bus is, how much RAM it requires, nah the price is going up.",Neutral
Intel,it has soldered ram ... so it's better then gold!,Positive
Intel,I guess that depends on Intel pricing too. Considering it's using both the latest TSMC and Intel foundries in one chip package. Not to mention the LPDDR5 9600.,Neutral
Intel,You mean OEMs.,Neutral
Intel,No?  People will still value AMD more ue to brand so Intel will have to rely on volume for revenue  For reference only yesterday on this sub we had people talking about Intel lacking efficiency in comparison in mobile space,Neutral
Intel,Crazy AMD haven't updated their iGPU to RDNA 4. I know they're probably waiting for UDNA but it would have been almost 3 years on the same architecture by the time we get the UDNA refresh next year (if they even bring it to their APUs right away). Sort of disappointing.,Negative
Intel,"tbf the most important issue is, few games implemented XeSS, just like AMD FSR.  And I think XeSS 3 being implemented in more games is a net positive for AMD GPU too.",Positive
Intel,"With everything happening around NVIDIAÂ´s price increases and AMDÂ´s lack of providing updates where it hurts, it **feels like** AI-Datacenters are more important right now for them (like the last 2 years).  But who can resent them as Intel had products that where not so much competitive that time.    Arrow lake (Desktop) at least closed on efficiency, but lacks a bit of gaming performance still, hopefully Nova Lake will be the step required to push more competition.   On GPU the same, AMD does not compete with NVIDIA in higher segments while NVIDIA is fairly comfortable with their setup and increases prices because they want to milk customers to increase their ridiculious margins (up to 70%) that they are used to from AI-Chips.   And now Intel also provides Multi-Frame generation, while a niche for me still, starting to compete with AMD and closes up to NVIDIA in terms of Software support, which they lacked the most and fixes a lot of problems.   Now let them release a B770 that is rumoured to be fairly mid/high range and we can hope for competition that actually learned from bad products recently and tries to make it better.",Neutral
Intel,"Handhelds is a tiny tiny market, basing your product stack around them would be monumentally stupid.",Negative
Intel,"It may not beat LNL in very low power envelopes (LNL was designed for ~10W, PTL for 15W+), but it's a much, much better baseline than what Intel's historically had in client. Even just extending vaguely LNL-tier efficiency across the stack is a very big deal. Looks like Intel finally has a respectable SoC architecture. Now just need to get the cores and such in shape.",Positive
Intel,"I mean the Xbox Ally X handheld is considered a $999 ""console"" so it sets the floor for what the Steam Deck and other handhelds would be priced at.",Neutral
Intel,"It's branded as a Battlemage for some reason, but the architecture is Xe3. It's much closer to Celestial than it is to Battlemage.",Neutral
Intel,"Battlemage is the brand name. The actual architecture of Lunar Lake is Xe2, same as desktop Battlemage, but they never explicitly called it Battlemage, only â€œArc Graphicsâ€.  What is meant to be desktop Celestial is Xe3P, but desktop Celestial is likely cancelled or significantly scaled back. Alchemist was a massive flop, and by the time the B580 came out to salvage Arcâ€™s reputation the axe had probably already swung.",Neutral
Intel,It's a mid-gen refresh of battlemage.,Neutral
Intel,"They claimed ""10% faster"" than 4050   https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.it%2Famd-is-done-v0-8op4m6l6bmbg1.jpeg%3Fwidth%3D1851%26format%3Dpjpg%26auto%3Dwebp%26s%3Df229e1ff0e364a6db90715de23ba799261ffe9e3",Neutral
Intel,APUs are always way worse at gaming than synthetics when compared to a DGPU due to memory bandwidth limitation and power sharing with the CPU among other things like cache set up etc.  when they compare them to GPUs its always synthetics unless you get benchmarks of games,Negative
Intel,"Where's the bandwidth coming from?   Reviewers were saying that the 890m was bandwidth starved, so how can this chip be neck and neck with a recent dgpu with multiple memory channels",Negative
Intel,60W is the laptop power draw. It looks like 30W for the 4050  this is the laptop they used for the comparison https://www.dell.com/en-us/shop/dell-laptops/dell-14-premium-laptop/spd/dell-da14250-laptop/useda14250hcto01#customization-anchor,Neutral
Intel,"At best, itâ€™s a 16% difference between a 100 watt and 60 watt RTX 4050 I believe, based on synthetic performance  Edit: Intel used a 30 watt 4050, this comment is incorrect",Neutral
Intel,What do you mean that a refreshed Strix Point canâ€™t compete with an updated architecture?,Neutral
Intel,"I got downvoted everytime I brought this up, but this is precisely why Nvidia wanted a deal to have an Nvidia iGPU tile on an Intel APU: Large iGPUs in thin and lights are going to get good enough over the next few years to make them the new entry-level graphics option for people. This directly threatens Nvidia's consumer laptop volume in the entry segment. Intel is claiming close to 4050 performance at this lower TDP, and that's certainly good enough for many to not have the tradeoffs of having a dGPU in their laptop.  If the new market is moving towards putting GPUs on the CPU package instead of discretely on the board, Nvidia doesn't want to place all of their hopes on WoA becoming better, and are hedging by doing both their own SoC *and* an x86 APU with Intel.  The XPS line dropping Nvidia discrete all together is proof of this. In these sub 70W total laptop power markets, a discrete GPU is just eats into the power budget too much.",Neutral
Intel,"In the ultraportables market (like XPS), integrated graphics just make so much sense (energy envelope; cooling system required; battery life; etc); and that's already substantial and before considering the cost of a NVIDIA mobile dGPU itself.  I don't understand why AMD decided to price Strix Point and Strix Halo so ridiculously -- it's their market for the taking.",Neutral
Intel,I think theyâ€™re trying to take away business from Qualcomm/arm on windows before it takes off,Neutral
Intel,"Lunar Lake was a expensive product which didn't make sense in handhelds, Intel just didn't have anything else so they slapped that on the MSI Claw. Now the options should be much better considering they are selling a lower core Xe3 version for cheap too",Negative
Intel,"I'm just curious how they handle the need for such high speed RAM on desktop though? I guess this is an application where CAMM2 will be required, I don't think DDR5-9600+ is possible without it and this is presumably pretty key to the performance.",Neutral
Intel,"It certainly would make a huge difference because iGPUs are very memory bandwidth bound; and as the name suggests, LPDDR5 9600 has literally twice the bandwidth of the JEDEC standard 4800.  Unfortunately I doubt we'll see reasonably priced laptops with LPDDR5 9600 -- even as an add-on option. I've been eyeing Dells and Lenovos, and basically all SKUs that previously had 6000 are getting substituted with 4800; and many SKUs that were 2x16GB are now 1x16GB; yes **single channel**.... they charge you extra if you want 2x8GB.",Neutral
Intel,"It has 12 Xe3 cores. Intel doesn't use the term Compute Units, AMD does.",Neutral
Intel,X9 and X7 have 12 Xe cores and the best Ultra 5 has 10 Xe cores,Positive
Intel,??? lunar lake has already shown to be faster than the 890m.  73 percent though seems like a bit much since panther lake was claimed to be around a 50 percent increase over lunar lake,Neutral
Intel,"They did make a graph specifically to compare the performance of HX 370 and this Arc B390 while they were both using 2x upscaling, which is where this 73% number comes from. In another graph featuring supposedly ""native"" 1080p, they claimed Arc B390 was 82% faster than the HX 370 (why don't they just call it Radeon 890M though...)",Neutral
Intel,"No, intel claims 73% with upscaling (both) and 82% native",Neutral
Intel,"If it was only a 73% gain *including* MFG, then that would be a serious performance regression. If they were using MFG in their graphs, it would easily be 200% - 300% ""faster"" at the same ""real"" performance",Negative
Intel,"The graphs all listed games and I didn't see any synthetic benchmark scores were listed, so yeah.",Neutral
Intel,The relative proportion of the die isn't as important as the die size itself and the node ofc.   Lunar lake for example has an estimated die size smaller than the hx370 so even if they did make the die bigger I don't think that is going to massively raise the price. Not to mention intel owns the foundry unlike AMD who are outsourcing to TSMC. This isn't in the realm of a strix halo competitor with a 300 mm\^2 + die size.   Dell for example has already refreshed the XPS line with intel panther lake and cut out the option for a dedicated gpu.,Neutral
Intel,"There are 50% more GPU cores here than on Lunar or Arrow Lake. CPU is still 16 cores as well compared to Arrow Lake, just shifted from 6+8+2 to 4+8+4.",Neutral
Intel,"Do you mean Strix Halo?  Halo is made up of THREE dies. Two are regular CCD and one is a ~300mm2 graphics die. Total die area is around 440mm2 IIRC.  It's expensive, but not THAT expensive.",Neutral
Intel,Doesn't this depend on use case? AMD laptops are more capable for gaming and the iGPU can also use the lesser version of FSR. Intel is obv better for productivity.,Positive
Intel,"I disagree, Arrow lake HX seems to be more expensive than AMD HX as least on Lenovo Legion Pro setup.   I would have buy Arrow lake for the same price but AMD is cheaper by $200.",Negative
Intel,Eh? It's a standard 128 bit memory bus.â€‹,Neutral
Intel,"You can't price it higher than people are willing to pay, how high that is I have no idea, people bonkers buying CPU only laptops at these high prices if gaming is something they really want to do.",Negative
Intel,Oems magically dont price intel variants as if they were made out of gold?,Negative
Intel,"Lmao check the data, Intel has 79% of the laptop market share currently",Neutral
Intel,"Reddit isnâ€™t indicative of anything really, most casual laptop buyers donâ€™t even know what AMD is.",Negative
Intel,"I wouldn't be surprised if this is because the team has chosen to focus efforts on UDNA because that's the architecture next-gen consoles would use. They only have so much talent and headcount on their graphics division after all, and consoles have much higher volume (even tho low margins) and thus take priority.",Neutral
Intel,AMD is planning on again using RDNA 3.5 on their next mobile chips as well.,Neutral
Intel,Not an ideal solution but Optiscaler exists,Negative
Intel,"NVIDIA has increased margins but they haven't been that terrible. Part of the compounding issue at play is limited TSMC capacity; with both gaming and DC on the same TSMC node.  Ampere (crypto bubble ignoring) was priced well and many excellent cards in there since it was on Samsung, a cheap fab; while DC/workstation chips got TSMC.",Neutral
Intel,Who said anything about basing the entire product stack around handhelds?,Neutral
Intel,"That's not quite right. Power levels are determined by the frequency of a given CPU core. The LPE cores in Lunar and Panther lake both clock up to 3.7 GHz, so given the added IPC of the new Panther lake e-cores and better process node, it is more efficient. Base power levels tell you nothing really.",Neutral
Intel,"[It's actually closer to Battlemage than Celestial. Straight from Tom Petersen](https://youtu.be/P2AsCkKi-vs?t=1576)  >""Unfortunately that Xe3 name got decided years ago, it's actually spread around the Linux stack. Changing the name of that would have been very, very painful. So, that's why you're seeing this disjointedness abut Intel Arc ""B"" series. **Well, [Panther Lake] is B series because it's similar to Xe2** and we want to be transparent with our customers. Panther Lake has a new and improved GPU, that GPU is bigger and **it's very similar to B series.**""",Neutral
Intel,"Xe3 isn't Celestial, only Xe3P will be. See [https://www.tomshardware.com/pc-components/gpus/intels-xe3-graphics-architecture-breaks-cover-panther-lakes-12-xe-core-igpu-promises-50-percent-better-performance-than-lunar-lake](https://www.tomshardware.com/pc-components/gpus/intels-xe3-graphics-architecture-breaks-cover-panther-lakes-12-xe-core-igpu-promises-50-percent-better-performance-than-lunar-lake)",Neutral
Intel,"Yeah, it's a proper generational jump. Intel marketing is just dumb, and the comments from Peterson claiming Xe3 is somehow a smaller jump than Xe3p are just laughable.",Negative
Intel,The reason is marketing (the Battlemage brand is hot and filled with good will ATM so resetting to celestial so soon is not ideal regardless of panther Lake being xeÂ³) Peterson addressed this a bit ago.,Neutral
Intel,Xe3p was alr confirmed coming im sure Celestial happens,Neutral
Intel,"We will see, while Intel's PR and marketing is extremely confusing, Intel did confirm Xe3P will come to desktop; and at least from driver updates (as a very happy B580 owner) driver support has been constant and lively.  I had some issues with an older Civ game, I reported an issue in [their app](https://www.intel.com/content/www/us/en/support/articles/000057021/graphics/other-graphics.html) with screenshots/etc, and while I never got any notification, the game works perfectly now a few months later. Dunno if they read those reports, but my card keeps getting better.  I actually think a MSRP B580 is another card that will age like fined wine -- YMMV depends on games you play, but in Australia they have been regularly sold slightly below international MSRP and represent phenomenal value in the price class.",Positive
Intel,That's bloody good for an iGPU. It's been nice to see them finally get to respectable performance over the last few years. Intel in particular has really upped their iGPU game & it shows.,Positive
Intel,not to mention it is a little skewed as they threw in a title which pushed the vram limit on the 4050 making the b390 over 800 percent faster in that title which obviously messes with the average.,Negative
Intel,It's 10% faster geomean across 45 games,Positive
Intel,That can be resolved if either Intel or AMD decides to unlock quad-channel on consumer chips and mobos. It's artificial market segmentation; the die area needed to deliver more (LP)DDR5 channels is absolutely minuscule; for a huge boost in iGPU performance.,Neutral
Intel,Cache. Lots of it.,Neutral
Intel,"They are using 9600mt/s lpddr5x, could also have a lot of cache, (iirc 890m configs were nerfed in cache because they wanted to put a npu instead), and also could be a synthetic benchmark or specific game that isn't very bandwidth heavy.",Neutral
Intel,Panther Lake still has a 128 bit memory bus so only models with 9600 mt/s will get slightly faster shared memory bandwidth than Lunar Lake.   I wonder how this will manifest in games as the only performance leaks have been from Geekbench and 3DMark which may not be as bandwidth intensive as real games and applications.,Neutral
Intel,"This seems to be correct, since checking NotebookCheck for the 30 watt 4050 shows that itâ€™s around 70% faster than the HX370 in games, which is roughly where Intel places their iGPU.  The performance difference between a 30 watt 4050 and full 140 watt 4050 is around 41 percent performance based on Time Spy",Positive
Intel,"basically cheating tho, rtx cards in dell laptops are barely getting enough watts to even turbo",Negative
Intel,"That's the only way to do a fair comparison, really.   Because the 45 watts that Intel chip uses is shared for the entire chip.   So it's still 45w Intel + igpu vs 60w Intel+gpu",Neutral
Intel,"Itâ€™s a super strong generational gain though, itâ€™s like the jump from Vega 8CU to rdna2 12CU. The kind of single gen gain you see once in 5 years at most",Positive
Intel,The thing about that... what sort of tile are we expecting them to package up? As you say if we can get 4050ish performance from an Intel iGPU then they really can't be far off 5050M... and maybe even 5060M performance in future.  Do you think they'll offer something like a 5070 tile? that almost seems excessive (and difficult to actually package from a thermal point of view in a laptop) but it seems like the 5050/5060 sort of tier is going to be pretty well covered as a traditional iGPU soon.,Neutral
Intel,AMD actually introduced lower tier Strix Halos in this CES; and the first budget laptop thats gonna use it is [the Asus TUF A14](https://youtu.be/h27w0PXFBgk?si=Pa7UQhinywF-uFMj&t=306),Positive
Intel,They're a lot more accurate than whatever the fuck Nvidia has been doing where you have to decode their bar graphs for proper scaling lmao,Negative
Intel,"I'm pretty sure Intel threw lots of ""marketing money"" for the MSI Claw too. There were heaps of MSI Claw promotional booths / draws at shopping malls / public places in Australia and it was heavily discounted.  I picked one up for about $550 AUD (after rebates; tax included), which is like $369 USD inclusive of tax.",Neutral
Intel,> Lunar Lake was a expensive product which didn't make sense in handhelds   What do you mean? All the tradeoffs LNL made were pretty good fits for a handheld.,Neutral
Intel,"I don't think that will really be an issue, laptops can be configured with soldered 8 channel RAM like AMDs Z2 extreme, or they can still manage easily with regular DDR5 6400Mhz sodimms, which run at 102.4GB/s  Plus the CPUs that have intels new B390 iGPU are 4P/8E CPUs, so I doubt there will be much issues from low ram speeds. Something like the Radeon 890M have done fine with such speeds",Neutral
Intel,"> I've been eyeing Dells and Lenovos, and basically all SKUs that previously had 6000 are getting substituted with 4800   You're looking at normal DDR, not LPDDR. LPDDR5-9600 *is* a JEDEC spec, and already available in mobile.",Neutral
Intel,"The majority of the lineup still only has 4. Will be interesting to see what the pricing and performance is on those since these will likely be quite limited. What's also a bit crazy is there's three different nodes being used for the various GPUs, and the full 12 unit one is probably on N3.",Neutral
Intel,cpu: compute processing unit,Neutral
Intel,"I doubt it's exactly 73% outside of cherrypicked games, but it should not be shocking that it's significantly faster than rehashed rdna3.",Neutral
Intel,"Every Intel marketing benchmark for like a decade or so, but especially their GPUs seem to do far better in their benchmarks than they do in reality.",Positive
Intel,"Ice lake, Alder lake, Metor Lake",Neutral
Intel,"Different poster than OP.  Compute tile on Lunar Lake is 140mm2 on N3E with a small 46mm2 controller N6 tile. Strix Point (HX 370) as a whole is 233 mm2 on N4P. Lunar Lake is clearly cheaper, but given the newer node and packaging not massively so, likely by around 20-25%.  Panther Lake, with the B390, is going to be significantly more expensive than Lunar Lake. The B390 GPU has 50% more CUs, and that is very likely still on N3 or some variant (Intel only labeled this as external on their deck). CPU size 4xP+12xE as opposed to Lunar's 4+4, which should still be significantly more area with the core upgrades despite being on A18.  The ""mainstream"" variant also has the 4xP + 12 x E CPU, so even with the GPU being cut to 4 units it's likely somewhat more expensive than Lunar Lake.  Intel Foundry in general isn't any cheaper than TSMC. With Intel being practically the only user and development expenses it's likely more expensive than TSMC despite TMSC's margins. For all purposes it's an accounting trick to hide CCG's and DCAI's 5-15% operating margins if you divide the foundry losses per group revenue.",Neutral
Intel,"Yes, although the actual low power 8 core successor to Lunar Lake is the 335/365 with half GPU cores and slower RAM.",Neutral
Intel,"even if you exclude the CPU CCDs the graphics die alone is bigger than a RTX 5070Ti mobile GPU, which also retails for \~$2000-$3000, same as Strix Halo laptop",Neutral
Intel,"This is slightly splitting hairs but the 8c CCDs in Strix Halo is actually NOT the same chiplet as the ones in desktop zen 5 parts. It iirc is produced on a smaller node, slimmed down, and has different ( or no) TSVs.  It is similar to design and cache sizes to desktop however, but the changes to the CCDs were done to improve low power performance characteristics. They are likely a bit more expensive than Desktop CCDs.  I believe it is discussed in a chips&cheese deep dive.",Neutral
Intel,"AMD have largely been ""winning by doing nothing"" due to their better driver support stack for gaming on iGPUs, rather than actually throwing superior hardware at it.  It's almost ironic how AMD's mobile chipsets are now the ""Intel 14nm+++++"" of this generation.  Constant minor refreshes or even straight-up re-badges of old chips.  Now that Intel Arc has been around a while now and is getting quite capable.  I suspect Intel have a real opportunity to overtake AMD this generation in the iGPU space (ie. handheld and mini-PCs), especially since the new AMD APUs are just **another** refresh with a clock boost and Strix Halo is not scaled or priced to be actually affordable by normal people in that market.  XeSS can also act as a massive force-multiplier in power-constrained scenarios like handhelds.  AMD really shot themselves in the foot by either not building or not allowing FSR4 to function on RDNA3/3.5, which all current and now next gen AMD handhelds are stuck on.  Given how effective DLSS is on the Switch2, one could only imagine how kickass a Nvidia chip in a handheld PC could be with the far more ubiquitous DLSS support.",Neutral
Intel,Now they are not. The panther lake igpus are undisputed winners (excluding the 395+ from amd since it's just not gonna be mainstream). You can get a 358H or 368H and you'll have solid laptop for igpu gaming far cheaper than the 395+,Positive
Intel,"For business apps laptops have been good enough for 10 years now, iGPU and battery life is really the only differentiator.",Neutral
Intel,"Intel is plenty competent for gaming, and has XeSS which is way better than FSR3.",Positive
Intel,Lol? No 6 or 8 core 3dvcache laptops and no 5080 or 5090 laptops. Strix Halo is a joke for gaming as well,Negative
Intel,The 9955HX + 5070Ti is $2240 and the 275HX + 5080 is $2540.   When both 5070Ti configurations are on sale they should be the same price.,Neutral
Intel,My mistake I was thinking of Strix Halo,Neutral
Intel,"It's about compromise. I don't *want* a 4lb laptop. I don't want a laptop that runs hot when web browsing. Or a laptop that has loud fans, or gets poor battery.  I have a desktop for gaming and other demanding tasks. For a laptop, I, and most of the market, want it focused on portability. Light weight. Cool running. Long battery. These big iGPU PTL laptops are really interesting because they provide *good enough* gaming without sacrifice to the non-gaming livability of the device.",Neutral
Intel,"It took me way too long to convince my sister the AMD laptop I bought her isnâ€™t going to blow up in her face and lose all her data, the Intel(and now Apple) CPU brands are very strong.",Neutral
Intel,"> most casual laptop buyers donâ€™t even know what AMD is  We're past that point now. Even ""normies"" have heard of AMD from news.",Neutral
Intel,"its always ""fix it next generation"" with AMD.",Negative
Intel,This is unfortunate news  (â•¥ï¹â•¥),Negative
Intel,"I mean yeah it's not ideal, but you could argue it's the same with XeSS or FSR 4 on RDNA 3. Since the OP said ""there's no decent upscaling on AMD handheld"", therefore I assume Opsticaler is out of the question too.",Negative
Intel,"Well you said it, it's TSMC capacity, meaning also a priority issue. They prioritize AI over consumers and then increase the price by reducing availability, meaning the same chip costs more, meaning more margin.  Seeing they increase the 5090 to roughly 5k (USD) is just the beginning and as I know all companies will use the increasing memory prices to say they must increase the product price, just not proportional to the memory costs.  next step: then they will use this to move more to streaming instead of owning",Neutral
Intel,"> Power levels are determined by the frequency of a given CPU core   There are SoC and platform level targets that depend on a lot more than just clock speed for the same cores. Consider how LNL's PMICs scale vs FIVR/DLVR. Or what operating point benefits the most from the on package memory.Â   Especially at really low power, the cores are not your big concern. Consider the difference at 10W between 50% of your budget available for compute and 80%.Â   > so given the added IPC of the new Panther lake e-cores   We're talking a couple percent. DKT is a tick.Â    > and better process node   Very much unproven.Â    If you want to give credit somewhere, pretty much all of it should go to the SoC and GPU teams.",Neutral
Intel,"Xe2, Xe3, etc. are the ""real"", more accurate names. Battlemage, Celestial are the marketing names.  Intel's decision to label the new Xe3 iGPUs as ""Battlemage"" is certainly an interesting (odd) choice - my best guess for this decision is that next year, Xe3P discrete will launch alongside Xe3P iGPU in NVL, and they're saving the new Celestial naming for that launch event.  Xe2 -> Xe3 is the bigger change.",Positive
Intel,"Peterson states explicitly it's to take advantage of good Battlemage branding, around 1:30 of this video. [Intel Talks Xe3 Improvements For Gaming - YouTube](https://www.youtube.com/watch?v=Bjdd_ywfEkI)",Neutral
Intel,"> Xe3p was alr confirmed coming  Not for client dGPUs, which are what get the Battlemage/Celestial brand.",Neutral
Intel,> Intel did confirm Xe3P will come to desktop  They have not.,Neutral
Intel,"They also might be getting better value out of the ""2x scaling"" choice for benchmarking. Notice how they are behind Nvidia in all the none scaled titles except Dota2 that I saw.  Still very good results for a iGPU, but they are not entirely honest numbers either.",Neutral
Intel,It's 1 game out of 45 in geomean which devalues outliers. ~~9.9% faster instead of 10% faster if you take it out.~~  Edit: Oh no it's actually 6 FPS on the 4050. Yeah that's way too big for geomean to smooth out.,Negative
Intel,And the fact they showed 45 games shows how confident they are in this product.  I remember the Intel slides with 5 hand picked titles we used to get just a few years ago.,Positive
Intel,You mean in desktop? Or do you want mainstream mobile to go quad channel?,Neutral
Intel,I wonder how 96MB cache would do had Intel put that much on it.,Neutral
Intel,They have 16 MB of L2 just for the GPU alone lmfao,Neutral
Intel,> and also could be a synthetic benchmark or specific game that isn't very bandwidth heavy.  They're benching 45 games dude.,Negative
Intel,"Also there's like 45 games on display here, it's not just 3dmark",Neutral
Intel,41 percent difference in performance compared to a full 140 watt in Time Spy. Honestly a bit surprised it isnâ€™t more performance difference.,Neutral
Intel,"No, it's disingenous. Because everyone would think 60w 4050 = 60w on gpu alone",Negative
Intel,"And it's not like the ""last gen"" GPU in lunar lake was bad either, so we are starting from already good and making the jump up.",Positive
Intel,"Not really sure. I believe it's Hammer Lake that's debuting the Nvidia tile, and that's rumored for a 2029 launch, so still quite a ways off, and 2 generations ahead of Blackwell.  The only rumors I'm aware of that it's going to be a pretty big iGPU",Neutral
Intel,"Nvidia's graphics have shown to be more efficient for space than both Intel and AMD, so whatever they use it will likely be better than what Intel can currently put out.",Positive
Intel,Fantastic -- but at least six months too late ;),Positive
Intel,You don't like graphs with zero scale claiming their latest 100W GPU is somehow a gazillion percent better than a 4090 or something?,Negative
Intel,Wattage limited 4050 to 30 watts is the only slide thatâ€™s suspect.  Itâ€™s around a 41 percent performance loss based on Time Spy from the 140 watt 4050.,Negative
Intel,I think they meant that the chip is very pricey which sucks because the handheld is already low-margin otherwisr and can't be priced too high else it got undercut by its competitors.,Negative
Intel,The standard 4Xe models use the extra die space they save to have more PCIe lanes. that large iGPU adds cost and doesn't make much sense to use that chip if you're gonna add an Nvidia dGPU,Negative
Intel,"yeah just looking at the game sample I can see a few that really don't perform well on RDNA architecture at least relative to nvidia(idk what really constitutes an ""intel favoured"" title)   Like stalker, csgo 2, civ vii, dying light the beast, and delta force ik run a lot better on nvidia relative to amd so im guessing the same holds true for intel vs amd.   A couple titles amd does well in were thrown in there too though like God of war and Cod but im guessing the real performance difference is more like 40-60 rather than the claimed 70-80.   Pretty large sample though which is nice so the numbers can't be that off.",Negative
Intel,Why not?   It's 50% more cores + architectural improvements + clock  speeds,Positive
Intel,"Please provide a **single** example in the past ~5 years of an Intel marketing benchmark that is materially inaccurate or untruthful.  NVIDIA is the one playing it loose with BS charts, AMD generally has a good track record (with some exceptions), and Intel on the GPU side has been pretty accurate. For example, these benchmarks have 45 games (!!) and use geomean to reduce outliers.  While I disagree with their choice of LPDDR5 9600MHz (hah, imagine a single consumer product shipping with that in this DRAM market), it is not untruthful.",Negative
Intel,All were pretty accurate.,Positive
Intel,But lunar lake igpu actually perform better than 890M.Like comparison of core ultra 7 and z2 extreme in handheld like msi claw.,Positive
Intel,">The ""mainstream"" variant also has the 4xP + 12 x E CPU, so even with the GPU being cut to 4 units it's likely somewhat more expensive than Lunar Lake.     The mainstream unit that's more directly comparable to LNL is the same core count (4+0+4) with a smaller iGPU tile. It'll be cheaper.  The 4+8+4 w/ 4Xe is the direct replacement to ARL-H, and that should also be cheaper than ARL-H.",Neutral
Intel,"True, but then still, that's not a removal of CPU cores like they said it was.",Neutral
Intel,That is due to the Nvidia tax and AI bubble rather than the production cost of the chip. Even Apple ships cheaper silicon than that.,Neutral
Intel,"This is very topical and cyclical of Intel/AMD. Intel did really poorly for like a half a decade which was unusual but usually they go back and forth. One gets lazy and incompetent, the other curated a masterful product that becomes dominant for a while and then they get lazy and it flips around.  Intel is planning on socketing a ton of cache on their next breed of chips which will massively boost their gaming perfomance and they have pretty darn efficient chips now too.",Neutral
Intel,Thank you for the thorough explanation! Very excited for the future of miniPCs and handhelds since there's so many games I'd like to play on the go.,Positive
Intel,"Yup, I am very happy to learn how wrong I was thanks to other people in this thread as well.",Positive
Intel,"For business apps 10 years ago yes, now even Office has bloated itself up so much it's genuinely taxing even on the Apple chips  And well, the better the chip, the more outrageous the user workload gets. I appreciate the modern laptop chip's ability to import a CSV the size of Excel's row count limit and make a pivot table out of that, but now that it *can* do that I'm *expecting* that to be possible as quickly and as efficiently as possible.",Negative
Intel,I was under the impression that XeSS needed a dedicated GPU? If it can run on iGPU that's a whole different story.,Neutral
Intel,"Their GPU's only look good when compared to 1 generation old bottom tier GPU's of their competitors. Its wild the praise they get.  Same thing will happen here, AMD will release a new iGPU architecture and Intel will be left comparing to out of date CPU's no one buys anymore.",Neutral
Intel,Sorry I should have specified that I'm talking about budget laptops with iGPUs.   I would sooner build a pc than even think about a 5080 laptop with 3dvcache options.,Negative
Intel,"Yeah; meanwhile NVIDIA just released DLSS4.5 for **every single RTX GPU**... yes all the way back to Turing. It runs a lot better on more recent cards, but it's available on every single RTX GPU if you want to.",Positive
Intel,Except with UDNA it might be the first time over a decade AMD isn't phoning it in.,Neutral
Intel,"XeSS and FSR 4 on RDNA 3 both use downgraded versions of those upscalers, that either look worse, perform worse, or both. In the case of FSR 4, it's a leaked one-off model that people got their hands on. All I really meant by ""decent"" was having an officially supported modern upscaler without all the downsides.  An Intel GPU running XeSS would presumably get the full version of XeSS without the performance hit and with good visuals.",Negative
Intel,I can currently buy a brand new 5090 in Australia for $2841 USD with express postage included; I'm not sure why it's 5k USD in your region; but there's no reason you should be paying 5k USD. Which country are you in?,Negative
Intel,"The ultra X9 388H has a base TDP of 25W and minimal assured power draw of 15W. Meanwhile the ultra 7 155U has base TDP of 15W and minimal assured power draw of 12W. Both these numbers are lower for the meteor lake chip, yet the Panther lake chip is waaay more efficient (+2x). The base power level doesn't mean anything. It might be the point where the chip had the most perf/watt, but that doesn't mean that the performance at lower wattages is the same.",Neutral
Intel,"Battlemage, Celestial, etc are named they (usually) use only for the dGPUs, even if that does correlate with the B/C-series naming. I think at some point this is just reading the tea leaves. The name's misleading for the tech difference.",Neutral
Intel,XeSS FG has lower overhead than Nvidia IIRC,Neutral
Intel,If you actually do the maths it'd go down to (1.1^(45)/9)^(1/44) = 1.049 = 4.9% faster,Neutral
Intel,"Oh wow that's a lot later than I expected, I was thinking this year or next.  Yeah no clue in that case.",Negative
Intel,Infinity percent better at a feature the older GPU used for comparison does not support!,Positive
Intel,"I don't really think that's ""suspect"". They said they're limiting the total laptop power on the 4050 to match the total laptop power of the PTL chip. If you want stronger performance out of a 4050, you're gonna need to have much higher power draw than the PTL laptop",Neutral
Intel,"CSGO is known for running like utter shit on Intel Arc, you can check r/IntelArc for details LOL. The game selection looks pretty reasonable to me.",Negative
Intel,"Yeah all depends on pricing, 6 core ultra 5 model is however technically downgrade from last generation and the same core config as the i3 1315U.",Neutral
Intel,Honestly not that unusual. It takes an average of around 4-5 years to develop a processing unit from the ground up. If we assume each one does this when they get mushroom stamped by the other for being lazy it accounts for the 5 years gaps till they show back up with something to sell.,Neutral
Intel,"I think AMD is getting a bit lazy when it comes to consumer graphics. I think their attempts at laptop have been really half-assed given just how good their IP portfolio is.  But when it comes to their core businesses, they're definitely been keeping the heat on and have been quite aggressive. They're datacenter first and foremost, and that trickles down to amazing desktop CPUs too. They're heavily focused on building out their Mi series too...but they're just dropping the ball in laptop and consumer GPU",Negative
Intel,Pantherlake also has an oddity in that it has MUCH higher L2 cache than even desktop zen 5 parts. I'm curious to see its CPU performance in low resolution scenarios.,Neutral
Intel,"The good version of XeSS runs on any chip with XMX units (Intel's version of tensor cores). Lunar Lake, Arrow Lake mobile, and now Panther Lake have GPU tiles with XMX units, so they get the same XeSS as discrete Arc cards.",Positive
Intel,"Dedicated hardware, not dedicated GPU. The new Intel CPUs have iGPUs with the necessary hardware.",Neutral
Intel,"It needs dedicated GPU hardware to run faster, but theyâ€™ve started incorporating it on Lunar Lake and Panther Lake",Neutral
Intel,Intel has been very aggressive in the iGPU space. AMD isn't going to have any real updates to their iGPUs until 2027 the earliest.,Neutral
Intel,"> Same thing will happen here, AMD will release a new iGPU architecture   ... Based on what history? AMD's iGPU has not significantly changed in years. It's still hugely memory bottlenecked and no matter how many times they add an extra 2 CU's, it will still be memory bottlenecked.  IIRC someone disabled 2 CU's on their 7000 series APU and their in-game FPS almost didn't change because the bottleneck was actually memory access.  Intel ARC is actually very good on this metric. Intel doesn't exactly need to sling anything better than ""slightly more Battlemage on a better transistor"" to completely swamp out AMD iGPU in this space.",Negative
Intel,"Intel Panther lake base tdp is 25w, around the same as AMD Strix Point/ Gorgon Point. Why will they compare it to a 55w tdp Strix Halo?",Neutral
Intel,"Even on the budget laptops category the new Ryzen 7s suck compared to the Intel Lunar Lake options, they seem to be priced closer with Lunar Lake getting stuff like nice displays. In the really budget category I feel like they are tied on value and I don't know how sales affect that. This is partially cause AMD went cheap on the mid-range kraken point chips and also had to fit in the still dead weight 40 tops NPU for Microsoft. So it only has 8 GPU cores.",Negative
Intel,"Yeah but basically unusable on pre 40 series. But at least NVIDIA gives users the choice.  AMD should just stop the BS pretending and just enable the full FP8 model across RDNA2-3 with FP16 emulation. But it prob runs so bad that they won't, far far worse than DLSS 4.5 on 20-30 series.",Negative
Intel,"It would be good if that is true, but so far ive seen nothing that would inspire me confidence in AMD. And yes i remember the AMD patents you posted last year.",Negative
Intel,"Yeah, it's DLSS4>FSR4>XESS (Intel)>=DLSS3>XESS (fallback)>FSR3      quality wise.",Neutral
Intel,"First custom design OEM are fast, here 4400â‚¬ on Amazon https://amzn.eu/d/idxVW9M  And you know how this goes, one starts the other follow.  Here in the US for a normal founders edition for 4.2k USD + TAXâ€¦ one article from the first of January quoted ot that time being at 3.7, like 5 days ago.  https://www.newegg.com/nvidia-founder-edition-900-1g144-2530-000-geforce-rtx-5090-32gb-graphics-card-double-fans/p/1FT-0004-008V4?source=f",Neutral
Intel,"When I talk about ""design targets"", I'm not referring to an arbitrary TDP. There are very specific decisions each SoC made that have tradeoffs at different power envelopes.   Also, the context was LNL which is an entirely different beast from MTL.",Neutral
Intel,">The name's misleading for the tech difference.  Yeah, that's my point. People are reading too much into the ""B series"" naming scheme for B390.  As you said, ""(usually) use only for the dGPUs"". So if Xe3P is launching as a discrete Celestial Card, then it would make sense to have Xe3P tile be part of the ""Celestial"" launch, rather than Celestial Discrete being ""one year later than Celestial integrated""",Negative
Intel,Oh dang you're right lmao.  The 4050 has SIX (6) FPS at 540p high. I thought OP was exaggerating with 800%.,Neutral
Intel,Yeah those kinda suck. Should be Ultra 3s given they're basically WCL spec.,Negative
Intel,"More like 10 years, 5 to realized that they are getting stomped in the face, and another 5 to actually make something of it.",Negative
Intel,"Man, there are so many older and less demanding titles I'd love to play through on the go, but knowing that Lunar Lake laptops have better displays for the price is really good. Thanks for the info!",Positive
Intel,"If you're referring to the April dump, heck even the August dump (analysis of Kepler\_L2 patents) then that's not close to the complete picture. A lot of new patents have surfaced since that expand upon the design in many ways, but I'm waiting for the last RDNA5 to be made public before making a potential follow up post.  But regardless even if they fix HW situation completely they'll prob fail spectacularly with SW stack as they've done so far with FSR Redstone and FSR4 game adoption. Even hear a lot of people complaining about having to use Optiscaler, even in newer games.   Also NVIDIA will no doubt move the needle a lot nextgen yet again. They already did with DLSS 4.5 and DFG and something tells me that DLSS5 is gonna be even worse for AMD. They better prepare for what's to come.  Worst case it's a complete massacre. I can see the following scenario happening:  **HW:** NVIDIA invests all their silicon budget into fixing 5090 scaling bottlenecks (16 GPCs instead of 12, revamped scheduling etc...), fixes other problems with 50 series (redesign cachemem mostly) + goes Brr on ML and to some extent RT. Raster goes up 35-40%, everything else goes up multiple times.   Worst case ML HW gets bumped to 4-8X NVFP4 rate, although 2-4X sounds more likely.  **SW:** NVIDIA uses this new insane ML HW to make new DLSS models. DLSS5 goes all in on NVFP4 and is faster than DLSS4.5. DLSS5 SR and RR for 50 series + 60 series which is lightweight and fast on new GPUs (high FPS), and a new DLSS ULTRA SR for 60 series (released across stack but painfully slow for anything pre 60 series) striving for maximum Image quality. The smaller model will be better than DLSS4.5 and the big model another tier entirely (DLSS3 -> 4 leap easily on top of DLSS4.5).   They also make DRS compatible with DLSS SR and RR so users get greater flexibility here similar to DFG for framegen.   FG will also release in two versions one light and heavy. Will also work with Reflex 2. It's possible only the big model will be frame extrapolation + limited to 60 series. Should make FG result in lower ms instead of higher + overall image quality far superior and basically all issues solved up to at least 4X.   Oh and a flood of MLPs and a demo showcasing the absurd visuals the 6090 can push. Moves goalpost past ReSTIR PT and will look borderline offline render quality. Very close to Blender renderers. IDK how they'll do it but MLPs are borderline magic, so prob doable.  Thinking about it more you're prob right and even if RDNA5 HW is amazing even beats 6090 in PT, a DLSS5 feature suite this impressive + moving goalpost to MLP based neural rendering will make RDNA5 irrelevant. As always SW and marketing will kill any momentum from HW side. Really hope I'm wrong but don't think so.  Sorry for the rambling.",Neutral
Intel,"That's a marketplace listing, it's basically eBay, because Newegg is out of 5090FEs directly.  You can get it on the overpriced StockX for far cheaper: https://stockx.com/nvidia-geforce-rtx-5090-32gb-graphics-card-900-1g144-2530-000",Neutral
Intel,"That would make some sense if they *did* plan a Celestial launch, but that's a big ""if"" and is just creating confusion for now. And it'll be even worse when NVL mixes Xe3 and Xe3p.Â    You also have Intel marketing actively making the situation worse like that Peterson interview people keep quoting to justify this nonsense. As if Xe3p isn't much more incremental than Xe3.Â    It's a particular shame when the product itself is actually good.",Negative
Intel,"Yeah, the first 6 core i/u5 series since 11th gen. :/",Negative
Intel,"Yeah idk why but they typically got OLEDs exclusively, though could be a US market thing. I would also note I was mostly looking at decently built midrange to high-end laptops. I think AMD is more common in the plastic crap box design and may be a better value there, but those also typically seem to have a ton of older rebadged processors instead of the newer Kraken Point unless something changed.",Neutral
Intel,"I enjoy reading your optimism. I hope it all comes true, but it sounds a bit too good to be true given the recent hardware developements. The 5090 scaling issue is that we stopped resolution scaling. If you go beyond 4k the 5090 scales a lot. VR resolutions report the 5090 being as much as twice the framerates of 4090.",Positive
Intel,I've rewritten prev reply to provide more info.  I'll also link the scheduling patent here in case anyone reading this thread is interested: [https://patents.google.com/patent/US12153957B2](https://patents.google.com/patent/US12153957B2)   It sounds like gains in workgraphs scenarios will be be even greater.,Positive
Intel,"Yeah prob not realistic. I just tried to outline a nightmare scenario for AMD. As for the RDNA5 stuff we'll see how good it ends up being.  Agreed serious issues fs. RTX 5090 scheduling is brain dead. 16 SM GPCs, one central scheduler for 170 CUs. The smaller the internal res the harder it is to keep things going. Someone smarter than me could prob make a core scaling efficiency chart for different resolutions clearly showcasing how RT > raster and derive different formulas for 1080p, 1440p, 4K etc... . There's simply no reason why it has to be this bad moving forward.       But it's also interesting to entertain that RDNA5 could be a nightmare for NVIDIA. If NVIDIA doesnâ€™t fix scheduling AMD's nextgen could be a real nightmare scenario for them. The modular and decentralized scheduling will be a gamechanger and based on what patents have said scaling is almost perfect and can scale to [arbitrarily large configurations](https://patents.google.com/patent/US12153957B2), yes they used that wording. AT0 will function like 8 x AT4 instead of running into massive scaling issues. In fact based on what the patent has said it might be even better. Consider each scaling domain with a local cache independent of the L2, where the global command processor only acts as a distributor of work, not an orchestrator. Gains will be observed across the stack but expecting IPC gains to scale with number of CUs. Is this a big deal for RT and 4K native? Yeah but even more so for lower res gaming.    And assuming they reduce CPU overhead even further in new uarch AMD will easily take the max FPS crown although I suspect NVIDIA can finally address their driver overhead issue after booting Maxwell-Pascal. Weâ€™ll see who comes out on top in CPU overhead nextgen.  I thought most of that gain vs 4090 was due to extra BW? But yeah high end perf scaling falls apart at sub 4K internal res.",Negative
Intel,"I dont think much can be done with overhead. AMDs overhead is already small, basically letting the API go directly to GPU as it is. While for Nvidia side, isnt most of the overhead related to how Nvidia handles DX12? in that case i dont see it going away for a long time.",Negative
Intel,"Interesting, GN usually gets Tom to do discussions like these but instead decided to publish whatever that previous video was on 'Intel pulling an Nvidia'. I bet GN will probably have their own video with Tom, but I appreciate DF a little bit more with this discussion.  At around 21min, it's interesting to hear his talk on cross-vender SR, mentions how they'd like to work more on Nvidia's Streamline and a candid talk about DirectSR and how it isn't really the concrete solution for the work on cross vendor SR. At around 23min, Alex brought up something interesting about research they've published before on joint denoiser and SR. He kinda skirts around it, but continues on suggesting they have more plans on it. He also then continues on the state of PT, DXR 1.2, obviously it isn't a real focus with something on their iGPUs, but any future HW, will be their primary goal to tackle. Alex mentions Valve/Linux, and Tom says it isn't entirely their focus right now, at least for gaming.",Positive
Intel,"Super interesting that he randomly announces that Intel will be dropping a pre built shader program for Panther Lake. And not build with the new Microsoft framework/infrastructure, but just on their own?? How can Intel randomly drop this, but nvidia and amd canâ€™t??",Neutral
Intel,"Seems like we're not the only ones that think FG isn't ideal rn. I really hope Intel succeeds in their efforts to pair Framegen with reprojection, but it'll prob be NVIDIA that gets there first. Might be the killer app for 60 series, but pure speculation of course.  The stuff about using AI to smoothe frames is interesting as well.  Things prob gonna change a lot in the coming years. We'll see if it's for the better.",Neutral
Intel,Are PC games becoming more stuttery or we're just paying more attention to it?,Negative
Intel,This will probably piss off MLID since he hates Tom Peterson,Negative
Intel,This future of gaming is ridiculous.  Aggressive upscaling (360p) and one-in-four frames actually rendered and the rest FG?   For what?  Path tracing?  Nanite?,Negative
Intel,You still watch GN? Dude only farms drama after realizing how much clicks they generate.,Negative
Intel,Thank you for the summary!,Positive
Intel,"He's talked about it before I believe in a previous interview, might have been with PC World from memory or perhaps GN. Regardless, it wasn't exactly new iirc. [Anyways this is definitely old news.](https://overclock3d.net/news/software/intel-plans-to-make-shader-stutter-a-thing-of-the-past-with-arc/)",Neutral
Intel,"What do you mean? The Shader delivery program was launched on an AMD handheld, so I presume they will use the MS advanced shader delivery infra.",Neutral
Intel,"Intel already talked about this a couple months ago. It's not an announcement here, but it seems people are more interested in AMD and Nvidia news so those threads don't get as much traction.",Neutral
Intel,I feel like more people paying more attention since the marketâ€™s grown a lot.   I remember old games I played in the early 2000s having micro and regular stuttering depending on the game. I chalked it up to â€œhuh guess itâ€™s loading in data as I playâ€ when I didnâ€™t know much.,Neutral
Intel,We are paying more attention to it but I suspect as we push higher frames with new engines and techniques the micro stutter is getting worse. It just starts becoming less perceptible to people than say the micro stutter from SLI and other stuff that caused issues in the past.,Negative
Intel,"I think digital foundry answered that question on their podcast. Compared to 15 years ago the frame rate is higher on average for most gamers, but it also stutters more. So it's huge fps with huge drops and hangs.",Neutral
Intel,"Worth remembering no one even gave a shit about stuttering enough to measure it until someone at I think it was anandtech back in the late 00s was so fed up with shitty perf on his crossfire system he started doing 1% lows on benchmarks.   Back in the 90s people would run like 6x SLI voodoos and not even care that the game hitched every 10 seconds down to sub 30s fps lol...  Edit: it's also key to remember that a lot of the games that stutter on PC these days stutter in the exact same places for the exact same reasons, and worse considering the lack of CPU power, on consoles. Console gamers just don't give a fuck lol....   DF did a good video showing this truth with the Silent Hill 2 remake.",Negative
Intel,"With a lot of PS3 games dipping to 20s, I guess we are just paying more attention to it now",Neutral
Intel,There was DF Clip of this exact question.  https://www.youtube.com/watch?v=pxsfT4c-F-Q,Neutral
Intel,They're more surgery stuttery.,Negative
Intel,Everyone hates MLID,Negative
Intel,Funny piece of lore. Why so?,Positive
Intel,Who's MLID?,Neutral
Intel,If the end visuals are better who cares. we already did a lot of such things in engine just didnt tell the players about it. One in four frames actually rendering shadows is a thing for example. Heck some games go as bad as once a second shadow updates.,Negative
Intel,"Well, I think that most people (myself included) don't really care how it's done if the end result is looking good and feel good to play, off course something like 30fps based with MFG to 120 is bs, but I quite regularly use 60 -> 120 using frame gen because It feels okay input wise to me at 60, and the added visual smoothness is quite nice. So it all depends how it's implemented and talked about.",Neutral
Intel,"yeah i had to tap out a couple months back. it's a shame, they did great work, but i refuse to support ragebait.",Negative
Intel,"Doesn't help that there isn't any particular new hardware to review or anything new besides AI, the PC industry has hit stagnation in the consumer market.",Negative
Intel,"In other news, guy who is being served turds at restaurant loudly complains about receiving fat dooks instead of food.     *""man that guy is such a whiner""*",Negative
Intel,"No it didnâ€™t sound like they were going to use the MS shader delivery program. Or no, they said they want to, but they have their own solution that theyâ€™ll launch before that.   And I also donâ€™t think the MS solution is ready. The ROG ALLY XBOX also doesnâ€™t have this feature already as far as I know",Negative
Intel,"> The Shader delivery program was launched on an AMD handheld  i assume you're referring to the steamdeck, which to my understanding was done by valve... so the point kinda stands, you just add valve to the preamble.",Neutral
Intel,"I dunno I remember many games, especially based on Quake engine, being buttery smooth if you could get to reasonable FPS",Neutral
Intel,also more cause for stutering. Back then we could compile shaders real time with no siginficant issues because they were small. Now we have to compile shaders real time that are huge to the point where we pre-compile half of them before we even start the game.,Neutral
Intel,Console gamers *of certain genres* care.   The FGC rejected the idea of playing Street Fighter IV & MvC3  on PS3 because the Xbox 360 port had better input latency.   Even the PS4 port of USFIV wasn't liked.     Part of why I stopped going to tournaments is because SFV & Tekken 7 on PS4 always felt *off* compared to PC.,Negative
Intel,"Not really. In many cases, console versions of games just don't stutter whereas PC games do because modern games are mainly designed for consoles and then ported to PC.  A couple of good recent examples are Wukong and Outer Words 2. Neither of those games on consoles have the horrid stutters that are prevalent on PC.",Neutral
Intel,MLID more like MID,Neutral
Intel,Heâ€™s been calling Tom a â€œsnake oil salesmanâ€ for performance claims on Alchemist,Neutral
Intel,"Moore's Law is dead, he's a YouTuber who makes predictions and purports to have insider information from Nvidia/Intel/AMD but in reality he is better described as FanFiction for PC enthusiasts.",Negative
Intel,"I worry about things like latency.  Or what happens when you move suddenly, or fire, and the whole image falls apart.  If the hardware can't do it all yet, then wait a few years instead of using these... methods.  And just to be clear, I think very highly of  Mr. Tom 'TAP' Petersen; I'm just not liking where this is all heading.  Are you happy with Borderlands 4 or Outer Worlds 2?  If you are then we live in two different worlds.",Negative
Intel,"There's plenty of old stuff he needs to review. I've said it before but I will say it again and beat it like a drum: He STILL has not reviewed the 9060 XT 8GB for instance. Plenty of content he could have farmed off that, especially BEFORE the RAM shortage where having an 8GB card was some sort of sin in his eyes (except for some reason he ignored it but raile roaded the cheaper RTX 5050, lol did someone say bias?). Instead, he just tore the 9060 XT 8GB down and never touched it again after that teardown. I'm sorry but there's GENUINELY stuff he could be doing instead of farming clicks about 'NVIDIA bad' and 'Intel pathetic', but that won't get him views from drama farming NVIDIA which is what he craves these days. So sad to see a big channel like his who got big off doing solid technical content become a drama-hype ""news"" channel.",Negative
Intel,No wonder that strategy has proved successful. There are a lot of people that only care about complaining and bitching. Which I get up to a point but it starts to feel childish and pathetic quickly.,Negative
Intel,"I love how reddit down votes you,  reddit posts all day complaining about the industry, GN does a video on it   Redditors ""whiney cry baby engagement farmers """,Negative
Intel,"Valve does have one on Steam, but Microsoft announced a store agnostic, eventually hardware vendor agnostic one launched with the Asus ROG Xbox Ally X last year.  It was supposed to be working already but there's no sign of it just like everything else Microsoft releases about gaming half-baked like their gaming UI, their attempt to unify upscaling, and Directstorage.   So I imagine they're referring to what Microsoft called ""Advanced Shader Delivery"" that they've done little with but name and announce to sell more Asus Pretend-Xbox's.",Neutral
Intel,Iâ€™m talking about the Xbox Ally as the other commented said,Neutral
Intel,We considered solid 60 or 75 smooth back then. Now at least I complain as soon as I can't stay above 100.,Negative
Intel,"Shader compilation stutter is a PC problem thatâ€™s been especially bad in UE4 and 5 since the transition to DX12. Other types of stutter and bad frame rates used to be equally bad on consoles, or even worse in the 360/PS3 era.",Negative
Intel,Outer Worlds 2 is fairly consistent for a UE5 game. To me its just very heavy,Neutral
Intel,"funny coming from MLID, notorious snake oil salesman",Negative
Intel,"Eeeegh, considering MLID overall story - can see that, can see that.  OTOH usage of such terminology - snake oil salesman - reminds me of that very infamous Intel presentation...",Negative
Intel,You say that as if we will reduce our base frame rate. But the direction of travel is to use MFG to drive the 480Hz and above monitors that will become more and more common in the future.,Neutral
Intel,I dont like borderlands franchise and i havent played Outer Worlds 2 yet so i cannot comment on them from personal experience. However things like Reflex/Reflex2 has actually decreased latency for me.,Negative
Intel,"I havent really seen it as some sort of drama farm, I think a lot of GN's videos do show how bad the current computer hardware hobby is doing and Im glad someone is focusing on that",Negative
Intel,Whata wrong with calling companies out? Like redditors cry all day but stop at GN when the channel brings up issues within an industry.  Sorry a person isn't running their channel the way the reddit collective wants.,Negative
Intel,"honestly, i had completely forgotten that was a thing.   i wish i had more faith in microsoft to pull this off, but i remain skeptical in basically anything they try until proven otherwise.",Negative
Intel,"People on gaming forums used to go around insisting the human eye could not distinguish greater than 60fps.  It was accepted as gospel in many places/by many people.  Granted, that was in the age of CRTs and almost no one had actually seen >60, but funny to think back on.",Neutral
Intel,snake oil salesmen dont like competition.,Negative
Intel,"MLID aka ""RTX 50 super will be released november 2025""",Neutral
Intel,this just makes me like tom more,Positive
Intel,"Replace that 60 with 30. Yes, people insisted we could not see more than 30 even while playing on 85hz CRTs.",Neutral
Intel,"Meanwhile quake players kept dropping resolution to hit triple digit refresh rates :) But yeah, it's wild that 30 was the norm for so long on console",Neutral
Intel,That's far from the worst prediction he's missed.  Remember SMT4 for future Zen architectures? 24 and 32 cores on desktop Zen4? L4 cache for Zen 4?,Neutral
Intel,Which Tom?,Neutral
Intel,"console used to lock at 60, dont know why they choose to drop down to 30.",Negative
Intel,"Because when the hardware cant handle all the sprites, it slows everything down including game logic which was tied to frame rate back then. It happens in plenty of hardware from snes to arcade cabinet.",Negative
Intel,"also happened the other way round, older games would run faster than they should because they tied it to framerate rather than delta time. This bad practice was so common you can still find studios like bethesda do this.",Negative
Intel,"for context, this G14 was the one that gave us [the first ever Geekbench scores for Panther Lake](https://www.reddit.com/r/hardware/comments/1ocaslx/panther_lake_geekbench_leak_its_good/) over on r/hardware",Positive
Intel,"The price probably wasn't going to be low enough compared with other SKUs.  In the past, Intel skuss with Iris HD etc were so expensive and were only included in $2000 ultrabooks. This is probably going to be same.",Negative
Intel,When I first learned about I was confused why it existed. Not surprised Asus decided to cancel it.,Negative
Intel,"It makes sense, a B390 only G14 kind of defeats the whole purpose of the Zephyrus, even as a base model.     Basically brings the GPU performance down to 3060 levels (actually a little worse than that), which is roughly 4 years ago at this point.",Negative
Intel,"Hello LastChancellor! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
Intel,"Ugh this would have been such a cool business laptop option, I'm finding current-gen integrated graphics to not be enough to really handle Teams + external monitor + a presentation. Sounds like this would have hit the performance mark without having to pay through the nose.",Negative
Intel,Itâ€™s also the one that didnâ€™t have a dedicated GPU in Geekbench,Negative
Intel,"I don't think so, they're making it available on more than just the top 9 series, they also confirmed a custom chip for gaming handhelds which we'll prolly see at computex",Neutral
Intel,It probably made more sense as an low-end gaming Zephyrus when fitting it with 32GB LPDDR5x wasn't half the BOM,Neutral
Intel,esp since on CES 2026 they launched an even more premium 14 inch laptop that actually does have the B390 (ExpertBook Ultra),Positive
Intel,esp since Asus ended up launching the ExpertBook Ultra at CES  an even more premium 14 inch laptop compared to the G14 which does have a B390,Positive
Intel,"But it actually can be used on battery unlike normal laptop gpus which make your laptop die in 5 seconds or performance is awful and it dies in 10 seconds, so what's the point of having a powerful GPU on a laptop if I got to plug in all the time it sucks.",Negative
Intel,"A 3060 is still useable imo. If the efficiency is right, they can make usb-c powered gaming laptop and completely remove the dumb dc brick.",Positive
Intel,"It would have made _some_ sense, but the Arc B390 mustâ€™ve been real good. But as you say, with the raise in RAM prices, you can forget about it.  I wonder whether Intel themselves would pair a mid-range Panther Lake with a top-notch iGPUâ€¦ It would make sense, since the high-end CPUs tend to have dGPUs.",Neutral
Intel,"For the Zephyrus you can also just disable the dGPU to game only on the iGPU, and the customers of the Zephyrus are minimum looking for a decently powerful dGPU",Neutral
Intel,I hope their plugged out power scheme is permanent and doesn't vary based on application,Neutral
Intel,"> so what's the point of having a powerful GPU on a laptop if I got to plug in all the time  I have a laptop for travelling. I travel to places that have plugs, and I don't need to use a laptop while I am actually in transit.",Neutral
Intel,"It still pulls 60W (and apparently 80W, briefly) at full pelt...  That is to say an hour and a half battery life when gaming should be expected. It's not magic.",Negative
Intel,Usb c powered gaming laptops are more common now. The new ideapad 5 pro with panther lake and 5060 (combined 110w system power) uses usb c exclusively,Neutral
Intel,"> A 3060 is still useable   Nvidia seems to agree with you, which is why they are looking to put them back into production.  /I'm sorry, I couldn't resist.",Positive
Intel,"Useable, yes, but what customers of the Zephyrus are looking for, no.",Neutral
Intel,"Yeah, and it gets pretty good battery life on that and in power saving mode/60fps screen mode. Like 8 hours. Best I've had on a gaming laptop- not a high bar, but it's nice to be able to take it into the living room and use it light a normal laptop instead of it dying instantly.",Positive
Intel,Still better than 45 minutes  Also it can obviously be put in a lower power mode to save battery while not hurting performance too drastically.,Positive
Intel,"The G14 used to have gtx1650, so not sure what do you mean.",Neutral
Intel,Which was the 5050 of that time which is significantly more powerful than panther lake's igpu.,Positive
Intel,Why does this need an article? It's a tweet by an official account praising their own product.,Negative
Intel,"The B580 has 200W TDP, in a perfect world and TDP scales linearly, the B770 would be 50% faster, that would put it around the 5060Ti/9060XT.  If the price also scales linearly, that would be around 375â‚¬, seeing that the 9060XT is going for 350â‚¬ now, it's gonna be tough competition.",Neutral
Intel,Im really looking forward to panther lake X. 4-4-4 core configuration and Xe3 iGPU with sr-iov is perfect for running a Linux-Windows mixed vm environment without having to get a gaming laptop with a dedicated GPU for virtualisation.,Positive
Intel,I hope the Linux driver support and performance is good in these,Positive
Intel,"Intel ARC needs to maintain their momentum. They have an excellent pricing strategy and genuinely compelling features, it's time they released a card that competes in the midrange. And no, I don't count the A770. As a B580 owner, increased ARC adoption rates will be sure to benefit all cards in the range, so I really hope that intel is committed for the long-haul here. They are not in the position to be burning consumers anymore",Positive
Intel,"Releasing a GPU more than 1 year after the B580 came out seems weird to me. Unless this is a new architecture, or is using Intel's own process, and fabs.",Neutral
Intel,"4070 performance for $350-400, I'm calling it now.",Neutral
Intel,Hopefully they've seen Nvidia and AMD fuck things up by having two VRAM configurations and know not to do that.,Negative
Intel,"Hello Revolutionary_Pain56! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
Intel,They wouldnâ€™t need a B770 or mystery GPU if they actually released more than just a B50 to the masses.,Neutral
Intel,"I don't know what the driver situation is like a year later, but B580 was anywhere between a 4060ti and a 3060 (or less if the driver really choked), so comparing B770 to a single Nvidia point of reference probably isn't the whole story.  Intel has been selling a big chip with a lot of hardware relative to what they charge, so when the drivers work Battlemage can punch way above its price class. I expect the same this time.",Neutral
Intel,"It's been deleted, so it might even be inaccurate.",Negative
Intel,Ad revenue.,Neutral
Intel,Trying to apply logic or rules to the internet is a waste of time.,Negative
Intel,"Scaling by TDP is not a good metric as they can pack more cores ect. and run them at lower, more efficient speeds. That however will mean a bigger die and viability might be questionable (considering they're already massive for the performance).",Negative
Intel,"Price doesn't scale linearly because die sizes make defects scale quadratically. so pricing is the same, 2 50mm\^2 dies are cheaper than 1 100mm\^2 die     However in GPUs there is a fixed cost for every GPU so there is a sweet spot",Neutral
Intel,"As always, TDP is a semi-arbitrary figure and has little to do with what the GPU requires.  Most GPU's of today have heavily inflated TDP's simply to try and juice benchmarks on review day as much as possible.",Neutral
Intel,"The BMG-G31 is supposed to have 32 Xe cores in 8 render slices on a 256-bit memory bus, compared to the 20 Xe cores and 5 render slices on a 192-bit memory bus for the BMG-G21. Unless Battlemage is seriously memory bandwidth-limited, it should be almost 50% more performant.  The only question is die size. If it's 50% larger than the 270 mm^2 BMG-G21, that would exceed 400 mm^2. The GB203 in the RTX 5080 is 378 mm^2 for context.",Neutral
Intel,With tdp of 300 w it better be RTx 5070 or 9070 territory for much low price,Neutral
Intel,Intel never confirmed SR-IOV on Panther Lake - did they?,Neutral
Intel,"You can choose between high performance and crashes (xe) or low performance and stable (i915), and with Intel firing linux devs left and right I wouldn't expect much improvement any time soon.",Negative
Intel,That would be an amazing value proposition.,Positive
Intel,Rtx 5070 16gb for 380$,Neutral
Intel,Iâ€™d be happy if they didnâ€™t gate the Arc Pro B60 behind bad distributors.,Neutral
Intel,"So banking on the hope, that *everyone* ***else*** *somehow falls behind by accident*, only for Intel to succeed?  If that's their business-plan (looking at their foundry-woes, it seems it is), that's an awfully idiotic business-model.  ---- Last thing I heard, was redditors moaning about en masse that monopolies are bad. *Which one is it?!*",Negative
Intel,"The B50 is not a gaming GPU and actually underperforms in gaming tasks compared the the B580. They need to have an actual range of cards, not just a budget option, and even more budget option, and a server/workstation GPU. The B770 is essential to compete in the midrange",Negative
Intel,"A year later the drivers are fantastic, seriously not even a single hiccup. Been playing Hogwarts legacy at 4k 60fps with Xess Quality upscaling, and no frame gen.",Positive
Intel,"> Scaling by TDP is not a good metric as they can pack more cores ect. and run them at lower, more efficient speeds.   The problem with this idea, is that this would cost them far more money, as you need more die space, which they already use relatively inefficiently compared to nVidia.  They can't really afford not to use every bit of die space they have for all that its worth.",Negative
Intel,"Battlemage doesn't have the ability to add more Xe cores per render slice, this is something Intel has changed for Xe3. The BMG-G31 will have 128 ROPs, the same as an RX 9070 XT, or more than an RTX 5080.",Neutral
Intel,"afaik it works on every iGPU since skylake, but the driver is not in the mainline kernel",Neutral
Intel,I'm using an Arc A770 right now in Linux.  With i915 performance was unusably (for me) low.  With xe it's been fine.,Neutral
Intel,"the driver is already open source right? i think it will get better over time on virtue of being open source, but relying on intel to fix it now probably isnt gonna pan out.",Neutral
Intel,"Well it kinda has to be, the 4070 came out nearly three years ago.",Neutral
Intel,5060 performance for twice the price isn't a good deal.,Negative
Intel,"I could see that. Nvidia really bailed out Intel by making the 5070 not much faster than the 4070 without using MFG to cheat lol   Edit: for all the Nvidiots downvoting, [the truth hurts](https://www.techspot.com/review/2960-nvidia-geforce-rtx-5070/#RT-1440p-png)",Neutral
Intel,This seems an absurd overreaction. All I'm saying is they don't do a 5060ti or 9060xt situation where there's a 8 gig model and a 16 gig model.,Negative
Intel,"Itâ€™s not but the B50 is the only Arc Pro that isnâ€™t gated behind a bad vendor like Hydratech.    If they canâ€™t properly launch the B60, why should I trust Intel or itâ€™s partners with the B770 or some mystery GPU?",Negative
Intel,5060 is not nearly as performant as the 4070,Negative
Intel,"Interesting results. If this is representative for consumer laptops, Panther Lake is a much bigger upgrade than most here, including me, expected. But it almost seems too good to be true somehow.",Positive
Intel,is Geekbench a CPU or a GPU benchmark?,Neutral
Intel,"Hello LastChancellor! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
Intel,How does this compare to the Snapdragon X2 Elite?,Neutral
Intel,4 pcores  8ecores 4 lpcores..,Neutral
Intel,"Geekbenchâ€™s scaling has always been problematic, and the differences between architectures are huge. The benchmark is very friendly to ARM and least favorable to AMD. Even a random Apple M5 chip can easily score close to 20,000.  Therefore, cross-architecture comparisons using Geekbench scores have little real meaning. The only valid reference is **same-generation, same-architecture comparisons**, such as between the 285H and 388H.  Based on the actual results, the improvements are about **9% in single-core** and **21% in multi-core**. Given that the 285H scores around **22,500** in Cinebench, I estimate that the 388H should be able to reach roughly **24,000**.  But the key point is **power efficiency at lower power limits**. For example, if the 285H needs around **80W** to reach 22,500, then the real question is:  * How much power does the 388H need to reach 22,500? * How many watts does it take to exceed 20,000?  This is what really matters. If the 388H can achieve 2**0,000 at 35W**, **22,500 at 60W**, and **24,000 at 80W**, then that would represent massive progress. It would also strongly indicate that Intelâ€™s 18A node indeed offers significantly better energy efficiency than TSMC's N3B.",Negative
Intel,"Is Intel just ""squeezing the toothpaste"" again ? Even a low-frequency single-core 288V gets 2,700+ on Geekbench, while the 285H gets 2,600+ in single-core and 14,785 on multi-core. Therefore, TL;DR: I don't see Panther Lake being a huge improvement over the current Alder/Arrow Lake pairing. We will have to wait and see the power consumption, though.",Neutral
Intel,"Iâ€™m sorry, but thatâ€™s awful? Only 9% better single core when it has a better node and a newer architecture? Compared to what Apple and Qualcomm achieve every year, thatâ€™s pathetic",Negative
Intel,"Probably because GeekBench 6 only scales to a certain point, where more cores wonâ€™t help with improving performance compared to improving core IPC",Negative
Intel,"Fr, I really need to get a new light laptop (bc my old one's hinge is broken), but starting to feel  like I'd be better off waiting for Panther Lake than compromising with a bulky gaming laptop....",Negative
Intel,"Geekbenchâ€™s scaling has always been problematic, and the differences between architectures are huge. The benchmark is very friendly to ARM and least favorable to AMD. Even a random Apple M5 chip can easily score close to 20,000.  Therefore, cross-architecture comparisons using Geekbench scores have little real meaning. The only valid reference is **same-generation, same-architecture comparisons**, such as between the 285H and 388H.  Based on the actual results, the improvements are about **9% in single-core** and **21% in multi-core**. Given that the 285H scores around **22,500** in Cinebench, I estimate that the 388H should be able to reach roughly **24,000**.  But the key point is **power efficiency at lower power limits**. For example, if the 285H needs around **80W** to reach 22,500, then the real question is:  * How much power does the 388H need to reach 22,500? * How many watts does it take to exceed 20,000?  This is what really matters. If the 388H can achieve 2**0,000 at 35W**, **22,500 at 60W**, and **24,000 at 80W**, then that would represent massive progress. It would also strongly indicate that Intelâ€™s 18A node indeed offers significantly better energy efficiency than TSMC's N3B.",Negative
Intel,cpu,Neutral
Intel,"Probably one of the worst benchmarks out there for multicore tbh, Iâ€™d be more curious about the cb r24 scores",Negative
Intel,"Panther Lake doesn't bring any major changes to the cores. It's mainly about bringing node shrink, redesigned SoC, and new iGPU.",Neutral
Intel,"Itâ€™s obvious that this is the viewpoint of an outsider. Professionals would never look at it this way. Professionals first evaluate a processor based on its specifications, features, and process technology. Lunar Lake and Arrow Lake are *not* using some outdated process â€” they use TSMCâ€™s then-most-advanced N3B node, Intelâ€™s first time adopting it. Meanwhile, Panther Lake uses Intelâ€™s own **18A** process.  Based on the current benchmark results, Intelâ€™s 18A appears to outperform TSMCâ€™s N3B by at least the same margin that **Intel 4** trailed behind N3B â€” which is an astonishing result.  Every day you hear people saying how much TSMC has advanced, how far ahead its processes are, how â€œoutdatedâ€ Intelâ€™s nodes are, how AMDâ€™s processors using TSMC have excellent efficiency. These kinds of statements have been repeated endlessly over the past decade.  Yet today, Intel is using its newest process node to **clearly surpass** TSMCâ€™s top process from just one year ago.",Neutral
Intel,"the real test will be how many watts the X9 388H needs to achieve its scores, because the 285HX needed like 90 watts to achieve its scores  so if the X9 could hit its scores while on its base TDP (65 watts) then thats a \~40% increase in efficiency, not bad",Neutral
Intel,"But it does that while clocked almost 6% lower, so the IPC gain is actually decent. Especially considering most people expected Panther Lake to be a side grade because of the small architectural changes on the cores.",Positive
Intel,"For the use cases of PTL, Geekbench (which is mostly consumer focused) is a good indicator.  It doesn't assume that its workloads are perfectly parallel, it assumes some threads are used more heavily than others, so its value in nT is influenced by its 1T.    If someone is using this for rendering or other highly parallelizable workloads they might want to look into a subtest or into an alternative benchmark, but for typical consumers it seems like Geekbench is a good approximation of their experience.",Positive
Intel,"Geekbenchâ€™s scaling has always been problematic, and the differences between architectures are huge. The benchmark is very friendly to ARM and least favorable to AMD. Even a random Apple M5 chip can easily score close to 20,000.  Therefore, cross-architecture comparisons using Geekbench scores have little real meaning. The only valid reference is **same-generation, same-architecture comparisons**, such as between the 285H and 388H.  Based on the actual results, the improvements are about **9% in single-core** and **21% in multi-core**. Given that the 285H scores around **22,500** in Cinebench, I estimate that the 388H should be able to reach roughly **24,000**.  But the key point is **power efficiency at lower power limits**. For example, if the 285H needs around **80W** to reach 22,500, then the real question is:  * How much power does the 388H need to reach 22,500? * How many watts does it take to exceed 20,000?  This is what really matters. If the 388H can achieve 2**0,000 at 35W**, **22,500 at 60W**, and **24,000 at 80W**, then that would represent massive progress. It would also strongly indicate that Intelâ€™s 18A node indeed offers significantly better energy efficiency than TSMC's N3B.",Negative
Intel,"Is macOS not an option? Because IMO, MacBook Air is *the* thin and light laptop to get, hands down.",Positive
Intel,"Couple of subtests leverage some new arm vector instructions and get huge scores, but those have limited influence to the overall score. Apple is better across the board, though the difference isnâ€™t as big as the overall score suggests.   One difference is that since geekbench is distributed as binary itâ€™s compiled more directly for apple architectures specifically while others use more generic targets. But that has very limited effect.",Neutral
Intel,But they have a gpu compute test too,Neutral
Intel,"Geekbench claims it's much more realistic than those multicore tests that scale nearly perfectly with tons of cores, and I think that's a fair take. It's not as if they didn't know how to create a benchmark that scales like other nT tests do, geekbench 5 nT does that.   I wouldn't call it worse, just different.",Positive
Intel,Geekbench runs common workloads as they are commonly implemented. It gives you a score on how well a multi core implementation of that workload would actually run in that CPU.   I think that is far more useful than some perfectly parallel workload measuring max power and core count.,Positive
Intel,"I have carefully compared the various models across Geekbench, PassMark, and the differences between Meteor Lake, Arrow Lake, and Lunar Lake. If my judgment is correct, the theoretical peak performance of the 484 in Cinebench R23 should reach around **24,500**; the 285H scores **22,500**. Compared with the 285H, it should be easier for the 484 to achieve high scores because its power requirements are significantly lower than the previous generation built on TSMC N3B.  Its peak performance will not be extremely strong because the frequency is not high. IPC is likely improved by around **10â€“11%**, but clock speeds drop by about **6%**. Overall, that means single-core performance should only rise by **4â€“5%**.  The improvement will be most noticeable in Geekbench. Since PassMark single-core also shows gains, the IPC uplift and resulting single-core increase should be quite certain. If Geekbench were the only source, it would still be questionable, but PassMark is more solid and has higher reference value.  Overall, in terms of peak performance, the uplift is averageâ€”around **10%**, close to that figure.  However, the real key is the **efficiency gains**. I believe they will be excellent. Compared with the 285H, which requires **65 W** to reach **20,000** points in Cinebench R23, I estimate that the **388H** may only need **40â€“45 W**.  I also estimate that the Cinebench R24 score should fall around **1300â€“1400**. Compared with Qualcommâ€™s X Elite 2 at **1950**, there is still a significant gapâ€”but the two products differ drastically in scale.  Overall, Panther Lakeâ€™s greatest achievements lie in several aspects:  1. **Energy efficiency** â€” likely the best among all x86 products. 2. **Performance per mmÂ²** â€” excellent. For example, the 484: if you look at its die shot, the total area of the CPU (including the CPU tileâ€™s 4P and 4 LPE cores and all caches) is essentially equal to the die area of a traditional monolithic 8-core design. That means the 484 uses the same silicon resources as past 8-core chips, yet **no AMD mobile 8-core processor surpasses it**, either in raw performance or efficiency. 3. It also offers better performance-per-area than Qualcommâ€™s processors. The X Elite 2 has **18 cores**, including **12 â€œvery largeâ€ cores**â€”similar in size to Intel P-coresâ€”and **6 large cores**, each larger than Intelâ€™s E-cores. The die area of this chip is **2.5Ã— larger** than Panther Lake 484â€™s.",Neutral
Intel,"I mean, it does bring SOME changes to the cores, both are a next generation, it just isn't a more radical change like will be happening with NVL.  A mid single digit improvement is still pretty decent.",Positive
Intel,">The benchmark is very friendly to ARM and least favorable to AMD.Â   How so?   >The only valid reference isÂ **same-generation, same-architecture comparisons**,  Geekbench is nice because it explicitly allows cross ISA comparisons. You don't have to take my word on it either, Intel and AMD themselves have used geekbench before to compare themselves to the ARM competition.   Same thing applies to spec and cinebench 2024.",Positive
Intel,"What's with the Cinebench fascination? At any rate. Geekbench 6 runs a raytracing test, and the 388H leak shows it at 29700 points compared to a 285H scoring 25300 points. That would place the Cinebench R23 scores at about 20% higher for the 388H  https://browser.geekbench.com/v6/cpu/15500755  https://browser.geekbench.com/v6/cpu/15474224  At any rate, the reason Geekbench doesn't scale perfectly with more threads is because a lot of workloads hit scaling limits due to Amdahl's Law, or memory bandwidth limitations. This applies to SPECint and SPECfp results for multiple threads as well.",Neutral
Intel,My old 14900hx gets 35k multi core in cinebench r23,Neutral
Intel,better go for cb2024 cuz r23 is being less relevant these days,Neutral
Intel,"lemme know once UTAU and Fighter Maker 2002 works on Arm macOS    (my point is that I work with a lot of old abandonware apps that barely even run on x86, so there's no chance in hell they gonna work on macOS)",Neutral
Intel,"Thus useless to compare high CPU core counts.  If you actually need more than 8 cores you also have workloads that scale much better than Geekbench 6. It's especially dumb to claim this CPU is close to a 16 core, 32 thread zen 5 cpu based on Geekbench...",Negative
Intel,I have workloads that scale fine with 16 threads and would scale fine with 32. People who actually buy high end multicore CPUs have a use for them.,Positive
Intel,It runs for far too short a time to reflect accurate multi-core performance.  People don't get a multitude of cores to run a task for a few seconds.  They do it for tasks that take minutes or hours to complete.  I'd argue it spends too little time on single-core tests as well.  I don't trust it to provide any useful information about anything other than transient performance.,Negative
Intel,I agree but the problem is it's being mindlessly used to compare MT scores as in this article.,Negative
Intel,Bro there's no need to spam this same comment like 4x in the same post's comment section T-T,Negative
Intel,"Why's the scaling ""problematic""? Its nT scaling is by design because GB6 is trying to replicate common consumer workloads which are rarely embarrassingly parallel. If you wanna see how well nT scaling for rendering is, there's cinebench for that.",Neutral
Intel,"was your 35,000 score achieved with power consumption above 100W? Can you try it now at 80W and see how many points are left? Also, limit it to 40W and check if it can reach 20,000 points. Because I estimate that the 388H has a chance to hit 20,000 points at 40W.",Neutral
Intel,"Ok, a simple no would have been fine.   Seems like those extremely old apps would run on any old POS x86 machine, if anything harder to run on modern hardware but hey what do I know. Best of luck.",Negative
Intel,"I mean, shortness is more of a problem if a device can cool itself properly or not rather than a problem of the CPU itself, unless said CPU in question is impossible to cool in that form factor",Neutral
Intel,Geekbench correlates with SPEC really well while taking a fraction of the time to run. Making it run for more minutes changes nothing,Neutral
Intel,"It provides useful information about the chip itself to real computer architecture enjoyers. Idk if gb6 changed it but geekbench has historically correlated with spec scores. Longer running programs like cinebench test the whole system including the thermal solution but geekbench gives a much better view into the pure performance of the cpu itself (and the associated memory system :/). Besides, you can always slap on a bigger cooler if thermals are that limiting.",Positive
Intel,"It's being used for comparison because that's what we have. AFAIK, this is the *only* 388H benchmark we have",Negative
Intel,That looks like an AI post to me,Negative
Intel,It has been going hayway since SME just like GB5 had issues with AES Skewing results,Negative
Intel,Fair enough but I'd rather they kept something similar to GB5 multicore test in addition to their new 'more realistic' one.,Neutral
Intel,Incredible hardware news. Thanks for the share.,Positive
Intel,"This was sarcasm, by the way. A video from Usagi Electric on how computers count isn't hardware related but this is? OK mods.",Neutral
Intel,"Frankly, I wouldn't buy one for gaming, though I must admit Battlemage is pretty sweet for video editors thanks to 10-bit AV1 and 4:4:4 chroma on the HEVC side + you also get two codec engines (at least on the B580 with the same G21 core).  For perspective, you'll have to move up to Nvidia GB203 (RTX5070Ti), or better, to get your hands on two or more NVENC engines for the same 10-bit AV1 + 4:4:4 H.265.  If I was a serious video editor, this is *the* graphics card I would get.",Positive
Intel,The main bit that intrigues me about these ARC GPUs is their Linux gaming performance & how they compare to their windows performance.,Positive
Intel,"One interesting data point is he's testing with 7500f. We have no comparison with contemporaries or higher end CPU to examine CPU bottleneck, but it's a realistic scenario and system for the card.  Interesting how that 1gig made all the difference in TLOU2",Positive
Intel,Not in the same system the 1080 ti was in.,Neutral
Intel,"idk why, intel gpu is so expensive in my country like bruh that gpu perform worse than cheaper nvidia/amd. those sucker trying to scam buyer just cause ""intel"" name in it.",Negative
Intel,Yeah intel's quick sync is very good at video editing and streaming as well. Even preferred over nvenc in streaming (no idea about video editing),Positive
Intel,"I would and I did (Intel B50 gpu).  So far, zero regrets and zero issues on linux.  Edit: Fedora for those that are curious.",Positive
Intel,Rumour has it Linus torvalds uses an Intel card because he wanted something on a budget that could drive dual 6k screens.,Neutral
Intel,"For desktop use Intel on Linux is great, but gaming performance and compatibility is horrifically bad.",Negative
Intel,Iceberg's intention always been to show realistic performance and average user would get with prices imaginable lol. Otherwise for highest possible performance people would prefer gn or hub.,Neutral
Intel,"it's the retailers, they don't sell well and need higher margins",Negative
Intel,"Yeah retailer margin and taxes made arc GPUs very less desirable, in my country b580 is close to rtx 5060 in price",Negative
Intel,Its not a rumor lol he did a video with Linus tech tips and specifically requested they put a b580 in the PC they built him  [link to video](https://youtu.be/mfv0V1SxbNA?si=jT_3dFy1H40vrVjk),Neutral
Intel,"Performance is a little worse than on windows, but compatibility is not horrifically bad. It's pretty much the same as on windows.",Negative
Intel,"I believe Linus Torvalds wanted an ARC Pro B50, but settled for the B580 because that's what LMG could get their hands on",Neutral
Intel,can you imagine a bunch of nerds whispering about which graphics card an old man uses?,Negative
Intel,"I'm curious as to how much worse. I've considered an upgrade to a B570 due to them being seen for Â£150 new, putting it into used RX 6600/6600 XT territory, but if the Linux performance of say a B580 on Linux falls closer to either or, then it's probably not a worthwhile choice over the used AMD options for me.",Negative
Intel,"TLDW:    GPU Models Tested: MSI Shadow 2X RTX 5050, Intel Arc B580 FE      16 games average:    1080P, High-Ultra Settings:     Native TAA: Arc B580 is 14% faster, 23% faster at 1% lows due to higher VRAM        DLSS 4 Quality vs XeSS Ultra Quality: Arc B580 is ~11% faster     DLSS 4 Quality XeSS Quality: Arc B580 is ~20% faster     DLSS 4 Balanced XeSS Balanced: Arc B580 is ~15% faster     DLSS 4 Performance vs XeSS Performance: Arc B580 is ~14% faster",Neutral
Intel,"""There was a time, about a decade ago when the $250 price tag offered solid products, but the world has changed""  Yep, inflation. $250 in 2015 money is $342 in todays money. And you can get a very solid product at that price tier, the RX 9060 XT is $369 on Newegg.  GPU prices haven't gone up, you money is just worth way less.",Neutral
Intel,"5050 really has no right to exist at the price it does. B580 is obviously being sold at near cost or even a loss however, it's not exactly a fair comparison but that doesn't matter to consumers.  If you just want to game then I can't see any reason to consider anything else at this price point.",Negative
Intel,I'd still probably go nvidia here as I don't trust intel's compatibility with older titles and the like.   Still it would probably be better to spend $20 more on a 9060 xt 8 gb or $50 more on a 5060 than either of these.,Neutral
Intel,"If UE5 games generally run this poor on Intel GPUs, there might be trouble ahead as there are lots of those games in the pipeline.  You still couldn't get ~~more~~ me to buy an Intel GPU, even if I was desperate for a cheap GPU right now. I'd just adjust my settings.",Negative
Intel,"The B580 is decent enough, but it might be better to just save a bit more and get a 16GB 9060 XT for $350 or something. That card is likely to last 10 years flat at this point, and it will definitely last at least 5.  And yes the 5050 is not good. Getting something with a half-decent iGPU would be a better use of your money at that point.",Negative
Intel,The biggest issue is that he did not test PCIE 3.0 vs 4.0 vs 5.0. Those GPUs are very likely to go into budget builds or as upgrades to older motherboards like the B450.,Negative
Intel,Imagine spending $250 on a GPU when you could literally just save $100 more for like a 100% percent more performance.,Neutral
Intel,Wait isn't xess a lower resolution per quality setting?,Neutral
Intel,"yeah there is a reason why there are 5050s for 210  the thing is a sub 200 dollar GPU, which matches it capability and vram well, its more or less the I want to step up from igpu deal",Neutral
Intel,Maybe for the low end but high end I canâ€™t even buy a card at msrp outside of America.,Negative
Intel,"*ignores that this is a 50 tier product and should be compared with the 950 and 1050*  This kinda of ""but but inflation"" virtue signalling I'd very unhelpful to these kinds of discussions. It's as if you're saying people should stop complaining gpus are several times more expensive than they used to be with the actual low end market completely destroyed.",Negative
Intel,Tech is supposed to beat inflation. Look at monitors or TVs or SSDs (before now) or CPUs or ....,Neutral
Intel,All the tech tubers are just turning into old men shouting at clouds. They will probably all be replaced by younger people living in the now soon enough.,Negative
Intel,"First of all 250 euros bought way more gpu in 2015 than 360 does today. And the lower end and midrange gpus were much less cut down vs the high end chipa today.  A 5050 sits where the 750ti did when the 980ti was out. Now you get entry level performance for mid end prices  Have wages actually increased that much? Because that is the only useful measure of ""inflation"". Everything else is just corporate profits   If prices for everything go up but wages don't then that leaves less money for frivolous shit like ram and storage and laptops and consoles, not more.  Even in my country where our wages are automatically indexed to match inflation, our purchasing power has dropped because the actual cost of living isn't properly represented in whichever calculation is used for the inflation number.  Houses have gone up by 100+ percent since 2015, rents have gone up by over 60 percent, grocery prices have more than doubled, utility prices have risen sharply, public transport has more than tripled in cost.  Minor expenses like clothing or a tv you buy every ten years have stayed flat, but that isnt what people are spending 80 percent of their income on.",Neutral
Intel,"Shh, everyone knows that prices only go up on luxury goods due to evil corporations, after all how will people live without their computer not being 800% faster than last year?",Negative
Intel,"> Yep, inflation. $250 in 2015 money is $342 in todays money.   People really need to stop using CPI. I can bet you that GPUs don't make it to the market basket. Yes, your money's value has fallen but not by that much.",Negative
Intel,You're getting downvoted for speaking the truth.  The RTX 5050 should be a $150-180 GPU for the price and value it offers but unfortunately people are gonna defend the price tag that the card was set for by Nvidia,Negative
Intel,"For a while you could get them for $229, which would be more acceptable vs a 5060 for $299, making it the same FPS/$. But the 5060 is actually the one on sale right now for only $30-$35 more. 30% faster for like 12% more money.",Positive
Intel,"I'd say that the cheapest new GPU that I'd blanket recommend with no ifs, buts and caveats is the 9060XT 16GB, everything below that either struggles with outright performance, VRAM or software issues like Arc.",Neutral
Intel,"Intel checks all the right boxes on paper (generous VRAM, decent pricing compared to competitors, an alternative to the duopoly) but the recent CPU overhead stuff coupled with the crapshoot that is trying to play older games and it just isn't worth it",Negative
Intel,"Yeah they cover this at the start of the video https://youtu.be/lLe5AP6igjw?t=229   XeSS 1.3 shifts everything down a tier, so their quality scaling ratio is everyone elses balanced ratio.  Older versions of XeSS match DLSS/FSR scaling ratios.",Neutral
Intel,"I know quality is, not 100% sure about others. dlss quality preset uses higher resolution than XeSS and FSR quality presets",Neutral
Intel,Its fine for people who need a dGPU but not a beast for work. think stuff like CAD or Photoshop. It will also be fine for people who only play competitive multiplayer games.,Neutral
Intel,Nvidia cards are bellow MSRP here in eastern europe. AMD cards slightly above MSRP.,Neutral
Intel,"They are all selling below MSRP in the UK. Â£979 is MSRP for a 5080 and I can buy 3 in stock models for less than that price without much searching, at scan.co.uk.  If you are in South America its probably your countries insane import taxes, protecting their home grown GPU market lol.  29 upvotes from children who have not bothered to check or do any kind of reasoning.",Neutral
Intel,"> Tech is supposed to beat inflation.  And it does, wtf are you trying to claim?  $100 CPUs these days run circles around 6700K which was the flagship in 2015. A B580 is faster than a GTX 980 Ti, which was the flagship card of 2015.",Neutral
Intel,"It does. For the price of a 1993 CRT TV, you can get a flat-screen LED thrice the size and with 10 times the resolution.  SSDs? A 2 TB nvme is a fraction today than a 128 GB Sata one was a little over a decade ago.   What actually changed is inflation, and that the buying power of today's middle class person decreased significantly relative even to the 2000s.",Neutral
Intel,Gpus are way more expensive to produce,Negative
Intel,"> Tech is supposed to beat inflation.   It does, despite wafer prices increasing the last 10 years.",Neutral
Intel,Wrote a fucking who? The fact that TVs are cheaper in nominal terms than they were 15 years ago does not mean it has to be the same thing with every other tech product. TVs are not products manufactured necessarily on cutting-edge expensive nodes.,Negative
Intel,"It does. For the same amount of money, you get way better GPU(unless your braindead thinks the gtx970 has same performance of 9060xt)",Positive
Intel,"It does, but also, inflation has been extremely bad for 5 years.",Negative
Intel,"You are just making shit up at this point. NVIDIA GeForce GTX 760 (2013) release price: $250.   That was a shit card, arguably a worse product than the 9060 XT is today, when you compare it to contemporary rivals. How do i know it was shit? I had it.",Negative
Intel,TSMC inflation is FAR higher than CPI. You are half right,Neutral
Intel,"according to US bureau of labour staticstics that measures the CPI it includes  all personal computers (desktops, laptops, tablets) and related equipment (printers, monitors, smartwatches, smartphones). It does not look at GPUs specifically, but the effect of that will be visible.",Neutral
Intel,I doubt ppl are gonna defend the 5050 considering a 5060 or an 8GB 9060XT is not much more and a fair bit faster.,Negative
Intel,"i mean, the 5050 off of amazon rn is 210, so it is getting there as a sub 200 dollar GPU for improving over iGPU right",Neutral
Intel,I pretty much but there's nothing else people *trust* in the category because apparently Arc cards are for professional nerds or something whereas I haven't had a real bad driver issue in over 2 years with my A770  People are also conditioned to fear older gen GPUs so 6xxx and 7xxx parts are sitting on shelves waiting for blowout discounts. People would still rather spend more on a basic nvidia from the 5000 series.,Negative
Intel,B580 user here. I coupled it with a R5 5500 and as of the recent updates the card just seemed to run much better vs when I got it last July.  There was a video before which also revealed that the CPU overhead is now being addressed in subsequent updates.  https://youtu.be/gfqGqj2bFj8?si=PyAfB2NhqZKWWVXY  Iâ€™d say itâ€™s getting better and that Iâ€™d recommend it over a 5050 since the overhead is now fixed/negligible.,Positive
Intel,Intel is in their second GPU generation. Its going to take a lot longer to catch up with the institutional knowledge and practical application in videogames that the others were developing for over 20 years. The CPU overheard was not an issue in Intel iGPUs and Alchemist because GPUs never got fast enough to matter. It is only now that they noticed that issue since the GPU is far enough to create it.,Neutral
Intel,And that only in terms of native resolution and does not mean equal final image quality.,Negative
Intel,\>dlss quality preset uses higher resolution than XeSS and FSR quality presets  Not exactly. FSR and DLSS are evenly matched in internals at all quality presets.,Neutral
Intel,Iâ€™m in Australia lol. The msrp for the 5090 is 1999 USD which translates to 3011 AUD The cheapest 5090 is 4800 AUD. Thatâ€™s not even close at all to the msrpâ€¦,Neutral
Intel,"It sure is funny every time all those 6700k/8700k era CPU's pop up on used parts sites or FB Marketplace and still expecting close to initial prices.  Who even buys them anymore? At least a Q6600 has retro value ,but those are just obsolete.",Negative
Intel,"Not if you consider how the workloads being run on them have also changed. A GTX 970 ($450 inflation adjusted) would have run 2015 games better than how a RTX 5060 Ti ($429) or 5070 ($550) run 2025 games.  In other words, demand for performance has outstripped performance improvements, and those improvements are not felt as much.",Neutral
Intel,"A 100$ CPU in 2015 would easily run 2015 made software. A 100$ CPU in 2025 would barely run the electron JS slop. This includes Windows.  In 2015 my run-of-the-mill laptop (cost 300-400 bucks at that time USD equivalent) instantly opened the control panel when I clicked or file explorer even with a old HDD. Now? It needs few second to run settings, it lags when opening notepad, it is disgustingly slow while navigating file explorer on my 1000 dollar ""gaming laptop"" with NVMe SSD.  Yes yes yes it is very good on benchmarks but I don't stare at benchmarks all day. I use my computer for things you do at computer. Don't force my CPU to crunch how much digits of Pi it can compute.  A 980 Ti can easily run top 2015 games. Now? My laptop barely runs modern AAA games without looking a blurry mess. I simply can't fucking understand how you people look at the glorified motion blur and call ""yup it is the pinnacle of computer graphics"". How the fuck majority of modern AAA games look any better than RDR2 can anyone fucking tell me?",Neutral
Intel,"Why aren't you comparing relative buying power of 2014/2015 vs now then?  $650 got you what in 2014, a GTX 980TI?  $330 got you what in 2014? How close to the top end are both these things?    That's $900/$455 today, thereabouts.  What does $900 get you today?  Does that buy you anywhere near the top end?  And how does that product compare in relation to others above and below it?  Because the $330 product in question ($455 today) got you about ~75% to top end performance for ~half~ MSRP of the 980TI.  How does a $455 product of today square up relative to the top end?   Why don't we throw in a GTX 980TI vs a GTX 280 comparison while we're at it.  Make things really interesting.  I'll let you fill in those blanks (along with the $330 card in question) hoping you actually learn something in the process here.  The bar is very low, try not to trip.    The underlying point that user was making was pretty obvious if you read the comment they responded to.",Neutral
Intel,"cmon man, give him some slack, he just made shit up cause it's convenience for his argument.",Negative
Intel,How is it comparable? The 9060 XT is a very good card for 250. Ideally it'd be around 200 or below but for 250 you get a card that's a bit overkill for even 1080 P gaming.,Positive
Intel,In quite a few countries the 9060 XT is at or below the RTX 5050s MSRP.,Neutral
Intel,Then why did the comment above mine get multiple downvotes? It's Reddit and that's how it goes unfortunately,Negative
Intel,6x and 7x are priced far too high for old stock and are poor value compared to nvidias 50 series. They really haven't had a good price/performance low-mid end card since the 6700XT which are extinct at retail.,Negative
Intel,"I think they must have to go into every game, and adjust that t fix it, because it's not a universal fix it seems. Maybe per-game optimizations .",Negative
Intel,yep. XeSS 1.3 is closer to DLSS 3 rather than DLSS 4 in terms of image quality. Its good enough to game on in my opinion.,Positive
Intel,"> Who even buys them anymore?  The best SKUs on sockets have always demanded a premium in the used market. Since that's where people upgrading old machines will go.  And many machines from OEMs are not readily upgradable with just new boards/CPUs combos. Since they use custom form factors etc. So it's either a in socket upgrade or replace the whole machine. The socket 6700k is on is also especially affected by the ""premium"" factor. Since there's no lower end SKU with 4C/8T. You either get the 6700/7700 variants or are stuck with lower thread count.",Negative
Intel,"> would have run 2015 games better than how a RTX 5060 Ti ($429) or 5070 ($550) run 2025 games.  I think your memory is impacted by the expectations at the time. And the problem of reviews often using older titles inflating numbers, ffs some are still benching with GTA V to this day.   The [970](https://tpucdn.com/review/nvidia-geforce-gtx-1060/images/witcher3_1920_1080.png) couldn't even get 60 fps in witcher 3. Which was released in 2015.  And the performance it got in Witcher 3. Was not much better than what the 5060 Ti got in [Black Myth Wukon](https://tpucdn.com/review/msi-geforce-rtx-5060-ti-gaming-16-gb/images/black-myth-wukong-1920-1080.png)  Which even including 2025 titles. Is one of the hardest/heaviest titles with the worst performance. You can expect much better performance in almost every title. Just like the 970 was doing better than it did in Witchers 3.   But to argue that we got a lot better performance back then in the games releasing at the time, that is just false.",Negative
Intel,Yes 3.5GB of memory in 2015 was soooo much better than 12GB today /s,Positive
Intel,"All the GPU makers are betting on you using DLSS/FSR/XeSS as part of your usage to play games. Maybe even frame generation along with Relex, and all the other tech they ship GPUs with. They used to only rely on you using regular AA techniques.   If you ignore all those options you have today, and pay like it's 2015, it might be worse a lot of the time. If you use those options, you're generally way ahead of where a GTX 970 would fall. So it depends if you're willing to adopt new rendering tech, or rejecting it.",Neutral
Intel,"No, not really, in 2015, you happily accepted 45 FPS on not the highest settings at 1080p",Neutral
Intel,"This don't sounds like CPU problems at all, more like either Win11 is a vibe coded pile of bugs, or ACPI problems.",Negative
Intel,"> Now? It needs few second to run settings, it lags when opening notepad, it is disgustingly slow while navigating file explorer on my 1000 dollar ""gaming laptop"" with NVMe SSD.  Something is wrong. I keep reading people's experiences of stuff like this and I haven't experienced it, I'm not doubting it but I'm so curious as to what is wrong.  In particular I read a lot of people saying Windows Explorer takes forever to open etc",Negative
Intel,"> In 2015 my run-of-the-mill laptop (cost 300-400 bucks at that time USD equivalent) instantly opened the control panel when I clicked or file explorer even with a old HDD. Now? It needs few second to run settings, it lags when opening notepad, it is disgustingly slow while navigating file explorer on my 1000 dollar ""gaming laptop"" with NVMe SSD.  That's Windows for you.",Negative
Intel,it does not matter how close to the top GPU is. its a completely useless comparison.,Negative
Intel,I'm not sure what you're saying. The 9060xt is $250 only in 2013 money. They are arguing it's better value than a GTX 760.,Neutral
Intel,"Ppl up/downvote kinda randomly, doesn't really mean much post can go from +/-20 to the opposite real quick sometimes.  Anyways It's at +8 currently was at +something(2 maybe?) when i commented so who cares.",Neutral
Intel,"Nvidia and AMD do a lot of per-game optimization in the driver as well. In some cases very brutally, for example Nvidia is known for grabbing all games DX12 drawcalls and rearranging them in driver because the way game handles it is inefficient.",Negative
Intel,I remember upgrading to a 970 in 2016 and still being unable to max Witcher 3 at 1080p60 but got close enough,Neutral
Intel,"funnily enough, GTA 5 Enhanced Edition can be quite a benchmark for ray tracing nowadays. But it took to this year for it to be released. I think we can consider it a testbed for whats going to be implemented in GTA 6.",Positive
Intel,"Bringing up 1080p no RT Wukong benchmarks sort of makes the point for me: the only way these cards look comparable is if we pretend features and standards are the exact same they were a decade ago.  High res and high refresh monitors were a luxury in 2015, now they are a dime a dozen. RT was not a thing in 2015, now it is and Nvidia marketing really wants you to use it. It's like you're comparing Witcher 3 on Ultra settings to Wukong on Medium or High settings, and acting like it's apples to apples.  The moment you take modern displays and features (including DLSS to be fair) into account, it paints a picture where technology has moved on, developers and players would love to move on, and GPUs are struggling to make that jump.",Neutral
Intel,"if you run out of memory today the game swaps textures and continues running, it just looks uglier.   If you run out of memory in 2015 it starts using the superslow 0.5 GB and everything breaks.",Negative
Intel,Nvidia is certainly expecting DLSS+FG to be the typical use case. The vast majority of their benchmark and marketing material is with those two.,Neutral
Intel,"I've got nothing against DLSS, I use it whenever I can, but sometimes it's just not enough to bridge that gap.  Another user brought up Witcher 3 and Wukong as an example of a graphically advanced 2015 game vs a graphically advanced 2025 game. The 970 would get 50+ fps on Ultra settings Witcher 3. Max out Wukong on a 5060 Ti and no amount of DLSS will make that card stop crying and screaming.",Neutral
Intel,"Like, Debian has no issues running on a n150 with multiple docker containers without instantly spiking the cpu to 100%.",Neutral
Intel,"I found a way to sort of kinda make file explorer slow. But its really a perfect storm thing. Have multiple screens, one of which is running in HDR and another in SDR. Have the file explorer tree open. Have a HDD, slower the better.  When you browse folders it refreshes the tree. When it refreshes the tree it asks connected devices if they are online, including the HDDs. Now move the window back and forth between your screens. When the explorer moves into HDR screen, it gets redrawn. Same when it moves to SDR screen. I suspect but cannot confirm there is a bug where the old instance is not cleaned correctly. So now when you browse it asks all devices if they are online 10 times. 100 times. At some point youll start noticing actual delays in opening folders.  Works even better if you havent restarted for a month.",Neutral
Intel,"the opening notepad thing, if you use taskbar it has a bad habit of not actually opening notepad until it finishes the online search for apps called notepad or whatever you typed. Disabling online search in start makes it fly really fast.",Negative
Intel,The 9060 XT 8GB is currently retailing for 250$ in many areas. I'm saying that the 760 isn't an ARGUABLY worse product. It is a worse product for it's time straight up.,Negative
Intel,"Fair point, but isn't lower and competitive prices good for us?",Neutral
Intel,">  and acting like it's apples to apples.  Apples to apples would be comparing W3 performance for both cards.  Wukong even without RT is a CONSIDERABLY more advanced game graphically than original W3.   >High res and high refresh monitors were a luxury in 2015, now they are a dime a dozen.   And? Better monitors showing up doesn't change the laws of physics and basic economics. It doesn't make scaling with die shrinks suddenly increase. With your logic the 970 was a terrible deal vs some early/mid 2000s GPUs that delivered better FSP at 1024x800 in games released at the time.   And before you start harping on about die sizes. The die in the 5060 Ti is actually more expensive than the die used on the 970. Wafer price increases more than compensates for the size difference.",Neutral
Intel,"Looked it up. Wither 3 got 52 FPS at Ultra settings, no Nvidia Hairworks turned on, for a GTX 970. Wukong gets 42 FPS at the cinematic preset native resolution, which is actually intended for cinematics, but developers allow people to enable anyways. As Digital Foundry has said, they maybe shouldn't.  Gets over 70 FPS if you turn the preset down 1 notch to high. No upscaling, or frame generation, or hardware RT, which is like what Nvidia Hairworks was for Witcher 3. It's really not hard to get Wukong to run at 90 FPS on a 5060ti with some minor tweaks.",Neutral
Intel,According to TPU review maxed out Wukong with DLSS got 42.3 fps. Not exactly the 50 fps you remmeberr for witcher but close. Heres a link to the review: https://www.techpowerup.com/review/black-myth-wukong-fps-performance-benchmark/5.html,Neutral
Intel,"That's very interesting thank you, I can definitely see why I haven't experienced it.  You genuinely wonder how Microsoft are testing these days.",Positive
Intel,"> With your logic the 970 was a terrible deal vs some early/mid 2000s GPUs that delivered better FSP at 1024x800 in games released at the time.  Except in practice from 2005 to 2015 you got considerably more advanced graphics *and* higher resolutions *and* generally higher framerates too. Now either you pay up or you gotta pick one.  As for the rest of your post, it's more of a digression. All I said is GPUs are failing to keep up with the rest of hardware and software, not that there are no valid reasons for it.",Negative
Intel,"> As Digital Foundry has said, they maybe shouldn't.  hard disagree. As someone who does not have a lot of time for videogames and often end up playing older games with newer cards, those beyond high settings are great as it allows me to make use of my newer card and make the old game look better.",Neutral
Intel,"I disagree with comparing RT to Hairworks, when the visual impact as well as the emphasis put on it by Nvidia is so much bigger. I also disagree with using 1080p as a reference for Wukong, when high res and high refresh rate monitors are as cheap and plentiful as 1080p was back then.  Imagine you went back to 2015 and told the GTX 970 guy he's supposed to play his games at 2005 resolution and turn off antialiasing, how do you think he'd react?",Negative
Intel,">All I said is GPUs are failing to keep up with the rest of hardware and software, not that there are no valid reasons for it.  Why complain about something that there are valid reasons for lol",Negative
Intel,"It just makes such a small difference in UE5, it's really not worth losing 30% performance over for this engine. They would agree with you for a lot of other games, and Avatar Pandora kind of has a hidden setting, they'll maybe make available in menu at some point. Right now you need to modify a config file to enable it. Maybe they just need to wait until the final patch of a game to show those settings, years after launch, or just name them ""next gen"" or ""experimental"" with the setting below called ""ultra"".",Negative
Intel,"You can use DLSS and frame generation to play at higher resolutions. That's their intent. Especially UE5 games, because TSR was developed by Epic for a reason. The games on UE5 are really never intended to be run at a native resolution. I don't tell people to run UE5 at a 2013 resolution, but I also don't tell them to have the 2013 mindset that everything has to be run at native resolution, and that's the only way to play it. 1440p Balanced DLSS should give you around 50-60 fps without frame generation.",Neutral
Intel,"The performance loss does not mater for future (re)plays.  The config settings are usually hidden because during testing there were instabilities found that they didnt think was worth fixing. There were some games that had settings beyond ultra with names like ""Extreme,"" ""Nightmare,"" or ""Insane"".",Negative
Intel,"Intel GPUs have come a long way, and part of that journey was from A to B. The current lineup are th B series and are regarded as significantly better than the A series. I recommend B580 GPUs for gamers on a budget. It's a good card, and most of the a series issues are gone. Drivers work, upscaling happens, compatability is good.  tldr: Current Intel GPUs are fine, just avoid the A-series",Positive
Intel,"A580? Nah not that much, the RX 6600 and RTX 3050 are the same price and generally either have better better performance or better tech, both have better optimization, the Arc B580 though, absolutely as it has good drivers and is on the same level as a 4060 for a lower price",Positive
Intel,Look up the model on Gamer's Nexus. They seem to like them for the price point and pointed out that updates have fixed a lot of initial issues.,Positive
Intel,so will b570 be fine?,Neutral
Intel,"I wonder why no one ever recommends the B570. Sure, it might be less powerful than the B580, but I suppose that has to work better for certain CPUs that aren't that powerful",Negative
Intel,"Sure. It's about 10-15% slower than the B580, so take that into account when doing ""fps/$"" calculations in your head.  https://www.techpowerup.com/review/asrock-arc-b570-challenger/32.html",Neutral
Intel,oh i deadass forgot that gpu existed ngl,Negative
Intel,"Drop a 5800XT in it and see what it does, if thats not enough, grab a 5070 (or 5060ti) and you should be good.",Neutral
Intel,Best option is probably a deal on a pre-built unless you live near a Microcenter and can grab a CPU/Mobo/RAM bundle.  Do you have a budget?,Neutral
Intel,pick up a used 5700x and a 9060xt / 5060ti.   Don't go wasting money on a 5080.      And chill.... you don't NEED 144hz to survive.,Neutral
Intel,"You should upgrade your CPU & GPU, what is your country and maximum budget for an upgrade? What is your budget for a new build?",Neutral
Intel,will your motherboard support a 5700X and DDR4 3200 memory (if that's not what you already have).    If so you'd be fine to get a new cpu and and GPU (provided your PSU can handle the load.... 50 series cards are thirsty.   If your MB is going to have issued (doesn't support pcie gen4x16 then I'd think about a whole new system...  But RAM cost is HUGE!!!!  so maybe upgrading everything around your existing DDR4 ram is a better option?,Neutral
Intel,"I would say upgrade the cpu since that game is cpu intensive. Your gpu is fine honestly  5700x/5800x/5800xt are all fine options, just choose based on what the pricing is in your area",Positive
Intel,"Your first question to yourself should really be ""what is my budget?""  Otherwise, we'd all be scrapping our rigs and building new ones every 3-6 months",Neutral
Intel,First question is - what is your budget .? 5700x CPU + 9060xt GPU or 9070 non xt . Very good performance increase,Positive
Intel,"Either upgrade to a 5800x/xt and grab a new GPU, grab a microcenter or newegg bundle, or find a prebuilt",Neutral
Intel,[This video](https://youtu.be/oF3gLKmYqpE?si=If70o-_RamZOxXJS) suggests the upgraded GPU will have the desired effect even if there is some performance left on the table. This might now be a bad thing as when the (if!) price of RAM comes back down I can upgrade the rest and keep the GPU.,Neutral
Intel,5700x3d/5800x/5800x3d would be a good upgrade,Positive
Intel,"That's the CPU I have. I upgraded to it at the beginning of last year. My system is a 5800XT paired with a 5070 TI and 32gb of DDR4. It does everything that I want it it, in the resolution and fps that I want. Except for Tarkov. It looks great, but without Smooth Motion, I'm only getting 70-100 fps with maxed out settings on most maps.  I actually just recently upgraded to the 5070 TI, from a 3080. Nice jump. I think later this year, I am going to upgrade to AM5 and I really want an X3D chip, so probably the new 9850X3D. I'm also going to shoot for 64gb of DDR5, unless it's still $1k. Lol!",Positive
Intel,"That would mean spending Â£200ish on the CPU, and then Â£1000 On the GPU and a couple hundred on the PSU. A new 5080 pre-built is around Â£2k.",Neutral
Intel,UK. We have very few options for walk in PC component shopping.      Around Â£1000.,Negative
Intel,r/usdefaultism,Neutral
Intel,No but if my 3060 isn't hitting that at 1080p what hope does it have for 1440?,Neutral
Intel,"If the solution is a complete build I'll hold fire while I save as I don't want to buy a new machine that's less capable than I'd like.      My first PC was a budget option and I've been duct taping new components onto that ever since. Next time I want to get the top of the range out the gate.      So basically, if I can't cheaply duct tape another cheap part to this old workhorse then my budget is limited only by my patience.",Negative
Intel,I'm fairly certain my motherboard will take the CPU as the website says it works with any AM4 chip. Is there a possibility the marketing is being sneaky?,Neutral
Intel,Just under Â£200 from Amazon. It's very edible at that price.,Positive
Intel,x3ds are gone for AM4 unless you wanna get taxed hard for used,Neutral
Intel,"x3d's are out of stock, only ones left are heavily upcharged.",Negative
Intel,ah yeah a prebuilt is the way then. Man are they really charging 1000 for a 5070 there? for reference i run a 12900k and a 4070 super on 650w with room to spare. My other PC is an 11700k w/ a 3060ti and thats on a 500w. The 5070 wouldn't need more than a 650w with a 5080xt cpu.,Neutral
Intel,"Yeah get the prebuilt and sell your current PC, you should be able to get $500 for it",Neutral
Intel,How much ram do you have in your current build?,Neutral
Intel,It is what it is,Neutral
Intel,"Thatâ€™s why I suggested a 5700x too.   As you move up the resolutions, the GPU has less of an impact on performance jumps.",Neutral
Intel,"You can cheaply duck tape it like, for sure! Although, I think the middle ground between cheap upgrades and a New Build is the smart choice.     Upgrading your CPU to a 5600(x)/5700x/5800x/5700x3D would get your better performance on your current hardware. The 5600 is Â£90 right now.     Upgrading your GPU to support your new 1440p monitor with something like a 9070 XT and a new 850w PSU(unless you have a recent/decent psu). You can also get a cheaper GPU, the 9060 XT 16gb/5060 Ti 16gb are way faster than the 3060.      Doing these specific upgrades would allow you to take your GPU and PSU to your next build. With the GPU+PSU already purchased, you would just need a Case, storage, CPU/MoBo/RAM.    Buying the CPU/GPU/PSU now will get you the best performance for the least amount of money. I strongly recommend you do this, then plan to upgrade the CPU/MoBo/RAM within 2 years.    [PCPartPicker Part List](https://uk.pcpartpicker.com/list/k4bwt3)  Type|Item|Price :----|:----|:---- **CPU** | [AMD Ryzen 5 5600 3.5 GHz 6-Core Processor](https://uk.pcpartpicker.com/product/PgcG3C/amd-ryzen-5-5600-36-ghz-6-core-processor-100-100000927box) | Â£91.95 @ AWD-IT  **Video Card** | [PowerColor Reaper Radeon RX 9070 XT 16 GB Video Card](https://uk.pcpartpicker.com/product/8ZJBD3/powercolor-reaper-radeon-rx-9070-xt-16-gb-video-card-rx9070xt-16g-a) | Â£599.99 @ Overclockers.co.uk  **Power Supply** | [Montech CENTURY II 850 W 80+ Gold Certified Fully Modular ATX Power Supply](https://uk.pcpartpicker.com/product/sqbypg/montech-century-ii-850-w-80-gold-certified-fully-modular-atx-power-supply-century-ii-850w) | Â£85.47 @ Scan   | *Prices include shipping, taxes, rebates, and discounts* |  | **Total** | **Â£777.41**  | Generated by [PCPartPicker](https://pcpartpicker.com) 2026-02-03 00:02 GMT+0000 |",Positive
Intel,"no, just checking some really old or limited old boards won't do the newest am4 cpu's",Negative
Intel,What is the difference with X3D?,Neutral
Intel,Â£400+ here,Neutral
Intel,"tldr: Much faster for gaming, espcially cpu intensive games  They have extra 3dvcache so the cpu can run more efficiently, which translates to faster performance for gaming. Just see where the x3d's rank in terms of gaming.  https://www.tomshardware.com/reviews/cpu-hierarchy,4312-2.html'  Heres a specific benchmark for 5700x3d in arc raiders. Vastly improved 1% lows, 1% lows is the lowest fps you will see. Thats when theres alot going on in game and your performance stutters, so having better 1% lows will prevent that from happening   [https://www.youtube.com/watch?v=uWzk6J09n\_A](https://www.youtube.com/watch?v=uWzk6J09n_A)",Positive
Intel,6600XT is still good for 1080p and perfectly matched with your CPU and PSU. For $400 you will not find anything significantly better (new). For used market it is hard to suggest because prices vary widely. I suggest  to save money for new build while using the existing system.,Positive
Intel,budget? PSU?,Neutral
Intel,"Thought about that too, but playing arc is not enjoyable at all",Negative
Intel,"Budget around 400, but im buying used. Psu 650",Neutral
Intel,What an adventure!! Enjoy your new setup ðŸ‘ðŸ‘ðŸ‘,Positive
Intel,I did the same thing. A couple of years ago I finally said to hell with consoles and I built a PC. I splurged and got the 4090 and holy crap thatâ€™s the most amazing decision ever.,Positive
Intel,Look at an x3d. Thatâ€™s my two cents. Looking good,Positive
Intel,I love that first line of closing thoughts and how PC gaming is a hobby in itself. I remember months ago a friend was talking mess saying you donâ€™t have money to blow cause Iâ€™m buying expensive ass PC parts while we were shopping at the mall and looking at gold chains. To me I was like yea itâ€™s a hobby thereâ€™s nothing wrong with paying a lot of money for a hobby you love and enjoy. I feel like it hit him pretty hard with the realization that it can be a hobby cause he didnâ€™t say anything back but he had this look and energy of â€œoh shit thatâ€™s true.â€ To him lol,Positive
Intel,Grats on 30. It gets worse.,Negative
Intel,"Sounds great, happy for you. Gathering up parts (on sale, open box or used) is so much more fun and better value for the money. 5070 is a good choice for your set up. Enjoy your new gaming pc.",Positive
Intel,This is mine: https://docs.google.com/spreadsheets/d/1n3_N2t-5craOfHSszlczoRQC9bdh809I/edit?gid=95224093#gid=95224093,Neutral
Intel,Congrats! Happy gaming!,Positive
Intel,"Sounds like you really had fun with, enjoy your rig!",Positive
Intel,"Grats on the new setup, also go ahead and get project lasso and tune your games to behave better across the cores and the right speed plus priority and you'll see better stability from your system :)",Positive
Intel,"I was in that phase too. At some point I noticed I would rather game more than tinker more, never overclocked anything again and just was happy with every game running as it happens to run.n  It's a lot easier with VRR nowadays.",Positive
Intel,Can't find it under 350â‚¬ used...,Negative
Intel,Def more of a hobby than buying gold chains. Lol.,Neutral
Intel,Bro that's smart af!,Positive
Intel,Yeah it was starting to get hard to remember everything I had in the past so just did a brain dump into a spreadsheet a few years ago.,Negative
Intel,Do not buy a high end cpu but garbage gpu. The other way is better. https://pcpartpicker.com/list/wrMq6Q The 5060 8gb is utter garbage. Do not buy it. 9060xt 16gb or 5060ti 16gb MINIMUM.,Negative
Intel,"If youre flexible about turning the graphics down and on a budget like you say, then you do not need a 16 GB card for anything. I run my games mostly maxed out with a RX 7600 8GB at 1080p which is comparable to that card. Dont let people convince you to waste money. Being willing to turn the graphics down a bit is the best way to save money doing this, youre doing it right.",Neutral
Intel,"for that price please look on fb marketplace, ive been seeing some good deals in that price range with 5070â€™s and 7800x3dâ€™s",Positive
Intel,If you are playing @1080p i think the build makes sense but id try to get the 16gb version if possible,Neutral
Intel,"I JUST built a $1600 PC earlier last month, and here were the specs:  MoBo: Asrock B850M Steel Legend  CPU: Ryzen 7600X3D  RAM: Klevv Bolt V 32GB DDR5  SSD: Crucial P310 1TB  GPU: Powercolor 9060 XT 16GB Hellhound  PSU: Thermaltake GT850W   Case: Montech King 15 Pro  Fans: Thermalright TL-M12Q  AIO: Thermalright FW360   Hope this helps as some kind of reference :)",Neutral
Intel,"I mean at that price range you would honestly have an easier time finding a prebuilt with those specs for cheaper/the same   $1,599 5060Ti https://www.newegg.com/icewolf-gaming-desktop-pcs-geforce-rtx-5060ti-amd-ryzen-7-7800x3d-32gb-ddr5-1tb-nvme-ssd-black/p/3D5-0074-00017   $1,630 9060 XT https://www.newegg.com/hoengager-gaming-desktop-pcs-amd-radeon-rx-9060-xt-amd-ryzen-7-7800x3d-32gb-ddr5-1tb-ssd-black/p/3D5-003E-00UF3   Or for +150 past your budget for a 5070 build with your other specs   $1,850 5070 https://www.newegg.com/p/3D5-001U-001S4",Neutral
Intel,Bestbuy has a good selection of prebuilt PCs for your budget,Positive
Intel,That card is definitely not garbage. This person says they're willing to turn the graphics down... why would they need 16 GB minimum? I run modern games with a card similar to the 5060 mostly on high some maxed out with no issues at all.,Neutral
Intel,Your best bet is buying a prebuild (OEMs get parts cheaper). But even then the prices still suck and you'd be getting significantly less than you would have just a month ago,Negative
Intel,"It is a bad time to build 100%  DDR5 ram prices have quadrupled- the GenAI bubble is gobbling up all supply   DDR4 ram prices have tripled - demand is high since DDR5 is expensive   SSD prices have doubled - the GenAI bubble is gobbling up supply   GPU prices have increased - vram costs more due to the GenAI bubble, and they are literally making less gaming GPUs because they make more money making AI GPUs  Unless the bubble pops sooner than expected, many speculate prices will not start to drop until fall this year",Negative
Intel,"I suppose it depends on your scope.   Is it a good time to build compared to a year ago? FUCK. NO.   Is it a good time to build compared to 6 months from now? Who knows. Prices could go down. More likely they'll hold steady or go up.   Ultimately you have to choose when to pull the trigger, and accept in-advance that there may be a more optimal time to buy in the future.",Neutral
Intel,"not really, RAM and storage are both hugely inflated. Not sure if there's an end in sight, though.",Negative
Intel,Right now is the worst time in recent history to build a new PC. Tomorrow will be even worse though,Negative
Intel,It's bad. And it's going to get worse. Prices will probably take years to recover.,Negative
Intel,"I just built my first PC, I bought everything secondhand from FB marketplace except the case. I think it was $350 total, I can play everything (so far) maxed out. It took a lot of running around and some sketchy situations but it was 100% worth it.",Positive
Intel,Lots of FOMO.  But its either now or never.  Nobody can predict prices in a year or two or three.,Negative
Intel,"I think right this very moment prebuilts are the best value that they have been in years. I love building PCs and I have been lucky enough to build a new one every couple of years and then passing down my ""old"" one. That's out of the window and now I'm likely going to keep my 2 current machines for the next few years because prices aren't going down anytime soon.     There are some good prebuilt options, you can even buy a used system.",Positive
Intel,"What region shopping in for parts, any chance access to a Micro Center? If can find a good deal for a combo deal with ram, could be worth for sure. Else, maybe a pre-built.",Neutral
Intel,"I hear ppl say this crisis could last a couple years. And when itâ€™s over prices will drop, but sadly I donâ€™t expect back to the levels we were last year ðŸ˜”",Negative
Intel,It's the worst time I've ever encountered in 25 years.,Negative
Intel,No,Neutral
Intel,I wanted to upgrade my 5 year old build.. but waited too long,Negative
Intel,"I recently bought a fairly high end PC and my final price tag ended up at roughly $4500.  It's a bad time to be a builder, but I don't think it'll get better anytime soon. The RAMpocalypse has just begun and I expect prices to rise further and I don't think we'll see a normalization of prices for a few years at least.  AI companies have bought out future stock, leaving less for the rest of us. Producers are shifting production to cater to AI companies, leaving even less for the rest of us.  It's bleak now and looking to get bleaker.. Unless the AI bubble unexpectedly pops.  Maybe you can get a decent used one? Many builders are looking to offset the price of their new builds by selling their old ones instead of keeping them as backups.",Negative
Intel,no. But it could get worse,Negative
Intel,I hate to say it but right now buying a prebuilt is more cost efficient. A lot of these prebuilts are mass produced and were built before RAM prices went through the roof. Now they can afford to sell them for the regular price without losing any money. It's only a matter of time before they start jacking up the prices of these prebuilts.,Neutral
Intel,"Same question, different day.",Neutral
Intel,"Honestly, no. Get a prebuilt or used.",Neutral
Intel,"Nope. Wait. Buy used to get by, don't get into FOMO. We've been through this before, it'll get better.",Neutral
Intel,"It is a terrible time, BUT the next two years may be worse.",Negative
Intel,Only if you're doing a slightly older build with used psrts. Even then probs not worth it. Prebuikt is most cost effective now because of everything thats already been said,Negative
Intel,"Buying pre-built doesn't feel too bad, as at least the price has you getting mutliple things, but god I could only imagine reaching the point in a build to buy a video card & RAM.  Was looking for a 5090 yesterday and saw Microcenter had a pre-built that had one for roughly 4k, or buy the card itself for 3.9k.",Neutral
Intel,"Price fluctuation is certainly an issue and, unless the AI bubble pops soon like others have suggested, there is no guarantee that prices will go down.   One thing you could do is design your ideal rig and get parts incrementally, as budget and sales will allow. Alternatively, you could build a rig that will allow you to run a majority of games you want on low to medium and upgrade as time and budget will allow. My point is, what is your timeline?",Neutral
Intel,"Just ended up settling for a pre built for my girlfriend's birthday from Microcenter. Even with the microcenter bundles that save you a ton, I was having trouble building a rig for even around the same price as the prebuilt I got. The prebuilt has a 7800x3d and a 5070 ti. The microcenter bundle with a mobo, 32 GB of ram, and the 7800x3d was $750, and the 5070 ti was around $800 at that point. (They literally just raised the MSRP of that card too) So I was already looking at $1550 without a case, ssd, cooling, power supply, operating system. The prebuilt was $1700 with a 2tb ssd, aio cooler, lian li case, gold rated PSU. So as much as I wanted to build things myself it would have been stupid financially or ended up with a weaker rig at that price point. I could have maybeee gotten close in price if I had gone AM4 instead but I'd rather have the ability to upgrade in the future.",Negative
Intel,"The best time to build a pc, is when you need one. Nobody can predict the future, especially when or if prices are going to return to normal.",Positive
Intel,"Honestly, from a purely pricing perspective, it is almost never a good time to build your own mid-range or lower PC.  However, after the shortages caused by covid 19 and the crypto-inspired GPU shortage, and the rebound in supplies that followed, we are coming off of probably two to three years of historically low prices for ALL components.  And that is what really makes the memory price increases hurt so much.  And it has affected components that use memory (SSDs and GPUs) as well.  So it really feels like the worst time to build a PC.  Historically, there have been much worse periods in which to build a PC.",Negative
Intel,I thought December 2024 was a bad time to build mine... now I look around and am really glad it did it then. Get a prebuilt and save some money.,Positive
Intel,"Itâ€™s hard to say, it depends if the Ai hardware rush is a bubble or not. If itâ€™s not, then the sooner the better to build and upgrade, if it is then waiting would be ideal.   If it isnt a bubble, then I may have built my last PC.",Neutral
Intel,Now is not a good time. It is the worst time. Followed by worse times to come. Which makes now a better time than then.  :(,Negative
Intel,If you wait for possible sales or bundles there will be huge discounts to move inventory put for like a 5090 your Fâ€™d,Neutral
Intel,"If price is a factor, you might still have a window to actually save money with a prebuilt (since they can buy in bulk for cheaper). But otherwise itâ€™s awful all around, thanks to stupid AI.",Negative
Intel,"Honestly I would say build it now- prices on Ram, storage, and GPUs is going to be high for the foreseable future.",Neutral
Intel,Every time is a good time to build a PC,Positive
Intel,Terrible time,Negative
Intel,"Back in 2019 I built a PC for $1400. If i built the same PC today, it would definitely cost more than $1400. I got 32gb of ram and 1tb nvme for $300 back then.",Neutral
Intel,No.,Neutral
Intel,"Phone manufacturers are reporting that they are reducing the amount of ram in their next models because of the current market price changes.  So yeah, it's a bad time.  But for me? Since I started building computers like 20 years ago, the prices have been bad for the last 10 years to me.",Negative
Intel,"Itâ€™s really not a good time. I built one for my partner before the ram shortage. Her kit of 32GB 6000MHz CL30 RAM was $180 CAD then, and is now nearly $800 CAD. I was planning on building one for myself too, but ended up spending the money Iâ€™d been saving on a good 4K OLED TV and sticking with my PS5.",Negative
Intel,"Everything is beyond expensive, and I donâ€™t know if it will ever go down",Negative
Intel,"I built mine during the GPU shortage back during the Covid crap when GPUâ€™s were overpriced. I lucked out with my RTX 3060 and got two for one. This new thing about NVIDIA upping the prices for GPUâ€™s seems  pretty similar, to me at least. It really depends on if youâ€™re willing to upgrade computer parts or just buying the new consoles when they come out. I personally love PC more than any console, and am comfortable upgrading when I need to. Hope this helps!",Neutral
Intel,"Howâ€™s your internet?  Honestly, this is as good a time as ever to try GeForce Ultimate. As long as you donâ€™t go over 100 hours a month.",Positive
Intel,Is now even a good time?,Negative
Intel,You can still build a solid system for $1k. Ryzen 7500f + rtx 5060 ti 16gb. Will run those games very well.,Positive
Intel,"Yes. If you are playing games from 2020 and before n1080p,,, you can build a dirt cheap PC",Positive
Intel,do. not. build. pc. yet,Neutral
Intel,"Get costco membership, buy costco prebuilt pc, replace PSU.  Bout the best youre gonna do.",Neutral
Intel,Ssd has only went up for 4tb and up.  1tb are still 100-150usd with some 2tb under 200usd.  990pro is still under 600 for a 4tb model.  Everything is a moot point.  Cpu and gpu are in good spots and the saving there make up for price hike in ram compared to building a pc in late 2024.  I however would bump that price up to 1500 if you want a console rivaling experience that will last a few years.  My 1300usd in late 2024 has been a let down compared to my xbox for smooth gameplay.,Neutral
Intel,"Buying a prebuilt with the specs you want is currently cheaper.  Once the stock of parts the manufacturers are sitting on is used up, they will get more expensive.  Good luck OP, and may the odds ever be in your favor.  >Will prices of RAM/SSD/GPU, etc drop eventually?  Yes, in about 2-4 years. Maybe.",Neutral
Intel,"No, but its not going to get better for long time, so actuly yes",Negative
Intel,"Generally, today is better than tomorrow, unless you want to wait 2 years on the hope it'll be better.",Positive
Intel,No and yes and no one knows is the best answer.,Neutral
Intel,Buy a pre-built from Costco. They are not the greatest specs and you didn't build it yourself but it's a great value with a warranty.,Positive
Intel,"Cutting edge? Probably not - but second hand? There are plenty of great deals out there. I picked up a great deal from someone leaving town. You'll easily get a good few years of use out of them, maybe have to turn fog or shadows down in your games but otherwise still top tier performance for a few years. Will it mean I have to upgrade in 3-5 years instead of 6-7? Yes, but cost wise it's just way more sensible.",Positive
Intel,Is now even a good time to build a PC?     no.     Based on what various component makers are saying and the prices being as they are and will be for the next few YEARS...no.,Negative
Intel,"Second hand, depending on where you are. There are always deals to be had if you snipe listings like a hawk :)  Managed to snag something a month ago that I'm happy with.",Positive
Intel,>Kazoo noises  *Noooooooo* ðŸŽ¶,Negative
Intel,"The easy answer is no.  Iâ€™ve never owned a gaming pc that went up in value over the years until this year.  SSDâ€™s are double the price and my current ram costs 3x what I paid for it, 2 years ago.",Negative
Intel,Nope,Neutral
Intel,"If you wanna over pay, sure. But seriously, fuck AI",Negative
Intel,"definitely a bad time to build a pc like everyone else is saying. To put in perspective, a 1000$ PC pre Aug 2025 would be worth around 1300$ or more as of now.  Of course, none of these would matter if you're rich tho",Negative
Intel,"Now is one of the worst times to build a PC in a long time. Expensive GPUs, expensive RAM, expensive SSDs, and probably more as well",Negative
Intel,I donâ€™t know if thereâ€™s ever been a worse time,Negative
Intel,Ddr4 this is the way,Positive
Intel,"Its not that bad , i think it can be worst when the stocks will be depleted, prices will go a bit higher  (they are now sellings rams that cost not much :) )   I think its either now oR Farrrrrrrrrr as much as one year MINIMAL before seeing price drops.",Negative
Intel,"Nope, but doing it anyways!",Neutral
Intel,"I personally decided to go for it. You can wait and pray, but it feels like things won't settle down for a long time and might even get a bit worse. My suggestion is to try and go part by part, check deals around or maybe you can get a good pre build deal?",Negative
Intel,"the best time to buy was probably a year ago. i got a prebuilt about 14 months ago because i'm canadian and anticipated tariffs being pretty bad. didn't anticipate the AI squeeze on components, so it's gotten even worse. I wouldn't recommend building right now at all.",Negative
Intel,"It's the worst time to upgrade or to build a PC. Storage has increased their price by 200% I think and RAM by like 500%.  I mean, if you are willing to pay around $1000 just for the RAM itself, go ahead, everything else will be cheaper but my recommendation, look for some pre built PCs, you can still find good deals, but if you are going to buy the components one by one, for sure you will spend (or waste) a lot of money.  I was planning to upgrade my PC, but I will stick with DDR4 and my reliable 6700xt for the next two years at least, or whenever prices go down a little.",Negative
Intel,either pray you can get your hands on a good prebuilt  swap to console  or wait,Neutral
Intel,"It depends on what you think is going to happen.   Is hardware consumption from AI going to slow down? If so you should wait, let prices stabilize.   Is AI fever going to keep getting hotter? If so there may never be a cheaper moment.   Or wild card, is AI going to cause hardware and software capabilities to explode? Then perhaps buying now you'll end up with something obsolete faster than the historical trend.   No one really knows.",Neutral
Intel,I just built mine. All new parts except for the GPU. I belive it was around $650 total. It runs RDR2 at 1440p 60fps which is by far the most demanding game i will ever play so. Fits my needs.,Positive
Intel,Honestly build it right now since I heard nvidia was gonna stop or limit producing pc gpus and focus more on console and their other variant. So the prices of gpus are gonna go up. And ram prices isn't coming down any time soon either because of ai. So build one right now.,Neutral
Intel,"I strongly recommend not to listen to any of the top upvoted comments, because dear lord are they horrible.  You can still do an 900-1000usd AM4 build with an 5600 and 9060XT and play everything you like in 1440p, let alone 1080p.  If you desire, get a 9070 or 9070XT and you can play stuff in 4k.  These are 900-1400usd builds we are talking here.",Negative
Intel,"I remember earlier this year when I was trying to troubleshoot some issues that I thought were RAM at the time (they weren't) I looked up my Amazon purchase history to find the stated specs on my RAM to see that it was like $350. I'd paid a little over $100 for it just the year before.  I thought that it'd been discontinued and that was reseller market pricing. Nope. The world just went fucking insane.  Very bad time to build a computer, also a very bad time for a computer part to break on you.",Negative
Intel,"Unfortunately it is a pretty terrible time to build as far as price goes and that likely won't change for at least a year, unless a miracle occurs like the AI bubble popping (don't bet on it).  Unless you have access to a handful of price minimizing options (like the CPU/RAM/motherboard bundle deals at Microcenter) you're pretty much screwed on new hardware.  If you have a system already that is meeting your basic needs id stick with it until pricing improves in (hopefully) a year or two",Negative
Intel,"Yea Now is already too late, get started before it gets worst, no light in this tunnel for the foreseeable futureâ€¦",Negative
Intel,Costco near me has an ibuypower pre built that looks decent,Positive
Intel,Depends how rich you are.,Neutral
Intel,"PCs have always been relatively expensive in the respective days economy.   Today's economy is fucked so therefore PC building is as well.   We have current price increases in ram (especially), SSD and GPU because of AI being targeted by manufacturers.   If you want a PC now, buy it now. Pre built if you aren't too fussed about parts and don't want to do your own build. Own build if you care about parts and want to experience building.   If prices go down in the near future (unlikely), you will have gotten whatever enjoyment for the price difference between now and then for your money....there's worse things to ""waste"" money on. If things go up or stay the same then your laughing",Negative
Intel,"The only thing that makes it a good time to build is that it may be a worse time to build in the near future. We havenâ€™t had a real good time to build in years, though, so itâ€™s all relative.",Negative
Intel,"YES.   Before you guys bully me listen to my reasoning:  Prices are only going to go up, a bit because of inflation, a bit before there will be shortages in the supply chain because of the global situation, and a bit because other chip components used for AI will create bottlenecks like it happened with GPUs and RAM.   They made it clear that ""we'll own nothing and be happy"" (DAVOS 2016) according to them. This means that they'll push for cloud gaming, PC leasing, and similar BS. We've seen this happen all over the board in many sectors. Why do you believe this will be ignored?   The ""good"" companies will try to keep up for a while but will be forced to surrender because of prices going out of control.   You thing a global Crysis or recession (as the one we're sailing right into) might bring prices down? WRONG. They'll print so much money to save banks and businesses that inflation will make it impossible to own a personal PC.",Negative
Intel,"If you're gaming, I would go budget. There's a lot of good performance on older hardware. There are some good prebuilds out there that you can look into that might be more affordable. That's what I'd do. Get a prebuilt with decent performance, keep it for a couple years and then re-evaluate the market later. Good luck!",Positive
Intel,"No, itâ€™s a *terrible* time to build a new PCâ€¦ But Iâ€™m going to do it anyway because Iâ€™mâ€¦ Not smart.",Negative
Intel,"It's not a good time but unfortunately it's almost never a good time, it's always something. 10 years ago I was hearing ""not a good time"" because people were buying up all the graphics cards for crypto mining. Now 10 years later it's AI. Prices probably aren't going to go down any time soon, so absent going back in time and buying ram a few months ago, might as well just go for it if you can afford it.",Negative
Intel,You live close enough for a drive to a Micro-center? If so go pick up a Powerspec in your budget and enjoy gaming. You can always upgrade if prices fall later.,Positive
Intel,"Build? Maybe not.  Buy a prebuilt or mini-PC? Maybe.  There are some usable gaming prebuilts and even nice mini-PCs still on the market. If you don't mind gaming at 1080p, a careful purchase can get you in now. My bet would be that in a month or two basically everything that can run a modern game decently for under $1k will be gone, not to return until at least summer 2027.",Neutral
Intel,"With the sudden increase in demand by ai and one guy straight up just buying for 40% of RAMs global supply... no.  In ~2 years more factories should come online, flooding the markets dropping prices. That's a long time to browse for good deals, you probably can find something at least reasonable before then.",Negative
Intel,"It's REALLY not.  Give it a year. Asus is entering the RAM market, and lots of those ordered data centers might not come through.",Negative
Intel,"Itâ€™s a good time to build a PC when you want a PC and can afford it. Donâ€™t get caught up in following prices because the reality is no one here knows where they will go from here. Whatâ€™s the worst case, the ram you buy today is $50 cheaper in 6 months?",Positive
Intel,"No, I absolutely won't be replacing my PC - and if part of my current rig breaks I'll just aim to repair it  I would expect prices to drop eventually, but the question is whether it's 1 year, 2 years, or 5 years",Negative
Intel,"Many of the key components of a PC build have increased in price, some drastically so.  It is truly a horrendous time to be considering building a new PC.",Negative
Intel,"Well, it ainâ€™t the right time to build. But a good time to buy other components that are currently cheap. And leave the expensive ones out of your budget to go down",Negative
Intel,"Now is even a bad time to build a PC, unless you already have RAM and storage parts lying around.",Negative
Intel,It's up to you really.  You can buy the parts but they won't go down any time soon meaning 2026.,Neutral
Intel,I sold ram for the same amount of money i used to buy a pc before lol. This is the worst time posible except the gpu crisis i think,Negative
Intel,"Even though it is a bad time to build, I built anyway. I was waiting for gpu prices to come down for years. It never really did. Now ram prices have skyrocketed. I think if you wait for the perfect time to build, you are going to be waiting forever.",Negative
Intel,Bruh. Now is a good time to get a used gaming PC on Facebook marketplace. Tons of cash strapped non-pc gaming young people are seeing the uptick in demand and giving it a shot at a sale. Iâ€™ve seen TONS of really good builds for <$1k lately,Positive
Intel,Now is probably the WORST possible time in the last decade to build a PC. Go to Micro Center. Or donâ€™t build one at all. In my opinion,Negative
Intel,It is not.,Neutral
Intel,"Its the season for prebuilts or used parts. I just rebuilt my PC having replaced my GPU (9070xt) and ended up continue panic buying enough parts to have an entirely new PC.  However, the value of patience cannot be understated, especially with the used market. You can't jump on small savings relative to recent price increases, that's just a recipe for regretting a few months/1 year down the road when prices either stabilize or drop completely. (e.g. snatching at 20% off SSDs when prices have more than doubled).  For example, I ended up obsessively tracking new used listings and managed to get DDR4 32*2 GB 3200mhz sticks for 130usd.   Going jank is another option. I went with a Chinese MODT TOPC board with a 13950HX for 300usd and it performs beyond my wildest dreams if I were to go with standard off-the-shelf parts. Sure these may fail in a year, but I'll take the savings and insane performance (ended up spending only ~1300 for basically top of the line for 1440p) while it works!",Neutral
Intel,It is definitely not a good time to build a pc. RAM prices being as high as they are and the issues with Nvidia cutting production on their GPUs not to mention theyâ€™re investing more money and time into AI.. yeah it might be awhile before building a pc is worth it again. And thatâ€™s unfortunate because AMD has stated theyâ€™re doing the same thing so itâ€™s a shit show.,Negative
Intel,"Hard disk, SSD, and RAM prices are now more costly as the so-called AI boom takes the lion's share of parts production.  Better bet is to find a secondhand gaming PC where somebody's quitting to play games because they don't have time to.",Negative
Intel,"No, clearly not. It hasn't been a good time for a while. This pattern I see, when a hobby goes mainstream, capitalists find a way to cash in on it as much as possible, which ruins it for everyone. In the end people stop buying into said hobby, and we move onto something else. They did it with gaming, they are doing it with PC building, they will do it with anything and everything.",Negative
Intel,"It's a terrible time to build a high-end PC, but still a fine time to be a gamer. If you're just looking to play great games, any old ass-tier PC will play pretty much every 2D game that exists, plus tons of older AAAs and less demanding 3D indies.  Basically, if your hobby is gaming, you're great! If your hobby is playing the latest AAAs, you better hope you're rich.",Positive
Intel,Terrible time to build a pc im holding onto my DDR4 builds. They run great no need to upgrade for a while,Negative
Intel,"I fell for the trap of FOMO in 2021 when prices were peak, then 2022 price went down by a lot. Iâ€™m wondering about the same as you but donâ€™t want to buy high again",Negative
Intel,"I would look at bundles, and the used market for RAM. I am building a new PC and a bundle made it bearable but still expensive.",Neutral
Intel,"If you know you're going to build it in the next year, no matter what. Get the CPU, Mobo, PSU, case, and potentially GPU now. (Some GPU's are still at the prices they were last month and earlier this month, some have gone up).   Just wait out for a good RAM deal until then.",Positive
Intel,no lol,Neutral
Intel,Doubt prices will ever come back down tbh. People are still going to buy the components snd the companies will still rake in the cash.   Its a bad time yeah. But they might be cheaper right now than they'll ever be again.,Negative
Intel,"I just built this last weekend on a long awaited AM5 build (9800x3d, 64GB of Team Group DDR5 6000), and fortunately already had a 4TB Evo 990    Still need a good GPU and kinda kicking myself over passing on the 5090s I've seen (and had one in hand) but been kinda scared off by the burned power connector issues, too...  Maybe a 6090 in a couple years.   Other than that a smooth build except for the whole AM5 ""memory training"" thing but up and running and still spent about 50% more than what I would have spent on that RAM last year ($600 vs $400 or so). I decided it wasn't going to get any cheaper...",Positive
Intel,"Itâ€™s a terrible time to build. Then, if the AI bubble does burstâ€¦ global economy with crumble into deep recession to where youâ€™ll wish you had spare cash vs a pc.  Will prices drop eventually? Yes. Is that this year, next year, 5 years from now? Absolutely no one can say.  New chip manufacture facilities are coming online, AI demand wonâ€™t be infinite because we donâ€™t have infinite power.  When component costs get like this, prebuilts start to gain in value. You could look at those, or just deal with using GeForce now or something for a stop gap. Also, combos deals where companies are trying to offload less popular stuff might help you. Microcenter and the like.",Negative
Intel,No but it will get worse,Negative
Intel,"Horrible time to build, buy used one instead",Negative
Intel,It's not ideal but your finances are your business. How bad do you need it and how bad do you want it. No one can answer this for you all your gonna get from this post is seething about AI and corporations.,Negative
Intel,"No, itâ€™s a terrible time, but next month is likely to be worse, and the month after that worse again. Iâ€™m doing a build now even though itâ€™s bad because things are likely to get worse before they get better.",Negative
Intel,"at a $1000 budget, if you're building with all new parts, I think you're looking at a 1080p gaming machine",Neutral
Intel,"My old PC killed itself a month ago and I have to bite the bullet on a new build. So yeah, avoid it if you could.",Negative
Intel,Only way to get these prices down is to stop using ai.,Negative
Intel,"It's a horrible time compared to last year, etc, but there's no guarantee even when this ""AI"" bubble bursts that it won't get worse. They really want to move to a cloud-computing ecosystem where the consumer PC market is dead and you just buy some little piece of crap that you then pay them to compute your games/etc because you don't get the privilege of owning a powerful pc anymore. Or even if that doesn't happen, the move towards fully integrated boards where, say, Nvidia just sells a whole ass board with cpu/gpu soldered on and you basically have zero choice on your parts.  Maybe these futures don't come true, but they are certainly what some of the big players WANT to be the future. And if that's the case, then it may be a good time to build a pc because the window to even get to do so could be closing.  So if you do not have a pc, really want/need one, and can afford one, it may very well be worth eating the shitty costs to get it. Yeah it will be expensive but there is no guarantee prices go back down *even if both things I just noted do not happen.*  And the reason prices are skyrocketing is everything being bought up by datacenters, which are currently looking to be used for ""AI"" LLMs but in reality can just be shunted over to cloud-computing, mass surveillance, etc, so again there is no guarantee they don't stop hoarding tech even when the ""AI"" bubble bursts.",Negative
Intel,"Of course it s a good time. But not new pc. Old /used pc. A DDR4/3 pc should be a decent bang for the buck. Or you could go even older, i just payed 5$ for a Pentium 4, playing Half Life 2, Warcraft 3 and Gun ðŸ˜‡",Positive
Intel,"No.  And also yes.  The AI-pocalypse is ruining this industry, but some of the forecasts I've seen predict that this will carry on through 2027.  If you're willing to wait until 2028 or potentially beyond, go for it.",Negative
Intel,No if you compare to 6 months ago.  Almost certainly yes if you compare to any time in the near future because prices aren't going to drop any time soon.,Neutral
Intel,No it's not a good time. Memory and GPU prices increasing due to AI demand,Negative
Intel,I feel so bad for people who finally decided to build a PC only to have their dreams crushed due to reasons that are completely out of their control,Negative
Intel,"No, but yes, ram sucks right now, the market is so bad, but gpus and ssds (which are already bad) are about to get so much worse, so if your building, do it now.",Negative
Intel,best time now. soon people will own nothing and be happy,Positive
Intel,"It's definitely not a good time.  Will it get better? We can't really predict it, people like to say in a few years prices will go down a lot, after they AI bubble explodes, but we don't really know how the changes in production and the changes in the companies priorities will affect the landscape long-term.  If you have the money now and want the PC now, I'd just build it; otherwise you'd have to wait probably until late 2027 according to the most optimistic but realistic predictions I've seen.  However, I'd look into used PCs or parts, maybe you can get a good deal there",Negative
Intel,Worst time ever.,Negative
Intel,"My 10 year old DIY NAS died and I finally bit the bullet and spent WAY more than I wanted to for outdated parts to get it back up.  I donâ€™t even have all the parts yet but I found better deals afterwards, just not sure if I want to deal with the hassle of returns to multiple vendorsâ€¦",Negative
Intel,"Depends what for, Iâ€™ve gotten a PC towards the end of a generation (PS3->PS4 era), and my PC which was high end at the time was basically obsolete for PS4 era games so it barely lasted me a year and a half.   Iâ€™d suggest getting a very mid range PC now, so that when this new generation comes out which everything points to a 2027 window you wonâ€™t have spent 2-3k on a PC that will be obsolete.",Neutral
Intel,I bought a fully built PC last week for $1500 (on sale from $1900) with Ram costs going up it would have been close to $2000 if I had built it with the same specs.,Neutral
Intel,Yes,Positive
Intel,"No, it really isn't. And the unfortunate reality is it might not be a good time to build a PC ever again. Prices will not go down and the tech oligarchy don't want you do own anything, just rent a dumb PC connected to their data canters so you can slurp down all the AI slop they can cram into you.",Negative
Intel,"no. If this keeps going on, personal computing will be dead.",Negative
Intel,Elon is building Robots now instead the Model S and Model X.,Neutral
Intel,"Honestly itâ€™s not as bad of a time as people make it seem, but it is getting worse by the day.  Take advantage of sales and deals online, or find certain parts on local used markets.  Newegg constantly has 2x8 gb ddr5+mobo combos for 249ish, or 2x16 gb ddr5+mobo combos for 500ish, and even 2x8 ddr5+mobo+ram combos for 450ish and up.  You can also get a good quality 750w-1000w psu for 100 and under, as well as a nicely built good looking case for under 80.  I know a few days ago I threw together a list on Newegg, for 1050ish you could get a budget am5 build with 16gbs of ddr5, 1tb storage, and a 9060xt 16gb - plenty for 1080p and 1440p",Negative
Intel,If you want it buy it. Nobody can predict the market,Neutral
Intel,"It's a bad time.  But if this is your first pc, I say just go for it, work with a lower spec if your budget is limited. It's great experience having a pc.",Positive
Intel,"i would personally just decide which parts you want, and keep an eye on the prices over the course of the next 6-12 months, especially on aftermarket markets like facebook.",Neutral
Intel,No.,Neutral
Intel,Its best to hold off a little while if you want to build.  Currently there's insane demand for memory and storage due to the AI bubble.   While at the same time the producers of these parts were actually at a downswing in how much supply capacity they have.  Within a year you'll likely see this resolved as the producers will be able to make much much more to meet the demand,Neutral
Intel,Motherboards and cpus are kinda cheap but storage and gpu and ram are insane. I still did it tho lol,Positive
Intel,It's always a good time to build a PC. It's a terrible time to buy parts.,Negative
Intel,"If you don't want to build a new one, you can buy a refurbished one on the cheap still, especially if you aren't attached using Windows.",Neutral
Intel,"Its fine.  DDR4 is fine.  1TB NVME SSD + 4TB HDD is fine, just swap games on and off NVME.  Microcenter actually has some affordable pre-builts still.  I'd go that route personally.",Positive
Intel,No.,Neutral
Intel,No,Neutral
Intel,"Been wanting to build a PC for around a decade, finally did it for the first time a month or so back. Yes the PC part market is absolutely fucked but you can do what I did and Frankenstein used parts into a used office PC. Hp pavilions, dell optiplex, whatever Lenovo ones are all dirty cheap used on eBay for around/under $100. Add a GPU and upgrade what else needs upgrading and you're gold. I got out much cheaper than building new, threw Bazzite on there and I have no regrets been having a blast. This gets my foot in the door to upgrade one part at a time and still having a very capable 1080p 40-100fps htpc in the meantime.",Positive
Intel,I'm still sore at spending 1500 on my rig. But 3080 does it for me still. (bought 3080 used),Neutral
Intel,"Maybe now will be the last time you are able to, so go for it",Positive
Intel,"It will likely be several years before prices begin dropping. The big tech companies have already put out official statements on supply being locked up for a year or two.  It is not an ideal time to build a PC, but if you are going to need one it is better to buy now than a year from now.  The only sort of PC that I would soft recommend is buying an AMD APU like the 8700G. It has enough integrated graphics performance to play modern games on 1080p at lower settings, and you could overclock it a fair bit if you bought a cooler. It would let you play for now, and you wouldn't need to fork out for a GPU right away. Once you have money for a GPU down the road, it works fine as a CPU. You can look for used RAM and SSDs for cheaper, or settle for a small SSD and rotate through games more frequently. You could pick up a 1TB hard drive for dirt cheap and then just copy games over to your SSD when you want to play them.",Neutral
Intel,"Price is now unreal for ram memory.. If you dont have ddr4 already.. Dont by ddr5..  for 1k$ you cant build sh1t for future proof.. My setup with 5700x and 9060xt with 32gb of hoyer x fury is around 1500-2000$(depends where you buy) and this build is counted as oldy.. Cuz od am4 and ddr4.. Pc prices for good future proof are around:  Ryzen 7 9800x3d around 480$ Ddr5 kingston are around 600$ for 32gb kit, for 64gb around 1100$ Rtx 5070ti around 1100$ Mother board x870 chipset around 250$ Good case around 100$ Watercooling 150$ Corsair shift 80 gold 1000w around 220$ M2 samsung 990 evo plus 2 tb around 220$ M2 990 evo plus 4 tb around 420$ Total: around 4000$  I meam this build is near high-end.. If price did not skyrocketed, this pc build would cost around 2400-2600$",Negative
Intel,"Short answer no, long answer no.  Use market and part exchange with your friends and family is the only thing making sense currently.",Neutral
Intel,"I agree about the price of hardware but companies price based on what the market will bear.  Having built many gaming systems I can tell you that this is a never ending hobby that will consume all your lunch money.  My suggestion is to get a great base motherboard/cpu, a decent amount of ram, and adequate disk space.  You want a board that will have sufficient bus speed and room enough to add a good video card.  Buying used is a great option to save money.   Check the specs for the games you currently want to play, not for every game.  I would discourage buying a pre-built system.  Manufactures take shortcuts and value engineer to reach a certain price point.  You really won't find out what the PC's shortfalls are until after you purchase.  Building your own system gives you the option of swapping out and replacing/upgrading as you see fit.  When you replace a component, don't hold onto it -- sell it.  The longer you keep an unused part, the harder it is to resell.  The ultimate gaming system will be ongoing.  You'll be upgrading video cards, power supplies, memory, and motherboards as the technology improves.   Don't forget that you'll need low ping times and a high performing router if you want to compete with other online gamers.  The world's best performing computer won't help you if your ping time is 100ms!",Neutral
Intel,The best time to plant a tree is today. The second best time was yesterdayâ€¦,Positive
Intel,Microcenter got decent deals,Positive
Intel,"1k will get you a very low end gaming PC. Raising the budget to 1,200 + tax will get you a better system. I just saw such a build recently. Look around and you will see builds around your price range.",Positive
Intel,I donâ€™t think thereâ€™s ever been a good time to build a PCâ€¦you just have to do it.,Neutral
Intel,No obviously not.,Negative
Intel,Bro no,Neutral
Intel,"Im not building or buying shit until my processor is â€œminimum requirementsâ€ for anything I want to play, and maybe not even then - Ive been playing the same few games since before the pandemic  Its not just the AI bubble Trump is fucking the market with tariff nonsense.    Anybody remember when RAM doubled overnight after that typhoon in Vietnam like a decade back?",Negative
Intel,I did exactly this.  I noticed the pre built prices were lagging behind individual component price adjustments.,Negative
Intel,"Depending on your needs you still find good bundles too. Microcenter is good for this if you live near one, but recently I picked up a U7 265k, Strix Z890 mobo, 32GB DDR5, case + AIO bundle on Newegg for $850 so there's some good online deals too.",Positive
Intel,Costco has some good deals,Positive
Intel,Or he can just make an AM4 build with an 9060 or 9070 and you guys could stop giving horrible advise?,Negative
Intel,Fall?! Youâ€™re far too optimistic.,Negative
Intel,"People are hoping prices ""start"" to drop around the fall.  1. That's best case scario. We may see rising prices for years given what companies have said about ram/gpu manufacturing and not wanting to go heavy into making new factories.  2. Even if they ""start to fall"", they are going to be rising all year up to that point. It might be 4+ years or more before ram/gpu prices even come back down to the levels they're at right now.  I think bottom line is nobody can tell the future. Buy what you want, when you need it. Assume it's going to cost more than you'd like no matter when you buy.",Neutral
Intel,Hell even hdd's are jacked from AI was planning to fill out the rest of my nas after I only got 1 drive black Friday but even recertified enterprise drives are at least up a 100$ if you can even find any now :(,Negative
Intel,"There're a lot of different reasons (and, let's be real, excuses) for components' prices to just keep rising too.   Bubble keeps inflating and / or plateauing for our lifetime: prices go up. Even, or especially, if it just plateaus.   Bubble pops despite trillions put into its life support: market crashes, prices go up.   This just becomes the new norm: production companies shift to selling components specifically made for only industry use, so consumer product prices go up.",Neutral
Intel,This is the same thing I heard with the 3000 series and those prices never went down,Negative
Intel,">Unless the bubble pops sooner than expected, many speculate prices will not start to drop until fall this year  Some are saying they won't fall at all this year or the year after (if the bubble doesn't pop.)  As AI companies have bought out future stock from producers and more of them are shifting production to cater more to AI rather than private consumers. And there are many more data centers being built.  We might not see a normalization of prices for a few years until producers can ramp up production, if they even want to. If they increase supply they are investing in making the price of their product fall.",Neutral
Intel,"It doesn't matter when the bubble pops, we would still have to wait for the contracts to expire.",Negative
Intel,"These prices are never going down. There is no competition to the handful of companies that manufacture the chips needed for RAM and SSDs, now that the prices are up they'll stay up, because there is no choice for consumers to go anywhere else.",Negative
Intel,"More like the end of the decade. Spinning up more production fabs that's a long time, 3 to 5 years.   Open AI alone bought up 40% of Samsung and SK Hynix's production capacity through at least 2026.",Neutral
Intel,So is it a good time to sell my DDR2 and DDR3 that I have in a drawer?,Neutral
Intel,"More than quadrupled on the higher end. I paid $195 for 64GB ddr5 6400 in June and Newegg has the exact same kit for over $1,000 right now.",Neutral
Intel,I heard mid-2027,Neutral
Intel,"What about business branded solutions, like with ECC and what not?",Neutral
Intel,Yep. The G.skill DDR5 RAM I bought in November 2024 for $112.99 at Micro Center is now $519.99. Holy-O-Jesus.,Neutral
Intel,Bubble ðŸ˜‚,Neutral
Intel,DDR3 RAM are going up now as more people buy older computer because newer parts are getting too expensive to build a Minecraft gaming machine,Neutral
Intel,"Nope. If you don't build your pc now, you won't be able to till 2028 or even 2029. Prices ain't coming down anything soon, especially not in this fall lmfao.",Negative
Intel,I agree it is a bad time but is it going to get better any time in the future? Only thing that realistically can change is OP's economic situation.,Negative
Intel,"Fall this year? My man, the way this industry works is to allocate future production. They are committed through at least 2027. And in the AI arms race, the easiest way to cripple your competition is to buy as much as you can, even if you don't need it, just to deprive 'them' of the tech. You and I are peons and of no concern to multi-billion $ enterprises. The gaming PC is rapidly going the way of the dinosaur.",Negative
Intel,"The AI bubble will not pop anytime soon... Its just getting started imo. It will stabilize once proprietary ""AI"" pc builds start selling in stores (e.g. AI pre builds in costco)",Neutral
Intel,"Almost a month ago I decided to build a PC out of the blue and it was the best decision I did. Yes, I had to bite on the ridiculous ram price, but that's life. Reused my NVME that costed me 50 bucks and now it costs almost 200. 3 days after getting my 9070 xt for 667 bucks, they announce the 3070 ti is getting killed and prices sky rocketed.",Positive
Intel,In many cases SSD prices have tripled just look at San disks NVMe drives for proof of that,Neutral
Intel,"How can that sustain itself even for two years? Are they thinking everyone will just use weaker components?   Wonâ€™t they just destroy the home Pc market? Is the plan really for consumers to access high power compute via tokens, to an AI company?   I just donâ€™t believe everyone will accept this? But maybe Iâ€™m wrong.",Negative
Intel,'normal' decent prices will never return. The golden age of Pc gaming as we know it was well and truly over IMO. They may drop but things will always be overpriced forever going forward.,Negative
Intel,2000usd PCs are  like 200-300 more expensive. You guys are 12/10 overdramatic.  You can still do an AM4 build -  brand new  - for 800 and play everything you want in 1080p 60fps on max settings.  There is a reason Steams Hardware Survey disagrees with reddit to an extreme.,Negative
Intel,"I get it. This makes total sense, I am just beating myself up. I had been patient about ensuring I wasn't impulse buying a $1.5k item, and it turns out I waited too long LOL.  But to you're point, it's all relative.",Negative
Intel,"I agree. I built 11 months ago to replace a build from 2014. Going off Newegg, where I got most of it.    MOBO: X-870-A AM5. Paid $300, now $290   RAM: G.Skill Trident Z5 64gb DDR5. Paid $195, now $900   SSD: WD_BLACK 2TB SN850X. Paid $160, now $560   CPU: Ryzen 7 7800X3D. Paid $450, now $400   Case: Fractal Design Focus 2. Paid $70, now $75   Cooling: be quiet! Pure Loop 240mm AIO. Paid $80, now $90   GPU: PowerColor Red Devil AMD Radeon RX 9070 16GB (Amazon). Paid $650, now $700  What I built for ~$2k a year ago would cost me over $3k now, and almost all in the RAM and SSD - wild. And I was worried back then that I may have overpaid. Glad I did, though - she runs fast and quiet.",Neutral
Intel,"Honestly, I don't think memory prices will come down for a long time, if ever. The industry is an oligopoly, and even if the bubble bursts they won't let a good crisis go to waste.",Negative
Intel,"Would it be better to buy a used PC for the time being? Ideally I am fine doing that and revisiting building one in a while, or slowly upgrading.  I'm not certain the best path forward.",Neutral
Intel,"If they could get their RAM and storage overseas, then it's cheaper in 3rd world countries like in ph",Neutral
Intel,But also if u just wanna play and dont care about max settings u could probs still get a solid build just accept slightly older tech,Neutral
Intel,Parts list?,Neutral
Intel,"Define ""everything"" and ""maxed out"" please. I can understand being able play to Stalker 2 in 1080p (or even Cyberpunk)  but I doubt it's with max settings and 60 fps.",Neutral
Intel,"I spend my time between Brooklyn NY and Stamford, CT. I just checked and saw one near my in Brooklyn I could go to!",Positive
Intel,Combo deals have increased like $300 from when I bought my comparable combo.,Positive
Intel,Prices didn't drop after that fiasco during COVID.  Definitely not dropping after this bubble pops.,Negative
Intel,"Eh, I've got some newegg invoices that are 10+ years old that would make the me of today shudder.",Negative
Intel,We fkd bro,Negative
Intel,"Been building my own pcâ€™s for about 20 years.  Love to do it and handpicking your components is great.  In the early days I could save some serious money but the margins have been shrinking every year. I built 3 pcâ€™s in 2022 that should hold up until Windows 12 rears its head. May upgrade the video card on my gaming rig in the meantime.  Windows 12 will probably FORCE us into new hardware which for me would probably be motherboard, ram, cpu and an ssd. Iâ€™d expect a prebuilt will cost less by that time.  Sad because building your own is so rewarding.",Positive
Intel,"Honestly, no real timeline.   Itâ€™s year after year new awesome games come out that I miss out on so I finally started to look into it- and boom! Worst time ever to buy hahah. I just donâ€™t know much about building or PCs so I figured to ask.",Negative
Intel,That is what I've been doing just buying parts one at a time when i see a deal or discount. I can wait on ram and gpu..,Neutral
Intel,Nah mate. You will build another and definitely upgrade what you have regardless.   If AI companies continues to require all PC hardware be made for them. We will see changes to the PC consumer. What changes exactly time will tell but if you've done a recent build and worst case scenario happens it means you will be set for longer,Neutral
Intel,WHAT THE FUCK DID YOU JUST SAY TO ME? DO YOU REALISE WHICH SUBREDDIT YOU ARE IN?,Negative
Intel,"Dude, how can you even suggest that.  Why would we use a service from a company that is enabling the RAMpocalypse to begin with?",Negative
Intel,"They want us to tunnel into that and lose ownership of our PCs.  That is terrible advice or do you like clicking on ""This Computer""",Negative
Intel,In other countries SSD prices have hit 2GB 400$ it's the future.. consoles will increase in price too you know. A console is just a PC with autism they are still the same on the inside.,Neutral
Intel,"Same. Can't wait for prices to go up even more, and depending on how much money you have a few hundred extra isn't really THAT much",Negative
Intel,"As someone mentioned, buy prebuild.. Ultra cheaper",Neutral
Intel,"Getting into the hobby is the worst I have ever seen it.  If you have a built PC that you can use some parts, like the PSU and the GPU, it isn't terrible but it still sucks.",Negative
Intel,"There have been constant good times to build a pc. Literally all of 2025 things were cheap. Mid last year any thing you wanted would be in stock as well if it was a 5090 you wanted.   Right now, 64gb a ram is the cost of a mid level rig 4 months ago. The sad part is at least 2026 is likely an entire year of sucky to build in. No 5xxx super series gpus were announced as its data center focus time. Who knows how bad it will stay.",Positive
Intel,Just experienced this getting a prebuilt from microcenter. Had my eye on one of the prebuilts there with a 5070ti in it. They just increased the MSRP of the 5070ti up to $900 but that prebuilt didn't increase in price at the same time.,Neutral
Intel,"Yeah I bought a prebuilt with a 9800x3d  and 5070 ti. I normally build all my own stuff but it didn't work that way this time. I plan on selling the 5070 ti and putting my 4090 in after I replace the garbage power supply. Everything else seemed ""good enough"" and not complete trash so that's good haha",Negative
Intel,"Same here, this is the first time I've ever suggested buying prebuild (started with building 10 years ago). I wasn't planning on upgrading this year, was on 2080S, but saw a 5080/9800x3d PC for Â£2100 at the end of last year and knew if I waited any longer I'd regret it. Wish I'd known someone with a Costco card during the Black Friday sales though...",Neutral
Intel,"Same here. I built a 5060TI self-build for the same price as a pre-built 5070TI at Microcenter (1800). For me, I was not price sensitive and building was the purpose of the hobby, so pre-build didn't make sense. But fuck me if that didn't hurt.",Negative
Intel,"That's a really good deal. I wish they had more locations. MicroCenter is in Miami and I'm in northern Broward. It's like 45 miles away from me. Doesn't sound bad, but what makes it bad is the traffic and the really dangerous drivers. :(",Positive
Intel,"They indeed do at times that are worth it. Unfortunately not as great as it was a month ago like where my buddy got a gaming PC with a 7900X, RTX 5080, 32 GB RAM, and 2 TB NVMe for just $1999. It was an unbelievable deal.",Positive
Intel,"Nope. This isn't bad advice. I don't think you realize how bad the prices are, even on older platforms.  I have a coworker and I was about to give him an AM4 motherboard, RAM, and a PSU for free (I literally just have these parts lying around). He would be coming off of a 9900k. I calculated the cost to get other components, including a 5700X3D CPU and a 5060 Ti 16 GB (selling at around $520 just yesterday) and I found out way better value could be had if he spent a few hundred more on an AM5 prebuild where he'd have a bigger performance boost (it's hard to justify spending $1200-1300 when you include new storage and other accessories on an AM4 upgrade with a 30% performance boost on Tarkov). And again, all of this cost after I give him a bunch of parts for free. X3D CPUs are stupid expensive on AM4 used. You should look at the prices. A 5800X3D is often times being sold at prices higher than a 9800X3D brand new.",Neutral
Intel,I heard it was Fall 2028,Neutral
Intel,fr fall is pretty wild to speculate. That's fast.,Neutral
Intel,I hate how this^ post has two meanings that are both plausible.,Negative
Intel,"Yeah, likely more like end of year or next year with the way China is ramping up prod.",Neutral
Intel,I think itâ€™s over unless a competitor makes a new gpu line.,Neutral
Intel,The prices will drop before GTA VI that's for sure,Negative
Intel,Think he means the fall of rome 2.0,Neutral
Intel,Fall of this year!? Well bless your heart lol,Positive
Intel,"Why is every top upvoted comment on reddit pure moronic misery?  People are asking for genuine advise, they do not want to have pure egoistic misery dumbed on them for no reason.  I know, this is kind of the point of reddit, but come on....",Negative
Intel,"Key words are ""**speculate** prices will not **start** to drop until fall this year"" absolutely! ðŸ˜…",Neutral
Intel,"And this is all assuming they come down at all. I fear it'll be like crypto or covid all over again where prices just stay high because why not? A lot of people will still pay it. GPU prices never really came back down after crypto, they only got more expensive.",Negative
Intel,"They'll have to lower prices if people stop buying their products. Unlike high-end GPUs where its a dedicated product for a smaller userbase, flash memory is used in just about every tech product around. Hardcore gamers might be willing to pay inflated prices for their GPUs, but your average person won't be so willing to pay double for a new PC when they can just keep using their old one. And the last thing these manufactures want to do is sit on tons of stock that isn't selling and rapidly depreciates in value.",Negative
Intel,"I was just telling somebody the last time I upgraded my RAM was late 2022. I spent 84.99 (total) on two sticks of G.Skill DDR4 16GB 3600 from Newegg. Same exact kit now on Newegg is $254.99. That wasnâ€™t even any kind of new hotness when I bought it, now itâ€™s practically antiquated. $254.99. Itâ€™s scalper pricing.",Negative
Intel,The home computer market is a rounding error compared to enterprise.,Neutral
Intel,"There is always someone willing to buy. And home PCs are a rounding error when compared to everything else, especially enterprise products.",Neutral
Intel,"No way. I donâ€™t even get max settings on Cyberpunk at 60 fps at 1080p and Iâ€™m using a Ventus (no frills) RTX 2060 12GB. That GPU alone right now is $695 on Newegg.  With Windows 11 youâ€™re also going to need 32GB of RAM and the cheapest no-name 32 GB kit (DDR4 2400 at that) is $120. Weâ€™ve already busted $800 and havenâ€™t even looked at a CPU yet, let alone the rest of the PC.",Negative
Intel,"Its crazy to think that i bought my ddr5 2Ã—16gb ram for roughly 110â‚¬ about 18 months ago, i feel incredibly lucky that i didnt wait any longer to finally build my first pc. On the other hand i also waited and slowly saved up for about 5-7 years, allways looking if there were good deals. One can only hope that times will get better soon. Im honestly worried that thr whole ai thing will not crash and we will have to wait a couple more years until things stabilise again in the electronics market.  Sometimes its worth checking local electronic shops, they sometimes have really good deals, noone knows about, because we young people order everything nowadays. I have seen some crazy deals on prebuilds for like 600-800â‚¬ down from 1.5kâ‚¬",Positive
Intel,"Generally, your instincts are correct as prices usually go down. It's just crazy times we live in",Neutral
Intel,I bought a 1k pre built new with a 9060 16gb. Not sure of your expectations but it plays almost all games in high quality.,Positive
Intel,"Used PC's are banger deals if you're careful.   I sold a Ryzen 5700 system with a 2080 init for the price of the dang ram less than a month later. So yea, theres deals to be had.",Positive
Intel,Yes used is the way to go.,Neutral
Intel,"Are you in the USA? If so, might want to check local brick and mortar stores like Walmart or Staples. They sometimes have deals on parts that you can scrounge together. Or display units for prebuilts. Biggest price sinks right now are RAM, storage, and GPU.",Neutral
Intel,"As a teen, I would aways buy used parts because I was too impatient to save for newer parts.   I still do it to this day.  I've had a couple times where it did not turn out well for me but for the most part, if you are careful and fast enough, you will be able to score some really good deals.     I was recently able to build a pc with parts I got from a deal for a whole pc and some other listings I found for around 1800$CAD that easily would have cost about 2700 to 2800$ tax in new.",Neutral
Intel,I really wanted to finally get another PC to upgrade from an i5-7400 and 1050ti (my old one was from 2017 and I built it during the crypto ram price bubble) but parts got stupid expensive again. I seem to time it poorly every time.  Just bought a second hand rig for Â£470 with an i5-12400 and 3060ti. Seems to be playing everything on high/ultra super nicely so far! And not the end of the world if in a few years time I want to upgrade again! Though in my case probably another 8 years.,Negative
Intel,If you live near Microcenter it's not too bad. The used prices are kinda crazy right now.,Neutral
Intel,"You might find a good deal on a used PC, but they're also more expensive than normal,  and they might have undisclosed defects and expired warranty.  I haven't seen anybody mention it so I'll suggest you consider the upcoming Steam Machine, we should have some more info soon.",Negative
Intel,"I just bought one today after checking different options. I made part lists, tried builder sites, and looked at prebuilt. The used ones were cheapest but you might have fewer options on parts. Prebuilt is next cheapest, I was able to get a slightly better graphics card and processor with a prebuild over building my own for the same price, and that's not even counting shipping for ordering parts separately and having a warranty. I feel like right now a prebuilt is the best option. Or used/refurb if you find the right one.",Positive
Intel,Used is good but you really have to be careful and know exactly what youre getting. Make sure everything works,Neutral
Intel,"If you only want to game, your best option right now is to buy a PS5 (Pro), save the rest of your budget, and buy a new PC in a few years when prices have come down. A used PC will have a hard time beating a PS5 for the same price.",Neutral
Intel,Feels very bad buying slightly older tech for more than what it cost when it was new a year or two ago,Negative
Intel,"I second this, interested to see cause im going about the same route",Positive
Intel,"Nice! There's some pretty good bundle deals might check for. Might set the store location to check stock.   https://www.microcenter.com/search/search_results.aspx?fq=category%3aComputer+Build+Bundles%7c775&sortby=pricelow&storeid=115   Might also check there for any GPU deals maybe better pricing(also open box deals), and others.Â    PCpartpicker is also a great tool for price checking at a few retailers.   For storage, and GPU, also seen some deals at in store only not advertised online at Staples and Walmart of all places(but its slim pickins now that people have found out).   All and all, micro center sounds like a good start.",Positive
Intel,Ur better of getting an am4 system. Ddr4 3600 used is still cheap if u browse Facebook marketplace. I got 16gb corsair rgb for 70$ a week ago.,Neutral
Intel,"Yep, ram pricing the main culprit.",Negative
Intel,"Basically the ""discount"" you get is not paying super jacked up ram prices.",Neutral
Intel,"Nope, they'll just keep charging high because they can",Neutral
Intel,Uh. Yea they did. To levels seen before? No. From peak? Yes.,Neutral
Intel,It did though. Do you not remember graphics cards being 3x?,Neutral
Intel,Yes..,Positive
Intel,"Hello, your comment has been removed. Please note the following from our [subreddit rules](https://www.reddit.com/r/buildapc/wiki/rules):  **Rule 3 : No piracy or grey-market software keys**  > This includes suggesting, hinting, or in any way implying to someone that piracy, or violation of license agreements is an option.   > If a license key is abnormally cheap (think $5 - $30), it is probably grey market, and thus forbidden on /r/buildapc.    ---  [^(Click here to message the moderators if you have any questions or concerns)](https://www\.reddit\.com/message/compose?to=%2Fr%2Fbuildapc&subject=Querying mod action for this comment&message=I'm writing to you about %5Bthis comment%5D%28https://www.reddit.com/r/buildapc/comments/1qqmqb6/-/o2jlbyg/%29.%0D%0D---%0D%0D)",Neutral
Intel,"I hope youâ€™re right, I love this hobby and in the last 15 years itâ€™s been shit on over and over again, from crypto to Ai. I wish these Ai models never happened.",Negative
Intel,A cOnSoLe PlAyEr?! In mY bUiLd A pC sUbReDdIt?!?!?! bLaSpHeMy!!!!!!!!,Negative
Intel,"Because building a PC right now is crazy? Personally, Iâ€™m just sitting the next year out with my 3080. But there are worse things in the world than paying $200 for a year of 4k 120/240hz with 10-15ms of added latency. Much better than paying $1500 for old tech.",Negative
Intel,"I upgraded last year from a i7700k, new CPU = new motherboard & cooler = new ram = new PSU, upgraded GPUâ€¦same case & fans.",Neutral
Intel,"Indeed. Also sometimes there may be great deals. For $1999 in early to mid December, my buddy got a brand new IBuyPower gaming PC with a 5080, 32 GB RAM, and a 7900X. Even at that time, good luck getting that at such a price. I was looking the other day and now that same PC is like $2500 if I recall correctly.",Positive
Intel,"why are there SO MANY prebuilts with horrible psus even tho theyre built by alleged ""experts""? even the prebuilt im trying to buy has an E tier PSU that im gonna have to ask them to remove so i can place one of my own",Negative
Intel,Throw the power supply in head of trump?,Neutral
Intel,Wrong fall 38',Negative
Intel,Closer to the Fall of the US.,Negative
Intel,You all may be too â€œglass half fullâ€ kind of people. I was going for Fallout 76,Neutral
Intel,Fall 6050,Neutral
Intel,"GTA VI isnâ€™t being released on PC, so thatâ€™s unlikely.",Neutral
Intel,"Yes, you should expect this from Reddit.   But also every report indicates that these AI companies have bought up all the RAM for the next couple years. RAM prices ainâ€™t dropping in fall.",Neutral
Intel,"I've lived through multiple computer price boom and busts.  There is literally no way of predicting where prices will go.  They could stay elevated for 3 years, they could crash in 3 months (not likely, imo).  I remember when I built my first PC I bought RAM right before prices jacket up in 2017, and they stayed elevated for several years IIRC.",Negative
Intel,"Not sure where you live but GPU prices returned to pretty much the same in the UK.  During covid/crypto the RTX 20 Series was betweeen Â£1-2k, and I know people who were paying more. I remember seeing the RTX 30 Series for like Â£4k+ in 2021.  Meanwhile in 2023 I managed to get a 4070 for Â£550.",Neutral
Intel,That makes sense.,Positive
Intel,The only way youâ€™re getting a PC thatâ€™ll run anything you want at 60 FPS/1080p/Max settings for $800 right now is if you pay a truck driver $800 to have one fall off the back of his truck.,Negative
Intel,I bought the last 3 gen4 nvme ps5 drives that were the only reasonable option to buy ssd storage rn. An equivalent nvme was double the price,Neutral
Intel,"I just got my friend a used i5 12400 with 3060, 2.5 yr old PC for under $500 last week.",Neutral
Intel,Mr.pierogi do you not grasp the grave mistake you have made? This is nothing to joke about I will have my AI overlords feed you to the hungry machines at once!,Negative
Intel,Same thing on my end. 9800x3d/5070 TI/2 tb ssd/32gb ram $1899. I just jumped on it because they are going to catch on at some point and raise the prices on all the prebuilts,Neutral
Intel,Because it makes it cheaper for them. They must have a partnership with apevia or something. I know it wasn't ideal but it's the way I went in the current market. I bought a super flower 1200w 80+ titanium to replace mine because I DON'T fuck around with power supplies,Neutral
Intel,"NZXT has good components for their pre-builts, at least when I got mine.   Might want to take a look at their offering.",Positive
Intel,Average person donâ€™t know any better. Just another cost cutting measure.,Negative
Intel,"Yall really think these companies will remain solvent by 2028? They're hemorrhaging billions of dollars a quarter with little revenue. Vc funds are already drying up, and the talk of ad inclusion is bc shareholders want returns sooner rather than later.   There's just no way they have enough capital to remain afloat till then.",Negative
Intel,"Nah, Fallout '76",Neutral
Intel,Fall 3800 for sure.,Neutral
Intel,Fall of society,Negative
Intel,I heard it was Fall of Reach,Neutral
Intel,You mean 2138.,Neutral
Intel,Was it the bite of 87?!,Neutral
Intel,We might be done as a society by then because of their greed.,Negative
Intel,Donâ€™t tempt me with the RTX 6000 series GPUs ðŸ˜­,Negative
Intel,"In my experience, by the time youâ€™re ready for a new computer, the market will have levelled out and youâ€™ll know when itâ€™s time to start fresh. When prices go silly like the COVID bitcoin mining era, the market basically makes your decision for you. It levelled out for a couple years, by then my computer was around 7 years old. I built a new one 2ish years ago, Iâ€™m sure in 5 years when Iâ€™m ready to start fresh RAM wonâ€™t cost $750.  At least, I hope. If not, weâ€™ve got bigger fish to fry than PC builds lol",Neutral
Intel,"MSRP has gone up every series since the 1000 series, as have third party/reseller prices. Pretty sure the 5000 series is the first series where MSRP actually went down (just barely) compared to the previous series, but MSRP prices hardly exist. Just because cards aren't at their peak crypto absurdity prices anymore doesn't mean the prices in general still haven't gone up series after series on average.",Neutral
Intel,Nice. What mobo did you use? i was looking for a 119$ msi mobo. Too bad it doesnt have wifi.  I already have my gaming pc but i was building one for my mom with a 400 budget. i just need the mobo.,Negative
Intel,I'm selling a r5 3600 + 2070 8Gb + 16 Gb FFR4 + 1.5Tb (nvme + 2 SSD) + Bequiet case for 420 euros and people are still bargaining whereas I can de-activate the classified ad and sell it 500 euros in 2 months.,Neutral
Intel,Machines? Hungry? Impossible!,Negative
Intel,"as you shouldnt. And mine isnt an apevia, but it is in fact TR2 S from Thermaltake, which also happens to be one of their Worst psus, while not even being relatively cheap. Im still baffled tbh, but i would chalk this up to incompetence",Negative
Intel,"Seems vastly unlikely to me that any of OpenAI, Anthropic, Microsoft, Amazon, xAI, or Google will declare bankruptcy before 2028. Capex vs revenue run rate is not that extreme by historical standards, compute can be used for inference as well as training, and most of these companies are pretty diversified (public and private sales, B2B as well as general users; not just language assistants, but driverless cars, drug discovery, material science, miltech, etc).  There will definitely be middle rank AI companies that get eaten but the general AI bubble narrative doesnâ€™t hold water.",Neutral
Intel,"It's the dot-com bubble all over again. Just earlier today my dad was reminiscing on it. Billions poured into telecom companies that were supposed to be the backbone. It probably won't crash like the dot-com bubble, but it will come down, hopefully hard.",Negative
Intel,"If the AI bubble does pop, weâ€™re all going to have way bigger problems than the price of PC components. AI investment is the only thing keeping the economy growing, so it the bubble pops, weâ€™re in for the mother of all recessions.  The AI industry is great. If it succeeds like the proponents say it will, most of us will lose our jobs, but if it fails like the skeptics say it will, most of us will lose our jobs. Â¯\\_(ãƒ„)_/Â¯",Negative
Intel,The parts manufactures .,Neutral
Intel,"Dunno about that.    OpenAI is apparently about to get $100 billion from Amazon, Microsoft, Nvidia, Softbank, etc. ahead of an IPO late this year.  Wouldn't surprise me if certain nation-states also bought into it.  Google and Meta generate enough cash outside AI to keep throwing money at it for years.  xAI has...whatever deal with the devil Musk made to keep it afloat.",Neutral
Intel,trump will put some other guy and interest rates will go negative so that banks will give infinite money to VCs to blow in even more harebrained AI investments,Neutral
Intel,Theyâ€™re getting bailed out by daddy trump cause some how these scam jobs apparently became 50% of the stock market over night,Negative
Intel,Iâ€™m hearing the chip producers have just retooled for industrial production vs consumer productionâ€¦ But I hear a lot of shit so I dunno.,Negative
Intel,"Ai is here to stay, it doesn't matter which company wins they will be building data centers for the next decade.. it's not a bubble that will pop.    You don't just make ai and then forget about it because it wasn't profitable.  That's like creating electricity and then saying naw... that's too much work.    Look at Tesla.  It's been around like 15 years and it's still barely breaking even.    Rich companies with all the money in the world will fund it till it's profitable because it's too great of an invention to let go and whichever of these rich companies ends up with control over it will be in charge for the foreseeable future.    Lack of profits will never, ever kill AI.",Neutral
Intel,That's the price for 32GB RAM in fall.,Neutral
Intel,Last year I told myself by the end of 2026 ill need to upgrade my PC.  Not happy about the ram prices but it is what it is.,Negative
Intel,"Honestly, that's kinda overpriced even in this market. 3600 is very slow and that 2070 is quite old. Keep the 2 SSDs and sell it. The seller gave my friend additional brand new headphones and keyboard along with it noting how diligent and nice we were.",Negative
Intel,Darpas EATR robots are fiending for a meal they have already eaten 99% of the human population and their batteries are running low,Negative
Intel,Yeah it's ridiculous. Let's put high end components in a PC and put a time bomb in it with them when power supplies aren't even that expensive. I spent $189 on mine and it's an A+ on the PSU chart.,Negative
Intel,"The companies themselves may not collapse, but the more diversified companies (Google, Microsoft, Amazon) will toss AI aside once the bubble pops, just like they do with every other tech fad once the money is gone. They have plenty of other revenue sources that they can rely on to weather through a storm.  The AI-exclusive companies on the other hand (OpenAI and Anthropic) are bound to collapse with the bubble, since they basically exist solely from investment funds and hemorrhage money like there's no tomorrow.",Neutral
Intel,"This is why they are all investing and moving money into each other's companies. They don't want to crash. If everyone is linked together, the govt will bail them out anyway. They make their billions easy.",Neutral
Intel,"I worry it's going to be like the 2008 financial crisis.  That same level of dumb bullshit, the same level of ""we got fleeced, bail us out or everything crashes!""",Negative
Intel,Presumably they will raise prices in other areas to fund the AI for as long as possible.  So the people will end up paying one way or another.,Neutral
Intel,"Artificial Intelligence itself certainly isn't going anywhere, but Generative AI (which is what 90% of people are talking about when they refer to ""AI"" and is what the current bubble is built on) does not make money and will never make money. The operating costs are tremendous, and if they try to impose higher costs, they lose the majority of their users (which comes from everyday people using free models).",Negative
Intel,"The bubble can still pop, and it can still wreak havok on the global economy.  It's not like the dot com bubble killed the internet or the 2008 crisis killed owning property.  AI is definitely here to stay, and I am convinced we're also in a bubble. Those two are not mutually exclusive.",Neutral
Intel,I know but I sold 2 with comparable specs in the last 4 months at this price :p,Neutral
Intel,"Sounds like I just have to wait them out then! Can they catch me before they run out of battery? Next time, on r/BuildaPC Abridged!",Neutral
Intel,their clever ruse is to make your pc blow up and hope youre gullible enough to (for some reason) buy another one from them,Negative
Intel,"Google, Microsoft, and Amazon are not going to drop AI. You think Google is going to say its fleet of Waymos rolling out in cities around the world was empty hype? That the medical and material science research tools coming out of DeepMind were just fads? Meanwhile Satya Nadella has promised $80 billion on data centres and compute.  OpenAI and Anthropic are also not going to run out of funding any time soon. OpenAI just raised at $500B valuation, Anthropic has Amazon and Google as backers and a queue of sovereign wealth funds waiting for equity. They have years of runway, and revenues are increasing fast; OpenAI went from $6 billion in 2024 to $20 billion in 2025. Anthropic went from $1 billion to $5 billion in the same period.  All of this will resolve in the next 2-3 years anyway. But itâ€™s interesting to see how many people are classing AI as â€œjust the next hype thingâ€ alongside the metaverse and bitcoin when itâ€™s something utterly different â€” a proper general purpose technology covering dozens of different sectors and markets and the culmination of an 80 year research project.",Neutral
Intel,Oh god oh no they are connecting into a human centipede like structure using the charging cables coming out of their mouth to charge into eachothers behinds to charge up the batteries of the strongest robots now having enough energy to EAT YOU NOOO,Negative
Intel,I knew the risks going into buying what I bought and I'll have to gamble with it. I checked all the connections and everything was surprisingly well put together and managed. I'm hoping that with my new PSU everything will work out. I'm trying to get my buddy to upgrade his 3090 to the 5070 TI that came in it so I can make back some of the money I spent.,Positive
Intel,"Should've been more specific, AI as a whole isn't going anywhere, it's Generative AI that has no real future. AI for research and FSD clearly has a future and has tremendous value as a tool, but Generative AI such as LLMs bleed money without any real forms of profit.",Negative
Intel,"Insulated Scissors, go! Use Cut!",Neutral
Intel,"That 5070 ti was in the back of my head, i thought ""theres no way buying a prebuilt with a garbage psu AND weak GPU costs less than building everything on your own"", i thought you'd try to sell it, but that seems like a more coherent idea lol",Negative
Intel,"Good clarification. Overall I still disagree (eg, because a lot of valuable STEM AI tools are built on generative AI backbones) but itâ€™s definitely the area where thereâ€™s the greatest danger of a bubble.",Negative
Intel,"You could spend all that on ram alone, honestly your system seems pretty balanced and not in dire need of an upgrade unless youâ€™ve got fuck you money",Negative
Intel,I sold my 570x/5900x/32 GB CL16 for 250 flakes back then.,Neutral
Intel,Thatâ€™s not my system bro thatâ€™s what Iâ€™m eyeing,Neutral
Intel,"Ahh sorry I misread, itâ€™s definitely balanced. For the money could you get a 9060 xt instead of the b580? It performs slightly better and has more vram if you get the 16gb version",Positive
Intel,It's a good gpu for its price. The driver issues that ruined A-series seem to be gone. Just be sure to enable ReBAR: BattleMage needs to to perform best,Positive
Intel,[https://www.youtube.com/watch?v=00GmwHIJuJY](https://www.youtube.com/watch?v=00GmwHIJuJY)   [https://www.youtube.com/watch?v=npIpWFSfmv4](https://www.youtube.com/watch?v=npIpWFSfmv4)  Not sure what kind of options you have where you are. 3060 is pretty long in the tooth unless your getting a smoking deal. No low priced 9060s or or anything around where you are?,Neutral
Intel,At 250 its a crazy good deal. Its not top of the line but its winning competition is the fact that it beats out every other card in its weight class at its price point.,Positive
Intel,Itâ€™s great,Positive
Intel,"In comparison to other GPUs within its range, what would it be comparable to in terms of performance?",Neutral
Intel,"In comparison to other GPUs within its range, what would it be comparable to in terms of performance? Especially if the driver issues are no longer present with the more recent updates",Neutral
Intel,"A bit out of my price range, even for a used one. Iâ€™m only 19 and Iâ€™m building this by myself with my own money as my first ever build. From where Iâ€™m from, the 3060 12 gb is a bit manageable price-wise, I just wanted to check out other options.",Neutral
Intel,"i remember hearing that the overhead issues are less of/not an issue now, due to driver updates",Neutral
Intel,[similar to a 3060ti](https://www.techpowerup.com/review/intel-arc-b580/32.html) but with newer features,Neutral
Intel,Fair. If your on a tight budget. Consider some of the RDNA3 AMD cards as well. I mean if your looking at a 3 generation old 3060 anyway. Something like the 7600 XT 16gb might be on the market where you are at a good price. Its probably 20% or so faster then a 3060.,Positive
Intel,Have you checked the bios to make sure your ram is running at the correct speed?,Neutral
Intel,dlls/framegen?,Neutral
Intel,"If game is graphically intensive -> GPU usage goes up.  If CPU not able to provide enough frames to keep up with GPU -> CPU bottleneck, GPU usage unable to go up, stuck at X%.  If you play at 1080p, less graphically intensive, uses less of your GPU. If you play at 1440p, then naturally your GPU needs to work harder, so its usage is higher.  Looks like your setup is working as expected and you're cpu limited in arc raiders. Open task manager and under the performance tab, check if ram speed is running at 3200mhz. If it is, then you're probably just CPU limited.",Neutral
Intel,"What graphics settings? I get about the same at epic/high settings, dlss balanced, 1440p on a 5070ti and 12700k. Probably cpu bottleneck, idk",Neutral
Intel,You need to monitor your CPU usage,Neutral
Intel,"Just so we're on the same page, at 1080p you can expect the cpu to be working harder.",Neutral
Intel,"150-170 FPS seems just fine to me for a 4070. It's a previous generation mid-range card. See if there's something you can optimize in the options, sometimes stuff like shadows or reflections can greatly influence how a game runs.",Neutral
Intel,What power mode is your PC in? If it's in high performance mode it's not scheduling correctly because the scheduler in Windows will prioritize the cores with the higher clock speed rather than the ones with the higher cache.,Neutral
Intel,That isnâ€™t going to cause a big issue like this. X3d chips are less reliant on ram speed than other Ryzen chips,Neutral
Intel,"For these tests I was running all low settings to see if fps would be better. Have tried no aa, and other settings to see if it would improve.",Neutral
Intel,Sounds good! Thank you!,Positive
Intel,Should I change it?,Neutral
Intel,"It's totally irrelevant in OP's case. He's got a 5700X3D, not a dual CCD X3D chip.",Negative
Intel,Yeah if graphics settings don't improve that's a dead giveaway that you're CPU limited,Negative
Intel,Yes you should set it to balanced,Neutral
Intel,Ok and from there the only option would just be to upgrade my cpu right,Neutral
Intel,Nothing to really upgrade to. Time for AM5.,Negative
Intel,"Check your GPU utilization in the game. If it's near 100%, then a GPU upgrade is the best option. But, I encourage you not to buy the RTX 3050. Try to get at least a 3060.",Neutral
Intel,Intel has GPUs for a while they got a pretty good budget option too (just some problems with it though) called the Intel arc b580. Anyways upgrading to AM5 is not viable as its Ramageddon so ram prices are horrendous rn. I recommend checking out the 5600xt or 5800XT CPU. As for the GPU try looking for a 9060xt 8gb or 16gb it's a pretty budget option that'll do you well. If you have a budget of around 200-300 get rtx 3060. Before all this though what's your PSU wattage,Neutral
Intel,"If you're open to getting used, might be able to upgrade both. Ryzen 5600 are ~100-120 USD used on Ebay or on Aliexpress (or look around for a local seller on Facebook Marketplace or /r/hardwareswap) and it drops right into your board to replace the 2600. Pair that with an Arc B580 (~250, maybe less used) and you've got a pretty solid setup.",Neutral
Intel,Why not find a decent 5000 series cpu and thenulgrade the gpu?,Neutral
Intel,What's your budget?,Neutral
Intel,"What is you max budget? Anyway, since the RAM price is pretty fcked nowadays, I recommend you to stay on AM4 platform and just upgrade the CPU instead of straight away go to AM5 or Intel DDR5 equivalent  Unless you can only afford 3050 or 1660 Super, you'd better with something like 3060 12GB or something else",Neutral
Intel,What speed is that RAM?,Neutral
Intel,"Keep the Ryzen 7 2700, B450 mb, 32g ram and get a GPU. You said the Intel B570 but for a little more you can get Intel B580 if your PSU and MB support it. You also said I5 14400 but then you would need another Motherboard.",Neutral
Intel,"hey brother I have the same build (except I use Strix X470-I Gaming mobo and 16GB RAM). I am upgrading to a 5700x, a 9060 XT 16GB and 64GB of RAM.",Neutral
Intel,"Any 5000-series CPU would be a *massive* upgrade, howeverâ€¦ GPUs specifically will see massive price hikes & shortages in the next couple months. So it might actually be the last time you can snag a cheap used GPU.  Forget the 3050, a 3060Ti is an excellent value under $200. If you can find a 12GB version, youâ€™ll be especially glad you did. Iâ€™d recommend a 4060 for the same price range, but your motherboard is most likely PCI gen 3, so a 30-series card is your best bet. With the latest DLSS updates, Iâ€™d personally stick with RTX, especially with a lower-power card.",Positive
Intel,That or finding the best priced used 30 series card.,Neutral
Intel,600 watts,Neutral
Intel,3060 ti is sub $200 used. Not a bad upgrade. He can get a used 6800 (non XT) for sub $300,Positive
Intel,Because I am dumb lol. This is the better option.,Negative
Intel,250 or lower.,Neutral
Intel,250 or lower is my budget.,Neutral
Intel,3600 I think?,Neutral
Intel,Yeah that's sufficient,Positive
Intel,Used GPU for $150-180.  Used CPU for under $100.,Neutral
Intel,Thank you! :D,Positive
Intel,"You couldn't really have picked a worse time to upgrade then. If you really want though, the MC bundles look at least acceptable given the situation. The prebuilt route could also work, but definitely not with a 8700F which is barely an upgrade (if any) to the 5600X in gaming. Honestly i'd just let it go for now.",Neutral
Intel,5600x is still good. The 4070 is still good. Sell your 16gb of ram and buy a 32gb kit. I would rock this setup until prices arenâ€™t ridiculous.,Positive
Intel,"[There's no way the 5600x is bottlenecking your system](https://www.youtube.com/watch?v=RijAyVshtok) unless you're playing at 1080p. If so, just get more ram and a 1440p monitor, then your 4070 will be doing more heavy lifting over the cpu, and you'll get a huge jump in graphical fidelity :)  i say this only because prices are nuts, and you'll be spending lots and lots of money for just not that much performance increase.  Edit: If we watch the performance for [BF6 ](https://youtu.be/RijAyVshtok?si=zcS0W5laSZ6tPgSv&t=202)and [Arc Raiders](https://youtu.be/RijAyVshtok?si=PQ-s1sfGXjY7KBbh&t=235), the 5600x still holds up quite well",Neutral
Intel,I did 5600X to 5800X3D when it was a relatively affordable option and it wasnâ€™t a massive upgrade given the lower clock speeds of the X3D chip.  With PBO enabled on the 5600X it should be fine for gaming in 1440p.  A bump up to 32GB would be beneficial.  Otherwise thatâ€™s a fine system with the 4070.,Neutral
Intel,"which board you have currently, I am going to do similar build and confused about the board :/ [https://www.reddit.com/r/buildapc/comments/1qokwrr/please\_help\_me\_pick\_a\_vfm\_b450550\_motherboard\_for/](https://www.reddit.com/r/buildapc/comments/1qokwrr/please_help_me_pick_a_vfm_b450550_motherboard_for/)",Negative
Intel,"Any x3d bundle from microcenter is really good right now and would be well worth it over your 5600x.  The 7800x3d one for $650 is the best value one, but the 9800x3d one for $750 is the best one for just pure gaming performance.",Positive
Intel,Just a quick build/upgrade based on what you're looking for:   [https://pcpartpicker.com/list/jYk3HW](https://pcpartpicker.com/list/jYk3HW),Neutral
Intel,"I think you're lucky for living near a Microcenter store, and that you shouldn't second think.  I would take any X3D + 32GB RAM bundle. Just choose one according to your budget and needs.",Positive
Intel,Personally havent seen my 5600x be a bottleneck for my 5070 GPU @ 1440p gaming,Neutral
Intel,"Yup i get ~120 fps on ultra in BF6 with a 5070ti, 5600x and 32gb ram",Positive
Intel,I have a 9060 xt 16 gig and a 5600x with 16 gigs of 3600 mhz ram.  I get poor 1% lows running most settings on high.  My fps is around 110-130 but stuttering is an issue.  Capped my fps at 90 and that helps but definitely feel like an upgrade would help.,Negative
Intel,"Im on a prebuild from 2022? I forget what year. ASUS PRIME B550M-A AC  For you if you havent bought a CPU yet, I'd consider getting one of the lower end AM5 CPUs instead of the 5 5600X, that way upgrading later will be easier since you wont have to change the motherboard later.",Neutral
Intel,Just grabbed the 7800x3d bundle myself for a new build. Insane deal,Positive
Intel,BF6 has been the primary culprit for me. Arc Raiders kind of but to a lesser degree.,Negative
Intel,This is good to hear. I have a 5600x and just ordered a 5070TI. My only issue is I waited to long to upgrade ram and only have 16gbâ€¦,Positive
Intel,"If it was with a 5500 or other 16mb l3 cache CPU I'd be inclined to blame it, but very odd to see stuttering attributed to the 5600x and not something like verifying ram profile, reinstalling drivers, or perhaps a little PBO + curve optimizer couldn't fix  Playing at 1080p?",Negative
Intel,yeah with current pricing you are almost getting the 7800x3d for free with that bundle. MC is the goat for a very good reason.,Positive
Intel,I bought 16gb more of the same ram off ebay for like $80. Good luck.,Positive
Intel,1440 and have tried all of the above.  Specifically when I get near the fire line in bf6 redsec I get a lot of issues and my guess is the volumetric rendering of fire and smoke is CPU intensive.  My fps doesn't drop too bad but I get stutters and frame drops I can only assume are bad 1% lows.  Really wish javelin anti cheat didn't block third party software from capturing frame data.  Even amd adrenaline can't monitor my frame data.,Negative
Intel,Good idea! Thanks. No issues running 4 ram sticks?,Positive
Intel,"I use MSI afterburner + rivatuner to monitor my fps in BF6, maybe see if that works for you  I would try optimizing your graphics settings a bit and see if that helps [https://www.youtube.com/watch?v=eCb3rc9lvHY](https://www.youtube.com/watch?v=eCb3rc9lvHY)  Also make sure you don't have a lot of background processes eating up your RAM capacity since with only 16gb available running out of RAM could potentially be contributing.  Just trying to help ya find an alternate solution since an AM5 upgrade is so darn expensive.",Neutral
Intel,Not yet!,Neutral
Intel,I'll look into afterburner and riva I have them installed just haven't set it up.  I recently did a clean os install when I upgraded to my 9060xt.  Definitely run my system with no other windows open and have gone through a couple guides on optimum settings (both game and my windows/bios).  The game runs smooth with an fps limiter of 90.  Tried undervolting to give pbo some more room to push boost clocks and have process lasso installed with the game and anticheat set to priority.,Neutral
Intel,Maybe the wattage is too high to pull from your outlet.,Neutral
Intel,Try forcing the PCI-E1 into Gen4 mode. And how many lanes are used per PCI-E slot anyway?,Neutral
Intel,Is it vertically mounted by chance?,Neutral
Intel,Using dual monitors ?,Neutral
Intel,Hey mate. Try using DDU to completely get rid of everything associated with the drivers and install again.,Neutral
Intel,">Ventus  Probably as usual with them, overheating FETs. Ventus/Shadow is a massive avoid since they came out, no matter the Generation or renaming from. MECH/Armor",Neutral
Intel,"I had thought of that, and did move it to a different outlet just to test, along with it ran for years w/ a 4090 and the same power draw. But it is a good thought, thank you.",Positive
Intel,"It is not, horizontal w/ a support bracket.",Neutral
Intel,The clean windows install I did twice wouldâ€™ve had the same effect.,Neutral
Intel,Interesting as thatâ€™s the first Iâ€™m hearing of it. Is there any sensor I could poll to see and confirm that?      Interestingly I was wondering if the VRMs were overheating so I tried to kill and restart furmark in rapid succession to see if I could get it to throttle right away and itâ€™d always clock to 570+ before throttling.,Neutral
Intel,Got any links for this issue? Trying to find and canâ€™t,Negative
Intel,I would personally recommend a small UPS system to protect your investment!,Positive
Intel,You are seeing the bottleneck because your GPU is vastly more powerful than your CPU.   Not sure what Mobo you have but you might need to upgrade that to get to a more powerful CPU.,Neutral
Intel,"Congrats on the 5070!  Definitely time to upgrade the cpu. Take a look at Newegg or your preferred website for some mobo/cpu bundles. Definitely would pair well with a 9000 series ryzen but since you have ddr4 ram, and ram cost way way way too much. Maybe get the 5800X3D with an AM4 mobo.",Positive
Intel,"LGA1700 DDR4 board and a 12th gen i5/i7 or 13th/14th gen i5. If you can get a 12600K and a new motherboard, you wouldn't need to buy RAM which is more expensive than just a Mobo/CPU combo.",Neutral
Intel,Yes,Positive
Intel,thanks for the help! iâ€™ll look into them,Positive
Intel,iâ€™m not sure if this helps but i have 64 gigs of RAM. at least thatâ€™s what it says when i look on task manager lol. this also originally wasnâ€™t my pc i bought it off a buddy and he bought it prebuilt but since have swapped some parts off for custom ones. so i know my pc is kind of a weird build. but if i have that should i still try the 9000 series?,Neutral
Intel,thanks for the suggestion! iâ€™ll def look into that for sure!,Positive
Intel,"Sadly the new ryzen cpus only support ddr5 ram so your ddr4 ram wonâ€™t fit into the slots. There are some powerful intel cpus like the 12th, 13th, and 14th gen intel cpus. Just make sure the mobo you get would support ddr4.  Also, 64gb is fantastic to have! Thatâ€™s gonna be overkill with so many games but good for you ma.",Negative
Intel,sweet! thanks man!,Positive
Intel,Unless youre trying to get into 4k gaming you probably dont need an upgrade. In what way are you falling behind on performance?,Neutral
Intel,"Whats fallibg behind, cpu or gpu? Check the % usage when you play your games.",Neutral
Intel,"Definitely depends on your budget, but if you play games at higher resolutions, a GPU upgrade would be a good start. It can be quite expensive for a suitable upgrade though - Something like a 9070 XT starts at $700ish, which is a lot for a normal person.  Also, if you're one of the 3 people who live close to a microcenter, they have pretty good deals on AM5 CPU/Board/Ram combos. If you play especially CPU-heavy games that would be my go-to.  No matter what path you take, it will probably be kind of expensive. You have a good build as it sits, so really you're looking at some VERY high end components as upgrades.  With that being said, it's probably a good idea to buy sooner rather than later. Market for PC parts is already pretty bad, and things won't get any better.",Neutral
Intel,"A good GPU such as a 5070 Ti is going to provide the most benefit, the drawback is the cost. Unfortunately, itâ€™s a terrible time to do an upgrade bc of the AI bubble. If you donâ€™t have plenty of money to spend, you might want to wait for a year or two, when hopefully things will be much better, and next-generation parts will be out... but ofc thereâ€™s a chance the AI bubble wonâ€™t have popped and prices will be even worse.",Negative
Intel,Is your non standard memory config maybe causing gaming issues. Your only really  meaningful upgrade would be a 2 grand GPU as a gaming upgrade without changing everything.,Negative
Intel,What sort of games do you play?,Neutral
Intel,"in normal times i'd say storage, 1tb isn't really a lot these days. but these aren't normal times",Negative
Intel,"your pc is literally fine lol. what games are you playing that a 5600x and 3070 can't handle? unless you're trying to do 4k ultra on like starfield, you're probably just needing to turn down some settings",Neutral
Intel,Upgrade to 4070ti it's fairly cheap and will show the most value with your system.,Positive
Intel,"Agree, if you must spend money get more storage",Neutral
Intel,I havent checked what exactly is falling behind but on arc raiders for example i get to 100 fps max and thats after optimizing settings and dlss on balanced,Neutral
Intel,It shouldnt. i did some testing and everythings fine as far as i know,Neutral
Intel,"Pretty much everything but right now where i noticed poor performance is in arc raiders, after optimizing settings i get 100 fps max and thats on dlss on balanced",Negative
Intel,Cant hit 144 fps on arc raiders with optimized settings and dlss on balanced. Idc for 144 fps but in shooters its pretty important,Neutral
Intel,Are you experiencing things in game that impact play? You don't need 100 FPS to play a game.,Neutral
Intel,"cpu then, cpu is a lot more important for these sort of games especially on lower settings",Neutral
Intel,Frames are pretty consistent from what i could tell. I know i dont need it but its a pvp shooter and i dont have 144hz for nothing. I dont mind playing at 60 for singleplayer or pve games but i cant do it in shooters,Neutral
Intel,you could the say the same about wanting to play at 1440p or higher settings lmao,Neutral
Intel,"You have enough ram and storage for 2 gaming rigs and that processor is pretty solid. I'd start with a more modern 16GB graphics card, but youre going to pay a lot for it.Â    When I get competitive in games I usually end up turning the graphics down so I can see what's going on more easily. Theres a few I play on the absolute lowest settings.",Positive
Intel,What are you trying to say with this? I just asked because they didn't give specifics on what's wrong with performance.,Negative
Intel,"It's pretty obvious want I'm trying to say, he says he wants more than 100 fps you are saying that's good enough, which is a pretty fucking dumb thing to say, some people want more fps some people want better graphics",Negative
Intel,"Ok. That was not obvious to me. They answered the question and I gave them my suggestion on the upgrade, im not sure what youre upset about.",Neutral
Intel,"I mean I'm not really upset it's just a dumb thing to say, you don't need 100 fps the same way you don't need to play a game on anything but low settings, but people want to",Negative
Intel,"RTX 5060 is a better choice for Arc Raiders than RX 9060xt 8GB, however, RX 9060xt 8GB is a better GPU on average.   So up to you, what do you prefer.",Positive
Intel,Why they downvote you? Lol,Negative
Intel,9060xt is comparable to the 5060ti so it really doesn't make sense as to why you should go 5060 unless it's for frame gen or DLSS4.5,Negative
Intel,Do not buy an 8GB card in 2026. Just don't.,Negative
Intel,Are the Intel cards available in your region? What's their price?,Neutral
Intel,Rx 9060 any time,Neutral
Intel,Avoid 8gigs 9060xt at all costs!,Negative
Intel,5060 is a bit better in Arc Raiders however I'm not sure it's worth going over your budget that much.,Neutral
Intel,"FSR 4 is essentially unusable at 1080p, while DLSS 4.5 performs well. For that reason alone, Iâ€™d choose the 5060 if you can afford it.",Negative
Intel,"Hello, if the rx 9060xt  is cheaper get it  They are basically the same card.  Check out this benchmark:  https://youtu.be/xlbNsP5ySmA?si=XowPsOGMbrnOX1aD   Between the 9060xt 8 gb and the rtx 5060 you should allways get the cheaper one.",Neutral
Intel,"If you plan on using Linux down the road, the RX 9060XT might be the better option.",Positive
Intel,Where are u from ? They sell 9060xt 16gb for 380$ in iraq id assume the price is similar in such countries,Neutral
Intel,5060 is faster for arc raiders natively and considering the feature advantage I would def go for it.  Although keep in mind if you go over the 8gb vram limit the 9060 xt will handle that better and is faster on average just not in arc raiders,Positive
Intel,Get the 5060! It has a better feature set like better upscaling and better Ray Tracing! You also don't have to deal with crappy AMD drivers which I have experienced and many AMD RX 9000 series users are also experiencing! You have better peace of mind with the Nvidia GPU!,Positive
Intel,"From what I've heard arc raiders heavily favors Nvidia side of things, look up some testing with the either card. If that's all you play then 5060 will be the better choice.",Neutral
Intel,How much is a second hand 4060?,Neutral
Intel,"Go Nvidia but idk, is it possible for you to get 16gb? 8gb works perfectly fine in Arc Raiders, but 0 guarantee for other games, for example hogwarts or mafia are really struggling.  8gb can be a real gamble.",Negative
Intel,9060 XT 16gb,Neutral
Intel,B580,Neutral
Intel,"The difference between them is minimal and switches depending on the game.  He should get whatever is cheaper, in this case the 9060xt*  https://youtu.be/xlbNsP5ySmA?si=XowPsOGMbrnOX1aD",Neutral
Intel,Leaning towards the 5060 since I only see myself playing Arc for a while now. $50 difference to the 5060 is easier to stomach for me than the $200 for the 16gb 9060.,Neutral
Intel,"Tell me about it. Probably the ""save up 200 and get the 16gb card"" crowd. Even if I do save it up, I really wouldn't want to spend 60% more for just a 20-30% performance difference :/",Negative
Intel,Stop spreasing misinformation 9060xt 8gb compares to the rtx 5060 and you should allways get the rtx 5060 if it is at the same price or cheaper than the 9060xt 8gb.  The difference between them is minimal and fluctuates depending on the title ( amd or nvidia optimised )  https://youtu.be/xlbNsP5ySmA?si=XowPsOGMbrnOX1aD,Neutral
Intel,"I'm seeing that the 5060 is better for arc raiders too, so leaning towards that now.",Positive
Intel,"Thank you! That video was super helpful. Given he says the 9060 is only about 5% more powerful on average and the difference is more stark in Arc Raiders specifically, I'm more inclined towards the 5060 now. The $50 difference isn't too bad and I'm hoping to find better deals than $365.",Positive
Intel,"Yeah, that makes sense, but I just uninstalled bazzite a couple of weeks ago. It just wasn't for me. Found myself switching to windows more often than not.",Negative
Intel,India. It was ~$380 a few weeks ago. I guess I missed the bus :/,Negative
Intel,Thank you. I'm leaning towards the 5060 now.,Positive
Intel,"Thanks, I am leaning more towards the 5060 after seeing the replies here and considering the fact that it's the better gpu for the one game I play these days. I just wanted reassurance that the $200 difference for the 16gb model wasn't worth it, and I think I got it.",Positive
Intel,The 5060 is too slow for RT to even matter and the AMD driver thing is a complete myth in 2026. You might have had a point 10 years ago but you donâ€™t anymore.,Negative
Intel,"It is pretty much all I play for now. And thanks, the 5060 looks like it's worth the extra 50 for me. Hopefully I can find better deals.",Positive
Intel,"Hard to find here, but they usually go for 250 or do. Used market is not the best here.",Negative
Intel,It's $200 more.,Neutral
Intel,Its worse than both at 1080p,Negative
Intel,">The difference between them is minimal and switches depending on the game.  True, but 9060xt 8GB is a bit better and cheaper.  >He should get whatever is cheaper, in this case the 5060  5060 cost 50usd more for OP.",Neutral
Intel,"The 9060XT is the stronger card. At 1080p don't even think about the 16Gb. Traditionally, AMD updates their cards and the performance grows more and more over time. Personally, I'd get the AMD card. The ""benefits"" you get from Nvidia cards are useless at a 5060 level of performance. The pure raster advantage of the 9060XT will last you longer",Positive
Intel,Arc Raiders came out 3 months ago. You're going to own that GPU for years. Buying a GPU for one specific game seems like a bad idea.,Negative
Intel,You will massively regret buying an 8gb card if you ever want to use a higher resolution than 1080p. The 9060xt 16gb is worth it. Better to save up and put off the purchase than to buy something you will be disappointed with.,Negative
Intel,"There's a very good reason to not get an 8GB card though. It's just not worth it at this point in time. Its longevity is severely limited, do yourself a favour and just avoid any 8GB graphics cards.",Negative
Intel,Its not a 20% perfomance increase. It is the difference between 10fps and 80fps when you go to 1440p or your 4k TV.  See https://youtu.be/7LhS0_ra9c4?si=z9VGzFIq3qbLEMc_,Neutral
Intel,Seems I've been a victim of cherry picking then my bad I've just ran with it from what I've seen with most content creators. Still 9060xt is cheaper for them so they should get it,Negative
Intel,"I'm surprised how close the 5060 is to the 9060xt, 8gb. The both play games well at 1080p so most people will be happy with either and yes vram an issue but I'd you don't play many AAA games this won't be an issue, we also can't ignore ram shortage this will affect consoles etc in the future.",Neutral
Intel,"Im glad i could help, the advantage of going Nvidia is DLSS, it is superior to FSR and it is implemented in way more games.  It will serve you well, i also own it and i like it",Positive
Intel,The 16 GB model will be the 5060 Ti if I am not wrong! The 5060 Ti is around 15-16% faster than the 5060 but if you can afford the 5060 Ti 16GB then I would suggest you to surely get it as it will be relevant for much longer in the future and Nvidia is going to stop production of the 16gb 5060 ti this year going from the rumours!,Positive
Intel,No AMD drivers are still buggy! You can just check the r/AMDHelp and r/Radeon subreddits and there are multiple new posts everyday with complaints about driver timeouts or crashing or something else! I know from experience too! Just check the subreddits and you won't be disappointed with the number of complaints everyday!,Negative
Intel,"I couldnt play any God Of War games on my 2 different AMD cards because of awfull bugs which caused the fps to drop to 30 no matter the video settings ( rx 5700xt and 6650 xt) amd absolutely still has driver problems.  It is a common issue with amd card and god of war games ( you can look it up ), and it is insane that amd doesnt care enough to fix it. And there are more similar situations  Also in some games the 5060 can do rt, i use it in crysis 2 remastered and i get above 80 fps without upscalling, you can also use it in cyberpunk but dlss is required",Negative
Intel,250 compared to 350+ seems a decent deal tbh,Positive
Intel,Is it really? There's just a 50 dollar difference in my country.,Neutral
Intel,How ?,Neutral
Intel,"My bad i misread the post, i tought the 5060 was the  cheaper one, he should get the 9060xt",Neutral
Intel,But did he ever mention wanting to upgrade to 1440p?,Neutral
Intel,Okay what about a 7700 xt for ~$380? (Keep in mind the 9060 16gb is ~500 here).,Neutral
Intel,"Oh so true i tought the 5060 was the cheaper one ,he should get the 9060xt",Neutral
Intel,At 1080 both of them can play absolutely any AAA game without any problem ( medium is needed in indiana jones ) but the rest can run at high,Positive
Intel,"Yes, that still seems to be the consensus very much. Better upscaling and drivers.",Positive
Intel,"The 5060 Ti 16 GB is ~$630 here. Think the 9070 (non xt) would give better performance for that price range ($650 where I live). The pricing ladder in my market, I tell you! ðŸ˜…",Neutral
Intel,I own one buddy. I have never had a single issue with my 9070xt. The only people posting to this subreddits are people having issues that the overwhelming majority of people do not have. Itâ€™s biased by the nature of what it is .   If amd gpus had driver issues you would see big publications talking about them but you donâ€™t. You are propagating a myth.  Youâ€™re also conveniently ignoring the disastrous 50 series launch drivers for NVIDIA.,Negative
Intel,"Curious - in what kind of situations does the 5060 run into vram limitations in your experience with it? If I play something like Arc Raiders at 1080p at high (second highest), would I ""run out of vram?""   I'm afraid I still don't understand how that works entirely. Have you had such instances with the 5060?",Neutral
Intel,"Yeah, but super hard/rare to come by. They get snagged up pretty fast too.",Negative
Intel,"Yep. $200 difference between the cheapest variants of both here in India. If it were a $50 difference, I wouldn't have even made this post.",Neutral
Intel,https://youtu.be/xlbNsP5ySmA?si=XowPsOGMbrnOX1aD  You can watch this video to convince yourself,Neutral
Intel,Yes he is interested in using his 4k TV at lower settings and framerate. It will not be playable with a 8gb gpu.,Neutral
Intel,"Yeah i also moved to nvidia even though it is not allways the best price for performance because my last 2 AMD cards ( 5700xt and 6650xt ) could not run God Of War at all no matter the video settings or resolution, the game kept dropping to 30 fps, and it is a common issue with Amd and god of war games and they still have not fixed it.  There are more issues like this, some are fixable if you google the solution, some are not and after the thing with god of war i decided to give up on amd for now, they also didnt add FSR4 to previous gen GPU s ( like the 7000 series) , while Nvidia gave DLSS 4.5 even to the first RTX cards.",Negative
Intel,Then stick to 5060! For almost double the price it is not worth it!,Negative
Intel,You are welcome to make your assumptions and share your own experience but I can only speak based on my experience with them and what I observe from my reddit scrolls! I switched to the Green Side and won't be going for a new Radeon GPU anytime soon.,Neutral
Intel,"You can play Arc Raider at max settings and you wont run out of Vram, personally  i never ran out of vram because i dont allways play the latest games ( i play at 1080p )  In the Game Indiana Jones ( which is a very bad optimised game )you have to set the settings to medium to not run out of vram and i think in the new Doom you have to use high, thats it, in some future released games you might have to use high/medium instead of ultra.  When you run out of vram the game gets very bad frame drops.  I play Cyberpunk on a mix of high and very high i think and i dont have any issues with vram for example, same for BF6.  At 4k resolution the vram issues appear in newer titles",Neutral
Intel,At 1080p you will almost never run into a VRAM issue and Nvidia cards are also more efficient in VRAM utilisation! They are also much more power efficient i.e. they will consume less power for the same level of performance which saves some electricity while also giving your power supply more headroom!,Positive
Intel,Can you go find a 5700xt and run that until you've saved for a  16GB card?  If you ever wanna move to the TV or even a better monitor 8GB is gonna be out gunned real fast.,Neutral
Intel,"Oh right yeah ðŸ˜…  I donâ€™t even own a TV, that wouldnâ€™t cross my mind.",Neutral
Intel,"Haha what, more power efficient?",Positive
Intel,Not available here. What about a 7700xt for ~$380 (vs 9060xt 16gb @~$500) or a 7600 xt for $270 vs (5060 @~$500)?  Used market is not ideal here. They're either overpriced or they get snapped up in minutes.,Negative
Intel,"Regardless, the 8gb models on some modern games run out of VRAM at 1080p. I assume most spend hundreds of euros to have a useful product for several years, not just a single.",Neutral
Intel,"Yeah true, thatâ€™s why I grabbed a 5060 Ti 16 GB last month myself :â€™) But also I didnâ€™t wanna downgrade in vram from my 3060 12 GB.",Positive
Intel,"Sigh, how I wish I could get a 5060 ti. That's ~$600 here. How about a 7700xt for ~$380? (Keep in mind the 9060 16gb is $500 here)?",Negative
Intel,Well you could use Optiscaler to get FSR 4 on older Radeon cards and the 7700 XT comes with 12 GB of VRAM which is definitely better than 8 GB. I donâ€™t see why not.,Positive
Intel,"They're same thing, I don't even see point of pro tbh unless you need it for some reason.  The difference is Intel vProÂ® Essentials & Intel SIPP (Stable Image Platform Program) that basically it.",Neutral
Intel,I think one of the key differences is that one has the word Pro in it while the other doesnt,Neutral
Intel,the difference is money. if you ask intel they'll answer you with that:  https://preview.redd.it/mbnrjbrwy1gg1.png?width=1080&format=png&auto=webp&s=9d19e620addc72804f671b1c9706b6e77f93f7b0,Neutral
Intel,"The real answer is that it supports a different driver suite, and probably will have better support for photoshop and other softwares.",Positive
Intel,I love the krabs meme,Positive
Intel,Get a 9060xt 16 GB or a b580 before even thinking of getting a shitass 8GB card.,Negative
Intel,"If you pay about half the price for a B580 than you would a 5060 8GB, the deal is super solid. For the same price, 5060/9060. B580s used to be around (for me locally) â‚¬250 and that was quite a solid price for them, but â‚¬300+ feels a bit stiff.",Positive
Intel,"If you can afford it get 9060XT 16GB, if you can't get a used 2080ti",Neutral
Intel,"it depends on how you play games  roughly speaking if vram usage < 8gb, 5060 is slightly faster than b580  resolution, image quality setting, upscaling setting, etc, affect how much vram are required",Neutral
Intel,Get an AMD 9060XT over some Intel junk.,Neutral
Intel,If Intel Drivers were decent...,Neutral
Intel,It's 4060 level card and might even be 3060 level in some games.,Neutral
Intel,What do you think is the difference between the 9060XT 8GB and the regular 9060?,Neutral
Intel,"Except they are, haven't had any issues in the months that I've used my card.",Neutral
Intel,You can't buy a regular 9060,Negative
Intel,"There were games that weren't playable for days unless Intel released a Driver Update, they also had a massive Driver Overhead with lower-end CPUs, although this one was fixed from what I heard, but idk if 100% fixed.  If they fixed all of this stuff, then they already have better Drivers than AMD.",Negative
Intel,?,Neutral
Intel,#You can't buy a regular 9060,Negative
Intel,Why?,Neutral
Intel,Try to buy it,Neutral
Intel,"Why are you doing this instead of explaining properly? If you mean I can't find it, then I can find an RX 9060 in the country where I live.",Negative
Intel,"It means that there is no 9060, there is only 9060xt, with 8 or 16 GBs of vram.",Neutral
Intel,"It does not exist. You're asking about something which does not exist. There was one proposed model, shared between Asus and Asrock, but note from your link there are no reviews.  It appears AMD chose not to release the 9060 configuration of Navi 44.",Negative
Intel,https://www.techpowerup.com/gpu-specs/radeon-rx-9060.c4326  so you're saying this is fake?,Negative
Intel,"Hello :) Intel Arc isnâ€™t the same as Iris Xe. Arc is newer, and itâ€™s usually noticeably better for graphics.  Out of these three, Iâ€™d pick the **HP ProBook (Core Ultra + Arc)**, itâ€™s the most â€œfuture proofâ€ option, and ProBooks are generally better built. About the HP hinge issue, itâ€™s mostly a problem on some cheaper consumer models, it can still happen, but ProBooks are usually a safer bet. If you want the simplest â€œno worriesâ€ specs out of the box, the **MSI** is also a solid choice because it already has **16GB RAM and 1TB storage**.",Positive
Intel,Thanks man ;),Positive
Intel,you must have some huge hands judging from the apparent size of that box,Neutral
Intel,"Holy shit my hands look like a giant Hold on ill get you a pic with me actually holding the BOX, not the gpu.  https://preview.redd.it/kkndv19xh1dg1.jpeg?width=4000&format=pjpg&auto=webp&s=924d6b75377cecc6a98ac1bae1a765b4349dc025",Negative
Intel,"Thatâ€™s not a bad build for your needs whatsoever. You will struggle to reach 240fps in anything outside of GD, but Iâ€™m guessing thatâ€™s why you got the monitor. You will be able to play most modern games at 1080p 60FPS, setting obviously wonâ€™t be perfect. Editing may be a bit laggy though",Neutral
Intel,"If it works and youâ€™re complacent with your gaming sessions, no need to upgrade. Once something starts to slow down (esp when you optimize your pc) then maybe start upgrading.",Neutral
Intel,"CPU, perhaps more ram if you're already maxing it out.",Neutral
Intel,That cpu needs to be upgraded,Negative
Intel,CPU w/o knowing use-case,Neutral
Intel,Ha... haha.... ha.... imagine being able to buy RAM right now for a fair price...,Neutral
Intel,What CPU do you have in mind? Preferably LGA1700 still.,Neutral
Intel,"Would probably have to be a matching kit because buying a new set of 32gb would get expensive. Just a question of if he has 1x16gb or 2x8gb and whether the motherboard has enough slots if OP has 2x8gb.  another 16gb of similar DDR4 probably runs like $60-80 on ebay. Maybe not needed, maybe it's vital.",Neutral
Intel,13500f is a pretty decent deal. Basically a 12600k with 4 more E cores but can be had for cheaper.,Positive
Intel,"If you can, definitely the 9060xt 16gb.",Neutral
Intel,Sadly 9060 XTs are almost $200 more   Edit: Okay maybe not,Negative
Intel,The cheapest 9060 XT 16gb cards at Microcenter and on Newegg are $400+,Neutral
Intel,"Better gpu,",Positive
Intel,You got a bit of headroom on that 12400,Neutral
Intel,"I basically had this exact set up, except I had a i7-10700f and I feel like I was getting a bit better frames (90-120). That was like a month ago so honestly I donâ€™t remember. I was also playing 1440p low settings on a 4k monitor.  When I upgraded I kind of went all out and went with new am5 setup.  MOBO: gigabyte b650m gaming plus WiFi (budget MOBO)  CPU: Ryzen 5 9600x  GPU: gigabyte 9070xt oc  RAM: g.skill 32gb DDR5 6000mhz  I also had to upgrade my PSU. Went from Chinese 650w to a Corsair 850w.  And new cpu cooler, master cooler halo or something. (Air cooled) kept my old case.  I got my ram, mobo and gpu all from facebook marketplace. All brand new unopened, but it took me a while to gather all the parts. I was not trying to spend full price on anything.  Right now I play 4k max settings and get 250-300 fps with frame gen on. The game has gotten so much more enjoyable, itâ€™s not even funny. Everything is just so beautiful and smooth.  https://preview.redd.it/obu527cq0rfg1.jpeg?width=3024&format=pjpg&auto=webp&s=4470b56640b2eee442d76b2ffe26cb5a12bd9bac",Neutral
Intel,7700 XT or 9060 XT ?,Neutral
Intel,Thatâ€™s what I figured too. Seems like VRAM is the bigger issue,Neutral
Intel,"Damn, thatâ€™s really nice! Yeah I guess I do get 90 sometimes but never 120 consistent. Right now Iâ€™m using anti lag + frame regeneration so itâ€™s not too bad since I can get 200fps on that(just lower picture quality.   I just donâ€™t know much how only upgrading my GPU would do   Thanks for the spec list. Honestly might consider a full upgrade depending on prices. I bet that 9070 XT was pricy for sure",Positive
Intel,"Well, those two cost slightly differently. If you go for 9060 XT, make sure it's 16 GB version.",Neutral
Intel,9060 XT 16GB what settings are you running it at I'm pretty sure even a Steam Deck can run Arc Raiders,Neutral
Intel,"Got the 9070xt for $625 brand new unopened on facebook mp lol. And yeah, just the gpu is not going to do much. Maybe 15-30 fps which isnâ€™t bad but thatâ€™s a strong maybe.   Letâ€™s just say you get a 9070xt youâ€™re going to need to upgrade your PSU. And if you keep your current CPU, youâ€™re going be bottle necked. So then youâ€™ll need to upgrade that. One thing leads to another youâ€™ve spent damn near a grand so might as well just upgrade to a newer platform and throw everything at it so itâ€™s future proofed ðŸ˜‚. And just so you know, my whole upgrade stated from just wanting to get a better MOBO lol ðŸ˜‚ and look where I am now.",Negative
Intel,"Gaming was never doomed, but yes, those minimum specs are quite impressive for a game that looks the way it does.",Positive
Intel,might be even a good thing on some level ... nvidia tooting their horn proudly that they would unload old 3060s with only 8gb instead of more 50s gen kinda means stuff finally has to be better optimized..cause otherwise sales for games would decline (why buy smth that barely works on your pc after all),Neutral
Intel,Well damn. I've got a GTX 1650 laptop set aside. Might have to put this to the test.,Neutral
Intel,Horizon 4 & 5 were quite good optimized for my older PC .. i reckon they will be using same engine for 6 so performance should be alright  Only Forza i had problems before was 3 but that was when i had GTX 1650,Positive
Intel,"Same as the last game, I imagine this will be one of the flagship Xbox/Gamepass games. They want it to look good and still pull 60fps even on the Series S, so budget PC gamers get to benefit from that also.",Positive
Intel,the forza horizonÂ´s I played where allways good to me,Positive
Intel,"To be fair, most gaming companies will have to now invest into optimizing their games, especially giants like CDPR or Rockstar, because what everyone have bought the past year - that's it for the next 2-3 years. Apart from new gen CPUs, there wont be more GPUs coming our way for a while and even when they do come, raw-power wise we will prob get like 10% more, but new DLSS 6.7 will give us 10 x fake frames. Not that DLSS or DLAA is bad, on the opposite, it's quite nice, but yeah.  Like Witcher 4 and Cyberpunk 2 will seriously need to optimize and honestly, I can't see Cyberpunk 2 or Witcher 4 require more than Cyberpunk2077 does, because like, what else can you do graphics wise? The game's almost photo-realistic as it is. There's literally no point.  That said, almost all AAA games are UE5 slop, which runs like a bitch.",Neutral
Intel,"Slightly sad with the CPU requirements, but given that those parts are 10 years old it makes sense.   4gb VRAM requirement is awesome though. Looks like it's going to be 1080p ultra for me and my 3070 ti!",Positive
Intel,"Gaming was never doomed.  AAA gaming was unsustainable years ago.  Nobody knows what ""optimization"" is or requires.",Negative
Intel,"This has to run on Xbox Series S. Do you know what CPU and GPU itâ€™s comparable to?  Itâ€™s simple math, use your brain.",Neutral
Intel,"Say it with me: JUST BECAUSE IT RUNS ON WEAK HARDWARE DOESN'T MEAN IT'S OPTIMIZED.  seriously, people here don't udnerstand what this work means and think ""high fps = optimized""  >and if anyone saw the trailer, you'd know that it looks to be graphic intensive.  You don't know how it looks on lowest settings, also I don't think it looks that great.",Negative
Intel,"Horizonâ€™s didnâ€™t perform terrible, when they worked. The sheer amount of crashes 4 threw my way as soon as 5 came out actually made me not buy 5.",Negative
Intel,"I said a while back here on Reddit that game devs will see the PC parts crisis thats happening for the next 3 years and it would be incredibly stupid to release a game nobody can play, so optimisation will be a serious focus for any upcoming games. People told me that this would take years to adjust to... I dont believe it",Negative
Intel,Arent TW4 and CP2077 moving to UE5?  edit: yes. [https://www.youtube.com/watch?v=Nthv4xF\_zHU](https://www.youtube.com/watch?v=Nthv4xF_zHU),Neutral
Intel,That's why you don't pre-order or buy at release.   I've never had either game crash on my system as far as I remember.,Neutral
Intel,that recommendation like the others is for the system itself and not whats required for the game.,Negative
Intel,about damn time innit?  i mean i got pretty good hardware but man ...ive been a gamer for sooo long and the increase in quality of graphics is definetly happening over time ..but if you compare it with the increase of performance of hardware needed to run said games... what a joke sometimes the requirements are!  i secretly suspect companies like nvidia sabotage the optimizations as well ..to ensure people keep yearning for more and more gpu power.... bit like apple with the stories of artificial battery degradation and so on you know?,Negative
Intel,"Yes of course, It's been known for a long time. Not only that, TW4 and CP2077 are supposedly ""core"" games in UE5 development too.   It genuinely sucks though. Redengine was amazing, flawed, but amazing.",Negative
Intel,Isn't Arc Raiders UE5? Lol,Neutral
Intel,"Hitching or stuttering in most games is a sign that the GPU can't find enough work to stay busy.  The GPU may be running low on VRAM, depending on your settings you might be coming close to what 12 GB can do.  The CPU could be being distracted by any number of background tasks. Windows is pretty good at keeping out of the way, but anything else isn't. Is Discord updating? A browser still open? Even minimised tasks are still fully running. If the CPU's doing those things, it isn't keeping data flying at the GPU.  If those tasks aren't using CPU, they could still be using RAM. 32 GB should be enough, but check what RAM usage is like in the game. If you go north of 25 GB, this is going to be the problem.",Negative
Intel,"Yes, meaning?",Neutral
Intel,"*Hitching or stuttering in most games is a sign that the GPU can't find enough work to stay busy.*   So do you think when I'm able to run in 1440p this could resolve the hitching?  *The CPU could be being distracted by any number of background tasks. Windows is pretty good at keeping out of the way, but anything else isn't. Is Discord updating? A browser still open? Even minimised tasks are still fully running.*   I close all background apps. I don't even have discord running or a browser open. Checked and turned off any game overlays as well. Before I got a 5060ti, I was running a 3060ti (8gb) and it was the same then so makes me think it's nothing to do with the GPU or VRAM.   *If those tasks aren't using CPU, they could still be using RAM. 32 GB should be enough, but check what RAM usage is like in the game. If you go north of 25 GB, this is going to be the problem.*   I'll check this out but as stated above, I have nothing running in the background so can't see it being this.   Thanks for your advice anyway",Neutral
Intel,"It's a meme, ignore it.",Negative
Intel,"UE5 is notorious for in-game area transition stutters, it's an engine problem and even a 9800x3d-5090 rig will have stutters.",Negative
Intel,"*So do you think when I'm able to run in 1440p this could resolve the hitching?*  No. Hitching is very, very slow frames. They'll stay slow at 1440p. You can run that *now* just use dynamic super resolution.",Negative
Intel,"I see, I kind of thought it must be down to the games optimisation itself or as you say due to the engine its running on but having a quick search online, a lot of people seem to think the game runs flawlessly. The game is playable as its just every now and again there's a hitch but it sure is annoying!",Negative
Intel,"Yep, I did do that on my 3060ti but I don't think I ever played Arc on it. Do you play arc at all and do you notice any hitching/transition stutter as Churchillian mentions above?",Neutral
Intel,"Idk, I've heard Arc Raider is supposed to be relatively optimized for a UE5 game but pretty much every UE5 game I've played has the transition stutter issue.   If you play enough games on UE4/5 engine you kind of get used to it.",Negative
Intel,"I play it, I don't experience any of this. If the developer hasn't hidden a loading segment very well (""transition stutter"") then sure, any game will have to pause while it loads up the data, but I don't see that in Arc Raiders.",Negative
Intel,"Yeah, I've got nearly 100 hours in the game, it's just that I recently upgraded my card and hoped that this would iron out the hitching but it still remains.",Neutral
Intel,Yeah it's just an engine thing and I think it's been around since UE3?   Epic's own game fortnight has stutter problems still so it doesn't seem like it's something they can/want to fix anytime soon.,Negative
Intel,"Yep, I remember playing that years ago and it had stuttering issues for me. Its strange as it doesn't seem like everybody experiences this. PC's ey! You never know what it could be related to. I watched a youtube video earlier and a guy finally figured out it was his wireless/ Bluetooth card that was causing his stutters out of all things!",Negative
Intel,If you're using framegen maybe the stutter isn't noticeable?,Neutral
Intel,No c po aweonao,Neutral
Intel,"If you aren't overheating, and since you swapped Power Supplies, assuming other components aren't the issue which I would doubt, I would say to get a Uninterruptible Power Supply to make sure you get stable power from the wall.Â Â    You could try moving your PC to a different outlet or circuit to test.Â  Could be as simple as a loose cable in the wall, outlet not as tight, or something like a fast brownout if something causes a voltage drop hence PC turning off.",Neutral
Intel,If your CPU is spiking to 90c I would re-paste the CPU cooler. That dual fan cooler should have no problem keeping up. I bet you have a hot spot that's got an air bubble causing that spike. And I bet when your PC shuts off the spike is jumping over 100c,Neutral
Intel,"HI!, yeah sorry i forgot to mention that i also bought one just to make sure the power outages didnt ruin something",Neutral
Intel,thats what i though too thats why i changed the artic mx4 for mx6,Neutral
Intel,"That's very strange, that cooler should have no problem keeping up with that CPU. You should test it with Cinebench. Under a Cinebench load you should max out around 88 unless there is an airflow issue in the case. If your PC restarts running Cinebench you've got an airflow or cooler seating issue. If it handles the Cinebench load you've got another issue that might be harder to troubleshoot.Â    I'm assuming both CPU fans are blowing back towards the rear of the case? And your rear fan and top fans are both blowing outwards not inwards? If not configure them as such and see if that helps as well",Neutral
Intel,"iÂ´ll try the cinebench. The fans are exactly as you mentioned, both bottom fans are getting air in, thereÂ´s only one on top cause of the limited space and the 8pin for the cpu didnt let me set correctly the other fan, that one is getting the air out and the rear one i also extracting air. IÂ´ll test with cinebench and come back with results",Neutral
Intel,i did the test and it didnt turned off  https://preview.redd.it/1prpunnzowgg1.png?width=474&format=png&auto=webp&s=62a26488ad365292d646d1ef3528a88625123318  i used hwinfo to check tÂ° and the peak temperature was at the beggining of the test showing 91Â° but for the remaining 29 minutes the cpu had tÂ° around 60-78 degrees. At this point idk if its the cpu that turning the pc off,Negative
Intel,"yes, but choose the b580 instead (though it has 12gb of VRAM), also id recommend the rx 9060xt 16gb",Positive
Intel,Get the B580 in my opinion,Neutral
Intel,Had the a770 LE loved it! Wasnâ€™t very powerful considering the specs but it was nice to see Intel actually putting effort in the Gpu space. I would personally go with the B580,Positive
Intel,Yup. Also does media processing very very good.,Positive
Intel,I was scared you were financing a PC for $350/month :(   Sweet PC and it should serve you for many years to come! The scrapped together PCs are always my favourite. I remember slowly deal hunting and assembling my college PC from used PC posting in the local classifieds. Tons of money that can be saved if you are patient.,Positive
Intel,Please ignore the â€œmoâ€ in the title I can not figure out how to edit the post.,Negative
Intel,Sick build! That's pretty awesome for $350!,Positive
Intel,I personally love this case. I usually build with TT cases.,Positive
Intel,Broke but street smart,Neutral
Intel,Shout-out to a fellow Raider ðŸ˜  See you topside!,Positive
Intel,Are you one of the rats that shoots me in the back to take my equalizer mid matriarch?,Negative
Intel,"Structural support book, or convenient book storing location lol? Looks super cool",Positive
Intel,Wow dude that's sick!,Positive
Intel,I thought the aio tubes on the radiator suppose to be higher than the pump (just curious) but ðŸ”¥ build tho bro,Positive
Intel,College eh? One beer bong away from a total disaster. Good work and nice build.,Negative
Intel,"Nice build. BTW just curious, I see many people using these ""open"" kinda build, doesn't that make the pc parts and the fans more dirty? With open builds can the moisture in the air damage the pc parts? I use my case as a glorified foot stand so I cant use anything open or with glass.",Neutral
Intel,"I dunno, how much does that book cost?",Neutral
Intel,"Ah man, the Predator Arc cards are so clean! I think your build all around looks really good.",Positive
Intel,32gb better be ddr4 otherwise it is overkill,Negative
Intel,"hmm, maybe try entering a marvel rivals tourney ðŸ¤”",Neutral
Intel,"Haha no, Iâ€™m gonna get a lot of hate for this Ik but Iâ€™m a huge Dave Ramsey fan and I actually took a year off school to work 90hrs a week and all of the money I made doing that is going towards school. So Iâ€™m paying it all out of pocket and will be debt free. And yes this is hopefully my last build for quite a while although those new 9060xtâ€™s are kinda enticing ðŸ˜‚",Positive
Intel,You cant edit titles after posting. Only the body of the post,Negative
Intel,Appreciate it!,Positive
Intel,ðŸ«¡ðŸ«¡,Neutral
Intel,"Lmao no actually today Iâ€™ve been loading in with my hullcracker and helping raiders take down bastions,leapers, and rocketeers",Positive
Intel,Convenient location lmao and thanks,Positive
Intel,"Normally, yes, but if I flipped the AIO 180Â° then all of the air bubbles will get stuck at the top and then the pump will then start to get air in it which isnâ€™t great. All in all itâ€™s a loose-loose but I figured this was the best route",Negative
Intel,Thanks lol but thatâ€™s not me haha,Positive
Intel,Yes but I LOVE taking it apart and cleaning it (donâ€™t judge) so it doesnâ€™t bother me. Moisture is not an issue at all but yea she does get a lil dusty,Positive
Intel,Idk 20 bucks probably,Neutral
Intel,"Thanks man I absolutely agree that it is a beautiful card but man, these driver issues are killing me.",Positive
Intel,DDR 4 came out on like 6th gen Intel I believe lol yes it is. Itâ€™s actually underkill because I do alot of cad and rendering,Positive
Intel,Where are u working 90 hours a week? Thatâ€™s wild.,Negative
Intel,Ahhh that makes sense thanks for the input,Positive
Intel,Ok thanks for the info,Positive
Intel,"The top of the rad is higher than the pump, which common wisdom says is all that matters. With that said, if you're budget limited why not buy an air cooler? Cheaper, will cool maybe even better than the AIO given it's open air and won't be close to failing and borking your shit maybe like a second hand AIO. Although that does maybe look like that 1 cooler with a mosfet fan or whatever it is, which again seems somewhat useless given it's an open air case.",Neutral
Intel,Ohhh,Neutral
Intel,Roofing lol,Neutral
Intel,Oh because I got it on sale I think it was like 80 bucks. Also dumb reason Ik but I just simply like water cooling. Like idk how to explain it or describe it but to me itâ€™s just cool. This isnâ€™t my first system with an aio eairther and Iâ€™ve found artic to be pretty reliable. Also the cause is some what new (to me) it was in a â€œnormalâ€ case previously. Also yes it does have the mosfet fan.,Positive
Intel,"That one's pretty expensive, right?",Negative
Intel,Yea but for 80 brand new Iâ€™m happy,Positive
Intel,iâ€™m glad I convinced my friend to build his pc a few months before all this nonsense. only issue for me is that Iâ€™ve been wanting to add more storage for a while and I just KNEW the prices would go up before I would be able to get one smh,Negative
Intel,Bought one used last year for $360 and bought a 3070 ti for $260 last November. I think it'll last 3-5 years and then I can afford AM5.   I do feel bad for those buying currently. It's a really good time to wait.,Positive
Intel,"I built a steam machine for my TV 2 weeks ago, already had DDR5 and a NVMe on hand. Found good refurb deals on Amazon for mb and gpu. Spent $730 after tax on everything but what I had already had.  Ryzen 9600x and Radeon 7600",Positive
Intel,People will pay the price so itâ€™ll keep getting worse. Itâ€™ll be 5-7 years before ram manufacturers can make another foundry to keep up with the demand and then prices will stay the same so they can recoup the billions spent to make the new factory. This is the new normal get used to it,Negative
Intel,"Well, constantly looking for 5700x3d or 5800x3d. And yeah, hating ai more than ever.",Negative
Intel,"I'm not in a terrible position hobestly... my 2080Super is still beast for 1080 and totally capable for 1440, was planning a full build... and now I'll probably just upgrade my 7tear old copy and maybe add an nvme if prices are decent....  Currently on ddr4, old 500g ssd for OS and current game.. HD for rest. 16g Ram.  Will probably add 16g if I c an match it or if 32g is decently priced. . And hopefully wait out rameggedon? Maybe a new case so it feels new",Positive
Intel,Constantly reminding myself I'm good. My r5 3600 and RTX 3070 will do. Honestly shocked my system is 5 years old lol.,Positive
Intel,"I'm doing great! I have spare DDR5 RAM, a spare 4090, a spare 9700x, a spare X870 Mobo, a spare 9070xt. I just ordered a new lga1200 Mobo for my server rig as a backup. I'm in a good place.",Positive
Intel,Upgraded to AM5 this past July. Will have to survive with 32GB and 4080 for the next foreseeable number of years.,Neutral
Intel,"Really glad I built a new PC in June the only annoying thing was I only got 32GB of RAM planning to upgrade to 64 later, that's not going to happen. I gave my old PC to my partner, it has a 2080 so it's still ok enough to play the games she likes. I had to buy a new SSD for it because I had moved the SSD with my steam library to the new PC so it was left with a 250 boot drive and a slow 4TB hard drive. I paid more for a 1TB drive than I did for a 2tb 4 months ago but looks like they're even more now.",Positive
Intel,![gif](giphy|c16VH0CFMh7gOqqXOM),Neutral
Intel,glad i put 64GB of ram in my PC when i did 2 years ago.  I'm pretty much set for the forseeable future with my 7800X3D. If it lasts even as long as the 5800X3D has then i'm good well past 2030 lol.,Positive
Intel,Me going with LGA 1700 ddr4 build in 2023 when AM5 was the conventional choice seems to be working out- will miss out on the CPU upgrade though.  3080TI was a bad call on my part,Negative
Intel,"I made an entire new build from scratch right after trump started his tariff war because I worked in imports and was directly seeing what was coming down the pipe for potentially the cost of... everything... and wanted something that was going to get me through the next so many years.   Ironically none of this ended up being because of that, but it did cause me to dodge it.",Negative
Intel,I have ddr4 from older builds and am upgrading to the last possible intel cpu that still uses it so I can swap it out.,Neutral
Intel,Seeing some sites asking 1000$ for a Rx 9070 XT literally made me just not want to buy it.   Iâ€™ll wait.,Negative
Intel,> iâ€™m glad I convinced my friend to build his pc a few months before all this nonsense.  Very nice! Are yâ€™all best friends now?,Positive
Intel,Yeah Iâ€™m at this I see new stuff I get all ðŸ‘€ but have to talk myself out of it cause it will break the bank,Neutral
Intel,"we were best friends before, gaming together is just more fun now",Positive
Intel,"It'll still be getting security updates until something like 2028, it just won't be getting any more ""Game Ready"" updates. Which isn't a total loss since the kind of games that receive those updates are going to keep running increasingly poorly on older cards and are probably not going to be worth playing anyway.",Negative
Intel,Thatâ€™s still ~9 years of support for game related updates.  AMD didnâ€™t even give me 4 with the 6950 XT,Neutral
Intel,I'll believe them (either Intel or AMD) when I see the benchmarks.  Until then this is all just pointless noise.,Neutral
Intel,well yeah you can't compare them because strix halo is on a signficantly larger die wheras panther lake is more comparable to something like the hx370.   If amd is able to get strix halo at a competitive price then sure it will compete but the issue is that with such a large die I don't think it is possible for them to compete in price with panther lake,Neutral
Intel,Iâ€™ll never understand why AMD is not committing to design RDNA4 based APUs and at this point I just take RDNA 3.5 as a joke because they canâ€™t even support FSR4 on it officially nor the RX 7000 cards.  Itâ€™s like they are losing on purpose,Negative
Intel,"AMD has this â€œitâ€™s good enough for a while and weâ€™ll release something great that people will forget this happenedâ€  Vega lasted in mobile for nearly 5 years and got RDNA2 designs. Now, itâ€™s RDNA3.5 being built for mobile platform and betting on that to be good enough until RDNA5/UDNA bridge die designs releases (unverified rumor)  AMD also has this weird obsession with competitor naming. Sure, itâ€™s meant to confuse buyers but itâ€™s hurting them than helping, maybe it does help in terms of inventory.  Theyâ€™re not intel-like of stagnation. Theyâ€™re competing but not for us in the consumer market and weâ€™re just getting scraps until enterprise trend die down (currently AI trend/bubble).  Well, itâ€™s understandable as Zen designs are really focused in Epyc and scale down to Ryzen SKUs.  And the 400 series is a bad refresh when Ryzen 6000 mobile is the definitive refresh they have done, Zen 3+ and move to RDNA2. AMD couldâ€™ve done similar commitment but itâ€™s not currently.  Also, AMD forgor Strix Halo laptops are still nowhere to be found aside from 1 or 2",Neutral
Intel,Amd really doesnâ€™t gaf about anything other than data centre these days,Negative
Intel,Idgaf when Strix Halo products are nowhere to be seen (notebooks),Negative
Intel,"Except that the B390 will be far more common as it will be seen in far more laptops. Yes, the 8060S & 8050s can be found in some laptops, but for the laptops you'll find in places like Currys, Best Buy or Mediamarkt, the B390 will be the most powerful iGPU you'll likely find & it'll happily outdo a Radeon 890M",Positive
Intel,"AMD is at the point where Intel was before they went down the route and are recovering, history repeats before it's too late.  Not going to believe either until we get actual benchmarks and results.",Negative
Intel,Meanwhile AMD keeps putting out new chips with years old GPUs.,Neutral
Intel,Core Ultra 2 is already a better mobile soc.  I don't know why AMD thinks 12-16 cores is more important than battery life when it comes to laptops.,Neutral
Intel,The Intel igpu has a better upscaler by far. FSR3.1 is a third class competitor in comparison. People have been crying out for AMD to release FSR4 for RDNA3.5 but AMD has some seriously stupid execs in charge.,Negative
Intel,It does sound complacent but ultimately the proof is in the pudding.,Neutral
Intel,"If it is not even fair to compare (because Strix Halo is WAY more watts) then why is AMD comparing them? B390 will exist, Strix Halo virtually does not in laptops.",Negative
Intel,"AMD is playing the same intel book a few years ago. Except now instead of 14nm+++++++, it is RDNA 3.5555555.",Neutral
Intel,Lot of markets and Intel did bribe the oems for decades and still do,Negative
Intel,Benchmarks first,Neutral
Intel,Beware hubris.,Negative
Intel,"There are already benchmarks, look them up.",Neutral
Intel,Don't they already have an integrated GPU that's on par with an RTX 4060? According to Framework?,Neutral
Intel,"strix halo is nice and all, but too prohibitively expensive to be considered for many people  arc b390/b370 will be available in much cheaper products for which amd doesn't have a proper answer to atm. amd's next lineup can't be lazy if they want to stay competitive",Negative
Intel,"The GPU doesn't matter if you don't have proper drivers and they are so far behind still Intel.   Great progress, but the drivers are still going to be the thing that makes people say no.   If intel keeps on chugging away and they work with all the DirectX games backwards and going forward.   I'm talking past DirectX games, you can't just worry about the new games there's games that are older that don't run well.   It took AMD many many years to get decent drivers, Intel I don't know if they're just focusing on hardware and not the drivers, but that so far is what's been holding it back.   Hopefully they can release a true dedicated GPU back in rival something that's out there at a much better price that will bring at least some competition back until the AI scam is over.",Negative
Intel,Panther Lake is using a superior process technology. So they are right. But it doesn't matter as customer will choose what's better. But until AMD has something out that uses 2nm then yes they will be behind probably,Neutral
Intel,I hope Intel stays competitive and AMD also brings its best to the table.,Positive
Intel,They should be worried about DLSS 4.5 though. Fix stuttering on FSR 4 and improve image quality,Neutral
Intel,I just wish Intel would make a very cut down panther lake offering to be the successor to the N1xx/N3xx line of efficient chips that have found their way into mini PCs.,Neutral
Intel,amd unfazed? I bet they are talking big shit again then will get absolutely demolished (as it happened with vega too),Negative
Intel,"Yeah it's old architechture, that's the point, Intel moved to the lastest node and barely manages to eek out a win. A win is a win nonetheless, but AMD still have plenty to dials to turn up.",Neutral
Intel,"I don't understand the fuss about iGPUs? Like why do they assume the average Joe would care about an IGPU at all? That's maybe 5% of the market and even then...most of them would get a dGPU anyways.  And apart from the GPU, what's special about the CPU? Combining (Lunar Lake) efficiency with (Arrow Lake) power? Sorry but my Ryzen AI 7 350 does that already. The top of the line x9 388h is about ~10% faster in single core aka the only thing that matters and will probably be in 2500â‚¬+ laptops whereas my 7 350 is in 500â‚¬ laptops.  I tried a 285h laptop besides the AI 7 350 and not only did it run hotter and less efficient, it also felt less snappier.    And the AI 7 350 was designed as a Lunar Lake competitor anyways so it was never worse in efficiency and ahead of Arrow Lakes like the 255h in that regard.  So I don't see why anything should really change...?",Negative
Intel,"AMD doesn't want to bring RDNA 4 to APUs, so as not to give FSR4 to users other than those with dedicated GPUs.",Neutral
Intel,a brand new product on a newer node is better than an older product on an older node?! who knew?,Positive
Intel,"And the price. I used to be an AMD fan, but as soon as competition with Intel was gone, AMD raised their prices and now act as if they believe they are a luxury brand. Hope Intel gets back into the game and if Intel can slash their prices it might end-up being the right choice.  At the same price, Intel is dead on arrival. At a serious discount they will take the place of AMD. No one is buying Strix Halo for handhelds, it is too expensive.",Neutral
Intel,"Both are right/wrong.  Intel made their comparisons to Strix point because theyâ€™re in the same power class. Panther lake is much faster than Strix Point at the same power level (according to Intel, AMD doesnâ€™t deny that) at 45W.  AMD says it doesnâ€™t matter because their Strix halo (up to 120W) is faster which is pretty obvious.   Itâ€™s not technically lying, AMD is just referencing an entirely different class of product.",Neutral
Intel,Plenty of folks tested it at CES.  Intel was confident enough to let reporters run benchmarks and it's basically around 4050 level.  You should be able to run most games at 1080p at medium-high settings in an Ultrabook form factor.,Neutral
Intel,"Well lunar lake is a monster and competes directly with the z2e both on performance and efficiency, so no reason to think panther lake will be worse.  Even if it falls short of Intels claims it will still be the leader until next year.",Neutral
Intel,The noise is doing a great job advertising for them. A war between them with fighting words will get them tons of free advertising.,Positive
Intel,And a much higher power budget.  AMD says they win because their 120W chip is faster than Intels 45W chip.   No surprise to anyone.,Positive
Intel,"I generally agree but i suspect that the 388h is using a much larger gpu than people suspect. I think its probably ~165mm2 in size, not 55mm2. i suspect the 55mm2 die varient is for the 4xe version, and the 12xe version is 3x that size.  I also dont understand why strix halo is so expensive. It would be interesting to see bom and packaging costs.",Neutral
Intel,"It sounds like RDNA4 just doesn't scale at all. All the rumors point to them going straight from RDNA3.5 to RDNA5 in APUs, just skipping RDNA4 all together.",Negative
Intel,RDNA 3.5 was the only reason I didnâ€™t invest in a STRIX HALO mini PC. The price is too much for outdated unsupported tech.,Negative
Intel,"Might be the same reason they stuck with Vega for so long in APUs.  At the current available desktop memory (DDR4 at the time) an architecture change wouldn't have made a huge difference.    Once DDR5 came out for laptops, we finally saw RDNA 2+ APUs (Ryzen 6000 APUs).  I'd bet once DDR6 starts appearing on laptops we'll get a similar iGPU architecture leap.",Neutral
Intel,"AMD probably just didn't bother making a new APU design when they didn't have new CPU core to go with it. Medusa Halo is rumored for 2027 with Zen 6 and UDNA/RDNA5, so the Point version will likely release then too.",Neutral
Intel,AMD has and always will be their own worst enemy,Negative
Intel,"It's not like they aren't developing something this whole time, releases are planned many years in advanced. Intel will have some rope and then will get inevitably leap frogged",Neutral
Intel,It's not like Intel isn't doing the same. Panther Lake and ARC are holdovers of things developed under Gelsinger.,Neutral
Intel,"> AMD is going to f--- around and let Intel catch up, in CPUs and GPUs.  this is what we actually need: competition. AMD kicked intels butt, now intel is kicking back. it's a win for us either way.",Neutral
Intel,I hope Intel will catch up and encourage AMD to compete. Having cleat leader in CPUs or GPUs is bad for consumers.,Negative
Intel,"I mean, we know that AMD is innovating. They literally showed Zen 6 at CES. Its just not ready yet for mobile, and Intel caught up. Same thing happened with Alder Lake, where intel released that before Zen 4 was ready.",Neutral
Intel,"So AMD having much faster iGPUs for decade or more did not do much.  But now Intel rolling out something at unknown price/power package will absolutely decimate AMD.  Regardless of what will happen, ""AMD's fault"" indeed. (amazing silicon designers and experts at everything posting for free on reddit have convinced me)",Negative
Intel,"Laptops haven't really been AMD's focus, and apart from Zen1, AMD's focus has been mostly on data center, with desktop being the natural offshoot.",Neutral
Intel,Yeah they ain't immune to being complacent.  And bad press doesn't make Intel stay bad.,Negative
Intel,"News at 10: ""Companies prioritise profits""",Neutral
Intel,"so either AMD doesn't have the capacity to produce them, or OEMs aren't interested, neither option is a compelling reason for AMD to focus on mobile",Negative
Intel,"Weâ€™d wish they were, but theyâ€™re not. Intel was struggling on all fronts due to their fabs. Amd is actually moving super fast in data centre so both epyc and instinct which is where they believe their money will be. They just donâ€™t care to do anything in the consumer market.",Negative
Intel,"Halo is so much faster that the upscaler difference doesn't matter at all. Of course, it is probably also bigger.",Positive
Intel,"Yes, Strix Halo",Neutral
Intel,And having fsr4 supported in mobile at all,Neutral
Intel,FSR 4+ may be great but game support (number of titles + GPUs supported) is embarrassingly low,Negative
Intel,Dlss 4.5 not that great in my opinion. It fixes some ghosting but creates more shimmering because it has so much sharpening. I had to dial back to 4.0.,Negative
Intel,wildcat lake.  only issue it seems to be using 2 P cores and 4 LPE cores instead of E + LPE,Neutral
Intel,70% faster being â€œbarely eke out a winâ€? Go ask why amd is stuck with 18 month old architecture despite intel managing to replace arrow lake after 12?,Negative
Intel,"Youâ€™ve got it backwards. The majority of laptops use IGPUs. IGPUs being as powerful as integrated graphics allows for cheaper thinner devices that are more power efficient. The entire intel CPU/IGPU performs on par with a 4050 at 60w at only 45w. When you factor in the 10-15w the CPU takes with the 4050 and youâ€™re looking at similar performance at like half the power.   Being power efficient opens up a lot of form factors to be able to game with such as thin and light laptops, tablets, or gaming handhelds",Neutral
Intel,"> I used to be an AMD fan, but as soon as competition with Intel was gone, AMD raised their prices and now act as if they believe they are a luxury brand.   That's why it's silly to be a ""fan"" or ""supporter"" of one company or the other.  They don't care about you, they care about making money and when they have a dominant position they will exploit it.  > At the same price, Intel is dead on arrival. At a serious discount they will take the place of AMD. No one is buying Strix Halo for handhelds, it is too expensive.  Outside of that one device (Ayaneo maybe?), you're right.  But now AMD is also releasing an 8-core version of Strix Halo with the full 40 GPU CUs, which should be cheaper.  I expect that we'll see that in more handhelds at the high end.  Realistically speaking, it's easy to make the case that on a 7""-9"" screen the 40 CUs is way overkill.  There's still room for a middle ground that Intel could easily fill.",Negative
Intel,"Absolutely consumers win when competition is hot, AMD has a bit too much of a lead ATM so they are cashing in and getting lazy. That said I am glad they are having their day, only because a few years ago they were on the brink of bankruptcy and I really want to see them on a fairly level playing field with Intel... If we end up with 2 juggernauts training blows, having big resesrch budgets, etc we'll get lots of innovation and competitive pricing.",Neutral
Intel,"You had to shovel $1k for a 8 core CPU for about a decade, before AMD came.  So ""it just hiked the price"" is BS.  AMD cannot keep prices low while TSMC, effective monopolist, keeps posting record profits quarter after quarter.",Negative
Intel,AMD is basically just waiting for their chance to do the bad things. They are a corporation after all.,Negative
Intel,"Help us Cyrix, you are our only hope...",Positive
Intel,AMD has always been like this. The OG Athlon FX line from ~22 years ago were $1000 CPUs.,Neutral
Intel,Wasn't it equivalent more or less to the 4050m as it was power limited to 30 watts?,Neutral
Intel,"It's the price of the final product that will matter.  And given that Intel has lion's share of the mobile market, I don't see why the would not ask outrageous $$$ for it.  It is ""impressive"" only in the ""for iGPU"" context.   Based on the benches shown, laptops were consuming around 60W.  While AMD""s 370 HX has been shown to be able to game at below 20W, so uh.  Let's bait for wenchmarks in any case.",Neutral
Intel,"Sure, sure.  I'm going to wait for proper benchmarks done under lab conditions and documented by more than ""Intel let me run this game with the FPS counter on.""  I mean, the general impressions for Intel are quite positive and if they're true then I hope it spurs AMD to do more.  I'm just not going to blindly accept ""first impressions"" as a replacement for proper testing.",Neutral
Intel,*With 64gigs of ram at 9600mhz,Neutral
Intel,"Tbf, it's like dgpu winner is claimed by who has the strongest one, so in that way it's kinda fair.  But how's the availability? Is halo in laptops actually? What's the pricing?  And what's the bang per buck on point and this?",Neutral
Intel,"https://x.com/jaykihn0/status/1812898063502938260/photo/1  ""PTL-H 12Xe pictured."" so according to that the 55mm2 die variant is xe12",Neutral
Intel,"12 Xe cores is 60% of the 20 cores in the B580 and that's 272mmÂ², but of course that also has GDDR memory controllers, and such that aren't needed on a GPU chiplet, but it's likely that the die for the top SKU is quite a bit bigger than 55mmÂ², I'd say between 90 and 130 mmÂ².",Neutral
Intel,">I think its probably ~165mm2 in size, not 55mm2.   Which might open an ""dGPU sized iGPUs"" race.  NV could be the main victim here Surely AMD can oversize its iGPUs too.  I actually thought that AMD was forced to do so, by Filthy Green's GPP effectively banning AMD dGPUs. Typing this from G15 AMD Advantage Edition TUF.",Neutral
Intel,What matters is the intel chip regardless of actual die size runs on quad channel LPDDR memory instead of the octa channel of strix halo and is fitting into mid and small size laptops 15-45w.,Neutral
Intel,Then how is the exynos 2600 using rdna4 fron samsung if it doesn't scale?,Neutral
Intel,RDNA5 doesn't exist. The actual name for the next generation architecture is UDNA1.,Neutral
Intel,"Same here. No new FSR tech and ROCm was just as poor. It works now but Vulkan is often better.. Very disappointing. For AI, NVidia is so far ahead.",Negative
Intel,If intel can extract more out of LPDDR5x with B390 then I don't see how AMD can't. Just too stingy to give more die area to cache?,Neutral
Intel,So basically RDNA4 is just another RDNA1,Neutral
Intel,Kepler said in another subreddit that Medusa Premium and Halo is launching in 2028. You're only getting the crappy RDNA3.5 iGPUs for the third time.,Negative
Intel,"Intel: but the enemy of my enemy, is my friend.  Intel ðŸ¤ AMD  we're cooked guys /s",Neutral
Intel,"Yeah the people saying AMD is stagnating are just wrong. AMD is kicking all kinds of ass... They just don't care much for the consumer market currently.    The other issue is that there's no point releasing a new line of products when no one can afford anything because nand flash is so expensive.    Companies CAN afford this because they need to ride the ai wave, but consumers can't because the average PC cost almost doubled.",Negative
Intel,"Wow! Excellent. Hopefully we'll see the products coming to market soon, and hopefully the 2 P cores won't matter as much since we're seeing a major lithography improvement. Intel is really impressing me lately.",Positive
Intel,This. Plus even lunar lake outperformed Strix Point in many scenarios already. Intel is at least one generation ahead here,Positive
Intel,"It's not the 4050 at 60W. The laptop they compared only allows for 30W to the 4050. Nvidia's specs for the 4050 is 35W minimum, so I don't know how Dell even got to 30W. Below a certain wattage, gpu performance decreases exponentially because a minimum level of power is required to even have the gpu turned on.   Panther Lake is built on Intel 18A, which is supposed to be much better than the 'ancient' TSMC 5nm the 4050 is built on. The 4050's cpu is also Arrow Lake, which is less efficient than Lunar Lake. Again, that skews the agenda.   You can already game on thin and light devices with discrete graphics. Laptops like Asus's G14 is only 3.3lb, but sports a 4060 which is like twice as fast as intel's new igpu. The dgpu turns itself off when on battery, and the integrated graphics takes over. Anything more intensive should be used with a charger plugged in.   In short, paying for a big igpu doesn't make much sense for anyone interested in performance. And gaming handhelds? Does anyone really care about those useless bricks for investment into integrated graphics? It's not like the cost of Panther Lake is going to be cheap when its laptops start at $1300. With that kind of money, you can get 2025 Asus Zephyrus G14 with a 5060 and blow its shit out the water. Or for those on a budget, 5050 laptops have been seen for $600.   Integrated graphics have come so far, pairing Intel's newest 18A Panther Lake with an RTX 4050 could still make a lot of sense.",Negative
Intel,"Ehh not the mayority but *all* computers use iGPUs. The thing is, for the average Joe aka 95% of the market, there won't be a difference in the usage between an Intel Iris or RTX 5090 dGPU. And the efficiency would only come into place if they would game on battery (who does that anyways) or create/edit videos (again, virtually no one would do that without a dGPU). And even then, having your laptop drained in 2 hours 15 minutes instead of 2 hours is not ""gamechanging""   So it does not affect the efficiency at all during webbrowsing, watching videos, creating documents etc.  Thats also the reason why Intel has the non X 5,7,9 which will properly be by far the more demanded version as, again, the average Joe does not care the slightest about iGPU.  And apart from the iGPU, PTL is just a tiny step up from the Ultra 200 series...",Neutral
Intel,"It's so weird that people treat their computer parts with a cultish following. Most of the people I know don't think about their cards at all and are just happy to play whatever games.   Super weird to be ""team red"" or ""team green"".   I can't imagine describing myself as a ""my computer chip manufacturer fan"". Cringe lmao.",Negative
Intel,"How are you determining that AMD has a ""lead""?  In terms of Marketshare, Intel absolutely dominates x86, especially mobility (laptops), and if you walk into a Best Buy and ask 10 random customers ""Would you ever consider buying an AMD laptop?"", five of them would ask ""What's AMD?"", another three would say ""Isn't that a budget brand?"" (Their ""awareness"" of the zeitgeist of PC hardware is stuck in 2005), and maybe, and that's a big maybe, two out of ten would have a favorable opinion of AMD hardware so long as they've been paying attention for the last few years.  In terms of budget and expenditure, in 2025, Intel spent $17 billion in R&D versus AMD's $7.4 billion, outsizing it by a large amout. Total sales for 2025 are projected at approximately $53 billion for Intel and $33 billion for AMD.  I see this all the time and I've seen it for the past 8 years.... the only place that AMD has a ""lead"" is in the mind of PC hardware enthusiasts.... because it's not in the numbers as seen above (sales, expenditure, market share, etc), and it's not in the ""mindshare"" of your average consumer.  Hypothetically speaking, we could say that in a duopoly, as with Intel/AMD in x86, the BEST situation a consumer could hope for would be an even 50%/50% split in marketshare.... this would bring about the fiercest competition and would hopefully lower prices, increase innovation, etc. (and yet another reason why any fanboy who wants their favored company to dominate is LITERALLY cheering against their own interests as a consumer) Even with AMD's seriously impressive turnaround, their capture of marketshare, their ability to compete with two of the largest companies in the world while having considerably fewer resources, they still have a very, very, long way to go before approaching 50% of the x86 market across all segments.  In fact, to get any closer to that idealistic 50/50 split, AMD would have to continue winning and Intel losing for for many more years.  In other words, fears that AMD is ""becoming what Intel used to be"" and ""getting lazy"" are not an accurate reflection of the reality.",Neutral
Intel,"What no AMD deserves much worse. How can a company fuck up so much and still survive. I would rather good competition rather than competing for the sake of competing. Marketing is bad, products are bad and they keep shooting themselves in the foot. Id rather Qualcomm or some other ARM company compete with X86. Its ARM or RISCV time to shine.",Negative
Intel,Ever head a look at their profit margins?,Neutral
Intel,"Bullshit.  For starters, pricing is not a ""bad thing"".  Bad thing is, pick any piece from blue/filthy green's arsenals:  1) Strongarming OEMs 2) Strongarming Journalists 3) Proprietary standards",Negative
Intel,Waiting? Theyâ€™ve been busy doing that for years now,Neutral
Intel,"I WISH they were still around. I think their IP got sold to Via, who's not doing anything with it.  At this point, we might only get competition in the desktop x86 space if the government forces Intel and AMD to license x86 and x86-64 to some other chip designer (like Qualcomm or Mediatek) or Windows on Arm and Linux on Arm start getting wide application support, including office software and games.",Negative
Intel,"""Being good"" was never about price.",Neutral
Intel,"They said it rivals a 4050 at 60W. The 4050 maxes out at 100W on paper but it's actually at 80W that it hits its peak performance. a 60W 4050 is about 85% of it's max performance.  So performance wise panther lake should be about on par with a full powered 3050Ti laptop.  That plus more advanced ray-tracing cores, it's running doom dark ages really well, AMD is still stuck at RDNA 3.5 and ray-traced games suck on the 890M.  I wish intel released a 24 Xe Core Variant with a 256-bit bus, double the cores and bandwidth. That would compete with the 5060/5070 laptop GPUs.",Neutral
Intel,"Not synthetic benchmarks, we want to see benchmarks in games.",Neutral
Intel,"You're either intentionally mis-stating this, or truthfully aren't aware, BUT, you can game sub 20w on any igpu. What actually matters is the performance scaling.  Also, just to clarify, while the 890m CAN game between 6-20w its performance is essentially identical to the 780m, z1e, etc. It only gets impressive at power draws 30+ (signed, a very happy 7840u handheld owner)  So, what we need to know is how well the new Panther Lake chips scale",Neutral
Intel,Lunar lake came out after strix point. It was squarely a competitor to the 890m. Amd just officially released the cut down strix point as Z2E later.,Neutral
Intel,"No, not really. Making up a ""winner"" is stupid and nothing but fanboy behavior.  A faster dGPU is generally better because youâ€™re generally not power limited on a desktop. It doesnâ€™t really matter whether or not you have a 5060 or 5090 or whatever.  In mobile systems itâ€™s a huge difference.  There are entirely different power classes that donâ€™t compete with each other. A thin and light notebook with a 15W CPU cannot have a 100W CPU in it.  Panther lake aims towards unplugged performance which is the 45W power class and the same as Strix Point.  Strix Halo is a much higher power class that requires a laptop to be plugged in permanently for the full performance.  Itâ€™s for mobile desktops that are usually plugged in but can be mobile for some time with heavily degraded performance.  Itâ€™s an entirely different class of product and you wonâ€™t find (many) devices where Strix Halo and Strix Point/Panther Lake compete with each other.",Neutral
Intel,"Yeah, i am gonna contend that either that is wrong, and is the 4xe version, or that intel basically lied on their benchmarks.  If none of those two things are true, Intel's new graphics architecture will absolutely dominate in the next round of discrete graphics GPUs.  with B580 intel needed \~80% more silicon to match nvidia performance. Now they need \~10-20% less die area. meaning their performance per transistor basically doubled gen/gen. which is unheard of. Even maxwell (largest architectural uplift in the history of GPUs in the last 10 years) did not achieve anything close to that. And it was a massive overhaul with huge changes.  So . . . there is something big i am missing . . . or intel is going to dominate in all things graphics going forward.",Negative
Intel,"Let's not perpetuate this ""octa channel"" DDR 5 nonsense; it's a quad channel chip, and the Intel one is a dual channel",Negative
Intel,"If you're going to be pedantic about it at least be correct please, they both use 16b LPDDR channels so the actual counts are 8 channels for Pantherlake and 16 for Strix Halo.  You're fighting a losing battle either way, the industry has long since settled on 64b as the standard channel width for marketing, independent of the actual number of address/command buses.",Negative
Intel,Where did you find information of it being rdna4?,Neutral
Intel,It's a custom implementation. IIRC it's not even RDNA4 but some Samsung derivative that probably has a ton of changes in silicon design to drive power down.  The short story is that AMD didn't bother to do low power optimizations in the architecture and silicon design. RDNA5 should change that.,Negative
Intel,"Mark Cerny talked about RDNA5, AMD's leaked documents have talked about both UDNA and RDNA5",Neutral
Intel,This is nonsense RDNA5 does exist. I used to work there.,Negative
Intel,"Kepler's track record with AMD stuff isn't great, but everything is possible",Negative
Intel,">we're cooked guys /s  No sarcasm there lol  All tech companies are colluding right now, seeing as american business laws don't matter anymore",Negative
Intel,"Yes, a frienemy.",Neutral
Intel,"Oh, you didn't say AMD was ""slacking off"" and letting intel ""catch up"". Figures.",Neutral
Intel,But thatâ€™s also more because of the increased demand from AI than anything else.,Neutral
Intel,"It's 6C/6T and 2x Xe3, so don't expect a whole lot of performance. This is Intel's Mendocino.",Neutral
Intel,The slide specifically says 60w sustained for the 4050. I couldnâ€™t find your claimed 30w anywhere. If Iâ€™m wrong Iâ€™d be interested to see where you got the 30w number from because that would be shady by Intel,Neutral
Intel,"I posted elsewhere about the Framework Desktop with the Ryzen AI 385 and 32GB of RAM.  That's a pretty sensible config for a small gaming device, though it has 32 CUs instead of the full 40.  Still, that puts it ahead of anything in it's class other than the 395+.",Positive
Intel,"Yes, have you compared it to that of the competitors?  In general, pricing is not the issue to me.   Dirty play like blackmailing OEMs, proprietary standards and other misuse of the dominant market position is. (on top of being illegal)",Negative
Intel,"Let me guess, you're too young to recognize he's talking about before your time.",Negative
Intel,"Yeah while AMD can't even announce their product AT A CONSUMER ELECTRONICS SHOW! and instead ONLY TALK about AI and government work......   AMD sucks just as bad as Nvidia just as bad as Intel, it's just a constant moving circle jerk as to whom is the least evil.",Negative
Intel,How about this one: strongarming game developers into NOT including DLSS?,Neutral
Intel,"Nobody is interested in x86, otherwise Via would have been bought up.  We are in the age of the cloud and all software is custom made. Hence RISC+",Negative
Intel,"Also Intel has XeSS which is very helpful for handhelds since they can't manage higher wattages, although not all games provide XeSS as an option",Positive
Intel,Is there really a 4050 or are you referring to the 4050m even when you don't add the m?,Neutral
Intel,"they said 60W, but if you look at the laptop they used, it's 30W, probably 60W whole system",Neutral
Intel,Nvidia paid intel 5B dollars ....Read whatever u can ... But it was to stop intel giving high power gpu to mainstream... .,Neutral
Intel,"Perf + price + (to a lesser extent, but it still matters) power consumption together is what matter.   None of the 3 is decisive on its own.",Neutral
Intel,"I think youâ€™re getting downvoted because it was sold by reviewers as a Z1E competitor as thatâ€™s what was available in regular devices.  Hx370 was only used in niche manufacturers, like GPD only when it launched.   Youâ€™re right though, it was supposed to be a competitor for hx370, but was held back by drivers and other things until mid to late 2025, which corresponded to Z2E (cut down hx370) release.  Fast forward to now, and it competes/beats both",Neutral
Intel,"i mean you can legit put it over the intel provided slides and its pretty much a dead on match. the PCH is smaller in the presentation photos so they can make it look pretty, but the real chip is an exact match to that leak https://cdn.videocardz.com/1/2025/05/INTEL-PANTHER-LAKE-DEMO-1200x675.jpg  ~~this generation is seeing quite a significant leap forward in manufacturing technology (Gate All-Around/RibobnFET & Backside power delivery/PowerVia) these usually do result in big gains and that does make it a bit harder to compare to prior nodes. not to mention~~ **[GPU is TSMC N3E still quite a bit denser than N4 class tho]** its not the exact same uarch as B580, while still a derivative of battlemage, there does seem to be some (rather significant) improvements between xe2 and xe3 https://gamersnexus.net/gpus/intels-new-gpu-xe3-architecture-changes-handheld-gaming-cpus-xess3   but where a lot of the fps gain will be from is N-Frame and Pixel generation intel want to promote those numbers over native performance. AMD cant do with RDNA 3.5. id expect 8060s to be a much more powerful igpu but it is lacking what is essentially lossy compression for realtime graphics. that is a pretty big deal and i do think it will be what causes Strix halo to be a product that just ages poorly, costs too much for what it is really (308mm^2 io/igpu chiplet cant be cheap on 4nm) its really amds pipe cleaner for future packing tech.  people said they same when the zen chiplets were rumored to be the size they are. you save a lot of area not needing memory controller on that chip would be my guess. d2d bonding is very space efficient compared  for some perspective strix halo igpu block + media engine block is about 120mm^2 on N4P(143.7216MTr/mm^2) of the iod, the rest is i/o and the npu.  the 12 Xe3 chip is 55mm^2 on N3E(216MTr/mm^2) (so we could napkin approximate about 80mm^2 if it was on N4P)",Neutral
Intel,"Technicality is technicality, if the channel width is cut down by half but channel number is doubled then they still doubled the memory channel. People just need to know memory channels are not all equally wide just because thatâ€™s all they know being PCMR enthusiasts.",Neutral
Intel,"https://www.thelec.kr/news/articleView.html?idxno=50232. Seems your out of the loop, you think amd can't scale rdna4 but samsung can?",Negative
Intel,"Rdna4 is objectively faster than rdna3/rdna3.5 at the same clock, power' cu count and bandwidth  something 100% desirable for apus. Stop making excuses for amd and their bad decisions. Everything b your claiming samsung did for rdna4 to scale is something amd could have done aswell and has done as amd has made changes to rdna3(rdna3.5) for apu specifically the same can be done for rdna4.",Positive
Intel,Sure. weâ€™ll see,Neutral
Intel,Have the business laws mattered since the dawn of post-dialup internet?  I don't think they have. Where's our fucking bell-style breakup? 41 years ago was the last *real* monopoly breakup... and they let it come right back.  EU does half measures and they don't come to the rest of the world. It's a travesty that we don't have nationwide GDPR or force allow sideloading on ios.,Negative
Intel,An enerend of sorts,Neutral
Intel,"Sure. But they're still not stagnating. Since December 2023, when Mi300X and Mi300A were released, they released Mi325x, Mi350x, Mi355x and soon, Mi400x.    The latest gen is running HBM3e and 3nm CDNA4. Those are some immensely advanced products.    On the Epyc side, they've got the 9965, a 192 core 384 thread monster that Intel can't even attempt to compete with.    Intel hasn't advanced in server stuff at the time either. Their top SKU was 18c in Haswell, and that hasn't moved until like Cooper lake? So from 2014 until 2020, they haven't moved an inch in server space either.    AMD has gone from 32 cores first gen in 2017 to 6 times that in 2024.    It's honestly not even comparable. AMD advanced more every generation than Intel did from Haswell to Kaby lake at the very least.",Neutral
Intel,"The modern Atom is fine by me, the N100 had more performance than a 6500t so this one should have more than enough compute for many different use cases whilst retaining low load efficiency. This product could potentially obliterate even the newest and best SBCs for home lab use cases, even regarding efficiency.",Positive
Intel,"[Intel Performance Index](https://edc.intel.com/content/www/us/en/products/performance/benchmarks/intel-core-ultra-processors-series-3_1/) Search 4050. [Dell 14 Premium is this laptop, with a TGP of 30W](https://www.dell.com/en-us/shop/dell-laptops/dell-14-premium-laptop/spd/dell-da14250-laptop/useda14250hcto01#customization-anchor)  [In PCWorld's test, they got 48 fps for Cyberpunk](https://www.youtube.com/watch?v=NdLYuQQPo5c). My 4060 gets 73 fps using 60W using high settings and 2880x1800 DLSS instead of XeSS. That's a game where Intel gpus performs well above average. A 4060 optimus laptop uses around 3.5W an hour at idle without the screen turned on. With the screen and igpu powering it, it's about 8W. Having discrete graphics in modern systems doesn't really impact battery life anymore.   So yeah, Intel was intentionally being misleading, hoping people wouldn't actually bother to check their figures. Panther Lake's massive igpu still doesn't make sense for anyone who cares about performance. Maybe a little bit for battery life, if it's more efficient to drive high resolution displays, despite its large size being wasteful. Most igpus go into office pcs. In terms of gamers, Steam's hardware survey suggest that desktops and gaming laptops with dgpu are the biggest share.",Neutral
Intel,"Yes, I did. AMD could hold prices low, they choose not to.",Neutral
Intel,What AMD did a decade ago has no bearing on how they operate today. Corporations have to alter their behavior quarterly in order to maximize their legal obligation to constantly increase shareholder profits.,Neutral
Intel,9850X3D lol gottem,Positive
Intel,you didn't just try to suggest that CES is for....consumers..... did you.... seriously?,Negative
Intel,"Ahaha, lovely lie. And even if true, how would that change a lit of ""bad things"" lol.",Negative
Intel,"Seems like things are going that way. I guess all we can do is wait and see if the Arm takeover gets so complete that Intel and AMD have to join in, and then suddenly have to compete with Qualcomm and Mediatek.  If that ever happens, hopefully we'll see more competition.",Neutral
Intel,linux and optiscaler is the way,Positive
Intel,"4050m, although it really wouldn't matter either was as the 4060 and 4060m are functionally identical in regards to performance (+5-7% for desktop) so if there were a full size 4050 we'd expect it to be the same or even less of a difference",Neutral
Intel,"That's all fair, I'm looking at it from a handheld perspective. Performance at power draws that are actually feasible in handhelds has been stagnant since handhelds have really gotten popular. That is, it has if you want more than an hour of battery life",Neutral
Intel,"Actually, the supposed driver issue was only a MSI Claw specific issue and not a general lunar lake issue.  https://www.notebookcheck.net/Intel-Lunar-Lake-iGPU-analysis-Arc-Graphics-140V-is-faster-and-more-efficient-than-Radeon-890M.894167.0.html  Here's a review from September 2024 using a LNL Zenbook S14 with 28w TDP. It had no issues generally outperforming the HX370 in the Zenbook S16. As usual the PCMR-esque dominated crowd on here paid no attention to laptops (which is the real life volume) and only looked at some handheld (which is a niche irl) so they thought that supposed ""lunar lake issue"" was widespread.",Neutral
Intel,"Each DIMM of DDR5 has 64 bits total of bus width, same as DDR4, 3, 2, and 1. And I do understand what you're talking about (not to mention that Strix Halo can't even take SODIMMs), but nobody else talks like that. When you call it an ""octa-channel"" chip, what people read is that it has as much bandwidth as a Threadripper Pro, because that is how [AMD is marketing those chips themselves](https://www.amd.com/en/products/processors/workstations/ryzen-threadripper.html).",Neutral
Intel,"Yeah, and AMD says Strix Halo has four channels in their customer facing spec as well, because they have 128b and 256b buses respectively. They use the 64b channel convention as it is a customer facing spec, that doesn't meant they actually have that many channels in hardware.   The Pantherlake datasheet isn't public yet, but you can see plainly in the [actual spec sheet](https://edc.intel.com/content/www/us/en/design/products-and-solutions/processors-and-chipsets/core-ultra-200h-and-200u-series-processors-datasheet-volume-1-of-2/memory-controller-mc/) for Arrowlake H that it supports 8 channels of LPDDR5X (additional [spec](https://edc.intel.com/content/www/us/en/design/products-and-solutions/processors-and-chipsets/core-ultra-200h-and-200u-series-processors-datasheet-volume-1-of-2/supported-memory-modules-and-devices/) for channel width). Pantherlake will be the same.   The equivalent AMD doc is not available for Strix Halo but you can see the 16x16b spec quoted by Chips and Cheese [here](https://chipsandcheese.com/p/evaluating-the-infinity-cache-in#:~:text=Strix%20Halo%20has%2016%20memory%20controllers%20and%20CS%20instances%2C%20each%20handling%20a%2016%2Dbit%20LPDDR5X%20channel).  You cannot gang these channels into a dual channel mode, that is not how modern memory works, and there is no allowance in the LPDDR5 spec for 64b channels. The 16b channels have separate command/address buses and burst for a sufficient length (32n) to fill a cache line with each access.  To be clear I think standardising on 64b ""channels"" for marketing specifications is a good thing, it allows quick mental calculation of memory bandwidth without having to get into the nitty gritty. But if you're going to be pedantic and use the actual channel count, it's best to be correct.",Neutral
Intel,"Im not original guy you responded to I just wanted to know, becouse I couldnt find it on google. thx",Neutral
Intel,"I'm not making excuses just explaining the rationale, which I don't agree with BTW.       Yes I know AMD are some lazy mofos. RDNA 3.5 till 2029 for iGPU is cheapo strategy as usual.",Negative
Intel,https://en.wikipedia.org/wiki/Hyperbole,Neutral
Intel,">It's honestly not even comparable. AMD advanced more every generation than Intel did from Haswell to Kaby lake at the very least.  >Intel hasn't advanced in server stuff at the time either. Their top SKU was 18c in Haswell, and that hasn't moved until like Cooper lake? So from 2014 until 2020, they haven't moved an inch in server space either.  Since we're talking about the server side now, Haswell-EP went from 18 cores maximum to 22 core Broadwell-EP to 28 cores on Skylake-SP. Cascade Lake-AP (rare bespoke sku) went up to 56 cores per socket. ""Haven't moved an inch"" is inaccurate.",Neutral
Intel,"In CPUs theyâ€™re losing market share to arm, the Datacenter GPUs are mostly bought by companies who canâ€™t afford NVIDIA",Negative
Intel,"I think you were looking at the old core ultra series 1 testing not the current CES testing. For their claim they used the following settings:   Intel B390: Processor: Intel Core Ultra X9 388H (Panther Lake) PL1=45W; tested in Intel reference platform; Memory: 32GB LPDDR5 9600; Storage: Samsung PM9A1 512GB; Display Resolution: 2880x1800; OS: Windows 11 26200.6725; Graphics Driver: Intel Arc Graphics Pre-Production driver; NPU Driver: Pre-Production driver; BIOS: Pre-Production BIOS; Power Plan set to Balanced, Power Mode set to ""Best Performance"".  NVIDIA RTX 4050: Processor: Intel Core Ultra 7 255H (Arrow Lake); tested in Dell 14 Premium with Nvidia GeForce RTX 4050; Memory: 32GB LPDDR5 8400; Storage: Samsung 9100 Pro 1 TB; Display Resolution: 2k IPS; OS: Windows 11 26200.7171; Graphics Driver(s): dGPU: 32.0.15.8180 (GeForce 581.80) & iGPU: 32.0.101.8250; NPU Driver: 32.0.100.4404; BIOS: v1.4.0; Power Plan set to Balanced, Power Mode set to ""Best Performance""; Dell Optimized = Ultra Performance. Battery Size: 68Whr",Neutral
Intel,"Why would AMD ""hold prices low""?  Gross margins are below 50% (48, as in 2022), while NV has it at 70%.  We know they are worse in PC/GPU market and better in datacenter.",Negative
Intel,What did you think the acronym CES stands for?,Neutral
Intel,It would further validate what HisDivineOrder said which is that AMD is just another corporation.  Which they are.,Neutral
Intel,"Really wish Optiscaler had a better installer, something akin to Reshade. The whole manual process for each game makes it annoying to use.",Negative
Intel,Intel still takes a heavy penalty on Linux in graphics vs. AMD. Hopefully that improves as well.,Neutral
Intel,Well thereâ€™s more than one type of memory ðŸ¤·â€â™‚ï¸ PCMR crowd just defaults to DDR DIMMs but the world of mobile is mostly LPDDR from phones tablets to handhelds and most small laptops,Neutral
Intel,"Nope, I was looking right at the current testing. I do have to make a correction though: Panther Lake's cpu is built on Intel 18A, and the gpu is built on TSMC N3E  Let's summarize. In a head to head battle, Intel claims the 45W Panther Lake Core 388H with its ""massive graphics"" is 10% faster than a 30W 4050 paired with a 30W Arrow Lake 255H. Panther Lake's cpu is built on the most advanced silicon process node 18A, designed to compete against TSMC's N2 (2nm) which is set to release in products in the second half of 2026. Panther Lake's gpu is built on TSMC N3E, a significantly more efficient N3. The 4050 is built on a custom 2020 TSMC 5nm variant, and Arrow Lake is built on TSMC N3+6nm. Arrow Lake is designed for specifically for high power use vs the low Lunar Lake and Panther Lake.   The future of integrated graphics is truly bright. I can see it being exactly where it is now. Vital for battery life in office laptops and actual gaming laptops with discrete graphics. Big igpus? Mostly irrelevant and a waste of money.",Neutral
Intel,"Yes acronym has ""consumers"" in the name, but it's not directed or intended for consumers, it's intended for the big industry, the maker's manufacturers, the ones creating services, and the subtle parts of the distributors and such, it was and has NEVER been intended for the end users, the broad consumers.  Maybe bloody well look up what CES is and what it's for before asking a silly question.",Negative
Intel,"No, it would not. There is a difference between a shoplifter and a serial killer, even though both are criminals.  Filthy Green plays in a league of pieces of shit of its own.",Negative
Intel,True but you put command once in your game and you forget about it,Neutral
Intel,"This is so delusional  You're talking about AMD that made Int8 version of FSR4, which is THE hardest part, and then keeps it away from users to sell more RDNA4 cards.",Negative
Intel,"Missing the point. It's about accessibility and ease of use not how often you need to do it. If a tool to bring similar functionality as Nvidia isn't at a similar level of accessible and easy to use as the manufacturer apps, then it's relegated to enthusiasts only.   Reshade is one of the most popular modding tools for post-processing shaders because it's so easy to install, use, and manage for multiple games on the same system.",Neutral
Intel,"AMD had no reasons for such lock-in, it makes sense only for companies dominating the market, to push people to refresh.  I have not seen palatable proof that FSR4 could be ""easily backported"" but isn't.",Neutral
Intel,Already seen card prices here in Canada jump 10-15% since last night. It's insane.   Now is not the time to build.,Negative
Intel,"Hi, I was wondering if there's any reason to worry if my 7800X3D sometimes spikes for 1-2 seconds to 100Â°C while gaming and then goes back to the usual temp. I have noticed the highest temp recorded by HWiNFO at one point was 104Â°, though I never noticed it on the OSD while in a game and never noticed a performance drop. Is there a problem with the cooling or something that could damage my CPU or is it just a sensor bug/issue?",Neutral
Intel,"If you're looking to do a PC build...just don't.  If you NEED to do one, do it right now. It's not getting any cheaper this year.",Negative
Intel,"Here's a dumb question that would be absolutely ridiculed if I dared to create a whole thread around it.  Is there any truth to my hypothesis that Play Station PC ports are likely to be relatively well-optimized for AMD GPUs, given that the Play Station 5 itself is indeed some variant of RDNA? I recently got a 9070xt and have been overall very impressed, but its achilles heel seems to be ray tracing. This isn't exactly surprising to me, as I researched my GPU options to death before buying one, and the general consensus is that Nvidia is stronger in the ray tracing department. But if I were to boot up, say, Ratchet and Clank Rift Apart, a game that supports ray tracing at 60 fps on the base Play Station 5, could I expect it to perform better than a similarly demanding game that wasn't particularly optimized for AMD hardware?  It's largely hypothetical question, as I already own the GPU, am satisfied with the GPU, and of course did my due diligence before buying the GPU so I would know exactly what to expect. But I just haven't really heard much discussion of what, if any, overlap we get optimization-wise for games that were optimized first and foremost for the AMD-based Play Station 5.",Neutral
Intel,"Thinking about doing a platform upgrade from a 5800X3D to a 9800X3D, how much of an improvement will I see with my RX 7900 XTX?   Obviously I know that DDR5 is priced high now but I think it's only going to get worse if I wait. I live near a Microcenter as well so I'll be doing one of their combos with the CPU, Mobo, and RAM.",Neutral
Intel,"Early 2025 I was thinking about upgrading to AM5 but there's no way that's happening, I only got a sapphire nitro+ 9060 XT 16gb on Black Friday.  Current setup is Ryzen 3600 on Gigabyte b450 Elite v1, 16gb ram 3200, 9060 XT. My question is, would an upgrade to 5800X make sense? It costs 165 euros where I am and it's the only upgrade I can make that I see. I play games like Helldivers 2, BF6 nowadays. Also I play on 1080p.   Thank you.",Neutral
Intel,"Hi all  I'm about to give my water-cooled 6950xt to my brother as I picked up a 9070xt.  As I've got to.out the og heatsink back on I'd like to.replace the pads ofc. Does anyone know the sizes needed.  I'd also throw a kryonaut grizzly bear pad on the GPU, would this be a 1mm pad?  I'd like to get this right as he's on a 5700XT so it will be a good upgrade for him.  Many thanks.",Neutral
Intel,"Is PowerColor a good brand of GPUs?  Iâ€™m planning on upgrading my gpu from my almost 7 year old nvidia rtx 2060 to an PowerColor rx 7800xt Red Devil, and am bit worried if theyâ€™re a reputable brand.   Was holding off the upgrade due to not wanting to chase percentages, and now that I fully embraced Linux (Fedora 43 KDE) I wanted to get something that has better compatibility with the OS as I did encounter some issues due to NVidia drivers.  Edit: forgot to mention that I have a compatible system with 600w power supply",Neutral
Intel,"I could use some suggestions on upgrading a desktop box my son built for me in 2013. It was used for my graphic arts business (Adobe Suite) and has performed admirably for the last 12 years. It's running Windows 10 and most of the patches will not install. It can't be upgraded to Windows 11, and while I realize that every MS upgrade I ever did in the past caused major mayhem, I probably should go ahead and do it before it quits running altogether.  Below is a list of what he ordered and put in it.   What should I order that will swap out and last me another 5-10 years? I just used this for work and internet. No games.  â€¢ MB Gigabyte|GA-970A-UD3P AM3+R   â€¢ VGA Sapphire|100365BF4L R9 270 2GD5   â€¢ PSU Roswell|RX850-S-B 850W RT (has been replaced)   â€¢ CPU AMD|8-Core FX-8350 4.0G 8M R   â€¢ SSD 256G|Samsung MZ-7PD256BW R   â€¢ MEM 8Gx2|Corsair CMZ16GX3M2A1600C9  It also has a DVD RW Drive and I added a 12TB WD Hard drive   I'm sure most of you folks can look at that list and quickly see what I need to change. I'm thinking CPU, Motherboard and RAM? Thanks for your expertise.",Neutral
Intel,"I typically wouldn't do a pre-built but considering I can get my hands on this right now if I wanted and the prices of things going up, would this be worth grabbing?  $1,649.99 AMD Ryzen 7 9800X3D, AMD Radeon RX 9070XT 16GB, 32GB DDR5 RGB,2TB NVMe SSD  [https://www.bestbuy.com/product/ibuypower-slate-gaming-desktop-pc-amd-ryzen-7-9800x3d-amd-radeon-rx-9070xt-16gb-32gb-ddr5-rgb2tb-nvme-ssd-black/J3R75JYGZ5](https://www.bestbuy.com/product/ibuypower-slate-gaming-desktop-pc-amd-ryzen-7-9800x3d-amd-radeon-rx-9070xt-16gb-32gb-ddr5-rgb2tb-nvme-ssd-black/J3R75JYGZ5)  Thank for the input in advance!",Neutral
Intel,"Quick sanity check: Am I right to say that there are no new production of X570 boards at the moment, and therefore I should just sit tight with my Asus X470 Stix-F board until the RAMmegeddon eases before moving up to AM5/AM6?",Neutral
Intel,"Bonjour, j'ai un vieux pc qui a malheureusement commencÃ© Ã  rendre l'Ã¢me fin 2025 et je dois donc me dÃ©pÃªcher d'en racheter un avant que les prix deviennent exorbitants. Je recherche un Pc fixe (si possible prÃ©montÃ© Ã©tant donnÃ© que je suis peu douÃ© lÃ  dessus) pouvant faire tourner les jeux d'aujourd'hui (E33, Dlc Baldur's Gate etc...) et si possible ceux de demain.   J'ai un budget correct (1200 euros max) et je risque pas de faire grand chose Ã  part jouer dessus.    Merci d'avance pour vos avis !",Neutral
Intel,"I just installed my new RX 9070 XT today, replacing my RTX 3060 Ti, and after getting the new drivers set up and the old ones gotten rid of, i'm having an issue of intermittent audio crackling. Is there a know simple fix for this?",Negative
Intel,what are the best settings for my rx 9070 xt steel legend on adrenalin? should I prioritize lower temps or higher performance? and will the performance between settings be negligible playing in 3440x1440p? I'm currently running the default option under Performance>Tuning,Neutral
Intel,"When I'm playing a game, my screen suddenly goes black and I have no way to shut down my PC; I have to restart the power supply. Does anyone have any solutions, please?",Negative
Intel,"Are there plans for chipset refresh for Zen 6 or 7 or there will be only firmware and BIOS  updates  for existing ones? I heard Zen 6 should have better memory controller , with higher 1:1 RAM speed support (perhaps 8000MT/s + ) etc. , but of course still same AM5 socket.",Neutral
Intel,"Hey guys.  Whats the best way to get a smooth 60fps lock on a 120hz display?  I use MSI Afterburner and the adrenaline app, neither felt as smooth as native 60hz.  On nvidia i used the half vsync feature and that worked for me but AMD doesn't have an equivalent option.",Neutral
Intel,"weird issue as off 2 days ago: RX 7700 XT with 25.12.1 driver on W10 - when powering on the system, the secondary screen (HDMI) is not receiving any signal until the HDMI cable is unplugged and plugged back in. No recent updates installed.",Negative
Intel,"7800x3d SUSPICIOUSLY LOW TEMPERATURES   I just finished building my computer and tested it in two games, at 2k resolution and the highest settings: The Last of Us Part Two and Battlefield 6. My 7800x3d is showing temperatures below 50 degrees Celsius, even though I'd read on forums that it can get hot. I checked it on the cooling display, HWMonitor and in MSI Afterburner. Is it possible for air cooling to be this efficient, or do I need to configure something in the BIOS to get the processor to run at full performance? Bf6 runs with 180fps and TLOU have around 100fps.  I have rtx 5070 and 32gb ddr5. Cooler: Phantom spirit Evo vision with stock paste.",Neutral
Intel,"New to AMD and plan to keep the same cpu cooler, I have a NH-D15. I bought this cooler back in 2021-22. Would I need a new mounting bracket to accommodate this change?   I have upgraded to 7 9800X3D, Mobo is a Tuf gaming B650E-E if this information is needed. Any help appreciated!",Neutral
Intel,"Hi there, hope everyone is doing fine and started new year on a good note :)      Recently became the proud owner of a 9070 xt 16GB Ram - Hellhound specifically (https://www.powercolor.com/product-detail214.htm)  I just want to double - check that my AMD adrenaline edition settings are correct - What do I need selected for maximum gfx quality?     Thank you !",Positive
Intel,"looking for help understanding core parking on the 9950X3D, does it outright disable the other cores while gaming? or do other applications running use the non X3D cores?",Neutral
Intel,"I'm building my first ever AMD PC, and my second ever PC (My old one had a 2080 super, 10th gen i9 and sadly died a few months ago). I did not know that you were supposed to buy certain ram depending on what CPU/motherboard you used. I'm either going to be buying a 9850X3D or a 9800X3D, and the motherboard I have currently is the MSI MAG B850 TOMAHAWK MAX WIFI ATX AM5 Motherboard. My ram is the G.Skill Trident Z5 RGB 32 GB (2 x 16 GB) DDR5-7200 CL34 Memory. Should I return the ram and get the AMD EXPO equivalent? Will I lose performance if I keep it? Will I lose stability if I keep it? Will it even work properly?  Some extra info:   I can afford to return it and buy the equivalent for an extra $100 or so. My GPU is the Sapphire Pulse 9070 XT, I'll be gaming at 1440p, my I have an WD\_BLACK SN8100 2 TB SSD, and a Corsair RM850x (2024) 850 W Fully Modular ATX Power Supply.",Neutral
Intel,"Is a reasonable upgrade for my system possible?    Hello there,  i would like to know if there is any reasonable upgrade possible on my AM4 System...   I would like to play Call of Duty Warzone on a 1080p Monitor with 180 fps but ALSO use ~ 500 tabs at the same time.  Currently my System runs the 500 tabs but only gets ~ 120 fps in cod.   Since AM5 is very expensive currently due to RAM prices, i do not see any reasonable chances for a Upgrade and therefore am looking for advice :)    My current System:  AMD Ryzen 9 5900X - 12x3.7GHz  => OVERLOCKED at 4.7GHz with 1.304v (undervolted for that speed -> Temps below 80Â°C)   32GB DDR4 3600MHz Team Group T-Force Vulcan Z - DDR4 (2x16GB) => UPGRADED to 64GB (4x16GB)   AMD Radeon RX 7900 GRE 16GB => slight OC possible BUT Temps tend to go above 80Â°C, at higher OC even above 90Â°C... (possibly i could add more cooling to the Tower?)   * Systemtreff Gaming Mid Tower AirForce GT1   * Systemtreff ITS-Raven - Prozessor - LuftkÃ¼hler  * Gigabyte B550 Gaming X V2 - AM4  * 850W MSI MAG A850GL PCIE5 80+ Gold  => UPGRADE MSI MPG A850G  * 1TB M.2 SSD (NVMe) MSI Spatium M450 PCIe 4.0  * 1TB M.2 SSD (NVMe) MSI Spatium M450 PCIe 4.0   In the future i might want to play COD2026, which could receive a huge engine upgrade... and i also will run ~500 tabs at the same time.",Neutral
Intel,"Hi there, hope everyone is doing fine and started new year on a good note :)  Recently became the proud owner of a 9070 xt 16GB Ram - Hellhound specifically ([https://www.powercolor.com/product-detail214.htm](https://www.powercolor.com/product-detail214.htm))  I just want to double - check that my AMD adrenaline edition settings are correct - What do I need selected for maximum gfx quality?  Thank you !",Positive
Intel,"What does the 18th byte do?  On my system it changes on a daily basis. Display port radeon software rx 580  Also Current Link Settings - 2.7 Gbps x 4. Seems I have a bandwith issue, should be more as i have a DP 1.2 standard gpu port cable etc  ""BestViewOption""=hex:00,00,00,00,00,00,00,00,03,00,00,00,01,00,00,00,08,89,ff,ff,00,00,00,00,00,00,00,00  ""BestViewOption""=hex:00,00,00,00,00,00,00,00,03,00,00,00,01,00,00,00,08,80,ff,ff,00,00,00,00,00,00,00,00",Neutral
Intel,"AM4 CPU Compatibility question.     I currently have an HP system with a Ryzen 2700.   I'm thinking about picking up an AM4 motherboard for a ""new"" build. To be precise, an ASRock B550M-ITX/AC.  I can get a Ryzen 2600 on the cheap and swap out the 2700 into the new mobo. That way I can hand the HP system to my wife as an upgrade.  But. According to the ASRock lists. These older CPU's are not compatible. Just the 3000 series and up.  My question is, what makes these older CPU's incompatible on the same socket? I see some Chinese boards that support the 1000 to 5000 series Ryzens.  Right now, I can get the ASRock new for a decent price. Given the DDR5 debacle, I still have enough DDR4 sticks laying around that makes sticking to AM4 an easy , affordable choice.",Neutral
Intel,"HELP - GPU not detected after Ubuntu boot repair and CSM toggle  SYSTEM SPECS CPU: AMD Ryzen 5 9600X GPU: AMD Radeon RX 9070 XT Mobo: AsRock B650M PG Riptide Main Storage: Crucial T500 M.2 NVMe (Windows 11) Secondary Storage: ADATA SATA SSD (Old Ubuntu install)  THE ISSUE My PC was working fine until I tried booting into an old Ubuntu installation on my secondary ADATA SATA SSD. Now my RX 9070 XT is not detected at all in BIOS or Windows Device Manager, and I only get display output from the motherboard.  WHAT HAPPENED To see the old SATA SSD in the boot menu I had to enable CSM in the BIOS. Booting into that drive resulted in a black screen. I then used a Live USB to run the boot-repair utility with the recommended repair settings. This seems to have installed the GRUB partition onto my Crucial T500 M.2 drive instead of the SATA drive. Now I can boot into both OSs, but the GPU is completely invisible to the system.  CURRENT STATUS Windows Device Manager only shows the Integrated Graphics. When I try to install AMD drivers, the installer fails because it cannot detect the GPU. I was briefly able to get graphics output from my GPU by unplugging the PC, flipping the PSU switch to off, and holding the power button to empty the capacitors. I then booted it up with the HDMI cable plugged into my GPU and I saw the asrock logo but it was stuck there for 2 minutes and I impatiently turned it off. I'm also considering trying this again and letting it run it's course  PLAN AND QUESTIONS I am planning to disconnect the SATA SSD and try to wipe the Ubuntu boot entries from the M.2 drive to see if the GPU reappears. Has anyone experienced a Linux bootloader repair or CSM toggle hiding a GPU from the BIOS? Specifically, could the Crucial T500 and ADATA drive conflict be causing PCIe initialization issues after the CSM change? Should I try clearing the CMOS first? Any help would be greatly appreciated. Thanks!",Neutral
Intel,"I can buy a Ryzen 7 5700 (without X, the one that is 5700g without a built-in graphics chip) for 120 euros (\~$140) or 5800x for 188 euros (\~$218). Is it worth the extra? My GPU has 16GB, so PCIe shouldn't have too much of an impact.",Neutral
Intel,"So I have a question guess I want a 2nd opinion, with the new information of AMD potentially bringing back some old AM4 chips.   I recently bought a ryzen 5800x for my little brother to upgrade his 3600 thing is my brother is currently at the military until May so his upgrade isn't super urgent. Should I return it and potentially hold out on the chance that AMD brings back the 5800x3d?!",Neutral
Intel,# OpenGL to DX12 Wrapper on Windows? Do any of you guys know a program that wraps OpenGL API to DX11 or 12? Something like Dgvoodoo2.,Neutral
Intel,I have seen alot of posts about changing the Curve Optimizer to All cores -30 or -20 and it gives you same the performance and lower temps?  is -20 or -30 better?  and how lower does the temp go?,Neutral
Intel,"Hello guys, hope u're doing well today.   I currently have a perfectly working system, Ryzen 7 9800x3d, X870E aorus pro ice, and 2x16gb trident z5 royal neo 8000mhz cl38.   got a pair of corsair vengeance rgb cudimms, 2x24gb 8000mt cl38, as an upgrade.   after I got them I found about the cudimms and the ""incompatibility"" with ryzen which makes them run as a normal udimms in ""bypass"" mode.   searched a lot on the internet about performance or benchmarks, couldn't find any.   since I'm thinking of returning them if they don't work, and I can't if I open them, I'm looking for someone that has tried cudimms on 9800x3d and could share his experience, that would be awesome and I'll be really thankful.",Positive
Intel,"Question about dealing with overheating  Playing a game I'm getting 95ÂºC on my GPU and the performance is tanking. I know it's overheating. However, when I stop playing, the temperatures go down, I try playing again an hour later, now I'm getting 75ÂºC and the performance is just as bad as before. Has it not really cooled down somewhere inside?   It's a 5 year old 6900XT and I'm trying to see if I can reapply the thermal past, but until there I'm trying to see if there's anything else I can do to keep it from getting to the point of overheating, and I don't know what to do to really reset the test except waiting for the next day before I try again.",Negative
Intel,"Hi all,  Trying to use the curve optimiser for my 7800x3d so going Advanced CPU configuration>AMD Overclocking>Precision Boost Overdrive then setting it to advanced to use the curve optimiser. However every time I go back into the BIOS it's changed from advanced to enabled.  Does this mean it's not saving my settings or is it just a visual error - wondered if anyone else has had this?  The other reason I ask is ran three cpu cinebench tests with the curve optimiser set to -15, -20 and -25 and all returned results within 0.1% of each other and same temps too so doesn't seem to be working as I expected.  I'm pretty new to this so any help is appreciated thanks :-)",Neutral
Intel,"I have been looking at the user manuals for motherboards like H13DSG-OM which support eight MI300X Instinct GPUs.  *None* of them explain whether the midplane (like BPN-GPU-GP801) **must** be fully populated with eight GPUs, or if it will boot and operate with fewer GPUs installed (like four, two, or only one).  Does anyone know if any of the OAM motherboards (of any manufacturer, not just Supermicro) for MI300X support such partial installs?",Neutral
Intel,"I have a 9800x3d , is it worth having a negative curve of -30 and +200 on core clock for games?   I tried cpu intensive games and I didnt notice really any fps difference at all",Neutral
Intel,"PLEASE HELP. I just finished a build for my friend and I'm getting frequent no display out on power on. This is only fixed by a restart but I'm PASSING all my POST lights. The only thing I can think of would be a bios update but I'm not sure, these are all brand new parts.",Negative
Intel,"AMD Ryzen 9 9950x  ASUS Strix X670E  my current clock speed is over 5500 MHz (showing in NZXT cam, but Task Manager shows slightly lower), default is 4300MHz. Power hovers around 40-60W while browsing.  i have never touched anything regarding overclocking so dont know whats happening, didnt realize how long this has been happening.  I just tried disabling PBO in bios but that didnt change anything.  Any suggestions? Finding conflicting information online",Neutral
Intel,"# Is the 6000 series cards stuck with 25.3.1 forever now for stable VR?    I keep trying the updated software for my 6800XT, and every time it still has the stuttering/ghosting issue that doesn't occur with the 25.3.1. So I keep rolling back (properly with ddu) but now games aren't just whining about the old drivers (ninja gaiden) but Battlefield 6 flat out won't allow me to play (without some registry hack) So with AMD not doing any work on this card's drivers anymore, does that also include this issue that is THIS old being completely ignored?",Negative
Intel,"Should I disable my iGPU?  I have a 9600X and 9060XT and wondering if there is any benefit to leaving the iGPU active. I noticed that it allocates 512 MiB of system ram as vram, but I wonder if I could miss out on something if I disable it.",Neutral
Intel,"Hi everyone, the refresh rate of my Lenovo Yoga Slim 7 13ACN5 drops suddenly when I connect it with the Gigabyte M027Q28G. I can't change the refresh rate back then in that case.  I use my laptop basically as a desktop so I only use the display of the Gigabyte monitor. The issue only happens when I connect my laptop with the Gigabyte M027Q28G, when I try to connect my laptop to other monitors the issue doesn't even appear and the refresh rate is stable throughout the entire usage of the monitor.  When my twin brother hooks up his laptop to the monitor he doesn't suffer from the refresh rate drop issue at all so the issue only appears when I hook up my laptop to our Gigabyte M027Q28G.  When I'm using the monitor I connect it with a HDMI cable to my laptop through the Baseus Joystar 7-in-1 USB-C Hub as my laptop has only USB-C ports so no HDMI port or a DisplayPort port at all.  I've tried the following things in order to try solve the mentioned issue:  * Reinstall the GPU drivers of my laptop. * Pull the HDMI cable out of the HDMI port on my USB-C hub and then plug it in again.  Regrettably these things I tried didn't solve the issue so now my question is how I can solve the refresh rate drop issue when my laptop is connected to the Gigabyte M027Q28G.  Thanks for your help in advance lastly! :)",Neutral
Intel,My amd icon in system trey has a ! mark next to it i don't have any notifications i restarted and it wont go away,Negative
Intel,"**Is it worth waiting for the 9950x3d-2?**  My current system is a ryzen 5950x w/ 64Gib RAM on an x370 mainboard (Asus Crosshair VI Hero).   The mainboard is 7 years old (bought back then with a ryzen 1800x) and I really want to replace these components in my main PC.  The sooner I am thinking, the better, since I am using it 99% for work (Software development, virtual machines, local LLMs, databases, etc.) and everything needs to work - always.  Now the question is: Wait out the upcoming 9950x3d2? Or just go for the existing one?  I would pair the processor with a Crosshair X870E Hero.  Is it worth the wait considering my main use for the rig? My feeling says ""no"", but I am curious what others think about this :-)",Neutral
Intel,"Hey everyone!  Iâ€™m thinking about upgrading my GPU and found two used options: ðŸ”¹ PowerColor Red Devil RX 6800 ðŸ”¹ Sapphire Nitro+ SE Edition RX 6800  I currently have a Ryzen 7 5700X and Iâ€™m wondering if these cards are a good pairing with that CPU. I want to avoid any heavy bottleneck, and ideally get good performance for 1440p gaming.  Here are some pictures of the two cards: (attach your photos)  My questions: 	1.	Will the RX 6800 pair well with the Ryzen 7 5700X without significant bottleneck in most modern games? 	2.	Are there any major downsides to buying either of these used cards (e.g., reliability, VRM cooling, Coil whine, etc)? 	3.	Is one version (Red Devil vs Nitro+ SE) generally a better choice for long-term use?  Thank you!",Neutral
Intel,"Hey everyone!  Iâ€™m thinking about upgrading my GPU and found two used options: ðŸ”¹ PowerColor Red Devil RX 6800 ðŸ”¹ Sapphire Nitro+ SE Edition RX 6800  I currently have a Ryzen 7 5700X and Iâ€™m wondering if these cards are a good pairing with that CPU. I want to avoid any heavy bottleneck, and ideally get good performance for 1440p gaming.  Here are some pictures of the two cards: (attach your photos)  My questions: 	1.	Will the RX 6800 pair well with the Ryzen 7 5700X without significant bottleneck in most modern games? 	2.	Are there any major downsides to buying either of these used cards (e.g., reliability, VRM cooling, Coil whine, etc)? 	3.	Is one version (Red Devil vs Nitro+ SE) generally a better choice for long-term use?  Thank you!",Neutral
Intel,"hello. I recently built a computer with a 7900 XTX and a 9800 X 3-D. Iâ€™m getting really good frames, especially compared to the laptop I was using, but Iâ€™m really curious to see how far I can push this system. So far, Iâ€™ve been dissuaded by the bigger warning on the AMD overclock section on the app, and Iâ€™m not sure how to do it or what to do. my temps are fine both CPUNGPU are around 50Â°C under load. My power supply is like 200 W more than I need if that matters",Positive
Intel,"Hey all! I recently started venturing into Linux gaming and everywhere it says that AMD GPUs are way better than Nvidia's on that OS. That said I currently have an RTX 4060 and I love the performance since I game only on 1080p for now. I want to get around the same amount of performance or better if its possible for the price. Also, I have a Ryzen 5 5600 CPU so it would be nice to have an all AMD system.   Is there a good AMD equivalent I can get? Thanks!",Positive
Intel,"I need help! My rig was having issues mounting drives, and crashing, and hang ups, so I figured my 13900k was finally dying (as expected from Intel). So I bought a 14900k and that wouldn't boot even with the latest bios. I had an Auros Z790 elite AX motherboard with 96gb Corsair vengeance 5200mhz DDR5 ram, and RTX 4090. So I said screw it, I'm gonna rebuild my PC and switch to AMD.   So I bought a MSI x870e Tomahawk Wifi Mobo, and Ryzen 9950x3d. I assembled everything, and it posts first try. Great. So I install Windows 11 and get to configuring things, removing bloat, etc, and I start having freezes. And my screens blinking off and a message telling me there was a failure and that it needs to put the graphics into safe mode.   On top of that, I was having a lot of random hiccups and lag. I checked with LatencyMon and was having all sorts of DPC latency with my Nvidia drivers. So I uninstall the drivers with DDU and install an older driver (566.36) and cool, things seem more stable. Except they're not. Now I'm getting high latency from other drivers like storage and network. So I'm thinking okay maybe it's the ram. So I run memtest86 overnight only to find my PC shut off at some point. I figured the ram must be faulty. So I took out one stick and tested it with the other and the test completed. I'm thinking okay, ram stability could explain a lot of things, so I've found the issue. So I stay with one stick and up the DRAM voltage to 1.35 to see how it goes.   I'm still getting intermittent latency. Some programs crashing, and on top of that, my PC won't shut down now. When I press shut down, my screens turn off and it seems like it's off, but my fans and light and everything else are still running. So I have to hold the power button to shut it down.   I am suspicious of my PSU because I think it could cause some of these issues, but I've had this PSU only since 2023 and it's a Corsair HX1000i.   The only things I kept from my old build were the PSU, GPU, and ram. And considering both systems were having issues, it makes sense that maybe one of them is acting up. But I don't really know if that explains all the problems I've been having.   I've updated the Bios, I've reinstalled windows, I've tweaked power plans and bios settings, reseated hardware, and I feel like I'm just on a wild goose chase.   I'm hoping maybe someone else here has had a similar experience and can help, or if anyone has any suggestions, I'd appreciate it.",Negative
Intel,I/O Clock stuck at 1200 please help,Negative
Intel,I/O Clock stuck at 1200 please help,Negative
Intel,Already bought a asrock b650 to pair with my 9600x and I was unaware of the burnt cpu issue and I cant really return it. Am I safe to use it with the newest bios?,Neutral
Intel,"Hello,  I'm thinking of swapping from Nvidia gpu family to AMD to pair with my 7800X3D (love it) but I rely on Nvidia Broadcast a lot to remove voice echo from discord since I use a tabletop Mic and speakers (I hate wearing headsets). Broadcast completely eliminates this issue like a miracle so I'm wanting to hear if anyone else does a similar setup with success on AMD full rigs. Thanks in advance!",Positive
Intel,"https://i.redd.it/n3zqy5xj72bg1.gif  Apparently my driver stopped updating nearly 2 years ago, and I was never concerned about it. Do I need to do some ridiculous workaround here?",Negative
Intel,"Hi. HWiNFO is a very reliable monitoring tool, so unless there is a known open issue regarding sensors for your CPU SKU, I'd trust these temp readings.  I don't use a Ryzen 7 7800X3D, but the maximum operating temperature (Tjmax) for the 7800X3D is 89Â°C. If you're seeing temperatures over 100Â°C, that's likely a cooling problem that could damage your chip over time. I'd probably check my cooling system and setup if I were you. That said, another 7800X3D user might think differently, so maybe there is nothing to worry about.  Based on my experience, CPU temps over 100 Â°C usually indicate poor thermal management or inadequate cooling.",Neutral
Intel,"check if memory and/or fabric clocks spike at the same time (max values basically), if they do it is a sensor bug.",Neutral
Intel,You still can build a PC as long as you know where to get the parts you need at a price you can afford despite the crappy RAM and GPU prices.,Positive
Intel,"China stolen Samsung DRAM tech, this year we may have influx of chinese cheap RAM from CXMT to save us",Negative
Intel,"> how much of an improvement will I see with my RX 7900 XTX?  Up to 50% but this is assuming heavily CPU bottlenecked games (stuff like Battlefield 6, Factorio, Stellaris etc). Less than 15% in a standard AAA grade single player title if you play at 1440p. 0% if you play at 4k.   There's no single metric here as it really depends on a game. If you love 4X games like Stellaris I would upgrade. If you prefer Silent Hill or Alan Wake 2 I wouldn't.",Neutral
Intel,"It actually might make sense considering you are playing CPU heavy games at a relatively low res. I would also check if 5700X is available since it's pretty much the same thing as 5800X, except often a bit cheaper.   I see techspot actually tested BF6:  https://www.techspot.com/review/3043-battlefield-6-cpu-benchmark/#2025-10-15-image-png  3600 got 62 fps 1% lows and 86 averages whereas 5800X reached 80 fps 1% lows and 108 averages. So theoretically up to 30% better. Still, in both cases it's playable, fps dropping to 62 probably won't kill you.",Neutral
Intel,It can vary model to model. I watch search for the sku you purchased and if you can't find it try contacting the manufacture to see if they can tell you. EVGA used to be good about providing this info but it really depends.,Neutral
Intel,"CPU, motherboard and RAM yes. AM5 and DDR5 are the newest.  I don't like windows 11 and I will keep using windows 10 for as long as I can. Unless you absolutely need to upgrade I wouldn't bother.",Negative
Intel,"According to the review on that site it comes with 5200 MT/s RAM which is not ideal. 6000 matches the memory controller's speed so that's what I would recommend. It's not a big issue, only a small performance difference. Other than that it looks like a solid setup.",Negative
Intel,"The ram by itself is fine, though you'll probably need to manually set it to something like 6000 CL32. You can get the expo sticks, but the only thing that'd really change for you is the preprogrammed profile to allow you to get it with just a single setting.  The 7200 should run out of the box, but the CPU will switch into a different memory mode where it runs its memory controller at half clocks that lowers performance until about DDR5 8000, so that's why you'd go to the 6000 instead",Neutral
Intel,good point,Positive
Intel,"it's not constantly hitting 100 Â°C so idk what to think of it, hasn't happened today yet and I've been monitoring it so maybe it's nothing",Neutral
Intel,"Thank you for your reply!  Price difference for me between the 5700x and the 5800x is 10 euros so cost isn't something to consider in my case. I'll look up thermals to see if it makes a difference. The benchmark you linked is so helpful for my purposes, kudos!",Positive
Intel,"Thanks bud. It's the actual AMD card branded 6950xt, some people mis name it as a founders edition. I'll.try reach out to AMD today.",Neutral
Intel,"It's good that it doesn't happen constantly, but even if those readings occur occasionally or intermittently, it's generally not a good sign.  However, if it hasn't happened again today, and you're under similar or identical workloads to when you had those readings, you probably have nothing to worry about. It could just be a few inaccurate readings.  Continue to monitor your CPU temperatures and, if you notice occasional readings over TJmax again, it's worth checking your current thermal management (thermal paste, contacts, etc.) and cooling setup (fans, AIOs, and/or liquid cooling). Prevention is better than cure.",Neutral
Intel,"The Radeon RX 9060 XT offers the highest raw frame rates at 1080p, outperforming the competition by roughly 4-5% on average.  The RTX 5060 provides nearly identical performance but adds the advantage of DLSS 4 for superior upscaling and image quality.  While the Intel Arc B580 is the slowest card, its 12 GB of VRAM allows it to handle Ultra settings that cause the 8 GB cards to stutter.  Ultimately, the video recommends the 16 GB version of the RX 9060 XT as the best long-term choice for modern gaming.",Positive
Intel,Had to sell the 6600 XT and went for the 9060 XT 16GB to play at 1440p. Iâ€™m loving it,Positive
Intel,I got my 8GB 5060Ti open box excellent BestBuy for $309. It was brand new.,Positive
Intel,"Bought a 9060XT 8GB for 247e (renewed on Amazon, Black Friday stuff) and sold the temporary 4060 non-TI 8GB for 220e on marketplace. Good deal...",Positive
Intel,Personally out of the 3 I'd pick the 5060. Transformer model is but better than FSR4 at 1080p,Positive
Intel,Only compares 8GB cards from teams red and green since itâ€™s only considering <$300.,Neutral
Intel,ðŸ˜®ðŸ«³ðŸ¿,Neutral
Intel,"I found an openbox 9060 XT 16GB at Microcenter for $305 and jumped on it. Very impressed so far, especially with undervolting.       I have the Powercolor Reaper model and it is legitimately impressive that they were able to make it that small.",Positive
Intel,"I feel like the HUB guys are going too hard with their VRAM crusade. Why recommend a GPU that's slower now just because it might be faster in the future?   A slight downgrade in render resolution or texture quality is hardly even noticeable, and with looming shortages I feel like most studios are going to start optimizing for lower VRAM further reducing the long term disadvantage of 8GB GPUs.",Negative
Intel,"The real answer, buy a used 2080ti. Usable VRAM, DLSS4, it still is 250W so it can run on most PSUs.  It is the most balanced option if you can't afford a 9060XT 16GB.",Positive
Intel,"all of them are power hungry junk, where are good cards?",Negative
Intel,real hero here,Positive
Intel,"Intel is on the right path, but they need to start using 384-bit memory interfaces on 12GB cards instead of the 192-bit memory interface they used on this card.",Neutral
Intel,Does the 9060xt with fsr have higher performance than 5060 oc edition No Ti with dlss? And by how much?,Neutral
Intel,"The 5060 will crush, without less than a 40 percent difference, from dlls alone. Then add frame gen. WOW I can't believe you can get away with this.",Positive
Intel,5060 then cuz way better in AI  5% performance cut to gain 2x-3x AI speed,Positive
Intel,What processor are you using with 9060 xt?  Is it the same as you were using with 6600 xt?,Neutral
Intel,"Can you tell me how well it runs games at 1440p? Have you played some of the demanding ones like Black Myth Wukong, Stalker 2, etc? Do you play at medium? high? I assume FSR is always on.   And also what's your target FPS? Would really appreciate the feedback, because I have the same card and I'm thinking on switching to 1440p but I don't know what monitor would be good refreshrate-wise",Neutral
Intel,"Honestly? Pretty decent deal for a 8GB model, considering how the 16GB cost around 450$ these days, almost double the price.",Positive
Intel,"Well yeah, the cheapest RX 9060 XT 16GB is [$380](https://pcpartpicker.com/products/video-card/#c=596&sort=price&page=1&P=11811160064,51539607552) and the cheapest RTX 5060 TI 16GB is [$430](https://pcpartpicker.com/products/video-card/#sort=price&P=11811160064,51539607552&c=593). When you're comparing $300 GPUs, you're not going to bring up a GPU that's nearly another hundred dollar.",Neutral
Intel,"That would be a completely new phenomenon if you look at the past. Sure, some (probably indie) studio will optimize their games, but they would have done so already because they care about their customers.  Nothing will change with the current devs or tech, it's just a temporary issue that memory is that expensive. The prices will be lower in 2027, or we'll get used to it and buy more expensive stuff.",Neutral
Intel,"6 ish year old product that is out of warranty from some rando, is not exactly comparable here and definitely not a ""real answer""",Negative
Intel,"Dunno why you're being downvoted, the 2080 Ti is still very good value for the price and often has good OC headroom. Beats 5060 in most cases and you're right about 11GB being decent",Positive
Intel,The real answer is to stop being cheap and spend money on your hobbies.,Neutral
Intel,you tell us,Neutral
Intel,Why do power requirements matter?   Electricity costs pennies,Negative
Intel,So many think memory bandwidth matters more than it does. The 5060 ti has less bandwidth than the B580. Architecture matters a lot.  More bandwidth would do next to nothing for it.,Negative
Intel,AMD cards have upscaling and framegen as well...,Neutral
Intel,"Can you elaborate what do you mean by ""AI speed""?",Neutral
Intel,No. Dlss and frame gen is much less impactful in terms of performance boost at the low end and the latency is more noticeable. Itâ€™s also half the vram.,Negative
Intel,WOW 25 so far for the TRUTH. HUB and fooling now.,Positive
Intel,"Yes, same processor, 5600x",Neutral
Intel,"I only play Space Engineers, Cyberpunk 2077, Helldivers 2 and pre-2020 videogames, new games are meh for me.  All of them at high with ultra textures and a few middle settings at things i never notice mid-game at 1440p 27"" IPS monitor, 60fps (don't care for more, maybe one day i'll try 75fps).   Runs very cool and quiet, never hitting above 65Â°C on closed room 20Â°C ambient temperature, my case sounds the same as a 20"" metal fan at speed 1, which is the same white noise that helps me sleep at night, an upgrade compared to my old RX 6600 during the summer lol.  Not sure if this helped or way too late, just wanted to comment anyways.",Neutral
Intel,"yeah seriously, here b580 is noticably cheaper for example.",Negative
Intel,"Yeah, I just wanted to point it out because thereâ€™s people like me to whom prices in dollars means nothing (or who donâ€™t read the title) and then waste time watching an irrelevant video (though I skipped to the conclusion so not that much time).ðŸ™‚",Negative
Intel,"Point being? If a cap blows because it's old any repair shop can fix it, If it's a fan dying you can fix that yourself.  On the other side there's not much the warranty can do for running out of VRAM.",Negative
Intel,"In this economy? It doesn't make any sense to not keep perfectly usable hardware that does the job just fine out of a landfill.   A 2080ti or a 3070 or AMD equal is more than enough performance for most people. Easily, and is way better bang for your buck.",Neutral
Intel,"In a time of global economic uncertainty, it's a horrendous time to overspend on hobbies.",Negative
Intel,"heat, noise, size, messy cables",Negative
Intel,"Correct, but they do not have commercial dlss support. How many games do you not have the ability and ww do?   Thanks for the dowmvotes nvidia. Amd brainwashed.   Just to let you know: you have all been played. Look closer.",Negative
Intel,"They're seemingly referring to the speed of running LLMs locally using that GPU, unless I'm also out of the loop. A good sub to look into that stuff would be /r/LocalLLM   I wouldn't recommend doing that with a 5060 but the 16gb version must be the best choice in that price range and would handle the very small models easily and the small ones with a little slowness.",Neutral
Intel,"News flash: We're always in ""this economy"". I know someone who works at a fucking McDonalds, has a kid, and spends more money on his hobbies than you do.",Negative
Intel,nothing global about it,Neutral
Intel,"So you prefer low power for lower heat and smaller size.   I'm not space conscious, so those things don't matter.   What's with messy cables? The PC sits under the table, so it also doesn't matter how ugly it is.",Negative
Intel,"Well actually people have been modding games to put FSR where neither AMD or NVIDIA added official support.   Pretty much every game had amd nvidia and even intel upscaling these days.   In fact, when i still had my 3080ti, i was able to use AMDâ€™s framegen in many games (cyberpunk, dying light, talos principle) because NVIDIA didnt provide any option for 3000 series.   I still bought nvidia because amd doesnt offer any cards at 5080 level, so no brainwashing here. Youâ€™re completely uneducated blinded by consumerism",Neutral
Intel,"Your comment has been removed, likely because it contains trollish, political, rude or uncivil language, such as insults, racist or other derogatory remarks.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",Negative
Intel,They sound irresponsible.,Negative
Intel,"If you spend more on your hobbies than the things you actually need, you might be financially irresponsible",Negative
Intel,"the unhinged extra power cables attached to the card itself, it makes everything harder to handle  and heat isn't just about the size of the case, it's noise and comfort of the room  and no, AC doesn't solve that as it's another source of noise that is even worse than the PC itself, only to be used when the weather is too bad to live otherwise",Negative
Intel,"Oh yeah? And who do you think had went through hundreds of accounts taking about that mod?   Came out DEC 22 2023 I remember the day I went from 22fps in Alan wake 2 to 50 (3070). I posted in this site non stop ban after ban just to try and get you this information. Go on the forums you will pick me out if you look back.   I, in all seriousness, would not be surprised if you know about that mod from ME.   Therefore, I am not blinded. I simply understand that an entire company propped up by manipulation on social media (and GPU) should not exist, and a real competitor would be in their place. There I have just demonstrated that not only am I not blinded, it might be you. Good on you for knowing about that mod (serious).   I will tell you another secret, maybe not meant for you. If you don't mind using dlss and mfg? 5060ti 16gb all day for 1440p or lower. Not only is it hundreds of fps, it has valuable vram on it that will see the card rise in price since it's discontinued.   Hows that for an uneducated prediction?",Neutral
Intel,Gotcha.  What's your preferred card?,Neutral
Intel,from this generation that'd be RTX Pro 4000 Blackwell generation SFF with replaced cooler  personally I own a passive A2000 SFF that replaced my modded 1650 (KalmX was released too late),Neutral
Intel,"Hopefully I am wrong but there is no aftermarket cooler for the RTX Pro 4000 SFF, right ?  https://n3rdware.com/gpu-coolers",Neutral
Intel,"unfortunately no, nothing ready to use that I know of  if you have access to measuring equipment machining a shim isn't even that expensive, haven't seen any publicly available projects for it yet",Negative
Intel,"Hmm that sounds tricky.  Iâ€™m thinking about getting PCI express extensor and a GPU holder to be able to use it with my MS-A2, keeping the GPU externally til the n3rdware cooler is available.",Neutral
Intel,"From r/radeon   * Ray Caching: Only available in Warhammer40K today, more games next year. * Ray Reconstruction: Only available in Black Ops 7 today with more games next year. * AI Frame Gen: Available in Black Ops 7 today with 40 games by end of 2025.",Neutral
Intel,It's almost 2026 and AMD keeps reinstalling the AMD Install Manager that I do not want and have to keep manually uninstalling. Stop this AMD.,Negative
Intel,What is fsr redstone? and which games use it?,Neutral
Intel,I just tested the release on four machines (76X&78XT/78X3D&79XTX/97X&9070XT/75F&76XT). Every system still suffers from crashing drivers when hardware-accelerated apps are used (Chrome/Discord/etc.).  Please fix. :),Negative
Intel,"I got a notification for the update in AMD Adrenalin Edition, but it does not appear in the actual install manager lol",Neutral
Intel,so can I open adrenalin on this one with a rdna 2 igpu and rdna3 gpu or is it still broken like the last version,Neutral
Intel,<--- Int8 rdna2 enjoyer,Neutral
Intel,did they fix enhanced sync and noise suppression yet,Neutral
Intel,Did this driver fix purple visual glitches with the RX 7700 XT? It's a known bug that appeared after the driver 25.4.1,Neutral
Intel,"The ignorance by amd of Rx 7000 users is astounding tbh, but this is 2025 AMD not prior AMD where they would try to appease a larger user base.  It's going to make me rethink my loyalty for future gfx purchases",Negative
Intel,So we cant test path tracing performance yet on Cyberpunk? Lol,Neutral
Intel,"This is a very underwhelming update for RDNA 4 users I get that this technology needs to mature, but they should already be at a point where the implementation is across more wide array of games. My fallen RDNA 2 and RDNA 3 brothers will be remembered. The only reason AMD gpus are still relevant rn is price, nvidia tax is crazy. GG",Negative
Intel,"Thanks for nothing again, AMD.  Signed, 7900 XTX user.",Negative
Intel,So is there any point to installing this if I'm on RDNA2 and don't have any of the issues that they fixed?,Negative
Intel,This is the worst driver amd made 9060xt for me. 2 games instantly crashes. Indiana jones and silent hill 2. With this driver if you enable ray tracing game hangs and give error.i already report bugs in 25.12.1 and same with 25.11.1 and amd does nothing. every ray tracing titles works ok with 25.10.1 driver and this is bad. amd does not listen users anymore. anyone has any crashes happen like me?thanks...,Negative
Intel,AMD Software still crashes randomly,Negative
Intel,Nothing on Oblivion Remastered crashing? Intermittent application crash or driver timeout on 9000 series when playing Battlefield 6?,Negative
Intel,#AmdNeverAgain Give Fsr4 on rdna3,Negative
Intel,Pretty dissapointing ngl,Negative
Intel,New update new problems,Negative
Intel,"The adrenalin app just auto updated my 9070xt mid game, now my screen is black with no signal output to my monitor but my music is still playing lol. I waited for 10mins then I had to hard restart my computer for it to say the update failed",Negative
Intel,Should I get the RTX 5070 ti or 5080 at msrp? I am currently selling my XTX after radio silent news about FSR 4 int 8 on it.,Neutral
Intel,Everything is RDNA 4 exclusive? awesome /s  RIP finewine.,Positive
Intel,Please add the broken noise suppression to â€œKnown Issuesâ€.,Neutral
Intel,"If  this driver update keeps crashing my gpu im not leaving 25.9.2 for a while, im also starting to think about selling my gpu and get nvidea, and really black ops 7 why not a real game like cyberpunk i dont want to waste 70 euro for fifa with guns",Negative
Intel,"Can confirm on my 9060XT that Silent Hill 2 is still crashing and Avatar Frontiers of Pandora currently has a bug when FSR4 is enabled where the entire screen starts flashing like a strobe light, shadowy areas seem to trigger it. This is with both games fully patched & up to date.",Negative
Intel,"Let me see - all the new ""Features"" will be available for Cyberpunk 2077 in at least 1 year time and ONLY with RDNA4 ??",Neutral
Intel,AMD NoiseSuppresion still broken. Since September!,Negative
Intel,"Are pink artifacts fixed on RX 7700 xt, anyone ? It was bugged in 25.11.1 driver last month.",Negative
Intel,Whereâ€˜s support for 7000 series? Wtf is this dead meat,Negative
Intel,Iâ€™m on a 6000 card is there literally no reason for me to download this,Negative
Intel,"all i want is to be able to capture clips in my games but for whatever reason amd either doesnt understand im in the game, recognizes the game wrong (battlefield 6 shows as elder scrolls online which i dont even have).",Negative
Intel,It's december and still no FSR4 for vulkan.,Negative
Intel,25.11.1 was dog water driver timeout city for me I'm just gonna assume this new one will also be the same.,Neutral
Intel,Is this worth updating to from 25.11.1  Is it more stable?,Neutral
Intel,"I had to downgrade to 25.9.1 to have some level of stability, can somebody confirm that the new driver is safe to upgrade to without it messing stuff up?",Neutral
Intel,Still no fsr 4 support for rdna3 ðŸ™„,Negative
Intel,"Guys calm down. RDNA3 being moved to maintenance mode is part of their new strategy, no longer ""Fine Wine"", the new approach is Stale Ale. That way their products remain DOA after launch and people won't keep them very long.",Neutral
Intel,idk why I find it so funny that a specific Roblox game got called out in the patch notes,Negative
Intel,Did they fixed the amd noise supression not turning on?,Neutral
Intel,"Anyone know why Cronos: The New Dawn has been showing [""FSR 4""](https://i.ibb.co/nqW2VMng/Cronos-The-New-Dawn-2025-12-04-02-28.png) for me on a 7900 XT for a few weeks? At first it was 3.1.  I know it can be modded in but this is on a new Windows 11 install and I haven't done any modding.",Neutral
Intel,"Looks like new chipset drivers, too.",Positive
Intel,"I thought the application freeze fix might have stopped monster hunter wilds from crashing on me but nope still does it (DXGI_ERROR_DEVICE_REMOVED,)",Negative
Intel,/u/amd_vik are you aware of assetq corsa evo vr not working on AMD cards since 25.9.1 ? It displays the left and right eyes out of alignment and therefore fails to show a cohesive single image.,Negative
Intel,so no fsr4 support on Vulcan still? this is getting ridiculous,Negative
Intel,>Intermittent system crashes may be observed while using some high-bandwidth HDMI 2.1 displays during display standby.Â   Thank fucking god.,Negative
Intel,Still experiencing 100% gpu usage almost constantly as soon as you boot up BF6 on newer drivers after 25.10.1 and higher temps in general  I'm locking my FPS to 144 but the older drivers is showing better overall temps and less gpu usage for me ðŸ¤”  [https://imgur.com/a/ctbMCx7](https://imgur.com/a/ctbMCx7),Negative
Intel,BF6 crashing after a few minutes in game with that driver on a 6800xt,Negative
Intel,"ever since 25.9.2 still same bug is present even now and now it causes even more problems because ML based FSR and FG fails when it happens: Adrenalin app just shuts down randomly even when idle, no errors, no driver timeout, no dx12 trimeout, just adrenalin itself gets shut down in random times. why wont you guys do something about it finally? Seriously its been so long now... im on 9070XT Steel Legend Dark Edition from ASRock, 80% of your users or more report the same issue FIX IT for the love of GOD. I tried everything hoping its on my side but windows reinstall, DDU and AMD cleanup app and fresh driver install nothing helped its still here",Negative
Intel,"Both 25.12.1 and 25.11.1 drivers have the same bug on RX 9060 XT. When my screen goes blank and later i wake up screen, i have two mouse cursors on the screen, until i launch some app and then will second, fake cursor disappear.",Negative
Intel,"u/AMD_Vik Hey there! Just want to let you know that I've seen a lot of people have problems lately (including myself) with Direct-to-Display/Directmode implementations for DisplayPort/HDMI wired VR Headsets. DirectMode cannot enable reliably even on SteamVR native HMDs, and the only way to get them running right now is by installing a older driver version, enabling directmode there, and then updating to a newer version with the directmode already set -> so directmode itself still works fine, but there seem to be problems toggling into this. I also saw this happening with other VR compositors like PimaxPlay though radeon users are generally not as common there.  Happens with every driver released after and including 25.4.1 on my machine, and driver older than 25.3.1 can toggle into Directmode just fine. It is still broken as of 25.12.1 and 26.1.1  at first I thought this was a somewhat individual issue but as I've looked into it I saw more and more people have that problem with RDNA3 and RDNA4 GPUs across the board for basically any VR headset that uses Directmode.  I remember you mentioning on the AMD forums once that you want to be hit up about VR related issues - but really I didn't know how else I would reach out to you.",Negative
Intel,I hope this fixes the many crashes I've had since the last update...,Negative
Intel,"Still enjoying the piss out of the 7900XTX on 25.9.2. It chews through everything I throw at it at the settings I choose, don't care about new driver releases unless a new game I want to play doesn't play well on whatever driver I currently have installed.",Negative
Intel,"Even tho I have a 9070xt this is still so underwhelmingâ€¦ We waited 6 months and got basically nothing yet. Sorry for all rdna2, 3 users.  Fun fact: Its been years now that the adrenaline software cant be opened, the only fix ist to press win+p and select only main monitor. Than start it, than swap monitor profile againâ€¦   Definetly buying nvidia next time, not supporting this big company anymore, which is behind in every aspect. Image you just want to play alan wake 2 (looks beautiful).",Negative
Intel,"ass. no support for rdna2/3, no new features for rdna2/3, rdna4 have only one game that support all of that, redstone framegen almost identical to 3.1 framegen, frame pacing still there.",Negative
Intel,hardware unboxed tested it and frame facing is broken when amd frame gen is on sadly,Negative
Intel,So the HDMI crashing issues should be fixed in this version yes?,Neutral
Intel,Any news on fixing the gpu vram leak issue on bf6? Sorry Iâ€™m lazing not reading the patch notes,Negative
Intel,25.12.1 does not even install on my Minipc (780M) + 6650XT eGPU Setup.   I thought I might fix 25.11.X not opening in an eGPU Setup.   Guess I will be running 25.9.2 for another few Months.  God why something always break? I thought it would be better going all AMD for the eGPU setup.,Negative
Intel,"Yeah I'll still be with 25.9.1 until the texture flickering is fixed in BF6, also instant replay just didn't work in 25.11.1 for me.",Negative
Intel,Will this help Warzone not look so blurry on 7900xt? Game is unplayable,Negative
Intel,So there seem to be two links - going through support>picking GPU(9070XT in this case) downloads the 25.21.1 win 11-b.exe file meanwhile going from this release note article it downloads the win11-c.exe . Any difference?,Neutral
Intel,"im using 6800xt the driver page has the win11-a version and article have win11-c version. which one should i choose i really dont know and this ""different builds"" confusing a lot of people",Neutral
Intel,"Genuine question, why all the hype and rush to release this today when it has just two games to showcase the benefits?",Neutral
Intel,Jesus how long has that Cyberpunk Pathtracing crash been in the known issues. It feels like it's been more then half a year.,Negative
Intel,Installed with no issues,Positive
Intel,"I canâ€™t play Warzone because I canâ€™t update my bios, there doesnâ€™t seem to be a recent bios update available for my Acer Nitro 5, using Adrenaline. Anyone know if this will help?",Negative
Intel,Doesn't look like they fixed the bug with Enhanced Sync not working properly with Freesync.,Negative
Intel,Any fix planned for 9070 users who cant enable Hardware Lumen on Oblivion Remastered? Game crashes as soon as we turn on the option.,Negative
Intel,Still no fix for Battlefield 6 for those with AMD 6800M GPU. I swear my next setup is going away from AMD if this is not resolved anytime soon.,Negative
Intel,u/AMD_Vik      In 2022 AMD made changes to OpenGL Driver. So since 2022 the extension gl\_ati\_fragment\_shader is missing in the driver. It cause problems in older games like Call of Duty 1 from year 2003. Stutter on some maps and broken water rendering because the games can't use the extension anymore.     Our Community is waiting since 3 years for a fix.,Negative
Intel,in black ops 7 only 25.9.2 driver work better even new 25.12.1 much worse fps drops,Negative
Intel,Very unstable for me (7900XTX). Driver keeps crashing even when I'm just watching videos. Reverting to 25.11.1,Negative
Intel,i just had to roll back to 25.9.2 because 25.12.1 kept crashing my system with poe2   even GGG straight up said don't use 25.10-25.12,Negative
Intel,"After observing you guys for a few days xD, 25.12.1 was installed along with new chipset driver on my system.  To my surprise, unlike previous 25.11.1, Adrenalin interface now runs properly with igpu enabled.  I need to test it out with real games, but for now, I've dodged instant roll back.  FYI, If you're using two or more GPUs, including igpu, on a single system with muti-monitor. Download the C package(1.65GB one including rdna1&2+3&4).",Positive
Intel,"NoUnfortunately, they don't work (( Random crashes remained + In some games, the inability to use frame generation through drivers was added (( Sad ( R5 3600 32gb ram Rx 7700 xt ) Rolled back to 25.9.1 everything works with it",Negative
Intel,"I had a very weird issue:     My PC would just crash when i did an Windows Defender Scan (only Full Scan, it worked fine with QuickScan or other programms like Malewarebytes) like the power was cut. I did a number of things even rollback the chipset driver but that didn't help. Then i rolled back to 25.9.1 + the newest chipset driver and everything worked fine again.   In case somebody had a similiar issue",Negative
Intel,"Anyone having problem with AMD overlay with this update? Somehow not showing at any game even if enabled, if I click to different monitor, it shows up. But when I click back to the game it disappear again.",Negative
Intel,AMD Wattman settings don't apply for the first time they're set. They have to be changed and applied to a different setting and then to the desired one back and forth to get them to work. I use wattman to set my custom fan curve and it's been glitchy since 25.11.1.,Negative
Intel,Should I download the new driver version if I have 6800XT? There is nothing in the patch notes about this series... And if yes - why?,Neutral
Intel,"Error code 182 for my AMD Radeonâ„¢ 780M integrated GPU on my Ryzen 7 8854HS CPU.  All other driver updates before 25.12.1 worked fine on my Lenovo Legion Slim 5 Gen 9, but this one says my GPU is incompatible, even though AMD's driver download page is providing [this download link](https://drivers.amd.com/drivers/whql-amd-software-adrenalin-edition-25.12.1-win11-b.exe) to the installer:  https://www.amd.com/en/support/downloads/drivers.html/processors/ryzen/ryzen-8000-series/amd-ryzen-7-8845hs.html",Negative
Intel,7000 Series web browser glitch? and sound glitch? huh,Negative
Intel,"So I upgraded on a 6800xt and lost a lot of features like video recording, screenshotting, custom game profiles, and hotkeys. Is that intended?  Crazy to be missing hardware supported features",Negative
Intel,"AMD sucks: FSR 4 is locked to RDNA 4, while NVIDIAâ€™s DLSS 4.5 runs even on RTX 20-series GPUs. My next GPU will be NVIDIA only, and I advise everyone against buying AMD. Itâ€™s a greedy company with no respect for customers â€” you buy a graphics card last year, and the next year itâ€™s already outdated",Negative
Intel,"Is it safe to update, 25.9.1 is stable for my 9070XT and causes zero crashes with the timeout bullshit from clock speeds going to 3300+ MHz",Neutral
Intel,What does fsr Redstone means ?,Neutral
Intel,"Is this driver more stable than 25.11.1 it was causing driver time outs and i even got a blue screen. I rolled back to 25.9,2 and now im scared to update to this one lol",Negative
Intel,These comments are all over the place is it better than 25.11.1 or not? ðŸ˜‚ðŸ˜‚,Negative
Intel,"So in short, still no support for 7000/6000 series, yipee",Negative
Intel,"Idk what happened but after this update my game crashed and then my PC crashed and when I turned it back on AMD Adrenaline disappeared from my PC, completely gone. What did you do lol.",Negative
Intel,For Sale: 7900 XTX - $50 OBO  I know these are no longer desirable due to being left in the dust by AMD after only a few months of real support but hopefully it will be at least a good paper weight for someone.,Neutral
Intel,So now driver frame gen is gone? Unless the game specifically supports it? And the overlay as well? Both are completely gone now after the update...,Negative
Intel,What about the fixes for the 7900xtx crashing all the time?,Negative
Intel,"Â«#AmdNeverAgainâ€ Whereâ€™s the Christmas gift in the form of FSR 4 for RDNA 3? In the new 2026 year, it might be time to think about switching to Nvidia.",Neutral
Intel,"Toujours pas de FSR4 pour les sÃ©ries 7000 ? Câ€™est mort. Pour ma part, je nâ€™achÃ¨terai plus de cartes AMD. Si Nvidia continue Ã  proposer son DLSS pour les anciennes cartes, alors mon choix est fait.",Neutral
Intel,"Hey OP â€” /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible to others**. This is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.  Your post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).  **Posts regarding purchase advice, PC build questions or technical support will not be approved.** If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the [Q4 2025, PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1nvf7bw/pc_build_questions_purchase_advice_and_technical/).   *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",Neutral
Intel,"Downloads ""whql-amd-software-adrenalin-edition-25.12.1-win11-b.exe"" for 9070XT, ""whql-amd-software-adrenalin-edition-25.12.1-win11-a.exe"" for 5700 XT  What does it mean?",Neutral
Intel,It took a while for DLSS 4 to get implemented in a good way on 40 series cards too but a version made it there. Give it time. Now if they can just start prodding developers to incorporate that as well itâ€™ll be worth it. Not enough games yet but hereâ€™s hoping!,Positive
Intel,Any update the in fact that and adrenaline software is not working when second monitor is connected? Especially using iGPU for second monitor ?,Negative
Intel,Omg I think they fixed the LG oled tv reboot bug,Positive
Intel,Should i install it directly or should I use AMD cleanup utility first?,Neutral
Intel,some one have problem with instaling?,Neutral
Intel,Does this fix the driver timeouts that were happening with Edge? I had to revert the November update because of that problem,Negative
Intel,Any fix or still need iGPU disabled for 7000 and 9000 cards?,Neutral
Intel,The update is still not showing up in install manager,Negative
Intel,Honestly this software was the bane of my card for the longest time. Not having it anymore stopped so many weird bugs and crashes.,Negative
Intel,Does AMD's Instant Replay record still bug out?,Negative
Intel,Anyone tried the new fsr redstone yet? I am hoping for a big improvement over the old fsr,Positive
Intel,do you guys remove the old drivers before you install new ones? or just install ontop,Neutral
Intel,The path tracing crash STILL on Cyberpunk is absolutely wild to me. Finally AMD has a card capable of playable raytracing but we can't use it on the 'Crysis' of modern times to even test it out.,Negative
Intel,Adrenalin doesn't show this update for me yet lol,Negative
Intel,"> Intermittent system crashes may be observed while using some high-bandwidth HDMI 2.1 displays during display standby.   Glad for this, it was annoying that we were stuck in 25.9.2",Negative
Intel,Are the issues with SecondLife fixed? Last driver that didn't break textures was 25.9.1,Neutral
Intel,9060 non XT 8GB can do the math 7900 XTX Nintendont,Neutral
Intel,"Iâ€™m at work, so I cannot check for myself: does this fix the constant crashing in Oblivion when hardware lumen is turned on?",Negative
Intel,Has anyone tested Marvel Rivals on 25.12.1 version of the driver? The only stable driver that works without crashing on that game is the 25.8.1 version.,Neutral
Intel,Adrenalin Panel not showing bug still presentâ€¦ :-((((,Negative
Intel,Am I the only one who doesn't have the new option in the drivers for frame generation with a 9070 XT?  https://i.redd.it/7r86hslx3g6g1.gif,Negative
Intel,"why are there 2 versions, b and c, 1.65Gb and 991Mb, release notes and through the support page, and is it stable or shall i just keep 25.8.1 as any other seems to crash call of duty, regular, other games seem fine,  ryzen 9 7950x3d/rx7900xtx",Negative
Intel,Did it fix the god of war 2018 checkered shadows?,Neutral
Intel,"I spent all this time with 25.9.2 on my 9060xt because the following ones were disgusting to me, I will give this new update a chance and let's hope everything improves a little!!",Negative
Intel,Arc raiders crashes are fixed or not?,Neutral
Intel,"Makes my 9070 XT to constant run on 100% load in bf6 no matter if i play or sit in the menu. Cause device hung, graphic glitches and high temps.   Same with all drivers above 25.9.   25.9.1 works flawless with no errors and the load varies depending on the scenery as it should.",Negative
Intel,Noticing in Hogwarts Legacy with the new FSR and FG enabled over a period of like 30 seconds my 9070XT will go from \~250W used and 200 FPS and then drop down to say 120W used and 90 FPS and then after a short period go back up again. With FG disable it stays consistent 140 FPS-ish,Neutral
Intel,"FYI for ""Driver Only"" guys, 25.12.1 still have an issue to install this option.  l've open ticket to support team for last 2 versions. but I can't follow their request to observe the issue.  Don't know how long to keep using extracted file method. lol  Will see how 25.12.1 ""driver only"" perform.",Negative
Intel,oh nice! they fixed the FSR4 Quality Presets artifact issue,Positive
Intel,"When AMD finished Orange, Yellow Green, PurpleStone, can we unlock FSR Infinity?",Neutral
Intel,"Is it worth updating to this latest driver? I am not planning to use frame gen, is the image quality better or are there any fps improvements in games?",Neutral
Intel,"Updated to 25.12.1 now, before I was on 25.8.1, have a Rx 6800 XT and a Ryzen 7 7700X. Also updated my Chipset-Driver today. Haven't testet much yet, played now for like 1 hour Space Marines 2, watched some Youtube vids since I updated. So far looks ok. Only thing that worried me first was that I found in my Reliability History, 2 critical entries of LiveKernelEvents of code 1a8. But these were written down by Windows on the time, while I was updating my driver. We will see, if anything happens I will keep you updated.",Neutral
Intel,"Despite the device ID-based driver update blocking set in August, it has worked until now. The windows tried to install some driver on the 6700XT just now, and unfortunately, it also replaced the software itself somehow. threw an error message too.  Manual update would not go through unless i removed the driver update block.   What a sad situation.",Negative
Intel,"Anyone else has problems with CS2/Fortnite? Started happening after i updated drivers to 25.11 My whole PC would randomly freeze for like a minute with the ""AMD software detected that a driver timeout has occurred"" error. Once the PC unfreezes i must kill the game from task manager.",Negative
Intel,Does it fix the arc raiders dxgi crash of the previous driver?,Neutral
Intel,"How do I downgrade from this driver?   Iâ€™ve tried four different older drivers and all of them give me error 182 â€“ GPU is not supported (RX 9070 XT) during install.   Iâ€™ve already used DDU and the AMD Cleanup Utility, but the only driver I can install successfully is 25.12.1.",Negative
Intel,pc started to crash 7900xtx... reverted to 25.11.1,Negative
Intel,Hi me and other people I know. Also forums and Facebook pages . Have had an issue with the frame gen after 25.9.2 . When they released new features we have all had issues where its drops fps and is completely unplayable. Has this been fixed in 25.12.1 I have 7900 xtx 7800x3d. Friend has 9070xt 9800x3d Both have issues. And im on windows 10 he's on windows 11. I used ddu and tried all settings on frame gen and other settings to fix it. Not to mention the drivers where stutters and lower fps without frame gen. Thanks,Negative
Intel,"When I enable V-Sync in the game, I experience lag; it only runs smoothly with V-Sync enabled when I also activate the performance overlay. This problem has existed since driver version 25.11.1.",Negative
Intel,"I have a second card from amd. And both cards have driver problems. Now I have an rx 9070 xt oc. I don't do any undervolting. Everything is at factory settings including the bios. I had 4 driver failures in 7 hours. What good is FSR if the driver doesn't work? It would be good if you finally solved this problem. I can stand it for a while, but if it continues like this, I'm leaving AMD.",Negative
Intel,"Wish they would acknowledge the bug where turning on GPU scaling and integer scaling adds more input delay, so for example the mouse movement will feel sluggish.  Been having this issue for 3 months now since nya bought a a 9070 XT",Negative
Intel,"On the RX 7600S graphics card, Adrenalin does not launch at all, and during installation it removed the driver PCIVEN_1022&DEV_15E2&SUBSYS_15131043&REV_60.",Negative
Intel,"How are those with a Cezanne CPU supposed to install this?  Selecting the 5750G from the drivers download page offers 25.21.1, yet none of the 3 variants of the installer support it.  * whql-amd-software-adrenalin-edition-25.12.1-win11-a.exe (Vega, supposedly?) - nope * whql-amd-software-adrenalin-edition-25.12.1-win11-b.exe - nope * whql-amd-software-adrenalin-edition-25.12.1-win11-c.exe (combined? ""Systems with RDNA series graphics products"") - nope  Each of them return Error 182.  Even the minimal web installer, amd-software-adrenalin-edition-25.12.1-minimalsetup-251207_web.exe, only offers 25.8.1.  VEN_1002&DEV_1638 is nowhere to be found in the .inf for any of the 25.21.1 variants.",Negative
Intel,I'm still hesistant to upgrade on this driver until they resolve these driver timeouts hell I'm even on 25.9.1 still experiences time to time TDR's.,Negative
Intel,"Is it worth for my 9060XT to go from 25.11 to the latest, Im having some problems where ghost of tsushima crashes.",Negative
Intel,Driver is making valorant run like crap for me idk why .,Negative
Intel,im using an rx6600 and up until today i was fine avg 200fps on r6 today the game says its at 22 usaeg when it avgs 1-4 and now it has major fps drops/tears,Negative
Intel,This driver constantly crashes call of duty for me. Whatever windows update installs(which seems to be 25.10. something) is the most stable there is. 9070XT.,Negative
Intel,Anyone see if this fixes the issue of the graphics sliders not working at all and being stuck?,Negative
Intel,Still crashes. They will never fix it. Just buy nvidia or intel.,Negative
Intel,"u/AMD_Vik It says ""Intermittent application freeze when using the in-game Radeonâ„¢ Overlay."" in fixed issues but I've actually had my whole system lock up because of what seemed to be adrenalin having issues with the performance overlay....  I noticed one thing that pointed towards the overlay specifically: I was going through Adrenalin and when I was on the recording tab I switched to performance; it seemed like Adrenalin froze so I clicked Smart Tech. to see if it would respond.  Initially it didn't, before eventually swapping to the smart technology screen. I then went back to the record tab and tried again: same results.  That's about all I've got for specific steps. I closed Adrenalin and went back to doing whatever and I noticed my fans turned on and like two minutes later when I went to close my browser my cursor stopped before I got to the corner of my screen and I needed to hard power down my system.  Not sure if this is at all related to that issue. But i had it happen on the last driver as well, and came here trying to see if there was a known issue...",Negative
Intel,Any chance to support VR HP reverb G2 (WMR) 60hz mode with Oasis driver? I'm locked in win10.,Neutral
Intel,"Indiana Jones crashing every 5 minutes, cant complete the game. Its just freezes and the PC barely responsive with these Timeout messages.  9070 with 5800x3d",Negative
Intel,"czeÅ›Ä‡, jest sen instalacji jak uÅ¼ywam 7900xtx i nie uÅ¼ywam Å¼adnych wspomagaczy ?",Neutral
Intel,"Hi devs!   I would like to bring again to your attenction this thread: [AMD Software: Adrenalin Edition 25.9.2 Release Notes : r/Amd](https://www.reddit.com/r/Amd/comments/1nk9qgo/comment/nfb2o2j/)  Is there any chance you can bring us 60Hz mode for ex WMR drivers, now working directly in steamVR with Oasis Drivers?",Neutral
Intel,So uh... I just had an application crash on Blue Gate while playing Arc Raiders... I don't think it is fixed...    9070xt with a 7800x3D,Negative
Intel,FSR Redstone support? Will my minecraft machine run faster now?,Neutral
Intel,"Ray Caching in 40K?  Not sure how they got this to work on the tabletop in real life but sounds awesome  In all seriousness there are a large number of games in the Warhammer 40K universe, any chance they are saying which one?  Space Marine 2 Darktide Battlesector   Etc",Positive
Intel,"so pretty much nothing for today, shrug...",Negative
Intel,Is there a partial list of the 40 games with the new frame gen? Is it something different from the fg we already have?,Neutral
Intel,they wont,Neutral
Intel,"It's so annoying.  I would keep it if it didn't constantly pop up trying to get me to install ""AMD Chat"" and ""AMD Privacy View"".  I don't want your shovelware AMD, take a hint.",Negative
Intel,"There should be an option during install to exclude it, it can't be that hard to do. Same as you, u/MihawkBeatsRoger , I also uninstall it afterwards.       Notifying u/AMD_Vik",Neutral
Intel,"This.   Why I took it out are my own reasons and quite frankly, irrelevant. It's my PC and I don't want it. So please AMD, listen to me and keep it off.",Negative
Intel,"Focus on serious matters, this is a joke. If you do not want it feel free to install the driver only version, and be happy u have that choice. If you want the full features of adrenalin, well install manager is one of them.",Negative
Intel,It's a rebranding of the entire FSR ecosystem. What's new today is machine learning enhanced frame generation for RDNA4 cards. You can enable it in the driver for any game with FSR 3.1.4 or newer.,Positive
Intel,It adds denoising for Path tracing. In theory it should look way better now,Positive
Intel,All the games that don't use bluestone,Neutral
Intel,"Only one , the new call of duty ATM. So if you enjoy shitty games , have at it",Negative
Intel,9070xt i see brave or discord freezing and lagging when watching a YouTube video still. I dont understand how hardware acceleration bug hasn't been fixed yet. Wtf are they doing.,Negative
Intel,Yup same here. Had to roll back to October to fix again,Negative
Intel,25.9.1 works on my 9070 XT. Everything after that is a mess for me,Negative
Intel,Tagging u/AMD_Vik  so they are aware of the issues.       I encountered the same problems on my 6800xt. Figma on chrome is causing random BOSD. The system will just restart without notice. Every single web app seems unstable on my system and memory usage is all over the place. Rolling back to 25.9.1 doesn't fix everything but it eliminates 70% of the issues..,Negative
Intel,Oh well. :/  Funny thing is I rebooted my PC again for a Windows update. The first thing that greeted me after opening a web browser was the driver giving up the ghost.  On 25.11.1.,Neutral
Intel,Ive been wondering what this seemingly random crashing has been. Thanks for this comment!,Neutral
Intel,"9800x3d, 6950xt, no issue with either chrome or discord or firefox with hardware accelerated set",Neutral
Intel,"Me too.  Installed 25.12.1, whenever I use YouTube in Full Screen, the whole system freezes, while the sound is still audible, then I have to hard-restart my PC. Happened three times, decided to downgrade to 25.11.1 again.",Negative
Intel,"Same, and I'm still on the October drivers",Neutral
Intel,You can download it from the website. The app release notification always lags behind the site. This is nothing new.,Negative
Intel,"This should be fixed, I'm not sure why it was omitted from the release notes",Negative
Intel,<--- inte 8 rdna3 enjoyer,Neutral
Intel,"How do I set this up, can't find any info",Neutral
Intel,"I can't speak on enhanced sync, but noise suppression is still busted and not working =/",Negative
Intel,"I'm piggybacking, because I need that info too",Neutral
Intel,"I can't seem to keep framerates under control in a lot of games, generally smaller simpler games, with the new 9070xt. Enhanced sync, vsync, chill, boost, whatever I do I'm still wondering why my pc is at 100% gpu, 600fps, and 300w power draw playing something like minecraft or geometry dash.  Even with a 144hz display. I'd be happy locked at 60 even.",Negative
Intel,"Been using it for a few hours with the 7900XTX, so far so good.   Hopefully it's 100% fixed.",Positive
Intel,I hope they fixed it. I will test it now,Positive
Intel,"Did the typical test that I usually do and it didn't show up for me and I'm on the RX 7700XT as well. So hopefully, it's fixed.",Neutral
Intel,"AMD stopped giving a shit about it's fans once the company was saved and they started raking in the money. The change in tone was clear as day. That said, I'll still buy their GPUs because I hate Nvidia far more and I don't see that changing.",Negative
Intel,"yeah my next one will be Nvidia, better features, better performance espacialy with RT/PT   And apperently longer support... and AMD cards in a simmilar performacne bracket don't even cost THAT much less sooo.... jeah I am mad aswell",Negative
Intel,"I agree. AMD has shown poor support for 7000 series owners. If there was a FSR4 int8 leak, AMD should officially release FSR4 for 7000 series owners.  I bought my 7800xt only 2 years ago before RDNA4 cards came out.  Nvidia provides DLSS4 upscaling to their older generations like rtx3000 series",Negative
Intel,"Your system is almost exactly like mine, did you also have crashing problems while having the Xbox Gamebar DVR feature turned on? I would have constant driver timeouts until I turned it off.",Negative
Intel,"If you're referring to the app crashes with RTPT reflections enabled, we're working with CDPR on a fix",Neutral
Intel,Signed /another 7900xtx user,Neutral
Intel,"I came over from NVDA last March, bought a 7900xtx, RMAd it a few weeks ago due to pink/purple pixelation that would randomly happen. Now it's non stop driver timeouts and random performance issues every time I boot my PC or games. I am never buying another AMD card. I'd rather get ripped off by NVDA and not have constant headaches.",Negative
Intel,"Which driver are you currently on? I'm just curious; personally, I'm on 25.9.2, and surprisingly, I have 0 problems, unlike with previous versions. Should I try 25.12.1?",Positive
Intel,"Nope. Generally if the driver does not massively increases performance in some game, or you don't have any issues or the issue you have isn't fixed, then it's not worth updating, unless there is some new feature you want.    I reverted back to 25.9.1 (from the top of my head) because with any newer driver BF6 crashes randomly, and neither DICE nor AMD seem to give a damn about it.    And before someone asks, I tried any other fix on the internet for Battlefield and nothing else worked.",Negative
Intel,Same here. Anything above 25.9.2 crashes ray tracing games like Silent Hill  2 and Oblivion Remastered.   Ihr never had a more crash prone GPU than the 9070XT.,Negative
Intel,"Try this, taken from another comment branch https://www.windowslatest.com/2025/12/09/windows-11s-last-update-of-2025-quietly-fixes-amd-gpu-hangs-haunting-battlefield-6-call-of-duty-black-ops-7-arc-raiders/",Neutral
Intel,Might potentially be fixed by a recent Windows update?  24H2 (and an earlier mini-patch that included this) apparently resolved a lot of crashing for folks.  See [here](https://www.windowslatest.com/2025/12/09/windows-11s-last-update-of-2025-quietly-fixes-amd-gpu-hangs-haunting-battlefield-6-call-of-duty-black-ops-7-arc-raiders/),Neutral
Intel,"Yeah I was really hoping they'd have got buy in from a decent number of devs with updates to big RT showcase games like Indiana Jones, Alan Wake 2, Cyberpunk, etc. But Black Ops 7 and Warhammer 40K... and that's it (for the RT features)?",Neutral
Intel,5070ti fs  basically a better 9070xt,Positive
Intel,"Iâ€™d wait on 5080ti with more VRAM but these are going to be obscenely expensive knowing nvidia + current RAM prices. Both 5070ti or 5080 are more of a sidegrade than upgrade, not worth the hassle IMO.",Negative
Intel,Get a 5070ti. I never thought I would say that. But this is what is is.. 9 months after release and the drivers are still D.S.,Negative
Intel,What about a secondhand 5070ti?,Neutral
Intel,"I mean, I wouldn't get either. 5070 TI is a sidegrade from the XTX, and 5080 is only slightly better. DLSS and RT would be the only reason.",Neutral
Intel,Sidegrading for an upscaler sounds like a joke.,Negative
Intel,"I think Linux developers are doing some experiments As of now, FSR 4 (FidelityFX Super Resolution 4) does not officially support RDNA 2 or RDNA 3 GPUs, even on Linux. However, thanks to Develerâ€™s work on VKD3D-Proton 3.0, there is partial and unofficial support for RDNA 3 under specific conditions.  RDNA 3: Partial Support via Develerâ€™s VKD3D-Proton  - Develerâ€™s VKD3D-Proton 3.0 includes support for FP8 (8-bit floating point), which is required for FSR 4. - This means RDNA 3 GPUs (like RX 7600, 7900 XT/XTX) can run FSR 4 in some games via Proton, even though AMD doesnâ€™t officially enable it. - Global override toggles in AMDâ€™s 25.9.1 driver can bypass the FSR 4 whitelist, allowing it to run in FSR 3.1-compatible games.  I hope they succed it will be a slap in the face.",Neutral
Intel,Yeah AMD refusing to port features to any card released before the 9 series makes supporting them really hard.,Negative
Intel,Say thanks they haven't demoted 7000 series to only game drivers,Neutral
Intel,"Your best case is your RX 7900 turning into Balsamico, whatever that means.",Positive
Intel,"Its because RDNA 4 added hardware that 3 and 2 don't have. Now before I get kicked to death by angry people, there is a version of FSR Redstone that uses and INT8 path that is compatible and will work on 2 and 3, however that has not been launched today and AMD have not confirmed it will be.   That isn't to say they won't do it, but right now it's not been announced. Perhaps there will be enough noise to get AMD to change their mind or it might be that they want to get it out on their latest cards first before complicating matters with older RDNA support.  Only time will tell",Neutral
Intel,"Bro the AI accelerators completely got revamped, upscaling technique isn't usually the indicator for 'fine wine', it is when non-upscaling raw performance numbers improve.",Positive
Intel,Same boat here. Tired of trying.,Negative
Intel,Thanks for testing. Have you perhaps tested Oblivion Remastered?,Positive
Intel,Finally fixed! It's a christmas miracle!!!,Positive
Intel,I regret getting this 7800xt,Negative
Intel,Any card released prior to the 9 series.  Amd could give 2 shits as they chase the AI bubble (jokes on them if I was an exec I'd double down on the consumer market to insulate from the impending bubble burst),Negative
Intel,sadly,Negative
Intel,"Yep, I go back between 23.9.1 and 25.9.2. I couldn't be happier.",Positive
Intel,"If it's any consolation, I was on an NVidia card for 2+ years where I wasn't getting the DLSS updates. Then they actively removed features when they went to the NVIDIA app.  Looking at AMD's roadmap, RDNA4 looks like a stopgap anyway until RDNA5 (prob will be called UDNA?) comes out. So in another year and a half I'll be in the same situation with my 9060XT.",Negative
Intel,"Use OBS, replay buffer",Neutral
Intel,Was just thinking of giving a shot for Indiana Jones and the Great Circle - I guess not anymore since FSR4 doesn't work with it..,Neutral
Intel,"That was a terrible driver for me also. New one has been night and day improvement, give it a shot.",Negative
Intel,"Microsoft had bugs also causing hanging crashes. Everyone loves to blame GPU drivers immediately, but check this out:  https://www.windowslatest.com/2025/12/09/windows-11s-last-update-of-2025-quietly-fixes-amd-gpu-hangs-haunting-battlefield-6-call-of-duty-black-ops-7-arc-raiders/",Negative
Intel,I also want to know this.,Neutral
Intel,"I'm wondering the same thing, 25.11.1 is still the most stable for me!",Positive
Intel,Wondering too. I bumped back down from 25.11.1 because it was unstable on my machine.,Negative
Intel,Stay on 25.11.1 if you are on RDNA 1 or 2,Neutral
Intel,squash hard-to-find sharp reach memorize fade husky divide subsequent plough   *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*,Neutral
Intel,"~~It messed up my audio, now everything sounds 8-bit. If you're on RDNA4, avoid this update.~~  EDIT: it's not the drivers, after much tinkering I was about to deduce that it was my monitor. So it should be ok to update",Negative
Intel,I can't use anything above 25.9.1 on my 9070 XT,Negative
Intel,forget it they gave u the middle finger move on fuck both amd and nvidia,Negative
Intel,wonâ€™t happen,Neutral
Intel,"Fine wine is only a thing for very few and specifics types of wine, typical wine still goes bad over time.",Negative
Intel,What is the source for this or is it trust me bro?,Neutral
Intel,They should just remove this feature. It never worked from day 1..,Negative
Intel,what is the difference,Neutral
Intel,"Can you tell me if this is also applicable to 25.12.1? There are several (frustratingly unlisted) VR-specific fixes aligned, one of them closely relates to what you've just described",Neutral
Intel,Same here. 25.9.1 makes my problems go away,Positive
Intel,Same for my 9070 XT. Device hung error,Negative
Intel,"Thanks for reporting, had that once with 25.11.1 + 9070XT (W10) before reverting to 25.9.1 (since then, it never reappeared).",Neutral
Intel,Thank you for reaching out.   That's really weird - I don't suppose you have any links to posts about this for us to skim through?  I'll follow up with my colleagues about this tomorrow,Negative
Intel,Do you get a firmware update pop up? Is this one?  https://i.redd.it/w46j86mnct6g1.gif,Neutral
Intel,"I'm familiar with this impacting United Offensive, I don't believe we're reintroducing this old vendor specific extension, however. I do have a ticket for the performance issues though; I don't believe this is related to the missing extension.",Neutral
Intel,"Tested for 2 days(1day and 22hrs uptime)  No crash, No BSOD for me so far. Nothing strange.  MS Edge, Google Chrome video playback, youtube...etc all play nice while gaming on main monitor.  Diablo 4, MSFS 2024, Doom dark age, Forever winter(UE5), Witchfire(UE4)...etc All run fine.  Lossless scaling runs fine on spicy vids to all of the above games xD  HWinfo64 and MSI Afterburner, RTSS all run as they should.  (Win11 25H2 uptodate, X670E, igpu(98x3d)+7900xtx+6400 3gpus, 2 monitors, hybrid mode)  Edit) rx 6800 + r7 7700x on win11 25H2, X670E, Single monitor, igpu-disabled -> runs fine.  rx 6700xt + i7 8700k on win11 25H2, Z370, Single monitor, igpu-disabled -> seems good.",Positive
Intel,"25.11.1 had pink artifacts glitch on chromium browsers with 7700 xt but i installed 25.12.1 yesterday and no issue so far, i did not see artifact pink glitches or sound issue so far ?",Neutral
Intel,My 9070 XT hate every driver above 25.9.1,Negative
Intel,I updated to this driver and immediately got a BSOD. Rolled back to October 25.10.2 again,Negative
Intel,offer steep theory scale straight obtainable physical ad hoc selective test   *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*,Neutral
Intel,thats what I wonder too! Is it more stable??,Neutral
Intel,haha r u fr,Neutral
Intel,la mÃªme. C'est scandaleux,Neutral
Intel,"Means that they've created separate driver packages tailored for the specific gens (A rdna1/2, B for RDNA3/4, C - combined fat package that contains both drivers for systems that might have both gens on the same machine (igpu + dgpu) )",Neutral
Intel,"Your comment has been removed, likely because it contains trollish, political, rude or uncivil language, such as insults, racist or other derogatory remarks.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",Negative
Intel,"Cleanup utility first, always!",Positive
Intel,I also wanna know best way updating drivers. DDU kinda annoying but maybe must be done i don't know,Negative
Intel,It's doing it there too.,Neutral
Intel,Never seen any crashes on it with latest driver prior to today 9070xt w11,Neutral
Intel,"Just tested it tonight, and for me it's working fine, 9060xt here, windows 11 with the latest update, although i play with the ""medium"" preset which disables ""lumen"", can't say it might work for you but you can try it if it still crashes constantly",Neutral
Intel,Might want to check [https://www.reddit.com/r/radeon/comments/1pjeonb/fyi\_fsr\_ml\_framegen\_requires\_windows\_11/](https://www.reddit.com/r/radeon/comments/1pjeonb/fyi_fsr_ml_framegen_requires_windows_11/) :|,Neutral
Intel,nope. I still crash,Negative
Intel,"I fixed my arc raider crashes (mostly in blue gate map load) by running DDU, installing 25.10.1 (down from 25.11.1), and deleting shader caches (dont know if the shader cache delete helped or not). I upgraded to the newest drivers the day after they released and haven't had a single crash since in arc raiders, including w overlay.",Neutral
Intel,"for me, DDU in safe mode, disconnect internet, install 25.9.1 fine for me(9060XT).  I've tried 25.10/ 25.11 and revert back to 25.9.1 with this way. Now observing 25.12",Neutral
Intel,Yes. I downgraded from 25.11.1 because of the crashing. Now been on 25.12.1 all week and havent had any issues come up. You also get proper fsr4 upscaling now.,Neutral
Intel,"I just want to say I think I found the culprit. It also happens on the winupdate one too, because it started crashing all the time.  Core clock boosts itself WAY past what it is declared on the card(I got a Sapphire 9070XT Nitro, supposed to be 3060MHz). Here's the moment before it crashes to a black screen:  [afterburner screenshot](https://i.ibb.co/3YpJFtzM/Screenshot-2025-12-21-030537.png)  The dip in clocks is the moment it crashes. As you can see, it is running well above boost clocks. Hence, freezing in a few minutes, proceeded by a black screen, and a crash. The ups and downs are from me alt tabbing in the graphs, by  the way.   This is with core clock -200mhz applied in Afterburner and no crashes, boosts to just above declared boost clocks. Here the dips in up and down on power are probably me toying around how much exactly -mhz is needed.  [afterburner -200mhz](https://i.ibb.co/YTQfGJtc/11111.png)  All of the crashing behavior so far is replicable in COD, CS2, Cronos New Dawn.  u/AMD_Vik",Negative
Intel,thanks for reaching out - funny timing; I noted that on the internal ticket for this issue yesterday having seen other accounts of end users noting this issue persists even with 25.12.1. Perhaps the fix aligned to that point release somehow slipped.,Neutral
Intel,Itâ€™s for Darktide apparently,Neutral
Intel,any game with fsr 3.1 fg also has the new fg since drivers override it. itâ€™s also why they stopped versioning fsr. any game with fsr 3.1 should just automatically have any new version of fsr when the drivers update,Neutral
Intel,I forgoed any amd software entirely  Use more clock tool  10x better with 0% of the bloat   ^^ helped me get my 4th in world furmark score (7900xtx user),Positive
Intel,If you want to be in control of whatâ€™s on your computer then Windows is not the OS for you,Neutral
Intel,"Dumbest take one can have, since installing only the driver won't let you manage the settings at all.  Which has nothing to do with this useless launcher no one wants or needs.",Negative
Intel,Found the install manager dev lol,Positive
Intel,Thanks.,Positive
Intel,Unfortunately Redstone FG is bugged with poor frame pacing,Negative
Intel,Nice to see the innovation continuing on,Positive
Intel,But only on the 9060 and 9070 right?,Neutral
Intel,I remember this mentioned since the  GCN 1.0 days. Lol,Neutral
Intel,"On my end, the driver crashes. Most of the time it manages to recover (sometimes it will crash a few more times before stabilising). Sometimes it doesn't recover (leaving only 1 of my monitors working), so I had to reboot. Then after rebooting, strong chance it'll crash again the moment I open my browser.",Negative
Intel,Oh thank god it's not just me.,Negative
Intel,"My experience with switching to amd was so smooth and perfect until 25.9.1. Everything after that just caused stutter issues in games, programs randomly crashing, drivers crashing completely causing my pc to reboot, this is so sad i hope they fix this soon and bring back a stable version asap. Rolling back to 25.9.1 now aswell until that happens.",Negative
Intel,"\+1 on this. Most games crashed drivers with any newer drivers except 25.9.1, but poe2 i cant play with vulkan or Directx 12 only with Dx11",Negative
Intel,pÅ™esnÄ› zustÃ¡vÃ¡m na 25.9.1 vÅ¡echno jinÃ© crash,Neutral
Intel,"I had been having the absolute worst time with drivers when I first bought my 7600XT, but finally found stability with 25.8.1 (and turning the Xbox Gamebar DVR off...) but I'm so paranoid now to update my drivers again. The only reason I decided to check on updates now though is a sudden appearance of my screen flashing black at random times.",Negative
Intel,Are you able to tell us what the error code is on the BSOD? I don't suppose you have a kernel memory dmp pertaining to one of these failures over at      C:\Windows\MEMORY.DMP,Negative
Intel,Yeah same,Neutral
Intel,"Remember when you could click ""Check for Update"" inside the AMD Software and if there was an update, it would download and install it for you?  Glad they fixed that awful experience, and we have the Installation Manager now.",Neutral
Intel,Thanks will give it a try after I finish work,Positive
Intel,"Wait, AMD Customer Support told me that 2 monitors connected to iGPU and dGPU has never been officially supported and that this configurations breaks performanceâ€¦ so they told me bullshit?",Negative
Intel,Any update on three Oblivion Remastered and Silent Hill  2 Remake crashes? A lot of us are still with the September drivers because of them.,Negative
Intel,<--- Ditto,Neutral
Intel,Optiscaler lets you inject it. Do not use in multiplayer games though.,Neutral
Intel,it cannot possibly be this difficult to fix when thereâ€™s already community workarounds,Negative
Intel,both are still broken somehow,Negative
Intel,running at 600 fps with vsync on means that somethingâ€™s terribly wrong with something in your software thatâ€™s breaking vsync. thatâ€™s definitely not normal,Negative
Intel,I did some testing AND as far as I can tell I do think it's actually fixed finally,Positive
Intel,I would continue buying their GPUs if they gave me something to buy.  The XTX has no upgrade path on RDNA4.,Neutral
Intel,"I had Nvidia for years, the main reason I switched was that the drivers went to shit last year. I'm just sick of them in general, too. The 7800 XT I bought has been one of the most trouble free cards I ever had, aside from Adrenalin randomly closing in certain versions.",Negative
Intel,"If I could get my hands on a 5070 Ti Iâ€™d happily switch. AMD likes to take advantage of the underdog, for-the-people image whenever itâ€™s convenient but theyâ€™ll just as quickly throw us under the bus and fuck us raw once theyâ€™ve got the bag.  Is Nvidia a gang of greedy fucks? Sure. But at least the bullshitâ€™s right out front where you can get a good strong whiff of it. You know what youâ€™re in for.",Negative
Intel,"I purchased a 7700 XT and a 7600 8gb I'm March and while I'm satisfied with performance, it would definitely be awesome to have FSR 4 on both cards as FSR 3 and 2.2 (overwatch )leave alot to be desired",Positive
Intel,It's been so long bro :( Hopefully the fix comes with ray regeneration support?,Negative
Intel,"Hey Vik, is there any info for FSR4 Vulkan support?  It's quite sad to see that there still isn't support for it as it has been 9 months by now since the release of the 90 series  Also is there any info about the EAC issue with Star Citizen and the latest drivers?",Negative
Intel,"Amd Noise Supression doesn't work, when I try to turn it on, nothing happens, but in 25.9.1 it works",Negative
Intel,"Hey amd\_vik is amd Aware of the 1 year on going Darktide issues with amd  ( GPU , and specially X3D cpus ? ), and that even the Dev of Darktide ( Fatshark ) seemingly gets ghosted by amd ?  heres some more info specially first links includes a few Dev comments  [https://forums.fatsharkgames.com/t/investigation-poor-performance-power-draw-issues-impacting-amd-radeon-6000-9000-series-gpus/107462](https://forums.fatsharkgames.com/t/investigation-poor-performance-power-draw-issues-impacting-amd-radeon-6000-9000-series-gpus/107462)  [https://www.reddit.com/r/DarkTide/search/?q=Performance&type=posts&sort=new&cId=4bd6e7a2-8389-4e6d-8f79-d42d57b8562c&iId=eba79a3c-b764-4712-a529-951dc1e87c9f](https://www.reddit.com/r/DarkTide/search/?q=Performance&type=posts&sort=new&cId=4bd6e7a2-8389-4e6d-8f79-d42d57b8562c&iId=eba79a3c-b764-4712-a529-951dc1e87c9f)  [https://forums.fatsharkgames.com/c/darktide/performance-feedback/97](https://forums.fatsharkgames.com/c/darktide/performance-feedback/97)",Neutral
Intel,"Vik, weren't you on holiday leave? xd",Neutral
Intel,Any fixes for the SecondLife issues we've had the last few months? last driver that didn't break textures was 25.9.1,Negative
Intel,Will this update fix some of the artifacting Iâ€™m seeing in cyberpunk with fsr enabled?,Neutral
Intel,Also getting driver timeouts in Cyberpunk with RDNA3 with raster or RT. I did not have these problems with my RDNA2 card.,Negative
Intel,"The AMD FSR ML-based Frame Generation option in the Radeon panel disappears in Windows 10.  So I have a question: Is ML-based Frame Generation no longer usable in Windows 10? This option is available in Windows 11, but not in Windows 10.",Negative
Intel,Can I join if mine's just an XT?,Neutral
Intel,What GPU are you using?,Neutral
Intel,Try reinstalling Windows. That fixed it for me.,Neutral
Intel,"This doesn't work. We are talking about games that crash with or without it, the only difference being the older AMD driver working.",Negative
Intel,I already install the latest update before update drivers its not update related. Vulkan driver is the problem in indina jones and silent hill 2 after windows update 25.11.1 not crashing ray tracing enabled but in 25.12.1 its broken again. So driver is the problem...,Negative
Intel,"They said earlier in 2025 they were working on FSR 4 support for RDNA 3, and then it leaked in September with the INT8 version...",Neutral
Intel,"They might as well have lol, they aint getting no new features",Neutral
Intel,They also promised features to the few of us who bought 7900 XTX. Good luck defending them when it's your turn to be disappointed.,Negative
Intel,I expected them not to abandon their king card lmfao. Who does that,Negative
Intel,"Not really, they teased the possibility of including other architectures.",Neutral
Intel,Maybe next time you should read the whole thread before replying.,Negative
Intel,"It's also related to getting new features in generations other than just the latest one, ""bro"".",Neutral
Intel,"I have the 7800 xt hellhound i F love it, tbh i care less about this redstone thing but its frustrating why a 2 year old lineup is abandoned all of a sudden",Negative
Intel,"> I'd double down on the consumer market to insulate from the impending bubble burst  If that bubble bursts nobody is going to have much money to spare for consumer goods. That bubble bursting will tank the entire economy along with it.  *Long* term that might work out better, though.",Negative
Intel,further reminder amd is not your friend sadly,Negative
Intel,Same for me but Doom Eternal. I play at 4k and it needs upscaling at that res.,Neutral
Intel,What if I'm on RDNA 4?,Neutral
Intel,Yeah there are no good choices,Negative
Intel,[https://www.amd.com/en/resources/support-articles/release-notes/RN-RYZEN-CHIPSET-7-11-26-2142.html](https://www.amd.com/en/resources/support-articles/release-notes/RN-RYZEN-CHIPSET-7-11-26-2142.html),Neutral
Intel,Adrenalin is for GPUs.   Chipset is for CPU & mobo.,Neutral
Intel,"Most of the conversations happened across various discord servers, so I cannot directly link them, but I also found a few posts here on reddit that seem to point towards the same direction which roughly match with the timeframe.   [https://www.reddit.com/r/Vive/comments/1nl0540/direct\_mode\_not\_working/](https://www.reddit.com/r/Vive/comments/1nl0540/direct_mode_not_working/)  [https://www.reddit.com/r/AMDHelp/comments/1ljezuf/steamvr\_crashing\_on\_amd\_drivers\_after\_2451\_direct/](https://www.reddit.com/r/AMDHelp/comments/1ljezuf/steamvr_crashing_on_amd_drivers_after_2451_direct/)  It's a bit odd because if you set the flag beforehand with a older version and then update to newer versions, Directmode still works fine, but if you fully remove the drivers with AMD's driver removal utility or Display Driver uninstaller (which propably deletes some cached driver file for directmode, is my guess), Directmode disables fully and can't turn on anymore at all.      As far as headsets are concerned, I know at least Valve's implementation seems to suffer from this (I know about cases involving the Valve Index, Bigscreen Beyond and Vive Pro 1, all using Valve's implementation), but somebody in the pimax subreddit community discord seemed to have the same problem, which he also was only able to fix by rolling back the drivers.  I could propably reach out to a few more affected people over discord and encourage them to get active here, if you'd like.  But I do think that it is a fairly reproducable problem, at least on my end, it happened across two different systems.",Neutral
Intel,"Hi - I am having this problem. I wanted to try the special ROCM driver so dutifully did a clean install as suggested.  Tried to launch SteamVR and it errored. Realised headset had reverted to being a monitor, running at low resolution (less than recommended) Increased the resolution to recommended (combined resolution of the two panels), and SteamVR started detecting the headset - though promoted to enable direct mode. Pressing the button to enable it restarts SteamVR, but then prompts again, and HMD is still a monitor.   Interestingly reverting to the RDNA 4 release driver, it instantly worked - Direct Mode was enabled without me having to toggle.  So it is like SteamVR is successfully toggling something, but the newer AMD drivers ignore whatever it is doing/don't act on it. As soon as older driver is installed, it does act on it, and the HMD disappears from Display Settings/stops being treated as a monitor.  This wouldn't affect the majority of SteamVR users who are streaming to a Quest, and it wouldn't impact people who upgrade to a newer driver without a cleanup.  It would affect people doing fresh installs with a recent driver, and people who do clean driver installs/use DDU.",Neutral
Intel,"I installed the latest driver from a couple of days ago, and my Beyond is a monitor again ðŸ˜­   I didn't explicitly choose to do a clean install, but maybe because I chose to install the AI Package, it decided to do a clean install for me automatically?",Neutral
Intel,"u/AMD_Vik Hey! just following up on it!   Did you guys manage to replicate it? Just curious if there is anything happening in that area.  I know development and testing takes time, so I completely understand if nothing happened yet, just curious if you guys had problems replicating the issue.",Neutral
Intel,Yes thatâ€™s the one. I have no idea where to turn lol,Neutral
Intel,Sad news. Nvidia still supporting old extensions.,Negative
Intel,"Hey OP â€” Your post has been removed for not being in compliance with Rule 8.   Be civil and follow Reddit's sitewide rules, this means no insults, personal attacks, slurs, brigading or any other rude or condescending behaviour towards other users.  Please read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification.",Negative
Intel,oh wow i haven't had any issues yet but that doesnt mean much. 25.11.1 i didnt have issues for a week or so.,Negative
Intel,"Interesting, Iâ€™ll test it today. I was crashing non stop on 25.11.1 so hopefully this update fixes it",Positive
Intel,Same,Neutral
Intel,"I have the same model GPU inconsequentially boosting well above the advertised clocks (nearly 3.4GHz) in both windows 10, 11 and fedora 43 with no issues.  This has been discussed several times on this community; whilst the clock behavior may surface other issues or instabilities on the system, it's not in itself the cause of problems.",Positive
Intel,"I actually have one more potentially related thing for you!   During the game I tried to turn the overlay on using my hotkey. Noticed it didn't. Since I've seen this before (we can call this a ""soft lock"") I tried to open the full screen experience with the hotkey. Which brought up my mouse (was using a controller in game before pressing the keys) but I could not move it...  My workaround has been: ctrl+alt+esc to task manager, tab to the search bar, type ""radeon"" and force kill the host service.  The instance I reported before this was a ""hard lock"" that I've noticed while trying to use my browser over a borderless game running, before this time where it was when the gpu wasn't under any actual load as far as I knew.  Glad to hear it's a known issue and not my hardware though... Thanks for getting back to me!",Neutral
Intel,Which driver version DOESNT have this issue?   I've tried going back all the way to .10 and it's all having the issue...,Negative
Intel,"Good morning, when will the new AMD Software driver be available?",Positive
Intel,Literally the one game I don't play lol,Neutral
Intel,"Yay, I own that one",Positive
Intel,"It's not even out for Darktide yet either. Fatshark clarified that it's experimental and needs more work, so it's not in the live build",Negative
Intel,So it's under the umbrella of the fsr4 override if I understood this correctly. For the fsr2 and 3.0 games I can use optiscaler right? Sorry I just bought a 9070xt coming from nvidia so I need to get used to these things.,Neutral
Intel,I used to do that but a few games can use the FSR4 in driver upgrade.  The enhanced sync was nice too when it worked.,Positive
Intel,"Unfortunately I play games and run software that require Windows so I have it on a separate drive. When I do switch to it (and I update the driver to take advantage of new features), this shit typically happens along with a slew of forced updates.  You are right though, I do primarily run CachyOS.",Negative
Intel,found the linux user,Neutral
Intel,You're talking nonsense.  Engineer managing 2k endpoints and several hundred servers.,Negative
Intel,Wasn't the dude's claim it has been always bugged with AMD,Neutral
Intel,ðŸŒðŸ‘¨â€ðŸš€ðŸ”«ðŸ‘¨â€ðŸš€,Neutral
Intel,It's barely an improvement.,Negative
Intel,It's branding,Neutral
Intel,"Yes, RDNA4 refers to the RX9000 series.",Neutral
Intel,Disable mpo,Neutral
Intel,I have one of these captures if you want it (error code 0x00000119). I've been having a TON of driver timeouts and BSOD for the past couple of driver versions and I've had to roll back to October to resolve them. Seems like any app that has hardware acceleration enabled causes it and exasperated when viewing the system via RDP.,Negative
Intel,"Uninstalling the install manager brings back the ""check for updates"" functionality until you update again (and have to re-uninstall the install manager)",Neutral
Intel,Let us know how it goes!,Positive
Intel,"I don't know how much of an impact this could have on perf since it's not something I've measured. I personally wouldn't do this, though. With a dGPU installed I keep iGFX off.",Negative
Intel,"performance wise it should only be a couple frames of latency, when doing rendering on dgpu and going out through igpu it'll just copy over the frame buffers.   Main impact is on pcie bandwidth as it'll use up quite a lot there, and to a smaller degree RAM load, so you definitely don't want to run some other dynamic load on the igpu when gaming to overwhelm its pcie link. I think on 7000/9000 it's x8 so it may be fine? But I'm really not sure could be x4 too",Neutral
Intel,"We're tracking a failure in silent hill 2 remake, I believe a fix is aligned to a future release. I'll need to check in with oblivion remastered",Negative
Intel,"Do you have to do that convoluted setup and download the drivers from Limewire, or has Optiscaler wrapped it in to their application?",Neutral
Intel,"So, no official release... ;(",Negative
Intel,Any tutorial for a noob on RDNA2?,Neutral
Intel,what workaround?,Neutral
Intel,"Same issue with fsr4 on rdna1-3.   It shouldn't be this difficult, it's in a perfectly working state made possible by like one guy's few days worth of work.   And yet AMD just doesn't do it...",Negative
Intel,FUG,Neutral
Intel,"Oh, definitely not normal for sure... but I have this issue on multiple games and I did not have this issue on the 6080 it replaced. This seems to only be impacting my 9070.",Negative
Intel,"Such a relief, but i am also annoyed because they are ignoring 7000 series... I can literally use FSR 4.0.2 on my 7700XT and it is WAY better than FSR 3.1....",Negative
Intel,I hope it is fixed for me as well ðŸ˜­ðŸ™. Thanks for the info.,Positive
Intel,yep would have upgraded but with an XTX.... you can cut your vram in 2/3 and have less Raster performance for a good upscaler and better RT performance it's such a stupid fucking problem....,Negative
Intel,"That's not something I'm privy to, but it could be worth reaching out to them to request looking into if they're not already.",Neutral
Intel,"I'm not privy to any of the FSR stuff - that's a different team to mine. I can pass on the feedback.  The Star Citizen EAC issue should be addressed, please let me know how it is.",Neutral
Intel,i still am!   so many fixed issues out of the release notes that I felt the need to stick around and help clear things up in the communities I frequent. I'll go back into hiding again soon,Positive
Intel,"I've seen something like this over at OCUK Forums but weren't given enough data to work with. We've attempted to reproduce a corruption issue but apparently we've not been successful.  Can you give me a step by step breakdown on how to hit this, as well as a clear depiction of the issue?",Negative
Intel,"No, XT peasants needs to form their own group.",Negative
Intel,6800XT.,Neutral
Intel,Some of their marketing said they would like to get it working if possible.,Neutral
Intel,Yeah there are going to be serious consequences as major retirement funds have invested in all these AI stocks because they have made so much money.,Neutral
Intel,"Give it a try, for my 6800xt it's crashing in almost all games...  ![gif](giphy|QMHoU66sBXqqLqYvGO)",Negative
Intel,"Scrap that!   I ran SteamVR which caused Steam to crash but restarting it as prompted, my Beyond 2E disappeared as a monitor again - weird!",Negative
Intel,"Hey there,  Filed this to triage and debug some time ago. A few colleagues outside of that domain have attempted to repro on their personal systems with applicable headsets like the Index and Vive but haven't had any luck so far - the toggle's working for them just fine.  Should be picked up by the T&D team fairly soon, will see what they find.",Positive
Intel,"Sorry, out of curiosity, if you close it, it won't let you play? What do you get? Could you send me a photo so I can understand?",Neutral
Intel,"I agree. Please can you raise a ticket requesting support for this over at our GPUOpen and ask other end users and developers to upvote it and leave a comment registering their interest? (please share a link to it here if you do) https://github.com/GPUOpen-Drivers/AMD-Gfx-Drivers/issues  As far as I'm aware, the impacted titles are: IL-2 Sturmovik: 1946, Neverwinter Nights Diamond Edition and Call of Duty. If there are any others, I would really appreciate you letting us know.  E: I believe it's posted here: https://github.com/GPUOpen-Drivers/AMD-Gfx-Drivers/issues/80",Neutral
Intel,"Just an update - I ended up running DDU and re-installing the latest update and now things are pretty stable, no driver timeouts from hardware accelerated apps either. Could be something to do with the architecture change between driver packages - but doing a complete removal between updates seems required now.",Positive
Intel,I never seen 1 crash on 25.11.1 although I did use the preview update for windows 11 last week which fixed some amd gpu related crashing and that solved my arc raiders random crashing,Neutral
Intel,"My apologies then - it seems latest driver on Windows seems to be the source of issues then, seems more people have issues posting on /r/AMDHelp , also with 9070XT's. Seems all device hung errors and timeouts recently posted are with 25.12.1. I had no issues on cachyOS (Hyprland) running CS2 too, latest amdgpu.",Negative
Intel,I believe this was introduced with the 25.20 driver branch. it shouldn't be present in 25.9.1/2,Negative
Intel,"I think our SVP noted in a recent interview it'll be later in Jan, the date they provided was the 21st, though I'd treat this as a tentative timeline just in case anything crops up",Neutral
Intel,"yes, 3.1 is where AMD adopted the same modular approach as nvidia so any game at fsr 3.1 or above just runs at whatever latest fsr version your driver supports, which is currently 4 although now the versions aren't numbered anymore",Neutral
Intel,Hell yeah ðŸ‘ðŸ»   Impressive you can run that on a 5x86,Positive
Intel,"Since you're already an advanced user, perhaps you could block it from installing by selectively blocking AMD in your hosts or pi-hole? It's not a dumb solution, but it's better than having to deal with push-installs.",Neutral
Intel,I might be an ass but Iâ€™m not wrong,Negative
Intel,Sorry  If youâ€™re a **consumer** and want to be in control of whatâ€™s on your computer then Windows is not the OS for you,Negative
Intel,"Yes, If you mean the bad frame pacing when fps is lower.  I still opt to spent 1-200 hrs of my gaming session with FSR 3 frame gen, 7900xtx.  It's not that bad when the output is close enough to monitor max hz, similar to what hardware unboxed did in thier test.  The generated frame still comes out too early but it has to wait for the monitor's nest refresh which is consistent.",Neutral
Intel,ty,Neutral
Intel,can you run analyze -v in windbg or fire it over to me via your preferred file sharing method?  I personally like to use https://send.vis.ee,Neutral
Intel,"u/amd_vik it sounds like this person doesnt want the manager to install again, but I am pretty sure you can do custom option to uncheck it. If you do express of course it will put it back sschuler.",Negative
Intel,Can confirm this issue is fixed for me on 9800x3d + 9070xt (I had this issue on 25.11.1 and reverted to 25.10.2 until today) ðŸ‘,Positive
Intel,"Seems to be working fine, though when I was installing the driver my igpu showed up separately from the dgpu in the installer with a download link. But when re-running it they both show under 25.12.1  Should I be installing some separate older driver for it to keep things like hw accel working or was that just some hiccup?",Neutral
Intel,Oh great will also test after work itâ€™s been headache since last driver update,Positive
Intel,Thank you for taking the time to respond. This has been very frustrating.,Negative
Intel,"I'm sorry to comment directly to you here. Do you have any report about monster hunter wilds performance drops in recent GPU drivers ?    I'm using 9070xt.    I have to use version 25.3.1 to play wilds with no stutters, anything newer gives a lot of stutters in many places.",Negative
Intel,"Yeah you still have to download it on your own, the creator of Optiscaler already said they aren't going to bundle it probably due to the whole legality around it.",Neutral
Intel,"i saw a post that detailed how to essentially replace noise suppresion with the working version in newer drivers, you can probably find it here somewhere",Neutral
Intel,yeah somethingâ€™s definitely wrong. iâ€™m assuming youâ€™ve already tried ddu?,Negative
Intel,Thank you for this! been waiting for a fix with Star citizen.,Positive
Intel,Yeah SC seems to be working for now.,Neutral
Intel,"Bonjour, pour le moment sur Star citizen le problÃ¨me avec EAC fonctionne pour la 7900XT. Merci d avoir rÃ©glÃ© le problÃ¨me. Bonne fÃªtes de fin d'annÃ©e.",Neutral
Intel,That's good to hear. What about Noise Suppression not working since 25.9.2?,Neutral
Intel,Hmm let me try. So pretty much having installed the latest driver (25.12.1) I just open SecondLife. I look closely at my avatar/character and my skin looks like this  [https://i.gyazo.com/9285c648e1163ab0fcc653e1a22ac88b.mp4](https://i.gyazo.com/9285c648e1163ab0fcc653e1a22ac88b.mp4) (excuse my outfit but just easier to show)  this is how it's supposed to look and also does on 25.9.1 [https://i.gyazo.com/3fe61911f122ff21eac6af805c69c3c1.mp4](https://i.gyazo.com/3fe61911f122ff21eac6af805c69c3c1.mp4)  I've heard that this doesn't occur on linux but only windows (But I don't have linux so can't say for sure)  I think you need PBR / Materials or some reflection on your skin to see the issue.   If you fly up to around 2000+ meters above ground it becomes easier to see  These are my settings [https://i.gyazo.com/5686c88a62ea2c9ef8f721db34453c90.png](https://i.gyazo.com/5686c88a62ea2c9ef8f721db34453c90.png)  I have an rx 7900XTX,Neutral
Intel,"Hello! I am actually one of the developers on the client team for Second Life, and I have been trying to figure out how to get in touch - we have found at least one nasty bug on some of the Strix Halo chips with the current drivers.  Can you send me a message here so we can exchange emails?",Negative
Intel,ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­,Neutral
Intel,"I had a similar issue with my 6800xt and the other thing that helped was to sit it to fullscreen or borderless and swap back and forth. Now I'm only playing in fullscreen (which is annoying), but it doesnt crash anymore.",Neutral
Intel,I have the same card and exactly the same problem. Can't install newer drivers or BF6 just constantly crashes.  I'm on 25.10.2 tho,Negative
Intel,"And it is, and they did, we have the leaked int8 version from September... Just needs official driver implementation now.",Neutral
Intel,"Before the Black Ops 7 (which I donâ€™t own) integration to Warzone, I could click off it & carry on. But since the integration it just closes the game.",Neutral
Intel,"Yes, i have created this github issue.",Neutral
Intel,"If those failures are avoided by clock limiting the board, the problem area could be a different domain entirely (CPU, memory, power, etc.).  The linux remark is interesting, it kind of calls back to similar failures with NV31 in certain apps like Helldivers 2; we had a little internal discussuon about how the amdgpu kernel driver managed to mostly avoid such issues, though I dont recall the outcome.  If you get the opportunity, I'd recommend a suite of system integrity routines as a sanity check; please take a look at [one of my older posts](https://old.reddit.com/r/Amd/comments/1l9ox9r/amd_software_adrenalin_edition_2562_optional/nn3yuay/) for some background.",Neutral
Intel,issue persists in the newest 26.1.1 update....,Neutral
Intel,OK thanks.,Positive
Intel,"They aren't numbered in the sense of like 4.0.2 or like there won't be an ""fsr 5""? Thank you very much btw, very helpful info!",Positive
Intel,Like a charm. :D,Positive
Intel,"I probably could, but AMD (and any other company, really) should be following the users preference anyways. It is a band aid fix and doesn't solve the problem.  Not a bad idea though.",Negative
Intel,I've been using computers since dos 3.  You're a spanner.  I'm sure MacOS is soooooo much more open.,Neutral
Intel,Here you go: [https://send.vis.ee/download/2b9c553519ec5d1a/#WAbve98Ky-73b6ruGpvyyw](https://send.vis.ee/download/2b9c553519ec5d1a/#WAbve98Ky-73b6ruGpvyyw)  I did run in windbg but I have no idea how to save the output unless you just want a copy + paste of it here haha,Neutral
Intel,"Thank you for the idea, I just tried a custom install during an update, was given 2 choices (update/dont update driver and install/dont install privacy view). After installing drivers, step 2/2 was installing the install manager.    After updating through adrenaline using the custom option, I attempted reinstalling again using the auto-detect, custom install. I was given the option of install/dont install privacy view. The driver choice was not selectable and it reinstalled the install manager during step 2/2.   Installing via the WHQL package, custom install follows the same steps as above. I was given the option of install/dont install privacy view. The driver choice was not selectable and it reinstalled the install manager during step 2/2.",Neutral
Intel,Appreciate the feedback,Positive
Intel,Thank you for confirming.  That interesting though. I think the most seamless way to support products from both branches is to use the AMD auto detect tool. Can you tell me how the iGPU is represented in Windows' Device Manager?,Positive
Intel,"[https://www.amd.com/en/resources/support-articles/release-notes/RN-RAD-WIN-25-12-1.html](https://www.amd.com/en/resources/support-articles/release-notes/RN-RAD-WIN-25-12-1.html)  https://i.redd.it/3vxsa8yave6g1.gif  If you suspect the installation is incorrect, download the package that includes the IGPU driver using the link provided above. The basic version does not include the IGPU driver, but provides a separate download option during installation.  Anyway, it seems like a lot of bugs have been fixed in this version.",Neutral
Intel,"if you can find it, you will be the goat",Positive
Intel,"This isn't every game, this is only some games. Not all games have a native vsync option either. That being said, from what I can find, this is a known issue.  https://steamcommunity.com/discussions/forum/1/601900047372731730/  https://www.wumeicn.com/screen-tearing-fix-for-rx-9070xt-and-freesync/",Negative
Intel,Thank you for letting us know ðŸ‘,Positive
Intel,appreciate the info. I'll ask our technicians to check in with the settings you've provided,Positive
Intel,I can confirm there is no issue in linux. A windows version running under proton in linux has no issues as well.   In the video there is flickering on head and body. I see only flickering on the head (when running it on the windows pc)  But my body has no layers attached - the body in the video usually comes with layers. But all heads have multiple transparent layers. The problem occurs even when that layers are not in use and are fully transparent.   Probably related.,Neutral
Intel,"Hey there, thank you for reaching out!  I don't suppose it would be possible for one of our devrel folks to contact you via a linden lab email address like business@lindenlab.com?",Neutral
Intel,"So if you click dismiss, the game closes, did I understand correctly? It doesn't let you enter the COD HQ ? I'm telling you this because I too should update the bios, in fact it happens to me too, but I click dismiss and it lets me play anyway.",Negative
Intel,"for CS2, it was the newest driver that caused crashes exclusively, but on that driver I also got stronger boosts off the bat, hence it crashed faster. Now on 25.10.1(from windows update), COD still crashes with a black screen then tab to desktop with a driver timeout detected. Looking at afterburner(just using it to monitor clocks, no OC/UV applied or anything) the moment the GPU touches 3300+ I get thrown to the desktop. Can't even finish the training course even with ""speedrun strats"" before it crashes. It boosts [momentarily to 3300+](https://i.ibb.co/bgLFC0dp/coreclockcrash.png) and I get a screen freeze, crash, and sent to desktop with a driver timeout.   [These](https://send.vis.ee/download/103635cf66bdb907/#t2lRq409eeNwv6AaafhKJA) are both my crash report submissions. I'd go tomorrow over the stress tests, but I have managed to complete Time Spy/Steel Nomad without issues. And like I said, my system has has 0 issues before on a 2080ti.",Negative
Intel,"FYI, I passed [everything.](https://imgur.com/a/WyB9FeE)  This leaves the driver only. I made sure windows update didn't download its own driver this time, installed 25.12.1, still getting driver timeouts and crashes in games. I don't know what to tell you. Memtest86 also passed without any issues.",Neutral
Intel,that's... unexpected. Can you tell me what hardware this is with?,Neutral
Intel,"there won't be an ""fsr 5"" because any game with fsr implemented from here on out should, in theory, be compatible with every future version of fsr made, so numbering them isn't as meaningful. they're probably just going to stick with unofficial codenames like redstone for diffrentiation. Nvidia still uses versioning for DLSS despite it using the same system because it's good for marketing and diffrentiation so I'm not sure that dumping the version numbers is a wise decision but it also makes sense",Neutral
Intel,"I agree with you wholeheartedly, but super users do what they do best - sudo that shit. x)",Positive
Intel,"I've never had AMD Chat or Privacy View force install, I hate they show up in the available software to install when updating, but I just dont click to install them lol, just update the gpu/chipset drivers",Negative
Intel,I guess a snippet of the faulting component from the output would work.  This is a minidump. Do you have a kernel memory dump>?,Neutral
Intel,"sorry i missed this, seems it had expired. maybe someone downloaded it before i did?",Negative
Intel,"Right now in devmgr with re-running the driver installer from the site things look like this https://u.numerlor.me/2faMBA . I also remembered adrenalin has full driver details and everything looks fine there https://u.numerlor.me/w1Snxw https://u.numerlor.me/EOclpA so I think it was just the installer being a bit confused.  Compared to the installer on the first screenshot, when doing the actual update (from inside adrenalin) the Radeon Graphics was a separate item, and had a ""Download driver"" or something along those with the link I mentioned",Positive
Intel,What about the combined exe? It's still available? That will install both gen but was bugged with control panel disappearing on previous driver.  The combined exe is around 1.6GB.,Neutral
Intel,This might be it? Worth a shot I suppose.  Edit: This worked for me on the latest driver  [https://www.reddit.com/r/AMDHelp/comments/1oj27fj/comment/nr9h4ig/?utm\_source=share&utm\_medium=web3x&utm\_name=web3xcss&utm\_term=1&utm\_content=share\_button](https://www.reddit.com/r/AMDHelp/comments/1oj27fj/comment/nr9h4ig/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button),Positive
Intel,"i donâ€™t have this issue in any of the same games, but i have no idea what could be causing it in your setup and not mine though",Negative
Intel,"can you explain how one would reproduce this corruption who has never used second life and has no $ to spend in game? I am trying to reproduce the corruption you are describing but it seems that it has to do with in-game purchases or ""face layers"". can you explain how to apply these layers to the player?",Negative
Intel,geenz@ but yes,Neutral
Intel,any news? SL are not updating their customers with anything constructive and it is affecting most of us.,Negative
Intel,"Hmm, when I can, Iâ€™ll have another look! Thanks!",Positive
Intel,"I see. Is this specific to CS2 or does it occur with other apps on your end?  We're presently tracking and working on TDRs in that game specifically, though I'm kind of worried in a way that clock limiting works around this failure.",Negative
Intel,7900 xt!  I did a DDU and installed the newest driver too so I feel like it isn't carried over unless it was something from my settings ...,Neutral
Intel,"I do not, only the minidump but I've uploaded it again here [https://send.vis.ee/download/45e58a7ca188aa6c/#n9lCG59Od0RicrN\_IxLREw](https://send.vis.ee/download/45e58a7ca188aa6c/#n9lCG59Od0RicrN_IxLREw)",Neutral
Intel,"Yes it should be fixed under that scenario, and the combined package is linked on the release notes:  https://www.amd.com/en/resources/support-articles/release-notes/RN-RAD-WIN-25-12-1.html  https://drivers.amd.com/drivers/whql-amd-software-adrenalin-edition-25.12.1-win11-c.exe  Kind of guessing here but I believe the '-c' towards the end of the file name denotes a combined package spanning RDNA support.",Neutral
Intel,This worked for me btw - did it a few days ago before these drivers dropped. When I update I'll be using the same method.,Positive
Intel,"Are you running 4k in freesync on a 9000 series card?  I'm going by the radeon performance metric overlay saying minecraft/etc is using 300w power.  UE5 games are fine, games with an internal frame cap don't have an issue (well, they have their own frame pacing issues but that's not this).  I can always tell when framerate is going nuts because I can hear the squealing in my speakers when the gpu is at 100%. It's especially bad in menu's. If I turn off features/settings that improve quality or try a lower in game resolution, it gets much worse.",Neutral
Intel,just replying that I did find a regression point for the corruption in second life related to a change in the OGLP api :)   hopefully the change will be coming down the pipeline soon!   Id like to give a shout out to the user Eliza for being AFK where i first was able to reproduce the issue and i used their avatar to bug  check! o7,Positive
Intel,thanks a bunch. I'll pass this on to my ISV contact and see where we get with that.,Positive
Intel,You can find it here [https://github.com/secondlife/viewer/issues/5048](https://github.com/secondlife/viewer/issues/5048),Neutral
Intel,news ?,Neutral
Intel,"COD is the greatest offender - I can't even get through the training course for Zombies without a black screen>driver timeout message, even if I try to speedrun it in a way (because I've attempted it so many times) it is inevitable it's going to crash, that one crashes with this [error](https://i.ibb.co/KjxynXH5/image.png).  Again, NO OC is applied. Other than the ram running at 2666, which as stated with both mem tests successful and went through both by Karhu's test and Memtest, have no issues. Including no issues with my previous GPU,2080ti, again. CS, I can't even start a match with friends because it'll inevitably crash randomly, sometimes it is within 5-10 mins, sometimes it is near instant in a couple of minutes. Tried everything from 25.12.2 to 25.9.1. PSU is a RM1000e, using the 12pin cable natively from the PSU. It is all the way in, this PSU I specifically even got for this GPU as I didn't want to use an adapter to power the card from all the experiences I've read with the 12pin + adapters.  Here is also a [video](https://www.youtube.com/watch?v=cSkaI6WSfJY) of it happening.",Negative
Intel,"Okay, this is going to be tricky. I was under the impression this was completely eliminated, as we can no longer hit this internally.  Assuming that only your mouse input is blocked, I'll need your help capturing a usermode dmp of the RadeonSoftware.exe process via task manager.  This will involve setting some keys in windows registry. Are you comfortable with this?",Neutral
Intel,"huh, that's odd. Do you have any larger files over at       C:\Windows\LiveKernelReports\WATCHDOG\",Neutral
Intel,"Installed the c one. And seems to be working fine. 780M and 6800 here. Still when selecting a specific GPU for a specific app, both energy saver and performance show 6800. This bug has been forever. And it's probably just a registry key when the driver install. Win11.",Neutral
Intel,"iâ€™m using a 1440p freesync monitor, i basically always have fps counter on in all of my games so i can verify that vsync always works. even works without the freesync monitor. frame rate only ever goes uncapped when i disable vsync. is it only an issue at 4k?",Neutral
Intel,No updates there,Neutral
Intel,"at this point you kind of need to edit the windows registry to make windows usable: so I'm mostly familiar with the process.     though I'm a bit worried about the ""no longer hit this internally"" part since this has been a thing for quite some time now...",Neutral
Intel,I do actually have one in there that's 17MB from a BSOD yesterday caused by the AMD driver,Neutral
Intel,it's tagged as a milestone for feb,Neutral
Intel,"it was newly introduced in the 25.20 branch, eliminated at the tail end of that branch's production lifespan (25.12.1), though it seemed to still repro for several people, including AMDers. We've never observed it with 25.30 release candidate builds, which is why I'm surprised.  [Following this resource](https://learn.microsoft.com/en-us/windows/win32/wer/collecting-user-mode-dumps), can you set the DumpType DWORD at       HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\Windows\Windows Error Reporting\LocalDumps\  ...and set its value to 2, leading to the generation of full usermode dmps.  This is a non invasive configuration for the most part, and isn't something you should have to revert, but you can also save this location in the registry editor for ease of access.  When that's defined, you can reboot the system.  The next time you reproduce the issue with Adrenalin In-game Overlay hogging mouse input, see if you can pull up task manager (ctrl shift escape). The 'cursor' will be on the process list header, if you hit tab twice, it should focus on the hamburger menu element. from there you can arrow down to the Details header, and hit space or enter.   With details open, you can hit tab a few more times to cycle back to the process list elements. if you start typing 'RadeonSoftware.exe' (should just need to key in ""rad""), it'll pull that process element into view. I'm hoping you have a context menu key rather than a function button on your keyboard, if you hit that, you should be able to arrow down to the 'Create memeory dump file' option.  When you have that in hand, zip it up and fire it over to me via a method of your choice. I'm partial to https://send.vis.ee  hit me up if you need a hand with whatever",Neutral
Intel,"My PC won't wake up after sleep on previous 25.10.2 so I have downgraded to 25.9.2. It seems that AMD has added into Known Issue in 25.11.1.  >Intermittent system crashes may be observed while using some high-bandwidth HDMI 2.1 displays during display standby. Users experiencing this issue are recommended to use a DisplayPort connection as a temporary workaround.Â   Ahhh. It is caused by HDMI 2.1... I can't use a DisplayPort on my LG C2 42"" TV sadly so I'll have to stay on 25.9.2 for now.",Negative
Intel,"wait, so the branching did not happen? for RDNA2? I was under the impression that it was already in effect.",Neutral
Intel,"That last known issue is what a lot of us experience. Not fixed, can't use this one either.  Leaving your pc for long enough, like 25 minutes and your system just BSOD quickly into reboot.",Negative
Intel,I just did a clean DDU install to 10.2 last night because something weird was going on. Of course 24hrs later a new driver drops,Negative
Intel,anyone know if the low gpu usage was fixed for Battlefield 6? I had to roll back to 25.8.1,Neutral
Intel,"After install i cant open Adrenalin app, I get starting up for a few seconds and then it's closed and the tray icon is gone, too ðŸ˜¿.",Negative
Intel,I'm going to wait to see if others find it stable before I move on from 25.9.1 I think.,Neutral
Intel,Anyone can tell me if the new release fixes the Adrenalin Panel not showing when trying to open it? Iâ€™ve spent 1 entire afternoon try every solutions given by Google but today the problem is still thereâ€¦,Negative
Intel,"So what's the issue with Cyberpunk 2077? It's been present for quite a few updates now.   I'm asking because I've owned the game since day one but I haven't been able to play it cause my old 1060 6 GB was struggling hard with it, since then I've upgraded to a 7700 XT and for one reason or another I haven't gotten to play it yet but every time I update my driver and check the patch notes it's always a problem with it.   Can anyone with it installed and on RDNA3 tell me if it's playable?",Neutral
Intel,So does this mean Arc Raiders will stop randomly crashing in Windows?,Neutral
Intel,Just installed these zero issues so far!,Positive
Intel,"I dunno what people are expecting from Redstone?  It's on the game devs to implement, Blops 7 has the AMD Ray regeneration element of Redstone baked in.  It's not gonna be some driver toggle and all of a sudden you've got ray regeneration across all games.  Also all the people claiming ""not every game needs an optimized driver, Arc didn't get one"" when the RDNA 2 controversy happened, look, there it is, the optimisations were just late, hopefully it'll fix the crashing some people had in the game.",Neutral
Intel,Anyone know if this fixes the pink artifacting on Chromium based applications for the 7000 series GPUs? Can't check myself because I'm at work.,Neutral
Intel,There was a long delay with the blank screen. Made me a bit nervous,Negative
Intel,At this point i'm sure that cyberpunk will never be fixed.,Negative
Intel,Apparently I'm staying at 23.9.1 because I wanna keep using FSR4 INT8 with my RDNA 2 card.,Neutral
Intel,No fix for being unable to enable Noise Suppression...,Negative
Intel,When does Linux get this,Neutral
Intel,"Unfortunately after updating to 25.11.1 (even with a fresh install after using DDU), on a 9800X3D + 9070XT I am no longer able to open the Adrenalin software at all. It's the same issue as described in this post, caused by some conflicts between having both the RDNA3/4 drivers and RDNA1/2 drivers installed at the same time: https://www.reddit.com/r/radeon/comments/1okhlbw/_/  I had to roll back to the 25.10.2 combined driver which works fine with this setup without any issues, but yeah what a shame. Really hope AMD can resolve this issue shortly in future updates. You would think having both the latest gen AMD CPU and GPU would play nicely with each other, but alas...",Negative
Intel,"Why does the AMD install manager never find the updates for me? The AMD install manager only ever says the AMD Chat is available for install.  To get the updates, I have to uninstall 'AMD install manager' which allows me to manually check for updates in Adrenalin.",Negative
Intel,"Guys, I think I figured something out for those experiencing crashes. My RX7600 was overclocked in the default setting. I created a custom profile that matches the old default and seem to have achieved what appears to be stability in BF6.",Neutral
Intel,i am stable now in BF6 on AMD Adrenaline 25.11.1 ... and the game feels super smooth with FSR on 4k Ultra... so it was the AMD Driver 25.10.2 which was crashing ... annoying :-)  7800X3D + G.Skill Trident Z5 Neo RGB 64GB (2x32GB) DDR5-6000 CL30 + ASUS ROG Crosshair X670E Hero + 7900 XTX + Corsair Shift Series RM1200x,Positive
Intel,"Why is enhanced sync still broken? That was a feature I used to mitigate latency while capping frames to 120 and helped get rid of tearing. Now having it on causes major stuttering in a lot of games. I did come to find out that Vsync can be enabled globally and I'm not sure how long that's been a thing. Since being on the 5700 XT, 6900 XT, 7900 XT and now 9070 XT, I was never able to use it globally but it's been quite a few drivers since I've checked if it worked. I use Vsync and Gsync on my 5070 ti build and notice little to no added latency so I'm glad this is doable with Vsync and Freesync but I did like using enhanced sync and capping the frames to 120 better but this will do.",Neutral
Intel,"It's been almost 6 months and the 9060XT still crashes in DX12 UE5 games, especially with FSR4.  FFS AMD how long is a fix going to take?",Negative
Intel,Windows update keeps trying to update my driver.,Negative
Intel,I'm still having problems with FreeSync stuttering with the RX 7900XTX and this driver. Only when I revert to version 25.9.2 are the stutters gone.,Negative
Intel,No FSR4 on RDNA3 no care,Negative
Intel,"For how long ? One year already...Cyberpunk 2077 not fixed yet.   ""Intermittent application crash or driver timeout may be observed while loading a saved game in Cyberpunk 2077 with Path Tracing enabled. AMD is actively working on a resolution with the developer to be released as soon as possible.""",Negative
Intel,Yes thank you AMD for fixing Arc Raiders. I had to revert to 25.9.1 to stop the exception access violation issues. This would happen mid-game and I'd lose my entire loadout. Here's to hoping it works.,Positive
Intel,Awesome no stated support for Outer Worlds 2.... I guess driver timeout while playing it is not a driver problem...,Positive
Intel,hardware ray tracing crashes both oblivion remastered and the outer worlds 2 after 5 minutes to an hour of play and it seems completely random on my 9070xt.   To even get it to last that long I had to set my core clock -300mhz and turn off variable refresh rate and hardware accelerated GPU scheduling,Negative
Intel,"I noticed that this fixed my Geekbench scores     When I got my 9070 XT a couple weeks ago, my Geekbench 6.4 scores for OpenCL and Vulkan were about 185K and 187K.  Then they mysteriously dropped to around 135K each, and I believe it was after updating Adrenaline.  Now I just updated to 25.11.1 and I'm back at 184K and 189K for OpenCL and Vulkan.",Neutral
Intel,"> The AMDRyzenMasterDriverV30 service failed to start due to the following error:   The system cannot find the file specified.  Source: Service Control Manager, Event ID: 7000",Negative
Intel,This driver was way better than the version before it(for me at least).,Positive
Intel,"Since switching to this version, I've been experiencing constant driver crashes. i use RX7700XT sapphire pulse GIGABYTE B650 Gaming X AX V2 with 6000mhz 32 gb ram. I don't know which driver caused the constant pink artifacts when I have graphics card acceleration enabled, but it's getting worse with every update. Why AMD? -.-",Negative
Intel,"Sorry, I'm not very expert, I installed AMD version 25.11.1 from 0, before when I started the PC AMD was already open now instead the icon appears but if I press it says ""Amd adrenaline starting up"" is everything normal?",Neutral
Intel,For me the driver just times out randomly during normal stuff like youtube shorts. Today I opend steam and the driver timed out. That never happend with 25.10.1.,Neutral
Intel,"The Adrenalin Software instantly closes and restarts if I try to click on the ""Record & Stream"" tab (no crash/error report, it simply closes and then restarts in background).       Dunno if it's from 25.11.1 or not, it was the first time I was going to try it. Didn't tried a DDU full reinstall either, just a simple reinstall of the driver but for no use. Guess I will just use other software for recording so whatever but I'm curious if it's really a driver issue since I got no report pop up at all.  Gpu is a 9060 xt 16 gb.",Neutral
Intel,"I am an RX 6800 user, so on the RDNA branch of the driver,  25.11.1 introduced a severe performance regression on a DX9 game (Fallout New Vegas) , with framerate basically getting halved over what I had before  Downgrading to 25.10.2 fixed the issue , not sure if replicatable (I use 70+ mods) , and not sure if it affects any other DX9 games other than Fallout: New Vegas  (My cpu is an intel i5 10400F in case that matters, in New Vegas, on the 25.10.2 Driver, cpu utilization is almost always between 70-100% on the primary core that the game uses, while on the 25.11.1 driver , it was consistently at or below 50% , which leads me to suspect the new driver caused a regression in CPU utilization in DX9 and/or old single-threaded games, downgrading to 25.10.2 completely fixes the issue )",Negative
Intel,"Still no Redstone update. Well, wait for 25.12.1 just started. Hope AMD end the year with a bang.",Negative
Intel,"Brooooo, they didnâ€˜t fix the flickering in BF6 when recordingâ€¦",Negative
Intel,* Intermittent application crash or driver timeout may be observed while loading a saved game in Cyberpunk 2077 with Path Tracing enabled. AMD is actively working on a resolution with the developer to be released as soon as possible.Â  * Fucking LOL.,Negative
Intel,25.10.2 completely broke vsync... not even a mention about this in the notes?,Negative
Intel,"Hey OP â€” /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible to others**. This is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.  Your post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).  **Posts regarding purchase advice, PC build questions or technical support will not be approved.** If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the [Q4 2025, PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1nvf7bw/pc_build_questions_purchase_advice_and_technical/).   *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",Neutral
Intel,There is new AFMF features too.,Neutral
Intel,Did they fix the crashing for Outer Wolds 2 on 25.10.2?,Neutral
Intel,bf6 fps drop fixed?,Neutral
Intel,What about the cursor lock when pressing hotkey for adrenaline overlay? Is this fixed,Neutral
Intel,"Hopefully they fixed the anti-aliasing this time...  Nah, i'm sure they didn't.",Negative
Intel,"Don't know if anyone else has experienced this in Battlefield 6 on the last 2 drivers but whenever I uses those my GPU usage always stay at 100% load even with 144 fps cap on a 9070 xt. I revert back to 25.10.1 and then it stops doing that, reaches maybe 80% max in menu",Neutral
Intel,"I've been getting black screens since a while ago on my 6750xt, could be after a random alt-tab when gaming or after logging into Windows, on my tv connected via hdmi it looks green but my displayport monitor it is black, what is weird is sometimes  I can win+L and see the login screen again but if I log in it goes black, also while it is black and pc hasn't frozen yet I use an app called chrome remote deskop and I can see and do stuff from my phone, weird. Tried DDU, new drivers, nothing fixed it.",Negative
Intel,How is the driver ? 7700 XT here.,Neutral
Intel,Finally a potential fix for CPU metrics? Look forward to seeing if itâ€™s true!,Positive
Intel,Didn't they just release something already? Now we're getting another like. Do I have to update my rx 9060xt,Neutral
Intel,do yall use ddu for every driver or do yall just update it with the app?,Neutral
Intel,"New AMD update ðŸ‘ðŸ‘ðŸ‘ðŸ‘, I'll install it! Send Redstone as soon as possible!!!!! Thanks AMD!",Positive
Intel,I just canâ€™t wait for the instant replay to be fixed. Ever so often when I save a clip the infame notification starts glitching and I know that means the video Iâ€™m saving will have graphical glitches as well. It looks like big-ish squares of the image af slightly out of sync with the rest.,Negative
Intel,"There is a bug with Minecraft when using embeddium/rubidium or any forks on the latest driver. Many textures don't render at all. Launching through curseforge fixes it, which is very strange...",Negative
Intel,I'm not seeing this on my 6600xt. Only say 10.2 is available. Do I have to upgrade to that then upgrade to 11.1?,Neutral
Intel,>Intermittent system crashes may be observed while using some high-bandwidth HDMI 2.1 displays during display standby. Users experiencing this issue are recommended to use a DisplayPort connection as a temporary workaround.    Well that probably explains the crashes from the last driver whenever I locked my PC but that workaround is not an option. Good to see it's been recognised and being worked on at least.,Negative
Intel,Has anyone else been able to get FSR4 to work again with BF6? Worked for me before the season 1 update.,Neutral
Intel,Think this broke Vulkan in POE2,Neutral
Intel,"After installing this update neither Cyberpunk 2077 or The Witcher 3 will launch through Steam anymore. The hitting play just attempts to launch the game and then turns right back into the play button. Only CD Projekt games, no issues anywhere else.  UPDATE: Actual games run fine if launched directly from their install location. It's the CDPR launcher that Steam usually auto opens that broke after this update.",Neutral
Intel,Hope this patch will fix the driver crash while playing Arc Raiders. It crashes in a way that slows my computer so bad and i have to restart it. Temps are fine. Everything is off except image sharpening.,Negative
Intel,I mean Arc Raiders runs perfectly fine even on 23.9.1. Game optimized new drivers are a joke.,Negative
Intel,Hi u/AMD_Vik  Thanks for the VR refresh rate fix. However a bug that I though was related but still isn't fixed are the Beat Saber VR game wall shaders as they are still broken/distorted. Those shaders work on 24.12.1.  Could you investigate this u/AMD_Vik?,Negative
Intel,I never updated to the most recent driver but when I open up adrenalin and the update manager it only shows the previous one 25.10.2  I had to go to the link to get the newest. Does it always work this way?,Negative
Intel,"Wish i could use this software propelry for my 7800xt, everytime i have adrenaline installed after couple hours of gaming the whole pc black screens and gpu driver crashes running with default settings on the gpu. You have to use DDU to get it back running, gave up with adrenaline and installed only the bare bone gpu drivers without adrenaline and installed msi after burned, it has been running for a month just fine under very excessive loads.",Negative
Intel,"25.10.2 already have Terrible Fps spike and stutter in Gaming, this update did not fix the Problem (wth happen amd??).. 25.9.1 is Still the Stable one",Negative
Intel,Did this fix the insane fps drops in 25.10.2?   Reported here https://www.reddit.com/r/AMDHelp/comments/1lnxb8o/ultimate_amd_performance_fix_guide_stop_lag_fps and here https://www.reddit.com/r/lostarkgame/comments/1oq9ohp/insane_fps_drops_after_the_last_patch/,Neutral
Intel,"Installing this on Windows 10 got me a system shutdown at the first go xD. Luckily, the second one went just fine.  Also, since you seemingly cooperate closely with Activision on CoD, can you fix CoD:WWII constantly crashing? I just bought a month of Game Pass to play the game, but it's basically unplayable.     It'd be nice if you somehow fixed CP2077 situation - FSR implementation, bugs etc. This game is a showcase every single reviewer runs, not Call of Duty...",Negative
Intel,subtract strong cats brave outgoing husky coordinated important rustic juggle   *This post was mass deleted and anonymized with [Redact](https://redact.dev/home)*,Neutral
Intel,I can't even install it anymore as it doesn't recognize my iGPU (I have an R5 7600).,Negative
Intel,"The new version 25.11.1 still has the same problem that I had with version 25.10.2, that is, if while I'm in the game I press the Windows key on the keyboard, then when I return to the game the mouse cursor no longer works and I can't do anything anymore, which forces me to restart the PC, another problem is that when I open any game the overlay of the active Adrenalin techniques no longer appears in the top right, for the rest it seemed ok, but given the big mouse problem I mentioned above, I am forced once again as it was also for 25.10.2 to go back to version 25.9.1 which to date is the best and bug-free for my configuration with RX 9070 XT.",Negative
Intel,"Drivers fine for me on Arc Raiders so far, not had any issues with AMD drivers using a 9070",Positive
Intel,I'm glad the CPU metrics are showing again,Positive
Intel,"When I install this driver, I can't open the AMD Software any more. The start-up splash screen is shown for about a second and then it closes again. Doesn't matter from where I try to launch it. So it isn't the right click -> open bug.  There is no event in the Event Viewer.  I've reinstalled it, with prior DDU cleaning and disconnecting the internet connection, three times now... to no avail.  Anyone else?  Edit: Reverting back to 25.10.2 and it works fine. I'm tired of all these little quirks and annoyances I've had since I went for an AMD card...  Edit2: Tried 11.1 again and it worked now. The software started... once. The next time I tried to open it I got:   Download failed: Please visit [AMD.com](http://AMD.com) to download the compatible version of AMD Software.    I'm at the end of my rope here AMD... really getting tired of this",Negative
Intel,"Went to do the usual ""Leave AMD Experience Program"" after uninstalling the Installation Manager, but the option is gone.",Neutral
Intel,The update did not help. The problem with the driver crash remained (( ( Rx 7700 xt ),Negative
Intel,Any ideas for when the crashing when playing NBA2k25 is going to be fixed?,Neutral
Intel,"Is there another work around for system locking up?  My PC monitors never even turned off. I woke up this morning and the PC was simply frozen, had to turn off the power supply switch and turn it back on for it to work.  Couldn't even just do a hard reset.",Negative
Intel,"Im still having issues with easy anti cheat, rust game keeps crashing after a few minutes, maybe 2 or less",Negative
Intel,"2.5.11.1 fastest reroll for me to date, well done.   Booted arc raiders which now have support.  Game does not boot, instead I get a message frem arc davs that the driver has issues and want me to reroll to 25.9 ðŸ˜…   What a fucking joke",Positive
Intel,Shits been crashing my system since the update :( sapphire 7900xt,Negative
Intel,"Tested the new driver on 7700 xt, pink artifacts in browser and some weird flickering, some old bugs are fixed but  there are new issues instead, honestly it is not worth to update drivers at all if you find one driver that works without issues.",Negative
Intel,Still weird artifacts on COD MW2 game. Turned back to 25.9.1.,Negative
Intel,"With my Taichi RX 9070 XT OC after updating to the latest version 25.11.1 I still encountered the same problem that I encountered with the 25.10.2, which is that while I play Battlefield 6 press the windows button to go to the desktop and then return to the game my mouse crashes and I can't do anything, the only thing I can do is click ctrl+alt+delec and the mouse works and then I can restart the PC from there",Negative
Intel,"With this new driver, Adrenaline isn't automatically detecting Epic Games Store games (Steam games work fine). I tried with Fortnite, and it only adds to the games tab after launching it, but it doesn't work with ARC Raiders. I tried adding it manually, but I couldn't get FSR4 to activate. Is anyone else experiencing this?",Negative
Intel,"GV-R9070XTGAMING-OC-16GD    I have problems with Graphipcs since day one i bought from amazon.de. There is no driver that prevents some games from black screen and crashing on desktop, also Adobe Effects alongside Fortnite and others. The error is always amd software has detected a driver timeout on your system. Everytime i send logs, they updated drivers every 14days but no driver helped. I also made registry fix with increasing timeout from default 2s to 8s. Tlddelay did nothing, random black screens and app crashes to desktop. Also tried another cable DP instead of HDMI.    What can i do ???",Negative
Intel,"If anyone from AMD sees this. The recent drivers cause The Division 2 to consistently crash. It sometimes happens after 15m. Other times a few hours but is GUARANTEED to happen at some point. When it happens it's a hard reset case and doing so after about 10 times eventually wrecked my boot/login so I had to re-install Windows (bad AMD, spank!).   I assumed it was an issue with thelatest Windows update like the one that broke the other UBI Assassins Creed games a while back but when I installed 25.9.1 (with factory reset) I haven't had a single crash since.     7900xtx & 98003d.",Negative
Intel,Dose Arc raiders works now or not on new release 25.10.1 had prob with that game could not run it must go dx11,Negative
Intel,"Since this driver update my pc is unusable, only one screen loads the other stays black and after the os loads the screen just freeze, I can hear os sound like connecting and disconnecting of USB but the picture is frozen, I have the rx7900xt I tried to completely take the GPU off the motherboard and connecting back (after reinstalling the driver with factory reset when connected to the cpu display port) and it worked for some hours but after shutting down the pc and booting the next day it came back, you're saying the only fix for now is to roll back to previous driver?",Negative
Intel,Ð£ Ð¼ÐµÐ½Ñ ÐœÑƒÐ»ÑŒÑ‚Ð¸Ð¼ÐµÐ´Ð¸Ð° ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ð»ÐµÑ€ Ð²Ñ‹Ð´Ð°ÐµÑ‚ Ð¾ÑˆÐ¸Ð±ÐºÑƒ. Ð”Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð° Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²ÑƒÑŽÑ‚ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ñ‹Ðµ Ð´Ñ€Ð°Ð¹Ð²ÐµÑ€Ñ‹. (ÐšÐ¾Ð´ 28),Neutral
Intel,Noise Suppression still broken. 3rd release without that functionality in a row.,Negative
Intel,"Hay un bug que me suele pasar con varios de los ultimos drivers... cuando desintalo los drivers, la pantalla no vuelve, y no me deja saber cuando la desinstalaciÃ³n del driver termino, debo reiniciar la PC. Con RX 6800 XT.  Le eh pasado DDU, pero el error sigue estando.",Neutral
Intel,"Not sure if anyone else is experiencing this, but after this update, Adrenalin acts like BF6 isn't open so I can't force frame-gen thru the driver. On both 25.10.1/25.10.2 and 25.9.2, enabling frame gen in game doesn't work, so I've had to do it through the driver. On 25.11.1, NEITHER are working, frame gen completely non-functional. Tried DDUing/factory resetting 25.11.1, didn't work. Rolled back to 25.9.2 and works normally again...",Negative
Intel,"for some reasons, whatever game i play it either closes itself or looks so bad visually that the games (yes, games) are unplayable so i have resorted to uninstalling all AMD graphics software (drivers and applications) and am going to try to re-install it and see if i can choose a previous driver",Negative
Intel,is the horrible stuttering/flickering (feeling like dynamic hertz and micro stuttering) experience from the 25.10.x drivers fixed? If not I have to stay on 25.9.2,Negative
Intel,"This version, perhaps even the previous one, installs the AMD Adrenalin Edition software even if I select Driver Only when installing the drivers. Can you solve it?",Negative
Intel,"Adrenalin 25.11.1 terminating itself right after launching.  Can't run Adrenalin UI(App, Program...)  Seems like iGPU & multi-monitor related problems.  for more info [https://www.reddit.com/r/radeon/comments/1ox1gd8/adrenalin\_25111\_not\_opening\_after\_update/?sort=new](https://www.reddit.com/r/radeon/comments/1ox1gd8/adrenalin_25111_not_opening_after_update/?sort=new)  I'm going back to 25.10.2",Negative
Intel,Anyone else having trouble even getting the software to open since the update?   I've done a clean uninstall and reinstall of the drivers and software twice and Adrenaline won't even open.,Negative
Intel,"Hi u/AMD_Vik  im still waiting more than month legion go 2023 amd vga driver get released update latest for arc raiders,bo7,but asus rog ally x and xbox rog ally x yesterday updated already.is there a chance,we receive an update for legion go?also amd chipset driver very old for legion go.thank you if you answer me ðŸ™",Neutral
Intel,"Am I the only one seeing this bug in the metrics overlay? there are two ""gpu temp"", one would be that of the cpu,but written wrong. while the other metrics are written right,I already tried a clean reinstall with ddu, but nothing",Negative
Intel,"Anyone else getting per game Settings not being able to be changed? It sticks to just one whenever you click on a slider, this update and the last had it. Apparently older versions didn't and the only other fix is through screwing with the BIOS which i'd rather not.",Negative
Intel,I went back to 25.3 official gigabyte latest driver for 9070XT OC gaming and 2 days no crashes for now. Also changed HDMI for DP cable,Neutral
Intel,Still not working AMD NOISE S,Negative
Intel,New Game Support: ARC Raiders  I updated to this driver thinking it would be better for ARC Raiders since that is what I am playing right now but my game is crashing if I try to load into the Blue Gate map. I tried restarting my computer and it still happens. I almost lost all my gear because it took me a bit to roll back my drivers to 25.10.2. Come on AMD do better! It's a supported game on this driver! I surprisingly never had crashes in 25.10.2 unless I toggled the Adrenalin game overlay.  Running a 9060 XT and a 5900X.,Neutral
Intel,"I updated from 25.10.2 and saw the bug report tool pop up after restarting. I had no idea what caused it. I launched Battlefront 2 and the entire system froze, with WinAmp trying to play audio which sounded horrendous. I uninstalled Adrenalin, used DDU to clear everything then did a fresh install of 25.11.1.  On restart, the bug report tool showed again. This time Wallpaper Engine failed to show on the second monitor. I quit the program and started it again and boom - system freezes entirely.  So, this driver apparently has big issues with Wallpaper Engine. Uninstalled, DDU'd, fresh install of 25.10.2 and smooth sailing ever since.",Negative
Intel,I still have issues with the combo : 9070XT + PSVR2 + F1 25 in VR.   The image in VR is still bugged. The only version that is working is still 25.4.1,Negative
Intel,Software doesn't open at all for me. Used DDU but still doesnt work. Deleted CN folder from appdata aswell.,Negative
Intel,"After update I can't open the app. It just loads and crashes. I fully reinstalled windows and the error still persists. I can't update drivers or access the config, I can only download drivers externally. Any insight of what it might be?",Negative
Intel,"@AMD_Vik I still do not see CPU metrics after update via Adrenalin software, what to do?",Negative
Intel,"I'm new to this, i'm on 25.10.2 do i update? the only issue i have is fps drops on fortnite but other games i play are alright (r5 9600 igpu) it usually runs at 60 fps on performance mode but since last weeks of last season it started doing that",Neutral
Intel,"Unfortunately, version 25.11.1 does not start with Windows.",Negative
Intel,Is AMD going to come up with another driver soon?,Neutral
Intel,"My RX 7900 XTX now no longer run Frame Gen. The game becomes completely unusable even reporting 200+ fps, it still stutter like crazy.     Without Frame Gen all good, with Frame Gen, completely unusable for me :/",Negative
Intel,Over a few days after installing 25.11.1 on my 7900 gre system I had a few driver timeouts followed by a major screen-freezing crash which corrupted my drivers. DDU'd and rolled back to 25.10.2 and haven't had any new ptoblems.,Negative
Intel,"After installation 25.11.1 (from 25.10.2)  black screens entered the chat. After DDU and rollback to 25.10.2 they stayed, and after rollback 25.9.1 the same... RX 5700 XT. Sadly ðŸ˜ž.",Negative
Intel,"is there 25.11.1 for windows 10? the filename that i downloaded from AMD website is ""whql-amd-software-adrenalin-edition-25.11.1-win11-s"" where usually its filename includes windows 10 along the lines",Neutral
Intel,"they need to fix the BF6 texture corruption glitch, it's annoying af. had to roll back to 10.2",Negative
Intel,Any word on fixing the driver timeouts on the 7900xtx its a bloody joke worst gpu i have ever bought,Negative
Intel,Any of you also have issues with afmf2 and the game not opening adrenalin software or showing performance counter after enabling it?,Negative
Intel,"this shit was fucking with my PC, DDU current drivers and reinstalled 25.10 straight from Gigabyte Program and everything works again",Negative
Intel,getting bsod randomly since 25.9.1 sad..,Negative
Intel,"I started having an issue since the 25.11.1 update with unreal editor where all of my tools menus instantly close, nothing else changed except for this driver update and I've heard of Nvidia having similar issues with driver updates in the past so I think it may be the cause, Going to revert to an older driver and see if it works",Negative
Intel,"I've spent the last few days uninstalling, reinstalling, DDUing, doing everything I could think of to get Adrenaline to start/work. It would show the splash screen and then quit. No way of re-starting it. Couldn't open anything that used Vulkan and got errors. Couldn't install the Windows Store version cause ""driver error"". I eventually used DDU one last time and uninstalled everything AMD and was able to just install the driver through MyASUS. Now I'm able to open all the software again that wasn't starting before. I'll be holding off on installing Adrenaline again anytime soon. Sucks cause I want the features, but I couldn't use the programs anyway. I miss having nvidia.",Negative
Intel,"It seems on the latest Radeon driver that freesync is broken within CS2 when running fullscreen windowed. Freesync works initially when the game starts. But as soon as I alt tab, freesync breaks and I get screen tearing. I rolled back to 25.9.1 and I can confirm it works again as expected. So it seems this is a recent regression. Can we get this addressed please? u/AMD_Vik",Negative
Intel,"Been having issues with VLC freezing and stuttering during playback (video only, not audio) since anything after 25.9.1. Guess I'm gonna roll back to that until it gets figured out.... really frustrating.",Negative
Intel,Substance Designer won't start with this one. Access violation with amdvlk64.dll. Adrenaline won't start either,Negative
Intel,"Sorry but for me the drive give me crash pop up message every time i boot up my pc. Also just right now i got a freeze, black screen to all my monitors.",Negative
Intel,The worst driver this year so far,Negative
Intel,"Still havent fixed the noise cancellation lmao, guess its another month+ of old version :) Thanks amd, truly doing wonders.",Negative
Intel,CS2 crashing with driver timeout after tabbing out or watching streams on 2nd screen 7900xtx,Negative
Intel,"When is 25.12.1 coming out? I have read only bad things about 25.11.1 here, so I wanted to skip this one.",Negative
Intel,"Can we use FS4 on rx6000 series now without it crashing now on this driving now, or do i always need to keep downgrading my driver ?",Neutral
Intel,So no redstone yet,Neutral
Intel,FSR AI frame gen??? Didnâ€™t they say thatâ€™d it would also have a driver toggle?,Neutral
Intel,Did AMD ever add support for Cronos?,Neutral
Intel,Well Star Citizen will load now!  Now some longer term testing....,Positive
Intel,Anybody tried this with Anno 117 yet? Iâ€™m hoping it helps performance,Positive
Intel,Problemas y problemasProblemas y problemasProblemas y problemasProblemas y problemasProblemas y problemasProblemas y problemasProblemas y problemasProblemas y problemasProblemas y problemasProblemas y problemasProblemas y problemas,Neutral
Intel,NO LA DESCARGEN ES MAL LAGGGG EN LOS JUEGOS,Neutral
Intel,So are the issues with Arc Raiders fixed? I had to roll back to 25.9.1 because 25.10.1 kept crashing my game. Did they actually fix it?,Negative
Intel,Disabling ULPS seem to fix the crash. My pc crash pretty often when i wake the screen or turn it on if i dont disable ulps with msi afterburner. 9070xt,Negative
Intel,Doom: The Dark Ages does not lauch with the latest driver. I had to rollback to 25.9.2 in order to play. Please fix,Negative
Intel,Last driver crashes Apex Legends every joined game. Im fuckin over amd.,Negative
Intel,Support for Anno 117: Pax Romana - Incorrect. I have needed to downgrade back to 25.9.2 to play Anno 117: Pax Romana without crashing. The last updates have been a joke. I now cannot use adrenaline due to needing to play on this earlier version to be able to play any new games. Does anyone know of where I can express my complaints?  Edit: This is also the same for Arc Raiders.,Negative
Intel,"Here we go again, jetzt stÃ¼rzt Battlefield 6 wieder ab. Mit dem Treiber davor hatte ich es in den Griff bekommen auÃŸer XMP war aktiviert, dann stÃ¼rzte es dennoch ab.    Also es scheint definitiv ein AMD Treiber Problem zu sein.    Gut das bei euch die Kunden die Tester sind und nicht ihr das Ã¼bernehmen mÃ¼sst.  PS: Gespielt wird mit einer 7900XT und einem 7800X3D.      Das war definitiv meine erste und letzte Karte von AMD. So viel Probleme hatte ich mit Team GrÃ¼n nicht.",Neutral
Intel,Yeah same here LG c5 42inch ðŸ˜°,Negative
Intel,"Having system crash issues after putting the PC into sleep mode. Samsung 57"" Odyssey Neo G9. Now I know who to blame.  Reinstalled AMD drivers and changed the settings so that my PC never gets into sleep mode (turns off the screen, but doesnâ€™t sleep or hibernate). This fixed the issue temporarily for me :(  Also from the system crash minidump, it's very clearly an AMD driver issue  **IMAGE\_NAME:  amdkmdag.sys**",Negative
Intel,"I have this but on display port, HDMI works fine",Neutral
Intel,"DDU with full uninstall of all AMD related things and then chipset driver install, fresh GPU driver install fixed the crash from wakeup for me.",Neutral
Intel,"I had to go back to version 25.9.2 but I no longer have AMD Adrenalin. If I try to install it, it reinstalls version 25.11, which crashes my game. Is it necessary to have AMD Adrenalin? I have a 7900 XTX and a Ryzen 9 7950X3D.",Negative
Intel,Could you try a DisplayPort to HDMI adapter? I wonder if it works in this situation =D,Neutral
Intel,I have the same issue with display port but itâ€™s okay with hdmi :/,Neutral
Intel,"Honestly, I plan to make sure my next display has Display Port in it. Mostly for linux though.",Positive
Intel,"There will already be branching inside the code of the driver. This has been the case already, to various degrees, for years. It's not new.  It's just whether AMD wants to formally spread those branches out on a file / compilation level and distribute different packages. And then publicly whether they commit to updating all branches of code or only some.  For any particular bug / feature / optimisation, there will be some cases where it's the same code path for practically all RDNA versions, you fix it once and it applies to everyone. For some, it might be very similar but not the same, just some slight tweaks and what gets fixed in RNDA3 can also be applied to RDNA2. For some, there's some hardware feature of RDNA3 that would make the fix easier there and it will be much more work to adapt the same to the RDNA2 branch. Of course, we have very little outside insight into the exact spread of these cases that AMD wants to pay their engineers to work on.",Neutral
Intel,There is a separate code path for specific things bit both are in those combine driver. Its mostly about certain ray tracing extensions   There are also fp8 and fp16 codepaths    People misunderstand and thought its like pre rdna stuff.,Neutral
Intel,"V25.10.2  hereâ€¦ I have both CPU and GPU by AMD and if you download the specific package, they install drivers only for the specific hardware (and they have different dimensions). For installing both drivers you have to download the AutoDetect package.  EDIT: typo",Neutral
Intel,"I'm one of the 5 people still running a Vega 64 and for years we've had a separate driver ""branch"" despite being able to install new Adrenaline versions. Bf6 beta wouldn't run without spoofing my actual internally installed driver, which hadn't been updated since they dropped support.",Negative
Intel,combined again it looks like ðŸ¤·â€â™‚ï¸,Neutral
Intel,the display team are working on this with priority. Hoping to have this out in the next release. There are two similar display issues on their radar which are both P1.,Neutral
Intel,"what is triggering this? I can let my amd pcs run all day without any crashes. (7900XT,5700XT and 6900XT)",Negative
Intel,"Are y'all playing on televisions? HDMI isn't really optimal for modern monitors, with DisplayPort being the better spec for computer graphics.  Not criticizing, just curious as to use-case.",Neutral
Intel,You try install last chipset driver ?,Neutral
Intel,"Bummer you're having issues. Hopefully AMD gets it straightened out for you. Out of curiosity, why did you decide to use HDMI on your monitor instead of display port? I thought HDMI was mostly used for TVs nowadays.",Negative
Intel,So it's the driver that's why that happens ðŸ˜¡ and it's not fixed?,Negative
Intel,Thank you for your service,Positive
Intel,"I've had the ""device_hung"" error and the best drivers are those you are on.   AMD needs a lot of help with their drivers...",Negative
Intel,Any update mate?,Neutral
Intel,"No, radeon drivers update cannot upgrade your CPU so that it would stop bottlenecking your GPU.",Negative
Intel,"Had the same issue, just ddu and reinstall the drivers manually, problem now is with my hardware monitor screen not working, I have an aorus board with an internal hdmi, that is not being detected, will try to reinstall chipset drivers",Negative
Intel,"multi gpu? got the same problem with rx 6400 + 7900xtx. plugging in my secondary display to 7900xtx fixed the issue, but what's the point of secondary gpu if its not working properly...",Negative
Intel,"Workaround:  Win+P and disable the second Monitor in iGPU, then start adrenaline and you can enable the second monitor again  software should be okay then",Neutral
Intel,"I'm the opposite, IÂ just want adrenaline app to stop everytime I right click on desktop or open file explorer.... Bruh",Negative
Intel,"yeah same, my experience with 25.10 was terrible, had to DDU it once to get back my CPU metrics in Adrenalin, then DDUâ€™d it again to go back to 25.9.2 since games were stuttering.",Negative
Intel,Same.,Neutral
Intel,"Not stable, ddu install 11.1 and lag in old dx11 mmo game(BDO)  Same as 10.2, 9800x3d with 7900xtx, i can keep 144fps in town , 11.1like  fps 60-65 and lag spikes  Im go back to 9.1",Negative
Intel,"Both 10 and 11 are shit with 7xxx series, myself and most others have gone back to 9.1 or 9.2. Might be alright with the 9070, might not",Negative
Intel,I'm playing it on 7900 GRE with FSR4 INT8 with no issues.,Positive
Intel,na it works the problem only occures when using PathTracing and you are not going to play on an AMD card with PT anyways and especially not a 7700XT,Negative
Intel,"I played recently the latest patch of Cyberpunk 2077 with RX 7700 XT with drivers from February this year, 25.2.1 and had no issues, no stutter, no lag, no crashes, the problem is with path tracing or ray tracing something, you don't have to use that even and it lowers fps probably for very little visual gain.",Positive
Intel,If it still crashes set RTX Global Illumination to Static.,Negative
Intel,"pretty sure anti lag was causing my system to freeze up when in arc raiders on 25.10. turned it on and issues, turned it off and haven't had issues since",Negative
Intel,"Optimizing has nothing to do with fixing crashing, generally, that would be bug fixing.",Negative
Intel,"The only Redstone component that will work through the driver for upgrading existing features (like FSR3 FG) will be ML FG, but only for games that have FSR 3.1.4+(and FSR FG), as theyâ€™ve already announced in a GPUOpen article quite a while ago.   Ray Regeneration (RR) and Neural Radiance Cache (NRC) require dev implementation since theyâ€™re much deeper in engine code/inputs.",Neutral
Intel,"Does BO7 have ray tracing? Where is that feature mentioned, would be keen to read about it ðŸ¤“",Positive
Intel,"Itll probably work through optiscaler, but a game like indiana jones has locked dlss inputs, so you need dev implementation",Neutral
Intel,"And all my USB devices dropped for a while, far worse experience than the usual double screen flicker & it's done.  Edit: seems like that was because of iGPU driver for my Zen4. In the end and after 6+ reinstalls, I'm stopping on 25.9.1 and have Vulkan working again.",Negative
Intel,What is wrong with CP? Just got my 9070 after 10+ years of nvidia :o   Ah nvm i see it.,Negative
Intel,Ugh,Neutral
Intel,"Most likely when your distro provides a kernel update.  I'd give this a quick read: https://www.gamingonlinux.com/guides/view/how-to-install-update-and-see-what-graphics-driver-you-have-on-linux-and-steamos/  Pretty much the default is that you will be using the Mesa driver collection and they were last updated yesterday.  The fixes there do not correlate with the ones in this thread (I think).  As long as you are on a ""cutting edge"" type distro then you can expect that update in the next few days/weeks.  If you are on a ""stable"" distro that doesn't update often, you may be waiting a realllly long time.",Neutral
Intel,"Get what exactly? Features? Bug fixes? Optimizations?   Every 2 weeks there are new Mesa driver updates with bug fixes and performance optimizations. As for features, you have to wait a few months for versions with big numbers (25.2 is soon updating to 25.3, adding Anti-lag 2).   Depending on your distribution, you can get these updates faster or slower.",Neutral
Intel,"Linux doesnâ€™t work like windows. You get updates directly via Mesa stack. When your distro provides mesa package update, thatâ€™s when you get driver updates, and theyâ€™re completely different from windows branch.",Neutral
Intel,just uninstall it I prefer manual check myself.,Negative
Intel,So AMDs default driver overclocks and doesnâ€™t reflect that in the values?,Neutral
Intel,Same issues here i underclocked it but this new update just made it worse,Negative
Intel,ok it is still crashing ... complete reboot :(,Negative
Intel,"I feel like that crash is more on DICE's side, since Nvidia users get the same exact crash, although less often.  I tried everything I saw on the internet, nothing really works. Sometimes I can play for hours on end, other time game just crashes randomly after 10-15 minutes.  I am going to try to downgrade to 25.9.1 and see how it fares, since I remember that driver being really stable for me (6800XT).  Edit: been playing for 4 hours, no crash yet. Never had such a long session without the game crashing.  Will update in the next few days.  Edit 2: haven't crashed once, been playing at least 2 hours every evening.",Negative
Intel,Okay.,Neutral
Intel,Iâ€™m hoping Valveâ€™s new steam machine will push them on that since itâ€™s RDNA3 based.,Neutral
Intel,The RT/PT reflections leading to CTDs issue? We're working with CDPR to resolve this - it's not caused by the driver software.,Neutral
Intel,"Stuff like this is honestly bugging me.  First AMD card and while it is okay to have some driver issues, stuff like that shouldn't be a thing at all. It can't be that some bugs keep existing for multiple months let alone more than half a year.",Negative
Intel,A much more fundamental thing like playing video in a window without stuttering took 3 or 4 driver updates.,Neutral
Intel,"> One year already...Cyberpunk 2077 not fixed yet.  On year, I did not know.  I was thinking of a 9070XT earlier in spring, but choose... differently",Negative
Intel,welcome to amd,Positive
Intel,Yeah hoping it works. I guess the point about crashing with easy anticheat was the fix? Doesn't specifically mention but it was with raytracing enabled I was getting the crash. I suppose we shall find out.,Neutral
Intel,"Weird. I was running 10.2 and things were running fine for the most part. I kept getting a pop-up on launch saying there was a known issue with that driver and Arc Raiders though, so I rolled it back to 9.2 and had more issues on that release than the one with the stated problems.  My fan control profile broke and stopped tracking gpu temp so last night I did a clean DDU install back to 10.2.  Of course 12 hrs later the new release drops haha  Hopefully Fan Control continues to play nice if I just update",Negative
Intel,Same. Never even had Ryzen master installed.,Negative
Intel,"I'm receiving the same error in Event Viewer, but I have installed Ryzen Master. Most likely it's also a component of the Adrenalin drivers for system tuning and monitoring.  Registry search shows two keys for ""AMDRyzenMasterDriverV30"" (in both CurrentControlSet and ControlSet001): Computer\\HKEY\_LOCAL\_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\AMDRyzenMasterDriverV30  The ImagePath points to: C:\\Windows\\System32\\AMDRyzenMasterDriver.sys and the file exists. It's valid.",Neutral
Intel,25.2.1 had no pink artifacts on my Pure 7700 xt Sapphire but i switched to 25.11.1 and got it now also and also some flickering.,Neutral
Intel,What is redstone?,Neutral
Intel,What's weird is Black Ops 7 has ray regeneration.,Negative
Intel,"I'm afraid it may be released in January like they drop new major this year like AFMF 2 upgrade, FSR, etc..",Neutral
Intel,vsync issue fixed with win 11 KB5068861 update.,Neutral
Intel,had no issues with vsync on 25.10.2,Neutral
Intel,works fine for me,Positive
Intel,I agree.  I also have this issue  Weird is if you turn on amd overlay it fixes itself,Neutral
Intel,"That it did, lol. My only complaint.",Negative
Intel,"Not a problem on Linux with Wayland. Ever.   Main reason I ditched Windows 11, constant screen tearing and input lag made me go crazy.",Negative
Intel,The new AFMF features were added in 25.10.2 - Still waiting for AFMF 3.0 at this stage,Neutral
Intel,Suggest if you are using powertoys to stop... After their last game update it was crashing left and right. Powertoys was cause. I only crashed once and I believe it was cfeen blanking was cause for that. I was away too long.,Negative
Intel,"Fps drop over time? That's a game issue, it's got a memory leak",Negative
Intel,"What kind of FPS drops? I was having dog shit frame pacing, and hardcore drops to like sub 60 FPS at 1440p medium/high with a 6950XT. I went through every setting and found that anti-lag was the culprit. Once I turned that off it all went away. Then with future frame rendering it got even smoother. Now I can hold 100+ FPS at all times, sometimes peaking over 200 FPS in some scenarios. And frame times are smooth as butter.",Negative
Intel,Iâ€™d settle for bf6 going one entire game without drivers crashing the game and freezing pc,Neutral
Intel,"I'm also having this ""problem"" with driver 25.10.2; I haven't tested it with 25.11.1 yet.",Negative
Intel,Crashes?,Neutral
Intel,I have this problem in all games.,Negative
Intel,"Hello, I've been having this issue and I have exactly your gpu and cpu, whenever I played valorant and I alt tabed many times the screen goes black and keyboard become unresponsive but I can still hear friends in discord and they can't hear me, after conctacting valorant support and messing with alot of settings I think  what fixed it for me is to add these in windows defender exclusions : C:\\Riot Games\\VALORANT\\live\\VALORANT.exe   C:\\Riot Games\\VALORANT\\live\\ShooterGame\\Binaries\\Win64\\VALORANT-Win64-Shipping   C:\\Program Files\\Riot Vanguard\\vgc.exe   C:\\Program Files\\Riot Vanguard\\vgm.exe   C:\\Riot Games\\Riot Client\\RiotClientServices.exe   I hope this helps",Negative
Intel,"DDU was only ever for switching GPU families, e.g. Nvidia or Catalyst to Adrenalin.",Neutral
Intel,"Sad to say I am having the same issue. Did you find any workarounds, or just downgrade?",Negative
Intel,"You don't need to make it work on Adrenalin, Battlefield 6 already has FSR 4 support integrated into the game, so you don't need to override, just turn off FSR 4 from Adrenalin.",Neutral
Intel,Works on 25.10.2. I have been seeing ppl said it doesn't work on this driver. It also didn't work on 25.10.1 for me as well.,Negative
Intel,Epic version runs just fine.,Positive
Intel,Cyberpunk GOG last version patch runs fine on this driver.,Positive
Intel,"Hey there, can you give an example of how this looks now versus how it's supposed to?",Neutral
Intel,are you able to install driver only with the newest drivers? When i choose minimal or driver only it still install full version of the software anyway. Only 25.9.1 works perfectly.,Neutral
Intel,Yeah... it can happen. I was already locked outside windows after a bsod with my old nvidia card. I had to use a linux usb drive to fix it through the command line.,Negative
Intel,It's most likely the same as I've described here:  [https://www.reddit.com/r/Amd/comments/1ow4in7/comment/nop2o04/](https://www.reddit.com/r/Amd/comments/1ow4in7/comment/nop2o04/)  But yeah unfortunately seems like all you can do for now is either roll back to 25.10.2 or disable your iGPU if you don't use it,Negative
Intel,probably because those issues are build specific.  I've not had any freezing or locks on any drivers this whole year.,Neutral
Intel,"The game is booting, this message was for the 25.10 they just didn't removed it",Negative
Intel,I don't know your system specifications but in many cases setting the BIOS to PCIe v4 could help.     Try change in your bios,Neutral
Intel,no I hit alt R opens right away.  And i did an upgrade install over top of 25.10.2 no DDU or AMD clean up utility.  When you say you did a clean install was that just from control panel and remove?,Neutral
Intel,"First time yes, i downloaded with -s letter, but the last time i downloaded smth like -combined(1.6 gb). All two's is for WIn 11.",Neutral
Intel,"To be clear, are you able to confirm that VRR is disabled after you alt-tab? Do you have a display-side OSD to verify?",Neutral
Intel,"Good call, it caused nothing but problems for me and pretty severe. Were talking driver timeouts with black screens and even a couple bluescreens.",Negative
Intel,"Not even 7000s have support for FSR, you'll have to stay on 25.9.1",Neutral
Intel,My 9070 xt crushes while I try to use fsr 4 on new drivers,Neutral
Intel,Why don't you try it and let us know if you can. Would be helpful for lots of us,Positive
Intel,It's in Redstone. Still not out yet,Neutral
Intel,Didn't work for me...,Negative
Intel,Wait until you see how much your browser's cache is churning...,Neutral
Intel,Why cant you use Adrenalin? I'm using it on 25.9.1,Negative
Intel,I just received a windows extension update for my LG monitor. If you can boot up go check.,Neutral
Intel,The last time I had this problem it was a RAM issue.,Negative
Intel,I have this for my ThinkPad laptop with its internal display. Good to know I'm not the only one.,Positive
Intel,"if it happens, fill in the bug report that pops up. more reports will help AMD identify the issue better.",Neutral
Intel,I have DDUed the driver before upgrading. I still face the GPU crashes during display standby.,Negative
Intel,"Wait, chipset drivers uninstall too? I'm going to have to fix that on my system...",Negative
Intel,Do u reintall already up to date chipset drivers?,Neutral
Intel,You should use the Factory Reset installation in the AMD Driver Installer so it removes the newest AMD Adrenalin and install back the correct Adrenalin driver.,Neutral
Intel,"I don't have a DisplayPort to HDMI 2.1 adapter to try, sorry.",Negative
Intel,doing so (separation) will create a freak out shitstorm part 2.,Negative
Intel,> People misunderstand and thought its like pre rdna stuff.  It is. They've simply bundled two separate drivers together. RDNA1/2 are still stuck on the same 21033.x branch while RDNA3/4 have moved first to 22021.1009 and now 22029.1019.,Neutral
Intel,Is it combined though?  7900 XT Driver: ......amd.com/drivers/whql-amd-software-adrenalin-edition-25.11.1-win11-nov.exe (25.20.29.01 ?)  6800 XT Driver: ......amd.com/drivers/whql-amd-software-adrenalin-edition-25.11.1-win11-s.exe (25.10.33.03 ?),Neutral
Intel,All it takes is one random Reddit comment with some upvotes spreading misinformation and you will see people posting articles about it,Negative
Intel,"You have two differnt drivers installed and running at the same time, one for APU and the other for GPU? is that what you are saying?",Neutral
Intel,Combined only as far as the two driver packages are now in one file. RDNA1/2 are still stuck on 32.0.21033.x branch. RDNA3+ are on 32.0.22029.1019.,Neutral
Intel,Last driver was branched right? I never updated coz I had just fidled with the files to make FSR4 (INT8 or whatever its called run) and didn't wish to do it again...,Negative
Intel,Can we please have a fix for the 7700 xt artifacts showing? It's been ignored for so long. Using hardware acceleration on chromium (and not just that) causes pink artifacts everywhere.,Negative
Intel,Thank you for communicating,Positive
Intel,Unfortunately happens to me too. So for me itâ€™s a big issue as I canâ€™t update to this driver until it is fixed ðŸ˜°,Negative
Intel,"I have a dual PC setup, one system with a 9070xt where I have seen this bsod related issue, mostly when toggling HDR.Â  The other system has exclusivly an RTX 3090 that also has the same HDMI 2.1 related system bsod, but Nvidia driver instead.   It idles, display sleep, 1 in 5 ish chance it locks up or bsods on wake.Â  Issue goes away using a non 4k 240hz display.Â Â    I believe this system crash is deeply related to DSC on Windows.Â  I only got these two PC bsods when I bought a 4k 240hz display.Â  Returned a monitor (bad oled) and the issue went away.Â  Got a new oled a few weeks ago and now I have these bsods again.Â Â    Never had a bsod before I got these 4k 240hz displays.Â  Fresh Windows 11 installs too between both PCs and between my first and second oled.Â  Systems are both solid and stable.Â Â    Linux works fine, but no HDMI 2.1 support thus no 240hz, which makes using the oled pointless imo.   While digging into my issue, I wanted to see if DP2.0 / uhbe20Â  compatible display would have these issues, but my current display only has HDMI2.1 and dp1.4.Â  Hopefully someone else had experience with them on 4k 240hz.",Negative
Intel,Thank you AMD my bad for getting upset,Neutral
Intel,Thank you.,Positive
Intel,Any word on when noise suppression will be fixed? I would actually lowkey love a right up and why itâ€™s failing. Would be cool to see the technical details if thatâ€™s possible. (Iâ€™m actually more interested now on why itâ€™s not working vs just getting it fixed).,Neutral
Intel,Thank you!,Positive
Intel,There's a long-time standing issue with Chrome and hardware acceleration. Will that ever be made a priority?,Negative
Intel,Redstone when?,Neutral
Intel,"LG OLED CX and newer are good monitors.  I am using it with my PC and PS3, PS5, Blu-ray 4K Player...  I must say that that was my very first actual driver issue with AMD.",Positive
Intel,Not always true. HDMI 2.1 has more bandwidth than dp 1.4. I have a ASUS pg32ucdm and HDMI looks better and uses a lower dsc ratio. I have a Nvidia GPU in my main PC however.,Neutral
Intel,"Yes, my 9070XT is paired with a 5600X hooked up to my TV for couch gaming. I have a separate PC with a monitor for desktop gaming. My TV doesn't have DisplayPort, very few did when I bought it.",Neutral
Intel,"I currently run a gaming monitor as my primary one, with DP, and a plain old Lenovo office monitor as my second one. It only has HDMI, so i wouldnt be able to use it with DP.  I assume this may be the case for a lot of people. Getting a ""higher spec"" 2nd monitor really isnt a priority for me, as i just need a second screen for productivity when working instead of gaming.",Neutral
Intel,Non pc monitor tvs are sometimes cheaper especially for larger sizes. Iâ€™m on lg c5 oled 42inch and it only has hdmiâ€¦,Neutral
Intel,"Not universally true, hdmi and displayport depending on the version supported are very comparable.   Dp 1.4 Vs hdmi 2.1 is where hdmi has more bandwidth, before this dp was the easy choice.",Neutral
Intel,"> Are y'all playing on televisions? HDMI isn't really optimal for modern monitors, with DisplayPort being the better spec for computer graphics.  ~~Tell this to Valve, who are about to bring out a gaming-focused mini PC which **only** has HDMI 2~~",Negative
Intel,"This was true prior to HDMI 2.1 but no longer the case. However, monitors with HDMI 2.1 do still cost more than those with DP1.4 which has similar albeit slower bandwidth.",Neutral
Intel,"Yes, I am on a television. ""HTPC gaming (and turbo tax) from the recliner master race""!",Positive
Intel,> Are y'all playing on televisions?  Do you guys not have phones?,Neutral
Intel,LG OLED TV as a monitor. I have LG OLED CX which comes with HDMI 2.1.,Neutral
Intel,My game keeps crashing due to the same. I want this fixed ASAP. You'd think they'd test the biggest recent releases before publishing an update.,Negative
Intel,"I am also having a ton of crashes in BF6 RedSec, but I'm not getting any errors. Game just freezes, then crashes.",Negative
Intel,"I got a new pc 2 days ago and i literally cannot downgrade my drivers without amd forcing me onto the latest, even if i download the more stable drivers directly. Got any advice?",Negative
Intel,"I kinda fixed it by turn off XMP/EXPO running the ram the lowest bus, still crash to but 1 crash every 2-3 hrs still better than 15 minutes.",Neutral
Intel,Why does it seem like driver quality/support has gotten substantially worse this past decade? Are we running out of skilled software engineers or is hardware just getting too out of hand?,Negative
Intel,there are multiple reports of lower gpu usage with 25.9 and above.. after going back to 25.8 I have 15%+ fps  I guess the constant crashing with rdna1 cards is also not related to these drivers,Negative
Intel,"Tried but didnt work, tried the 25.9.1 and get error that no Software is installed tried the auto update to 25.11.1 again and same error with open and shut down again",Negative
Intel,"Thanks a lot mate, i tried everything and adrenalin not worked but after yours advice it's fine. Thank you!",Positive
Intel,"open powershell as an admin and paste this in. (type powershell in the search bar and there will be a choice to run as admin)  Get-AppxPackage -AllUsers | Where-Object {$\_.Name -like ""\*AdvancedMicroDevicesInc-RSXCM\*""} | Remove-AppxPackage -AllUsers",Neutral
Intel,OK thought I was the only one. 25.10 is bad bad,Negative
Intel,"25.10.2 just straight up didn't work for me when trying to play Arc Raiders (constant UE crash when loading into a match), in fact it actually gave me a popup when launching the game to downgrade to 9.2.  Only driver since switching back to AMD to give me issues.",Negative
Intel,Thanks for testing it,Positive
Intel,"I posted before in an arc raiders thread, but I've had zero issues with my 7900gre on 25.10.2. Playing since launch. I don't use any sort of overlays and play in borderless windowed always. Performance is locked on 140+fps native res 1440",Positive
Intel,I thought FSR 4 was only on RDNA 4? ðŸ¤”,Neutral
Intel,My thoughts exactly. Thanks.,Positive
Intel,Ohh okay. Yeah I don't use any of that lol. Hopefully it won't give me any issues. Plan on playing it after FF7Rebirth.,Neutral
Intel,I tried that before and amd antilag off. I tried all the suggestions.   Been really happy with Bazzite so haven't been back in windows for 2 weeks,Positive
Intel,I tried that and all the other suggestions at the time. Nothing worked.  I'm running the game in Linux now and have 0 issues. I can't even crash it when I try,Neutral
Intel,"There's not much documented about it  Videocardz has an article   AMD launches first feature from FSR Redstone with Call of Duty Black Ops 7, only for RX 9000 GPUs - VideoCardz.com https://share.google/VHJiZgwO6eqkMmHV3",Neutral
Intel,"Well currently none of the FSR 4 tech works in vulkan titles, through Optiscalar or driver override",Negative
Intel,Pink path tracing and crashing after a few minuets of gameplay. If you don't enable path tracing the game seems to work just fine.,Neutral
Intel,What are you seeing? I played last night on latest driver and everything seemed fine to me. Playing Ultra RT with Auto on FSR4.,Neutral
Intel,"Yes, modern AMD cards use various telemetrics to push past the rated max boost frequency when headroom is available. Even on default. Problem is, not every board runs stable under these circumstances...  This issue is known to AMD but they don't seem to care.",Negative
Intel,"Have you tried undervolting your GPU?   I've played BF6 since launch with AMD drivers before the game ready one and currently still on 25.10.2 and I've had 0 crashes while playing the game.     Since I got this 7900 GRE that I've ran it with 2703MHz min / 2803MHz max and 1010mv, power limit -5%.",Positive
Intel,Would be absolute insanity to release a brand new rdna3 product if its not about to recieve fsr4,Negative
Intel,"But that's Linux based, So while we may get FSR4 in Linux, not necessarily in Windows.",Neutral
Intel,I guess you can't drop any hints as to whether this work with CDPR also involves adding Ray Regeneration to the game ðŸ‘€?,Neutral
Intel,Fun fact - i am dual booting and on Linux this bug is not existent...:)),Positive
Intel,"On 10.2 the only crashes I was getting was if I pulled up the Radeon overlay while in game. My guess is that the anti-cheat doesn't like it, but as long as I avoided doing so it ran fine for me.",Negative
Intel,Hi. Did you ever resolve this? I'm getting the same error. Thanks.,Negative
Intel,"Yeah, I'm really starting to lose track of what's going on with AMD. I actually love AMD products, but I'm getting fed up. I've been waiting for a fix for over six months, and it never comes. Instead, new features are added, and bugs persist. AMD is making it really hard to continue relying on their products, which is sad. :/",Negative
Intel,https://www.amd.com/en/products/graphics/technologies/fidelityfx/super-resolution.html,Neutral
Intel,It's a thing you can search for on Google,Neutral
Intel,will it work with current version? Or is it based of some pre-release alpha driver for redstone?,Neutral
Intel,"They promised redstone as a feature for 25h2. So if they dont, that could technically be grounds for a lawsuit",Negative
Intel,ahh i'm on Win 10 so probably why I didn't see it.,Neutral
Intel,Weird. Why is it a Windows fix?   I also got vsync bug in specific games and the weird thing is that I needed to turn on the and perf overlay in order to work,Negative
Intel,"Yes, but was it in the previous WHQL driver ? I'm not sure.",Neutral
Intel,there is an another bug appears in 25.10.2 drvier. 25.10.1 works fine.  [https://www.reddit.com/r/AMDHelp/comments/1okvkvk/hows\_25102\_driver\_performance\_for\_battlefield\_6/](https://www.reddit.com/r/AMDHelp/comments/1okvkvk/hows_25102_driver_performance_for_battlefield_6/),Neutral
Intel,It's not only BF6  https://www.reddit.com/r/radeon/comments/1oj98iy/amd_software_adrenalin_edition_25102_release_notes/nm4hh37/  https://www.reddit.com/r/lostarkgame/comments/1oq9ohp/insane_fps_drops_after_the_last_patch/,Neutral
Intel,"I tried everything I saw online: meshes on low, XMP lower/off, chipset drivers reinstall and other stuff. Nothing worked.  I downgraded back to 25.9.1., haven't had a crash in days.  Kinda miss the improvements for AFMF they brought with 25.10 for other games, but eh I'd rather play BF6 without it crashing randomly.",Negative
Intel,"Didn't test long enough to see if it crashes as I reverted back to old driver when I noticed my gpu was permanently at 100% load which it never was before on old driver, doesn't feel like it's supposed to do that with a 9800x3d & 9070xt + 32gb ram, It's moving between 70-95% usage on old driver",Negative
Intel,Either launch with curseforge or rollback,Neutral
Intel,"Damn, didnâ€™t work for me last driver either. I can get FSR4 to work in other games just not BF6",Negative
Intel,Sorry for not replying in time with the pictures but I just saw that on Twitter that Beat Saber and AMD are now aware of the issue. The distorted flickering issue on the walls.  https://xcancel.com/BeatSaber/status/1993629046802882685  However there's another issue. I had not actually tried to use an Index at 90Hz until the other day. I discovered that the latency bug is back for 90Hz mode. As in I have to adjust the photon latency to ~5ms in the Steam debug commands to make it usable but not fixed. Just like in the the drivers before 24.12.1.   120Hz mode still works fine.,Neutral
Intel,"Even the rollback doesn't fix it for me now. It being related to the combination of iGPU and GPU makes sense though. Sadly I actively use the iGPU, so thats not an option for me.",Negative
Intel,You 100 procent sure on this?,Neutral
Intel,I went back to 25.3 official gigabyte latest driver for 9070XT OC gaming and 2 days no crashes for now. Also changed HDMI for DP cable  I will also change in BIOS and completely disable integrated GPU in BIOS,Positive
Intel,"I had auto update on (my mistake), so it did install over the previous driver. I've downgraded for now and it seems to be working just fine.  But no, after uninstalling from control panel I booted into safe mod and used DDU.   Then I downloaded the newest installer from the website. Restarting where needed during this process.   Didn't matter how I tried to access the software. Wasn't active in the system tray, not there in task manager.   Right click on desktop and open from there, click the exe, or go into a game and try Alt R. Didn't open with any of these methods.",Neutral
Intel,Driver with -s letter after black screen and reboot PC tells me that this driver isn't for my graphic cardðŸ¤¡,Negative
Intel,"I had randomly black screens with 24.2.1, this was annoying as hell. Had to DDU the Driver and went back to 23.11.1, after this everything was fine.",Negative
Intel,Does fsr 4 work on 25.9.1? I thought the only driver that works without having to change any files and risk a ban online is 23. 9.1?,Neutral
Intel,"I had to rollback to driver 25.9.1, start up Star Citizen, switch the renderer to Vulkan, exit game, start SC again to verify it's working with Vulkan, then reinstall the latest driver again. Now it works, just don't switch it back to DirectX. No idea who dropped the ball on this one but Easy-Anticheat sure doesn't like the atidxx64.dll.",Neutral
Intel,I'm not sure. However when I install the driver it states that I cannot use adrenaline and gives me a link to the newest driver. Wondering if there is an earlier version of adrenaline I need to install.,Neutral
Intel,What do you mean extension update??? Do you mean lg firmware update or something Ina  windows update? Where do I find this?,Neutral
Intel,They do not.,Neutral
Intel,"Well, I used the system before the latest updates normally, for maybe half a year. Installed every update without DDU. I wanted to triple boot, formated the drive, left windows to install stock updates and drivers, went to install chipset and GPU driver and voila, every wakeup, just before I could type the pin, kernel panic and shutdown. DDU, just the driver, installed again, black screen. Went into DDU again, wanted to see if I missed anything and without reading, uninstalled everything AMD related, went into windows, installed chipset drivers from vendors site (ASUS) and then the latest GPU drivers, and havent had issues. I have a monitor connected via DP and a TV via HDMI.",Neutral
Intel,Dont buy an adapter. Most of them are trash and dont put out the advertised resolution and refresh rate. Not to mention most of them dont support vrr or HDR.,Negative
Intel,The one linked in the release notes is combined. (in the sense that it's two drivers in one executable) (And 1.6GB)  .....amd.com/drivers/whql-amd-software-adrenalin-edition-25.11.1-win11-nov-combined.exe,Neutral
Intel,"AND is taking away one additional driver feature per day, you say?",Negative
Intel,"Yes, Iâ€™m talking about 25.10.2 (posted the other day here: https://www.reddit.com/r/AMDHelp/s/nNunS1QlFX ). If you go to AMD download page and select â€œGPUâ€ you get a file that has a different dimension from the one you download if you choose â€œCPUâ€. If you do the following steps 1) DDU (or AMD CleanUp Utility), 2) install CPU drivers => GPU not recognized or with a generic driver. If the you install the GPU driver you get the GPU correctly recognized and a yellow esclamation mark on the integrated. To have both VGAs working at the same time I have to download the AMD Auto Detect package (the file name ends with â€œminimal_install), but Adrenalin App does not open.",Neutral
Intel,Thank you for explaining it before the rage baiters go nuts.,Neutral
Intel,I've been following this one pretty closely. Unfortunately the fix *just* missed 25.11.1 release cycle; we hope to get this out in the next one.,Negative
Intel,"I have a 7900XTX and have this issue at times. It normally clears quickly on its own, but seeing pink pixels on the screen worried me that I had an issue with the actual hardware",Negative
Intel,"I totally understand. if you're running with an affected display config, you should be fine on 25.9.1 or the 25.10.1 preview driver for BF6. We'll get this out as soon as we can.",Neutral
Intel,"Appreciate you reaching out with this - that's an interesting data point to consider.  In this case, the quirky behaviour with HDMI 2.1 + FRL was attributed to a change made in the display stack, I don't think it explicitly involves display stream compression to repro, just high enough display bandwidth (though I could be mistaken)",Positive
Intel,"Interesting. I've been experiencing random BSODs on my PC too on a fresh Win11 install too, I was also suspecting it was something to do with auto HDR toggle but I didn't know for sure.  I'm running 180hz 1440 LG panel but I don't recall if it's using hdmi or DP. I've also never experienced BSODs until the last week or two, since i did a fresh install and I've had the same monitors/PCs for a long time.",Neutral
Intel,Don't apologise - this one is worth getting upset over. Hope it's fixed for you all very soon.,Negative
Intel,Was yours the DisplayPort config or HDMI? I may have a fix for this ready if you're available test,Neutral
Intel,Can you provide me some context? Are there any posts detailing the issue either here or at the chromium project side?,Neutral
Intel,Already launched in COD 7,Neutral
Intel,"Im currently using dp 1.4 on my 7900 gre.  My monitor has 2.1 hdmi, so youâ€™re saying i shoulf switch to hdmi?",Neutral
Intel,Some of us are using DP 2.1 though. DP 1.4 is a thing of the past.,Neutral
Intel,Are you sure? The steam machine has HDMI 2.0 and DP 1.4 listed in the specifications,Neutral
Intel,"Ah ok, that definitely makes sense if you're using a TV. Hope they straighten it out for you soon.",Neutral
Intel,What I did is get the 25.8.1 drivers shut off the fluid motion frames and in Windows set bf6 to run full power on your graphics card. Try some of those things and see if that helps you.,Neutral
Intel,"I tried to reinstall the chipset drivers, the same error, tried to install the drivers from gigabyte site the second screen worked but uninstalled adrenaline and it ran the auto update that disabled the secondary screen and the issue of no adrenaline opening came back, going back to older version, thanks AMD",Neutral
Intel,With the compiled leaked DLL you can use it on RDNA3 as well.,Neutral
Intel,"Wait until December, there's the 5th anniversary and they'll supposedly drop something new.",Neutral
Intel,For me playing it with path tracing on eventually the game crashes. Had no issues playing with ray tracing: psycho though.,Negative
Intel,Amen to that. Not a single crash since the game released on CachyOS. (9070 XT),Positive
Intel,Thank you! Exciting keen to see what itâ€™s like,Positive
Intel,"It has nothing to do with the lack of vulkan support, even when fsr4 comes to vulkan, the game still needs ray regeneration implementation from the devs, you cant use optiscaler through dlss inputs, like you probably will be able to in fx alan wake 2",Negative
Intel,I suppose is going to be fixed as soon as Amd Redstone go out. Basically is going to add every tecnology that Path tracing needs to work. Off course the devs would have to implement them in the game too,Neutral
Intel,"The issue is if you try to use path tracing. Which to be fair, you probably shouldn't unless the miracle of them getting Virtuous to implement Ray Regeneration in Cyberpunk happens.",Negative
Intel,yes i tried it ... maybe it is because of the 7800X3D ... i really dont know... i will wait for the next patch ... should come tomorrow 18.11. ... but i have read so many threads and i am not the only one...,Neutral
Intel,Hmm fair. For me on 9070XT if I had raytracing enabled it would crash most regularly on loading back to the menu after extraction which was annoying but at least not game destroying lol. But yeah annoying enough that I turned RT off entirely.   I hope this means I can turn it back on because the game runs well enough for it.,Negative
Intel,"Yes. So far, so good. I'm not 100% sure what fixed it.      I uninstalled both Adrenalin and Ryzen Master standalone applications. Deleted the ""amdryzenmasterv"" keys. Rebooted.  Then I installed Adrenalin and used the Ryzen Master installer in Adrenalin (Performance > Metrics > Install Ryzen Master).  I think this problem might have something to do with a handshake breaking between Ryzen Master and Adrenalin, after upgrading just Adrenalin.   From now on, I'll probably do clean installs, removing and reinstalling both Adrenalin and Ryzen Master, through Adrenalin Performance tab.",Positive
Intel,"My last two processors are ryzen amd, my last three video cards are amd radeon and next one will be amd also, nvidia has driver issues as well, to be honest.  But yes, some issues are too annoying and updating drivers is lottery at this point. I would advice against updating drivers unless you need it for specific new game or have the latest video cards - rx 9070 \[xt\]  or 9060 xt .  I should have sold the 7700 xt and bought 9060 xt 16gb instead but too late for that now and it has problems as well, so lottery as i said, its a risk.",Negative
Intel,"I see, btw I'm just telling the natural AMD trends on its major update/features on its GPU (kinda). Wish it coming sooner..",Neutral
Intel,lmao chill out dude go touch some grass,Negative
Intel,Could be grounds for lawsuitâ€¦ Thatâ€™s funny!,Neutral
Intel,Because of MPO.,Neutral
Intel,yeah same with 25.11.1 25.9.2 works for me,Positive
Intel,"25.10.2 was the previous WHQL, so also yes :P",Positive
Intel,"Huh, seems to be running in DX12 for me, as reported by MSI AB, and FSR4 is working",Neutral
Intel,Which driver version and does it still crashing?,Neutral
Intel,OK I will install it now and test it and get back to you. Give me 10 mins.,Neutral
Intel,Yuppp. It does not work on bf6 but it works on ark survival ascended for me. Seems it might be a bf issue. I saw ppl saying they were getting more fps with this driver in BF6 but I think they didn't realize it's using FSR 3.1 and not 4.,Negative
Intel,I'll work with the engineer from that ticket check if that issue has somehow regressed.,Neutral
Intel,We've not been able to reproduce this internally so far. Can you remind me which GPU (was this a 7900XTX?) + connectivity method you're using?,Neutral
Intel,Try using DDU to uninstall your current drivers and do a clean install of the 25.10.2 combined drivers if you havent already (you can find it here):  https://www.amd.com/en/resources/support-articles/release-notes/RN-RAD-WIN-25-10-2.html,Neutral
Intel,"Yup just need to say ""No""",Neutral
Intel,"whew thanks, good think i noticed it first before updating. i have 25.10.2 and 25.9.2 here and they both have windows 10 along their filename so i might as well asked.",Positive
Intel,I don't see how it would work on 23.9.1 lol,Negative
Intel,"Did you use DDU to uninstall the drivers and then reinstall using a driver installer from the AMD website? I found this guide yesterday and it was extremely helpful, specifically step 8:  https://www.reddit.com/r/AMDHelp/comments/1lnxb8o/ultimate_amd_performance_fix_guide_stop_lag_fps/",Positive
Intel,I did it this morning before the new driver and confirm chipset drivers were untouched,Neutral
Intel,Agreed the variability and stability of adapters can be quite hit and miss. Just wait it out unfortunately and donâ€™t use the latest drivers. At least AMD owned up to it so I canâ€™t be too upset but hopefully they really do fix this soon as new users may not understand whatâ€™s happening and think their card is bad.   We are already seeing this in other Reddit post from other users. I have been playing some damage control and telling them to downgrade and suddenly itâ€™s stable for them and they donâ€™t think their card is dead doh. So yeah AMD really needs to fix this soon.  More people use HDMI than what people think and those TVs donâ€™t always have a DP connector at all.,Negative
Intel,"ah, that explains it. Thanks. :)",Positive
Intel,"What if one does not check release notes? V25.10.2 point to different packages, for installing both CPU and GPU you had to download the AutoDetect package (named â€œminimal installâ€). Obviously Iâ€™m referring to AMD driver download page.",Neutral
Intel,"Okay, as long as they have a workaround for that... I was planning to get a 9060XT, but also keep my 6700XT for lossless scaling frame gen, was worried the branching would affect that..",Neutral
Intel,"What a mess. I have rdna2 and 3 on the same PC, so combined driver is the solution for this? Or auto detect is the only way?",Negative
Intel,"Damn, that's a huge relief to hear. Most of the frustration came from not knowing whether the issue was even acknowledged.   Thanks a lot for the update.",Positive
Intel,What about Noise Suppression not working since 25.9.2?,Negative
Intel,Finally. The last driver without pink artifacting was 25.4.1  It has been 7 months. AMD Matt acknowledged the bug on [the amd forums](https://pcforum.amd.com/s/question/0D5KZ000011WpJJ0A0/pink-square-artifacting-chrome-discord-and-steam) 5 months ago.  Please let it be fixed with the next driver update. So many 7000series users are on the verge of swapping to Nvidia.  https://i.redd.it/ywrg9at3lp1g1.gif,Neutral
Intel,"what about whatever changed post 25.3.1 for multi monitors? Any driver 25.3.1 and older i can run my main at 200hz, my side at 165, and my third at 60 without issue. Any driver newer than 25.3.1 and running my main at 200hz then playing a game will cause the second monitor (165hz) to flicker, glitch, and freak out the entire time, until the game on the main monitor is closed. Dropping to 165 on the main monitor down from 200hz \*fixes\* the issue but, i paid for 200hz and would like to be able to actually use it again.  (7700xt system)",Neutral
Intel,Hell yeah ðŸ™‚ amd I appreciate you see the issues Iv been a fan boy for a long time and I know it will be fixed,Positive
Intel,"Hi. Sorry, I thought this was pretty common as I've had this issue with two different systems and 3 AMD GPUs across 2 generations. [Here.](https://www.reddit.com/r/radeon/comments/1jayump/chrome_full_screen_freezes_after_switching_to_amd/) [Or here.](https://learn.microsoft.com/en-us/answers/questions/3890720/parts-of-screen-freezes-when-using-chrome) Chrome (or other Chromium browsers, I've had this happen with Edge too) in fullscreen, with graphics acceleration enabled.   Best way I can describe it is that very often the program fails to update its display information?? Most of the screen freezes to a certain frame and only small, sporadic parts of it - never the same ones, sometimes more, sometimes less - continue to be updated properly as I scroll or take other actions. Making the window smaller fixes this instantly. It seems to be tied to graphics acceleration as it just doesn't happen at all with it turned off. The issue seems to get exacerbated when the GPU is being stressed.   And in the same vein, Chromium browsers do not seem to mesh well with AMD hardware? I've had plenty of weird behaviors ranging from TDRs, WoW freezing in the background, crashing and restoring itself which do happen less often if I'm running Firefox in the background instead of Chrome.",Neutral
Intel,"Keep in mind this only actually matters if one protocol or the other is **actually** limiting bandwidth for the [resolution * FPS] you want to display on your monitor  For instance, DP 1.4 can do ~25Gbits/s, which translates to roughly 1440p @ 240fps, or 4k @ 120fps  If you have proper cable into HDMI 2.1, it should be able to do ~42Gbits/s, which would instead be 4k @ 190fps  Read up the wikipedia tables for bandwidth specs and resolution / fps / bit depth rates for more",Neutral
Intel,Yeah most people are still have dp 1.4 monitors though. No way I'm swapping my monitor just for dp 2.1 as it's just too awesome. Although these tandem OLED screens look interesting... Hmm lol,Positive
Intel,"lol, listened too much to linus  https://youtu.be/g3FkuZNSGkw?t=261",Neutral
Intel,That was my very first actual driver issue I experienced with AMD.,Negative
Intel,Oh that's nice! I'll look into it when I get the chance.,Positive
Intel,Cool. Thank you,Positive
Intel,I might turn on ray tracing in like a medium or low setting just for shits and giggles or screenshots but I don't plan on playing with it on all the time since I'll also play at 1440p so I don't wanna have a really bad experience ðŸ˜–,Negative
Intel,Exactly! It's insane. I can't believe running through a translation layer is more stable than running native,Positive
Intel,"but i dont know something is also wrong with 25.11.1 ... AMD Adrenalin randomly vanishes from tray     i dont want to roll back to 25.9.1 :-(    but this version was the last which was good so far      maybe when we have luck amd is able to provide next time a ""perfect"" driver without any issues?",Negative
Intel,"Could be it, nothing hardware wise at all and just software too.     Yeah, you're not the 1st I've read that says they have issues on the game.     If you're crashing and the system reboots it does make me think of some stability issues and not really just GPU, but I'm guessing you've already tried stability tests and using the system without OC+A-XMP/EXPO disabled.     Once upon a time I remember reading some people, on other instances and other games, having crashes like that (complete reboot) due to PSU instability as well.     Good luck!",Neutral
Intel,That's strange. My game defaulted to everything maxed out including running ray tracing and I haven't noticed any issues. The game runs incredibly well.  I've got a 5800X3D & 9070XT as well.,Positive
Intel,"Fair enough, and yeah sooner the better for all of us",Positive
Intel,It absolutely could be.  Europe has some pretty good consumer law and promising features that could impact your purchase decision are part of this law.  It can fall under misleading advertisement,Neutral
Intel,"It's not freezing, it's just that the GPU usage is practically at 100% all the time, even with V-Sync enabled. With the 25.9 drivers, this doesn't happen, and the clock speed varies normally, increasing and decreasing as needed when V-Sync is enabled. These 25.10 drivers are causing the GPU to consume more energy unnecessarily.",Neutral
Intel,Fingers crossed,Positive
Intel,"Thanks for attempting to retest.  It's a 7900XTX with an Index connected via DisplayPort. I am on the latest 25.11.1 driver.  I run a monitor at 4k 120Hz 10bpc with HDR Off, which uses DSC, as my main and only display. I tried disabling DSC in the monitor settings which runs at 4k 120Hz 8bpc with HDR Off but I don't think I noticed a change in latency. I thought that DSC on and off on two different devices might contribute to the problem but I'm not sure.   I have also tried running the Index under a RX480 on another PC and I fairly certain the latency looks different under 90Hz and looks similar under 120Hz. Can't play much to test though as an RX480 runs the Index at a very blurry setting. Getting around to doing this test is what took me so long to reply.",Neutral
Intel,Were you able to find the issue?,Neutral
Intel,"Allright ty, will Install new, any differences in performance?",Neutral
Intel,"im running 25.11.1 on win10 7900xt. no problems besides afmf2 breaking the performance overlay, which ive had for multiple updates now",Neutral
Intel,I don't think you understand what I mean.. If you downgrade to that you can get fsr 4 to work on 6000 series without having to change any files.,Neutral
Intel,Thank you for this. This was very helpful. Got adrenaline working fine now.,Positive
Intel,"I wish my LG C4 42"" had a display port. Its my primary monitor.",Positive
Intel,"Yep, AMD is not so quick in fixing their driver download page, I still can remember when X870E chipset came out but you found only X670 option. The drivers were the same, but man itâ€™s your flagship chipset! Anyway, drivers install but Adrenalin App does not work for meâ€¦ and have zero time to reinstall Windows.",Negative
Intel,"Don't do that, i'm suffering with both 7900XTX + RVII (and even with RX6400)",Negative
Intel,"I feel like AMD can do a bit of a better job communicating this, despite Vik's great efforts in this subreddit. Just saying: hey guys, we know about this, it sucks, bear with us please can make things better in the long run in my opinion.",Neutral
Intel,"We've not observed anything like this internally, and I've personally not seen this at all in the field. This one may be specific to your display combination. I'll talk to a colleague in our display team about what we can do to learn more about that behaviour on your side - we might ask you to capture a special kind of log file during a state when your secondary display is blanking with gameplay on the primary",Neutral
Intel,Can you tell us what content you have on the secondary panel when it starts misbehaving? Is this behaviour affected if you disable VRR on it too?,Neutral
Intel,"I see. I recall the partial display freeze being related to DWM & multi plane overlay in Windows. One of our community testers encountered this and remedied with the overlayminFPS DWORD here: https://www.reddit.com/r/Windows11/comments/1kgp7ar/cause_and_solution_to_windows_24h2_related/?sort=new  If you're getting TDRs, with chome(ium) + gameplay, pass us over a kernel memory dmp and we'll take a look into it",Neutral
Intel,"Oh yeah I noticed that too when watching it, kinda funny of him to say it as it's on screen",Positive
Intel,I've had a really stable 60 fps experience even with path tracing (minus the crashes) but I'm on a 9070 with fsr 4 on quality,Positive
Intel,Can't comment on the vanishing of the tray since I have mine configured to hide it from tray always.,Neutral
Intel,also i have coil whine since this driver 25.11.1. ?!  also in idle sometimes...  very strange driver...,Negative
Intel,Every roadmap since forever has a small print disclaimer at the bottom at the page saying that release times are subject to change.,Neutral
Intel,"I upgraded from 25.9 because it started crashing, it was not crashing until yesterday, also I have limited gpu usage, clockspeed it is working sometimes, sometimes not.",Neutral
Intel,We've still not been able to reproduce this unfortunately. I'll need to check in when I'm back at work next year,Negative
Intel,Didn't really paid attention to it :( but at least my game doesn't crash anymore!!,Negative
Intel,"did you download the same filename with the one i mentioned? i tried downloading windows 11 link and it also gave me the same filename, lol",Neutral
Intel,No you can't.,Neutral
Intel,"I don' think you understand either, 25.9.1 is that driver, 23.9.1 was released in 2023 before FSR 4 was even a thing.",Negative
Intel,"Glad I could help, the crashes on Arc Raiders were pissing me off big style so I wanted to share what helped me.",Positive
Intel,"They are TV's, not pc monitors. Buy the right tool for the job",Neutral
Intel,"I couldn't find the DWM key so I made one, we'll see if that fixes it. Thank you for replying. But please, forward it to someone. There must be people out there on AMD hardware that are not tech savvy and this just breeds bad reputation.",Neutral
Intel,"Nope, that didn't fix it. Chrome continues to forget to update its display. And WoW continues to crash in the background leading to massive stutters when panning the camera around quickly, along with plenty of other odd behaviours.",Negative
Intel,"Yeah, I'm facing the same issue on RX 9060 XT   Is it a GPU driver issue, or a Windows issue that Microsoft needs to fix?",Negative
Intel,since last BF6 Update i had zero crashes also on 25.11.1,Positive
Intel,"That's not how it works. Small print won't save you from stuff like this, you think that they can stop releasing this software for 2-3 years because some small print said 'Subject to change'?   European consumer law would absolutely support the consumer in this case. If you promise a feature by a certain date, you will need to deliver it. If the development takes way too long, you are in for a ride",Negative
Intel,What about 25.11.1?,Neutral
Intel,Yeah same for me. Considering how similair win10 and 11 are under the hood i just went with it. Still absolutely no problems sofar.,Positive
Intel,Can't what? I have been using fsr 4 on my 6700xt for a month now using this tutorial   https://www.reddit.com/r/pcmasterrace/comments/1nmyhpo/fsr_4_on_rdna_2_guide/?share_id=EEC5RH2XmDUZa2DjeRO-5&utm_content=2&utm_medium=android_app&utm_name=androidcss&utm_source=share&utm_term=1,Neutral
Intel,"> 23.9.1   Come on man, it's clearly a typo and you know it. That's why he's confused.",Negative
Intel,"Look online for fsr 4 on 6000 and 5000 series, you will understand,Â    Edit :I will just link you a tutorial to understand...      https://www.reddit.com/r/pcmasterrace/comments/1nmyhpo/fsr_4_on_rdna_2_guide/?share_id=EEC5RH2XmDUZa2DjeRO-5&utm_content=2&utm_medium=android_app&utm_name=androidcss&utm_source=share&utm_term=1",Neutral
Intel,Did you reboot after setting that key? Is the display with chrome still only partially updating?,Neutral
Intel,"Haha. Sure thing buddy. If that would be the case, that a small print on a roadmap can't save a company, we would have hundreds of lawsuits in EU. You must be new to the hardware scene.",Negative
Intel,thank you,Positive
Intel,"Uh huh, yeah I did it too. You still have the overwrite DLLs. Hence the flipping tutorial. Completely irrelevant to this topic, anyways.",Negative
Intel,"Not a typo, I was asking about something else and he missed my point...",Negative
Intel,"Yes, it can't.   They could add that they can sell your organs, doesn't make it legal though.   Also lawsuits usually don't happen because of a feature or if they happen, in a very small amount that isn't meaningful. Class action also doesn't exist in Europe, so obviously you won't hear about it like in the USA.",Negative
Intel,"But flipping the dlls could get you banned from online games , that's why i was wondering if it's finally fixed in this update and we wouldn't have to flip the dlls anymore..",Negative
Intel,"You literally claimed we could do this without overwriting any files, that was obviously false.  Anyway, no. I would not expect AMD to bring FSR4 to RDNA3 anytime soon, if at all.",Negative
Intel,"What a disgusting build, I love it",Negative
Intel,the content we crave,Positive
Intel,">AMD+Intel+Nvidia GPUs within the same PC  okay, now i wanna know ***much*** more about how this works.  is this a linux only thing or does windows also let you have multiple gpu brands installed at the same time? i would assume it would be a bit of a hellscape of conflicting defaults and drivers.  im a bit of an aspiring dipshit myself and ive been quietly losing my mind trying to figure out how to get windows 10 to run software on a specific gpu on a per program basis, by chance you got any idea if thats possible at all, or if linux magic is the missing ingredient?",Neutral
Intel,What GPU are you using in your build?  All of them,Neutral
Intel,you're one hell of a doctor. mad setup!,Positive
Intel,The amount of blaspheming on display is worthy of praise.,Negative
Intel,Brother collecting them like infinity stones lmao,Neutral
Intel,I'm sure those GPUs fight each others at night,Negative
Intel,Bro unlocked the forbidden RGB gpus combo,Neutral
Intel,How does this card hold up compared to other comparable cards in your Computational Fluid Dynamics simulations?  Also how much of an improvement did you see from Intel Alchemist to Battlemage?,Neutral
Intel,What the fuck,Negative
Intel,I was wondering for a second.. Why such an old Nvidia graphics card until I saw it is a behemoth of a TitanXP. Good!,Positive
Intel,Yuck,Negative
Intel,Wait until you discover lossless scaling,Neutral
Intel,Can you use cuda and rocm together? Or do you have to use Vulcan for compute related tasks?,Neutral
Intel,"This gave me an idea for getting a faster local AI at home. Mine is eating all my 24GB vram, and its not super fast cause of the lack of tensor cores in any of my hardware.  But if i could just stack enough VRAM... I have an old mining rig with 1070s collecting dust.   Hmmmm :P",Negative
Intel,Now you just need to buy one of those ARM workstations to get the quad setup,Neutral
Intel,holy smokes! I follow you on YouTube!!! Love your simulations keep up the good work!  If you have some time you mind pointing me to the right direction so I can run similar calculations like your own?   Thanks!,Positive
Intel,Love it lol. How do the fucking drivers work? Haha,Positive
Intel,What an amazing build,Positive
Intel,wtf is that build man xdd bro collected all the infinity stones of gpu world.,Negative
Intel,Youâ€™re a psychopath. I love it,Negative
Intel,This gpu looks clean asfðŸ˜­,Positive
Intel,The only setup where RGB gives more performance. :D,Positive
Intel,Now you need a dual cpu mobo.,Neutral
Intel,Placona! I've been happy with a 6700xt for years.,Positive
Intel,absolute cinema,Positive
Intel,"That is not ""SLI"".  That is Crossfire.  There is a major difference.  ""SLI"" only permits alternating frame rendering (AFR).  Crossfire permits splitting a single frame load among different cards in addition to AFR.",Neutral
Intel,"Brawndo has electrolytes, that's what plants crave!",Positive
Intel,"Works in Windows too. But Windows has way too much overhead for all of the AI garbage, ads and integrated spyware running in the background to still be a usable operating system. Linux is much better.   The drivers install all side-by-side, and all GPUs show up as OpenCL devices. In the software you can then select which one to run on.   FluidX3D can select multiple OpenCL devices at once, each holding only one part of the simulation box in its VRAM. So VRAM of the GPUs is pooled together, with communication happening over PCIe.",Neutral
Intel,"Windows has a section where you can select a gpu to run certain applications. It was introduced in win 10, but i only know the location in win 11    I think you can get to it through settings -> display -> graphics",Neutral
Intel,"What kind of application are you trying to run on specific GPUs? IIRC Vulkan will let you specify what device to use, even if it's not the GPU whose monitor is showing the application. DirectX I think is controlled by the Graphics settings in Control Panel. I think there's a page somewhere that lets you pick the GPU. That might be a Windows 11 thing though. OpenGL is the one that AFAIK will only render via the device whose monitor is displaying the application.",Neutral
Intel,Team RGB,Neutral
Intel,"_snap_ and half of CUDA software is dead, as people prefer the universally compatible and equally fast [OpenCL](https://github.com/ProjectPhysX/OpenCL-Wrapper)",Neutral
Intel,"- The 7700 XT is quite slow, AMD has bad memory controllers, a legacy moved forward from GCN architecture. And the oversized 3-slot cooler doesn't make it any faster either - 2828 MLUPs/s peak - Arc B580 - 4979 MLUPs/s - The 8 year old Titan Xp (Pascal) - 5495 MLUPs/s - Arc Alchemist (A770 16GB) is similar memory performance, with wider 256-bit memory bus but slower memory clocks - 4568 MLUPs/s   Full FluidX3D performance comparison chart is here:Â https://github.com/ProjectPhysX/FluidX3D?tab=readme-ov-file#single-gpucpu-benchmarks   But performance is not my main focus here. I'm happy to have all major GPU vendor's hardware available for OpenCL development and testing. Quite often there is very specific issues with code running in one particular driver - compilers optimize differently, and sometimes there is even driver bugs that need workarounds. Extensive testing is key to ensure the software works everywhere out-of-the-box.",Negative
Intel,"Had that since 2018 - got it for free through Nvidia academic hardware grant program. It has slower memory clocks, but double (384-bit) memory bus. It's actually the strongest of the three GPUs.",Positive
Intel,"OpenCL works on all of them at once, and is just as fast as CUDA!",Positive
Intel,"ARM mainboard/CPU, 3 GPUs, and Xeon Phi PCIe card to also have an x86 CPU ;)",Positive
Intel,Start here with FluidX3D:Â https://github.com/ProjectPhysX/FluidX3D/blob/master/DOCUMENTATION.md ðŸ––,Neutral
Intel,"They work well together - all GPUs show up as OpenCL devices. Need specifically Ubuntu 24.04.2 LTE though, as all drivers need specific ranges of Linux kernel versions and kernel 6.11 happens to work with them all.",Positive
Intel,"Technically FluidX3D uses neither SLI nor Crossfire, but cross-vendor multi-GPU instead, for domain decomposition of a Cartesian grid simulation box, to hold larger fluid simulations in the pooled VRAM.   The rendering is done multi-GPU too, as domain decomposition rendering. Each GPU knows only a part of the whole fluid simulation box in VRAM and can't see the others. It only renders its own domain, at 3D offset, to its own frame with accompanying z-buffer, and copies those to CPU over PCIe. The CPU then overlays the frames.",Neutral
Intel,I find it sad we killed SLI and Crossfire especially now that we have Resizable Bar and higher speed PCIE connections. (Iâ€™m no expert but I know we have made advancements that would improve the experience of multi-GPU setups.),Negative
Intel,I recall Ashes of the Singularity demonstrated this capability almost 10 years ago. DX12 heterogenous multi GPU with AMD and Nvidia cards.  https://www.youtube.com/watch?v=okXrUMELW-E,Neutral
Intel,how much pcie bandwidth do you realistically need for this sort of thing to work? is there any headroom at 3.0 x4?,Neutral
Intel,"god i wish.   that menu is entirely useless, the only options are power saving / high performance, which are all forcibly autoselected to the same gpu.  please tell me that the windows 11 version actually lets you manually select what specific gpu you want via a dropdown menu?",Negative
Intel,"lets be honest, this is the REAL reason intel getting into graphics is a wonderful thing.",Positive
Intel,Thank you so much for the very detailed response!,Positive
Intel,Well worth it!,Positive
Intel,Thank you my man!! Looking forward to run some tests once I get home.,Positive
Intel,That's awesome!,Positive
Intel,"Yes, but SLI is a bad description for it.",Negative
Intel,"The faster PCIe 4.0/5.0 and future iterations mean that dedicated SLI/Crossfire bridges are obsolete. The PCIe bandwidth nowadays is more than enough. And PCIe is the generic industry standard interface, easier to program for than proprietary hardware that's different for every vendor.   For games multi-GPU is gone for good (too few users, too large cost of development, no return of investment for game Studios). But in simulation/HPC/AI software multi-GPU is very common as it allows to go beyond the VRAM capacity of a single large GPU for cheaper.",Neutral
Intel,"sli/crossfire were killed for good reason, its just a bad time all around if half of your gpu's core/cache is located a foot away from the other half, unless your baseline performance is so damn low that the microstutters just get lost in the noise.  ultimately chiplet cpu/gpu designs are basically just an evolved form of sli/crossfire, and we're happily starting to get quite good at those.  (assuming we're talking about games)",Negative
Intel,"indeed it did, if only game devs adopted this more. Then again, the idea of two high end GPUs like we have today in a single PC is kinda horrifying.",Negative
Intel,"There is not really a clear limit. More PCIe bandwidth makes scaling efficiency better, less means the software will run a bit slower in multi-GPU mode. 3.0 x4 (~3.3GB/s) is just enough for reasonable efficiency.",Neutral
Intel,"It does actually. I have 3 gpus i can select from (7900 XT, iGPU, and Tesla P4)   Ill reply to your message once i get a screenshot",Neutral
Intel,"NVLink 3.0 (2020, GTX3090 use this one for reference) is a tiny bit faster than PCIe 5.0 (16x, 2019) : 50GT/s vs 32GT/s  But PCIe 6.0 is faster nvlink 4.0 but not 5.0 (those are only use in DC GPU AFAIK)  [Source](https://en.wikipedia.org/wiki/NVLink)",Neutral
Intel,"Indeed, people forget that the speeds electricity travels is slow in the computer world.   Kinda why the RAM slot closer to your CPU performs so good. And why benchmarkers will use that slot, and not the one furthest from the CPU.  Same with NVME m2 SSD, the closest slot is the best one. PC will perform the best if OS is located on the closest one.   Much better off just slapping two GPUs together in a single form factor than two separate GPUs.  Guess that is why we have 5090 these days. At about double the price of the old flagships.    You can view that as SLI i guess :P",Neutral
Intel,"Iirc Rise and Shadow of the Tomb Raider were the only games to support the used of mixed multi GPU (at least mainstream) other than ashes. A bit of a bummer from goofy multi GPU setups, but yeah, today the thought of two 600 watt GPUs in a single system just sounds like a recipe for disaster. With an overclocked CPU, an intense game could literally trip a 120v breaker!",Negative
Intel,"thanks man.  that is incredibly relieving to hear, and equally annoying considering this is probably going to be the reason ill eventually 'upgrade' to win 11 one of these decades.  cant believe internet stories of a functional fucking menu is more enticing to me than the actual trillion dollar marketing...  â€‹â€‹â€‹  also this is a bit of a dumb question but can you actually play games on gpu-1 if the monitor is connected to gpu-2?  i'd assume so considering thats basically what laptops do, but... im done assuming that things work without issue.",Positive
Intel,"Yes i can do games on 1, but using monitor on 2. I have one monitor connected to the gpu itself, and the other to the motherboard, since my card only has 1 hdmi port which i use for vr",Neutral
Intel,Why are you connecting the monitor to the gpu and not the mobo?,Neutral
Intel,"ðŸ‘   thanks for the info, this'll definitely come in handy eventually.",Positive
Intel,why not? how would you benefit from connecting the monitor to the motherboard instead of just using the gpu's ports?,Neutral
Intel,No worries mate. Good luck,Positive
Intel,"For some reason I switched up, connecting to the gpu is the way to go. I derped",Neutral
Intel,"This post has been flaired as a rumor.   Rumors may end up being true, completely false or somewhere in the middle.  Please take all rumors and any information not from AMD or their partners with a grain of salt and degree of skepticism.",Negative
Intel,It's alive. Rejoice.,Positive
Intel,"This post has been flaired as a rumor.   Rumors may end up being true, completely false or somewhere in the middle.  Please take all rumors and any information not from AMD or their partners with a grain of salt and degree of skepticism.",Negative
Intel,"We know the Arc B580 runs well with a Ryzen 7 9800X3D, which is 8 core/ 16 thread CPU.  According to these graphs, the i9-14900K (8P + 16E = 32 thread) and the i5-13600K (6P + 8E = 20 thread) CPUs do fine.  The extreme budget CPU i3-12100F (4P = 8 Thread) performs with a notable degrade in performance.  My current hypothesis is Intel's driver is relying on a heavier multithreading with a bit of crosstalking of the driver workload, potentially to take advantage of underused E cores, which the 13600K and 14900K have plenty.  Given the Ryzen 5 series CPUs have similar performance issues as the 12100K, having 6 cores and 12 threads, I would like to see Ryzen 7 non-X3D CPUs (8 core/ 16 thread), Core i5-14400 (6P + 4E = 16 Thread), and Core i5-12500 (6P + 0E = 12 Thread) CPUs compared as well.  Playing off Intel translating DX11 to DX12 drivers as an example, when DX11 game loads, Intel establishes 2 processes, the DX12 driver and the DX11 translator.  For optimal performance, all threads need to be running simultaneously, the DX11 translator sends command to the DX12 driver in real time.  If there isn't enough room for the threads to be running simultaneously, any data traded between the two have to wait until the next thread is switched in before getting a response.  More threading density means more delays.  Some games don't get impacted either because the game involves less threads or the driver doesn't need the real-time translation threads.",Neutral
Intel,"It's probably because the Intel gpu drivers weren't written that well since it was probably ported with little changes from their igpu drivers where there was always a GPU bottleneck which meant that Intel might not have known there was even an issue until more attention was bought to the issue with Battlemage.  Alchemist was a flop, not many people bought it so not much attention was paid to CPU overhead issues.  AMD/Nvidia by contrast have spent the last 20 years painstakingly writing and optimizing their DGPU drivers. Nvidia had some CPU overhead issues a few years ago and they managed to improve it with driver fixes.",Negative
Intel,One thing I appreciate about AMD is having the lowest CPU overhead for their graphics drivers. Makes a difference if you're CPU limited in a game.,Positive
Intel,So Nvidia now has the lowest driver overhead? Seems like they took the HUB video seriously,Neutral
Intel,So the money you save on a GPU you will need to spend on a better CPU??  Might as well get a faster GPU.,Negative
Intel,Interesting that B580 doesn't look bad at all with a 13600k. I wonder what it's like with a 13400 or 12600k. It seems like just having those extra threads provided by the e-cores takes care of the overhead it needs.,Positive
Intel,"Unless you're running a CPU that's *many* many years old, GPU overhead is not really something you need to worry about. Whether AMD has less overhead or Nvidia has less, it really doesn't matter.",Neutral
Intel,"On an older post an Intel graphics engineer explained the issue, it isn't what you said. Intel is too verbose in commands which slows everything down.",Negative
Intel,I'm fairly sure they use dxvk for d3d9 to 11.,Neutral
Intel,Could just be a cache issue,Neutral
Intel,Battlemage drivers use the cpu for software accelerating certain processes that are not being hardware accelerated in the GPU.,Neutral
Intel,Glad you brought up Nvidia as I didnâ€™t know this had improved until the testing around Arc showed it had gone.,Positive
Intel,"According to the graphs, AMD has slightly less overhead than NVIDIA.",Neutral
Intel,"No, they do not.  The reason they have overhead can't be solved with software.  They've excluded hardware from their GPU's and required the CPU to do the work of that missing hardware.  The main example that seems to suggest otherwise is actually a demonstration of nVidia's forced threading of DX11 games, which can increase performance despite the increased overhead it entails, when the CPU has enough headroom overall (i.e. it doesn't eat into the single-thread performance).",Negative
Intel,"Lowest with DX11 and older, but not with the newer APIs",Neutral
Intel,And when is the last time HUB did a dedicated video showing the improvement in overhead?,Neutral
Intel,or it's just a cache/memory access issue,Neutral
Intel,"The overhead is minimal for both AMD GPUs and NVIDIA GPUs, which is probably why reviewers didn't look at the overhead until Intel GPUs came along.",Neutral
Intel,"> Unless you're running a CPU that's many many years old, GPU overhead is not really something you need to worry about.   That's just not true with Battlemage.  CPUs released in 2024 showed the issue in testing.    It's not year of release, it's capabilities.",Negative
Intel,"Intel uses software translation for DX11 and lower, so it does matter for them.",Neutral
Intel,"Hmm, Nvidia lost less performance going from 14900k to 13600k than AMD but more when going down to 12100",Neutral
Intel,"> No, they do not. The reason they have overhead can't be solved with software. They've excluded hardware from their GPU's and required the CPU to do the work of that missing hardware.  This was true for Alchemist but not for Battlemage.",Negative
Intel,That's not true. Intel's issue is being too verbose in commands/calls.,Negative
Intel,"Never, because HUB doesn't like portraying Nvidia in any light besides negative.",Negative
Intel,HUB used DX12 games that also showed the issue.  It's something else.,Negative
Intel,"The comment to which I am replying is talking about nVidia, not Intel.",Neutral
Intel,"Iâ€™m pretty sure HUB doesnâ€™t like Nvidia *or* AMD. Theyâ€™re calling it how it is, these parts are too damn expensive.",Negative
Intel,That's actually... just worse news.,Negative
Intel,I always dreamt of the day APUs become power houses.,Neutral
Intel,"Is it my expectations being too high or this ain't a huge uplift? To go back to the classic: hopefully Zen 6 with RDNA 4 will offer a bigger uplift. We only have to wait a year and a half...  Anyway, question for the more knowledgeable people: how could the 890M perform with a 50W chip variant, but with 5600 SO-DIMM RAM? What to expect?",Neutral
Intel,"I find it sad that most review outlet is not testing CCX latency for these new CPUs.  These Zen 5 + Zen 5c have insanely high cross CCX latency, 180ms tested by geekerwan to be exact. For reference the 5950x had a 70ms latency for their cross ccd latency and the 4 ccd 1950x had a 150ms cross ccd latency with the closet 2 ccd and 200ms between the furthest 2.  Essentially games will be limited to the 5.1ghz peak 4 core zen5 core cluster or the 3.3ghz peak 8 core zen5c core cluster.",Negative
Intel,Damn Why is AMD even involved in iGPU,Negative
Intel,"If this is true, Strix Point is going to claim total dominance over the GTX 1650 market. Won't be until 2023 when the theoretical RTX 4050 is released to surpass Strix Point's efficiency. Then super budget-friendly Strix Halo will come next year and take the RTX 2080's lunch money. Game over Nvidia.",Positive
Intel,"Strix Halo is rumored to be a whopping 40 CUs of RDNA3.5 so...   That'll do it no sweat, if they release it.",Positive
Intel,almost there,Positive
Intel,"We're a ways off from that still. These Strix Point 890M results are comparable to 1/2 the performance of the RX 6600. That's only good enough for \~30 FPS in Assassins Creed Mirage at 1080p Max.  I think this will be great for non-gaming purposes, like Adobe, Autodesk and so on. 890M should be a photo editing powerhouse.",Positive
Intel,"I mean current consoles are already APU power houses, they can give you 120fps depending on the game, and 30-60fps depending on what mode you select. And these consoles are pretty power constrained and pared down compared to PCs. So this APU here could easily double the performance of a console.   That's tapping on 4070/7800 levels of performance.",Positive
Intel,Never gonna happen as long as they use DDR memory.  The only powerful APUs are those that use GDDR or HBM. See: every AMD-powered console and the MI300A.,Negative
Intel,"Radeon iGPUs are mostly limited by the shared RAM bandwidth. I was thinking of getting an 8700G a little while ago, and the benchmarks varied wildly depending on RAM frequency and overclocks.  Maybe they'll improve it by hooking it up to a wider GDDR bus in laptops, similar to how the current PS5 and Xboxes work (IIRC?)",Neutral
Intel,The biggest uplift would be seen on lower power comparison.     Strix Point simply doesn't have enough bandwidth to feed all those GPU cores at high performance mode.,Negative
Intel,"This review is quite a bit different than the others.  The other paint a much more positive picture.  Also, so-dimm is much slower so expect worse performance.",Negative
Intel,"It depends on what your goals are for a laptop.Â  AMD added 4 CUs and 3% clockspeed increase but got only half the expected 36% uplift, so 2 CUs went to waste (memory bus bottlenecks)!Â Â  I would argue that the problem with laptops today is the horrible 100w+ chips from Intel, as Apple has proved with its wildly duccessful M1, M2, M3 chips.Â  If you agree with this, the Strix point chips use half the power of the AMD 884x chips and move alway from Intel Thighburner laptops, and this is the most important direction right now, as ALL recent Intel laptops have terrible energy efficiency ...",Negative
Intel,"likely memory bottlenecked severely and on-package memory will probably become standard for these types of chips thanks to Apple. the bandwidth benefits just can't be ignored anymore, especially with the slowdown and exponentially increased costs of node shrinks. Intel is already moving on it and I think the main thing holding AMD back is that they rely on 3rd parties for memory packaging so the capacity goes to the more lucrative enterprise chips first.",Neutral
Intel,"The iGPU uplift is extremely underwhelming, I guess this is why Asus did the ROG Ally X model instead of waiting for these chips. I wouldnt be surprised if Lunar Lake with Xe2 passes Zen 5's iGPU at lower power levels, at higher ones im sure RNDA 3.5 will be ahead.",Negative
Intel,yes its so bad. better go buy some steam deck or ally x,Negative
Intel,Low-quality trolling and shitposting. Spamming this same meme at different threads now.,Negative
Intel,"If they put it in the next Razer Blade / Asus G16 laptop, I will instantly buy it.",Positive
Intel,How are they going to feed all those CUs? Quad-channel LPDDR5X?,Neutral
Intel,That's considerably faster than an XSX.,Positive
Intel,>That's tapping on 4070/7800 levels of performance.  What is?,Neutral
Intel,"```That's tapping on 4070/7800 levels of performance.```   The PS5 Pro will land around there, but the current consoles are like 6700 ~ 6700 XT tier.",Neutral
Intel,"Your idea sounds good, been thinking about it myself, but the price is what determines its value.",Positive
Intel,CAMM2 (low power variant LPCAMM2) is already shipped in Thinkpad P1 Gen7 and its [specs](https://www.lenovo.com/kr/ko/p/laptops/thinkpad/thinkpadp/thinkpad-p1-gen-7-(16-inch-intel)/len101t0107?orgRef=https%253A%252F%252Fwww.google.com%252F&cid=kr:sem:cim8te&matchtype=&gad_source=1&gclid=Cj0KCQjw-5y1BhC-ARIsAAM_oKmKRTudxyl7UkjMEa1T5vUumlNVXVT6GwQitr32yqF1x7elrF3gBWoaAltREALw_wcB#tech_specs) show 7500MT/s,Neutral
Intel,Did the other reviews you looked at compare with a 780m with 7500 ram or have multiple 890m devices for comparison though?,Neutral
Intel,"bandwidth is mostly determined by the amount of channels, not whether the memory modules are in the same package or not",Neutral
Intel,"How is 40-60% performance uplift at half the power underwhelming? If anything it is the CPU performance and the usefulness of the NPU, which are the underwhelming parts of this package...",Negative
Intel,It's called satire. You're just salty because you're the butt of the joke.,Negative
Intel,throw it in the next steamdeck and Iâ€™ll upgrade immediately. If they bin the 890m they will have absolute monster in their hands.,Neutral
Intel,Praying the blade16 gets it.,Neutral
Intel,"This is the rumor, if youâ€™re interested in detail:  https://videocardz.com/newz/alleged-amd-strix-halo-appears-in-the-very-first-benchmark-features-5-36-ghz-clock",Neutral
Intel,256 bit bus + infinity cache.,Neutral
Intel,I wish they would make a custom design for mini pcs and laptops that had quad channel ram and 8 cores with 3D Cache instead of 16 cores.,Neutral
Intel,"can be, if you put enough wattage at that I'm certain it can match or be better than PS5/XSX",Positive
Intel,"Yes, itâ€™s like a desktop 7700XT or RTX4070! Juicy rumor, that one.",Positive
Intel,The rumored 40CU strix halo chip. Not the actual chips released this week.,Neutral
Intel,7500mhz ram and the 780m,Neutral
Intel,"if you don't consider power, sure, but in that case you may as well go discrete. efficiency is a big reason for these AIO packages and on-package memory can prevent breaking the power budget while pushing higher bandwidth.",Neutral
Intel,"Indeed. Also the closer the memory is to the CPU, the higher the speeds, thus bandwidth. On-package memory will always be faster.",Positive
Intel,"Have _you_ looked at the actual game benchmarks in the review? The Ally X (a low power handheld) is within 1fps of the bottom of the 890m laptops. It's 5-9fps to the very fastest (again a higher power laptop!!), all at 1080p high settings which i think should  be the target for this range of entries in the roundup.  There is nothing like a 40-60% uplift in those games and that very standard resolution? I was stoked for Strix Point myself but this is super underwhelming.",Neutral
Intel,Literally where did you see 40-60% uplift at half the power?,Neutral
Intel,> 40-60% performance uplift at half the power  Source?,Neutral
Intel,"i chuckled, then again im not a fanboy of anything",Neutral
Intel,Dont expect 40CUs in a handheld anytime soon,Negative
Intel,"Based on the results, it seems like the next steam deck might be more than a year away. Not particularly impressive gains from the previous gen.",Negative
Intel,"It'll need to be a custom tooled APU like Aerith/Van Gogh if it is to take full advantage of the 890m.     Nearly all of the configs that release of 16cu Point APU or 40cu Halo will be an APU slapped in a chassis without an adequate power or memory bandwidth setup for the igpu.     What we need is a Steam Deck with 6c12t of full zen5 and an 890m.Â  This chip should have custom power profiles set up, just like Aerith, so that the GPU takes a bigger share of the power budget and can actually perform at lower wattages.Â  The system should have an actual TRUE quadcore memory setup.Â  Many of these systems have currently (and will absolutely continue to have)Â dualchannel ram available to the igpu, and it cuts the bandwidth down which strangulates the igpu.     Each chip is on a 32-bit bus, so a dualchannel bus would come in at 64-bit, and with 7500mhz lpddr5x come out to ~60gb/s.Â  This matches my system that runs a 780m with 7500mhz lpddr5x.Â  In theory, a quadchannel setup would pump that to 128-bit and ~120gb/s.Â  This will continue to hamstring these APUs regardless of how many cu they throw at em.",Neutral
Intel,"â€œAbsolute monsterâ€? It is 1/4 the graphical power of M3 Max, and eats way more watts. We are talking about Steam Deck here, so you basically have the same catalog of games on SteamOS as you do on Mac/CrossOver.  If you want to go price to performance, the base M3 is the same performance for around the same prices (starting at $500 for Mac Mini and going up to $899 for MacBook Air, with SD OLED starting at $549 and going up to $649). (I am assuming if a new SD had a new chip, it would at minimum start at OLED prices.) With the SD you will get higher base storage and RAM (though in my testing on both systems, neither has been able to pull 8GB total system RAM use on AAA games, due to APU bottleneck.). On the Mac side you will have better build quality, higher resolution, more ports, better speakers and most importantly for mobile gaming you will have 6 hours plus of AAA gaming. Where as there were some AAA games that killed my deck in 1 hour, with most dying around the 2 hour mark.Â   Â AMD has a long way to go before claiming â€œMonsterâ€ class APUs. 890M gets absolutely destroyed by the fanless ultra thin tablet mobile APU in the iPad. AMDs desktop APUs with full fat coolers and pulling watts from a wall outlet arenâ€™t even close to being in the running with a tablet, let alone M3 Pro.. Let alone M3 Maxâ€¦ let alone M2 Ultra. Its desktop tower chip is behind the entry level mobile OS chip from its competitor. It is a decade behind the desktop chips of its competitor, itis hardly Monster class.",Neutral
Intel,Blade 16 with AMD HX 375 and RTX 5070 along with dual display mode. Dream laptop.,Positive
Intel,"Even for Strix halo, most optimistic prediction puts it on a level with _mobile_ 4070. Thatâ€™s far from desktop 4070, never mind 4080.",Neutral
Intel,A real one.   https://www.anandtech.com/show/21485/the-amd-ryzen-ai-hx-370-review/9,Positive
Intel,Everyone sane would seem like a troll for fanatics enthusiastically living in a different reality.,Negative
Intel,">AMD has a long way to go before claiming â€œMonsterâ€ class APUs  AMD doesn't need to make ""Monster"" class APUs as they cater to the x86 desktop market where they make ""Monster"" dGPUs which can be upgraded independently.   And AMD ""can make"" such APUs -> PS5 Pro (as a more cost effective solution). AMD isn't like Apple who can make up the expense of creating a mega sized APU by selling a finished product/selling services etc.",Neutral
Intel,"APU is one of AMDâ€™s biggest markets. You are kidding if you think they donâ€™t need to compete there. They are way behind the race with Nvidia in desktop cards so that is irrelevant, unless your point was to say that they donâ€™t need to compete anywhere and they should always be in second place.     AMD cannot make such APUs. Their GPU cores suck 1 to 1 core to core compared to Appleâ€™s, so the size comparison is irrelevant. The PS5 Pro sucks. It performs worse than M2 Max and M2 Ultra. It sucks way too many watts for that level of performance (which also accounts for cost). Not to mention games arenâ€™t the only thing APUs are used for so PS5 isnâ€™t wholey in the conversation. PS5 also costs monthly to play online and their games arenâ€™t more expensive than PC so the whole cost savings thing is thrown out the window when you consider the real money being spent. Apple is a hardware first company and thats where the bulk of their profits come from, not services. Especially on Mac where there are little services at all people would even use there that have a subscription or software for sale.   If services were the reason, then for sure you would be able to buy a Surface Laptop powered by an AMD APU that puts MacBooks to shame, considering all your data Microsoft is selling, along with Office sub sales, and all the ads and preinstalled third party software. But instead Surface laptops are priced around the same as MacBooks and they have less powerful APUs and the AMD version suck up battery life.",Negative
Intel,"Not a single point of yours make sense.   ""APU is one of AMD's biggest markets"" - No. The major APU customer of AMD is Sony and Microsoft for their consoles. Not the general public as it's going to very expensive to sell PS5 type APU in the open market. 8700G costs 330 usd which is crazy.  ""The PS5 Pro sucks. It performs worse than M2 Max and M2 Ultra."" - Interesting, you already have comparisons between an unreleased console and an Apple laptop/desktop. Oh and how much does the cheapest M2 Max and M2 Ultra machine cost?   ""AMD cannot make such APUs. Their GPU cores suck 1 to 1 core to core compared to Appleâ€™s, so the size comparison is irrelevant."". No idea what benchmark you are referring, what metric you are comparing.   However I can provide some idea on CPU cores and die size as cross platform benchmarks are available.  Cinebench R24 Multicore:  2x71 mm2 16 core 7950X: 2142 pts   2x70.6 mm2 16 core 9950X: 3000 pts  1000mm2 M2 Ultra: 1918 pts  So yea, Apple's solution is simply throwing more money at the problem. A budget RTX 4070m/7800m will crush an M2 Max in pure GPU grunt.",Negative
Intel,"This post has been flaired as a rumor.   Rumors may end up being true, completely false or somewhere in the middle.  Please take all rumors and any information not from AMD or their partners with a grain of salt and degree of skepticism.",Negative
Intel,"Hey OP â€” PC build questions, purchase advice and technical support posts are only allowed in the [Q3 2024 PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1dsetov/pc_build_questions_purchase_advice_and_technical/).  For help building your system, purchase advice, help choosing components or deciding on what to upgrade, we recommend visiting /r/buildapc or using [PCPartPicker](https://pcpartpicker.com/).  For technical support we recommend /r/AMDHelp, /r/techsupport, [the official AMD community support forums](https://community.amd.com/t5/support-forums/ct-p/supprtforums) or [contacting AMD support directly.](https://www.amd.com/en/support/contact).  If you have found bug or issue with AMD software or drivers and want to report it to AMD, please use the [AMD Bug Report Tool](https://www.amd.com/en/resources/support-articles/faqs/AMDBRT.html).  The [subreddit wikipedia](https://www.reddit.com/r/Amd/wiki/index) is also available and contains answers to common questions, troubleshooting tips, how you can check if your PC is stable, a jargon buster for FSR, RSR, EXPO, SAM, HYPR-RX and more.  The [AMD Community](https://discord.com/invite/012GQHBzIwq1ipkDg) and [AMD Red Team](https://discord.com/invite/k4wtjuQ) Discord servers are also available to ask questions and get help from other AMD users and PC enthusiasts.  Please read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification.",Neutral
Intel,Gotta remember that it's Intel's first line of GPUs. It's going to have issues ofc. Even now they're still improving. And it's only going to keep getting better from here on out,Positive
Intel,"Ok mate, take a first gen product and compare it to a 7th or 8th gen product.  Intel has their issues, anyone buying into them should have known that.",Negative
Intel,"You probably setup VRR wrong, whether that wasnt enabling V-Sync (yes, youre supposed to for VRR), or you tried to use an older HDMI standard, or had a bad driver install and didnt clean install new drivers. Because it absolutely does work as intended with Arc. Arc's VRR is based on VESA's adaptive sync, like Freesync and G-sync compatible also are.  As for A750 performance being worse than a 6800 XT, duh. One card sells for $180, the $450, they are in completely different price and performance tiers. Just like a 7900XTX would make your 6800 XT look like its junk.",Negative
Intel,6800 ultra??? EDIT: so im a dumb it's a nvidia gpu that was made 20 years ago,Negative
Intel,"Don't be afraid to voice displeasure with any of the hardware vendors, otherwise you end up like the Nvidia stans.  Grats on the upgrade.",Neutral
Intel,"I don't recall any real driver issues with my 9700 and 9800 pro. None specific to ATi at least,  rather just the norm for Windows XP era gaming.",Neutral
Intel,"My experience with my RX 5700 was also really bad in the first months. Driver timeouts, blackscreens, game crashes. Not even exaggerating. Never thought I'd ever buy an AMD GPU again.      Now I have a RX 7800 XT and very happy. No game crashes due to driver issues, no blackscreens, everything is fine.",Negative
Intel,"Hey OP â€” /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible**, this is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.  Your post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).  **Posts regarding purchase advice, PC build questions or technical support will not be approved.** If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the [Q3 2024, PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1dsetov/pc_build_questions_purchase_advice_and_technical/).   *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",Neutral
Intel,bruh. This is Intel first generation of discrete GPU. it's damn impressive how fast they are improving. I like AMD too but Intel is doing a pretty good job there,Positive
Intel,I had an arc a750 as a placeholder until I got. A 6950xt and I love it so much. Except amd still hasn't fixed the ghost of tsushima issue other than that it's been phenomenal and I get over 60fps in almost every game at 4k,Positive
Intel,"Well one great thing you have to look forward to is amd is going all in on software. They already said FSR with AI is coming, and I have a feeling a lot more. We should be seeing some pretty cool software features coming out now that they have more employees for software",Positive
Intel,"Actually not. Intel i740, released long time ago was the first discrete GPU from them.",Neutral
Intel,"I'm keeping my eye on Intel gpus, but I certainly won't be a first adopter. Honestly I'll be even more skeptical now with Intel's recent issues with 13/14 gen cpus. All in all though more competition is always good for us consumers. If Intel can be competitive in the budget market it will at least put a fire under amd to lower their prices/make a better valued product.",Negative
Intel,That would be fine if no one else had ever invented a GPU until Intel did.   The fact is there's lots of architectural precedent for Intel to have learned from that they just...didn't. Problems that Nvidia and AMD both solved decades ago that are holding Intel back in 2024.   It's not a mystery how a GPU should be built but that didn't stop Intel from not figuring it out.,Neutral
Intel,"Installs beta software, proceeds to complain about it",Negative
Intel,Doesn't make it less of a fact that users are experiencing issues and they still paid hard cash for those GPUs.,Negative
Intel,"Nope it was set up correctly and verified by Intel insiders discord ARC engineer team also verified it was set up by multiple people Intel acknowledge the VRR was not working as intended but had no solution and all drivers cleaned in safe mode with DDU.  VSYNC with VRR, both on and off, also verified to be working via windows confirmation, connected to Display Port because ARC does NOT support VRR over HDMI 2.0 and needs minimum HDMI 2.1  I am also a experienced PC Technician for over 2 decades.  The 6800 XT just works, right out of the box rock solid functionality, period!  I just happened to have a monitor capable of reporting extra statistics and I have knowledge of using Frog Pursuit from aperture grill to test both backlight strobing cross talk and VRR functionality for each individual monitor and GPU my monitor is also a Blur Buster 2.0 certified monitor  after realizing it was an issue with ARC I ordered the 6800 XT, removed ARC and ran DDU in safe mode.  Slapped in RX 6800 XT, installed newest driver and VIOLA, works beautifully first attempt with zero configuration whatsoever. Forget about the raw power we know the 6800 XT is obviously in a class far above anything Intel is currently offering so is it's price. It's just unfortunate the ARC fails to match even a 6600 XT in UE5 games but it's gonna be fixed with battlemage rest assured.   The ARC architecture just isn't there for UE5, drivers won't fix that performance issue, AMD just happens to do extremely well with UE5 because their architecture is more mature.  The bottom line the AMD drivers are obviously and understandably light years ahead of Arc drivers.  Nothing wrong with that ARC is a beta product that's why Intel doesn't build a 4090 or 7900 XTX competitor because drivers are their current issue not hardware.  Again there is NOTHING wrong with ARC having these issues it is a beta card, Intel specifically warned AGAINST buying it if you need a reliable card, I bought it to help intel and test it our of curiosity, I wasn't really prepared for that much issues but it's fine it has a happy new owner who isn't even using if for gaming he is using it for AV1 encoding.  I am just glad I could help out with the sale for a 3rd party vendor in the race here and am even happier I got rid of it and it has a new owner who isn't using it for gaming  It was an impossible sell for gaming nobody wanted it for gaming sadly but it worked out for me in the end",Neutral
Intel,What Ghost of Tsushima issue?,Neutral
Intel,"That was back in the 90's... While it would technically be their first, absolutely nothing from that dGPU wouldve carried over to Arc, its so old that its irrelevant to talk about.  You could also say DG1 from 2020 could be their 'first' dGPU since it was their first modern dGPU oriented at consumers, albeit it was clearly just an ultra low volume test platform to figure some stuff out prior to the Arc launch.  Most people would consider Alchemist (Arc gen1) as Intel's first dGPU, even though it technically isnt, it's still the most relevant one.",Neutral
Intel,"This was a graphics card, not a â€˜GPUâ€™ in terms that we understand them now, just to bolster the point about how much of a disparity this comparison reveals.",Neutral
Intel,"Arc is not beta, neither the hardware, firmware or sofware. Intel does not refer to it as beta, why should the consumers do so? They paid full price for a product and it should work as advertised.  With that said, the issues with Arc are widely known and complaining about it after the fact is a bit sillly at this point.",Negative
Intel,If you're playing ghost of tsushima with her enabled it will crash your drivers and you'd have to re-download them via integrated graphics on your cpu,Negative
Intel,"It's not completely irrelevant, as it shows they already had GPU produced before. That GPU had driver issues same as ARC and i believe same will be passed on to BATTLE MAGE.",Neutral
Intel,"Dude, GPU is not same as graphics card. i740 was a GPU in a same way nVidia RTX and AMD RX series are today.  You are mixing them up because todays graphics cards have names same as the GPU used on them.   Heres a bit of good ol' Wikipedia:  [Intel740 - Wikipedia](https://en.wikipedia.org/wiki/Intel740)",Neutral
Intel,Graphics Processing Unit.  Maybe you're confused and thinking of GPGPU?,Neutral
Intel,"her?   i cant say i encountered any problems other than launching with FSR activated crashed the game, but it was optimized enough that you dont need FSR at all (also a ps4 game port which helps)",Neutral
Intel,It's irrelevant because it's from so long ago the people who worked on it are likely no longer working at Intel so there's no organizational knowledge to transfer into designing Arc.,Negative
Intel,Not irrelevant though is that Intel has been making iGPU drivers for the last 20+ years with massive marketshare and still don't get it anywhere NEAR right.,Negative
Intel,The documentation for it would still be in their archives,Neutral
Intel,"""last updated by unknown user at 3:26AM March 15th, 2003""  Please keep this page updated. It's our only document for this application.",Neutral
Intel,"Pretty annoying how everything follows the same linear fps/price curve, thereâ€™s no advantage from buying the cheaper cards as there used to be in earlier generations years ago.",Negative
Intel,Wish Arc cards were better. They look so pretty in comparison to their peers,Positive
Intel,Thats actually a pretty solid and accurate breakdown.,Positive
Intel,I like the part where they declare that 8 GB of VRAM is not enough for today.   But that was a very well done article.,Positive
Intel,3080 still looking good too,Positive
Intel,What they have peaceful then 4k series?,Neutral
Intel,Just get a 4090. I will never regret getting mine.,Positive
Intel,i miss old good times where radeon HD 7970 as best single core card cost around 400$,Neutral
Intel,"Damn, the A770 is still so uncompetitive...",Negative
Intel,"It's like the free market priced cards according to their relative performance. How weird, right?",Negative
Intel,How is that possibly annoying,Negative
Intel,Honestly the Nvidia Founders edition in person is the best looking card I've ever seen.,Positive
Intel,"I bought an ARC A770 16GB card for experimentation and my experience seems to have been better than computerbase.  I had no problem using it for 3440x1440 without raytracing. I have to reduce some settings in the heaviest games, but then I can hit 60fps in most games without using upscaling.  It makes me wonder if they have used older drivers, since they don;t even get 60fps rasterized at 1080p in some games.  edit: And I paid much less than the minimum price they are listing, I'd need to check if prices went up - even though computer base suggest that isn't the case. The bigger problem still, but getting better, is that when it doesn't work it's really really terrible.",Positive
Intel,"Well I mean... I guess it depends on what you're wanting to do of course, but even my 12 GB card was struggling to do raytracing a couple years ago, so that claim isn't really far fetched.  My 20 GB card struggles to hit 60 fps with path tracing at 1440p",Negative
Intel,I have a budget build for my vacations off grid with arc a380 heavy oc pushing 2750mhz. Works amazing for 1080p e sport titles and some heavy games low settings around 50-60fps.. off no ray tracing lol.,Positive
Intel,8gb perfectly fine today :),Positive
Intel,"Ah yes sure, now where did I leave my 1500 euros?",Neutral
Intel,"I donâ€™t mind free markets, Iâ€™m just saying the state of the market is less fun now than it used to be.",Negative
Intel,Something about that sexy look of my GTX 1080 fe is gonna make it very hard to replace it.,Positive
Intel,"Yeah, i like the black super series.",Positive
Intel,"But that's not because your GPU has 20gb vram, that's because AMD doesn't perform well in RT and especially not in PT I promise you a 16gb 4080 will run circles around your 7900xt with PT.  And no I'm not an Nvidia chill I have a 7900xtx myself",Negative
Intel,"people have more information more easily available now, so they know what a good price is for a gpu.   Yeah, you can't a good deal on older cards just because they're old, but you can get more money for your old cards yourself when you wanna upgrade.",Neutral
Intel,I think this needs more mainstream coverage - someone like Wendell@Level1Techs should be interested in this and related phenomena.,Neutral
Intel,"Same experience when using AMDGPU on Linux. Hardware rings will reset after timeout, but you have no guarantee that functionality will return to normal after the reset. The only solution is to reboot the entire system. The video codec rings VCN/VCE/UVD is seriously affected by this. But there seems to be nothing the kernel developers can do about it. [https://gitlab.freedesktop.org/drm/amd/-/issues/3098#note\_2236916](https://gitlab.freedesktop.org/drm/amd/-/issues/3098#note_2236916)",Negative
Intel,"""The ability to â€œturn it off and on againâ€ should not be a low priority additional feature""  THANK YOU    Please please please AMD fix this. I use your CPUs and GPUs, and have for a long time. I am also a some time VFIO user, and I do NOT want to have to buy an NVidia GPU for this purpose.",Neutral
Intel,">listen to them and fix the bugs they report  AMD have been dropping the ball on this for decades, and aren't about to pick it up any time soon. It is genuinely astonishing how poor their bugfixing/driver development approach is. I filed a bug recently and was told they didn't have a single windows machine with a 6700xt available on for testing/reproing a problem, which...... is quite incredible",Negative
Intel,"""EDIT: AMD have reached out to invite  me to the AMD Vanguard program to hopefully get some traction on these  issues \*crosses fingers\*.""  That is a great idea actually and I vouched my support on the matter.",Positive
Intel,"They couldn't care less. We've had issues with AMD drivers in a video production house where we ran Vega GPUs under Linux for DaVinci Resolve editing on the desktops and for rendering on the farm.   Those were the worst years of my life where I had to support the investment that failed as soon as the decision to go with AMD was made.   It costed our company the weight of those cards in solid gold.   After years of battling AMD and failing, I made an ultimatum to our ceo and told him directly that I didn't want to support this anymore and that I'd leave if we didn't switch everything to Nvidia and I actually quit the company over this because the response was that it was impossible. 2 months later they sold all the AMD hardware at a fraction of the original price and managed to take a credit to switch everything to NVIDIA.  Somebody else even made a huge post here and on r/linux, phoronix covered it slightly and AMD went into full panic mode, their developer advocate came here and on AMD forums and in emails and made many grand promises. Here we are almost 10 years later, same issues still exist.  Oh yeah, and BlackMagic (DaVinci Resolve maker) today officially doesn't support their software on any AMD hardware. Thousands of editors, graders and admins go on forums and ask about AMD only to just get directed to Nvidia by the BlackMagic staff.  Great job AMD! You don't deserve a single customer...",Negative
Intel,"Bit of a rant, but I have an AMD 6700XT and do a wide variety of things with my computer. It feels like every way I look AMD is just completely behind in the drivers department..  * Compute tasks under Windows is basically a no-go, with HIP often being several times slower than CUDA in the same workloads and most apps lacking HIP support to begin with. Blender Renders are much slower than much cheaper nvidia cards and this holds true across many other programs. DirectML is a thing too but it's just kinda bad and even with libraries as popular as PyTorch it only has some [half baked dev version from years ago](https://github.com/microsoft/DirectML/issues/545) with many github issues complaining. I can't use any fun AI voice changers or image generators at all without running on CPU which makes them basically useless. [ZLuda](https://github.com/vosen/ZLUDA) is a thing in alpha stage to convert CUDA calls to HIP which looks extremely promising, but it's still in very alpha stage and doesn't work for a lot of things. * No support for HIP/ROCm/whatever passthrough in WSL2 makes it so I can't even bypass the issue above. NVIDIA has full support for CUDA everywhere and it generally just works. I can run CUDA apps in a docker container and just pass it with --gpus all, I can run WSL2 w/ CUDA, I can run paravirtualized GPU hyper-v VMs with no issues. * I'm aware this isn't supported by NVIDIA, but you can totally enable vGPUs on consumer nvidia cards with a hacked kernel module under Linux. This makes them very powerful for Linux host / Windows passthrough GPU gaming or a multitude of other tasks. No such thing can be done on AMD because it's limited at a hardware level, missing the functionality. * AMD's AI game upscaling tech always seems to just continuously be playing catch-up with NVIDIA. I don't have specific examples to back this up because I stopped caring enough to look but it feels like AMD is just doing it as a ""We have this too guys look!!!"". This also holds true with their background noise suppression tech. * Speaking of tech demos, features like ""AMD Link"" that were supposed to be awesome and revolutionize gaming in some way just stay tech demos. It's like AMD marks the project as maintenance mode internally once it's released and just never gets around to actually finishing it or fixing obvious bugs. 50mbps as ""High quality""? Seriously?? Has anyone at AMD actually tried using this for VR gaming outside of the SteamVR web browser overlay? Virtual Desktop is pushing 500mbps now. If you've installed the AMD Link VR (or is it ReLive for VR? Remote Play? inconsistent naming everywhere) app on Quest you know what I'm talking about. At least they're actually giving up on that officially as of recently. * AMD's shader compiler is the cause of [a lot of stuttering](https://www.reddit.com/r/Amd/comments/12wizig/the_shader_cache_stutter_on_amd_is_way_more/) in games. It has been an issue for years. I'm now using Amernime Zone repacked drivers which disable / tweak quite a few features related to this and my frametime consistency has improved dramatically in VR, and so did it for several other people I had try them too. No such issues on NVIDIA. The community around re-packing and modding your drivers should not even have to exist. * The auto overclock / undervolt thing in AMD's software is basically useless, often failing entirely or giving marginal differences from stock that aren't even close to what the card is capable of. * Official AMD drivers can render your PC completely unusable, not even being able to safe mode boot. I don't even know how this one is possible and I spent about 5 hours trying to repair my windows install with many different commands, going as far as to mount the image in recovery environment, strip out all graphics drivers and copy them over from a fresh .wim but even that didn't work and I realized it would be quicker to just nuke my windows install and start over. Several others I know have run into similar issues using the latest official AMD drivers, no version in particular (been an issue for years). AMD is the reason why I have to tell people to DDU uninstall drivers, I have never had such issues on NVIDIA. * The video encoder is noticeably worse in quality and suffers from weird latency issues. Every other company has this figured out. This is a large issue for VR gaming, ask anyone in the VR communities and you won't get any real recommendations for AMD despite them having more VRAM which is a clear advantage for VR and a better cost/perf ratio. Many VRchat worlds even have a dedicated checkbox in place to work around AMD-specific driver issues that have plagued them for years. The latency readouts are also not accurate at all in Virtual Desktop, there's noticeable delay that comes and goes after switching between desktop view and VR view where it has to re-start encoding streams with zero change in reported numbers. There are also still issues related to color space mapping being off and blacks/greys not coming through with the same amount of depth as NVIDIA unless I check a box to switch the color range. Just yesterday I was hanging out watching youtube videos in VR with friends and the video player just turned green with compression artifacts everywhere regardless of what video was playing and I had to reboot my PC to fix it. * There are *still* people suffering from the high idle power draw bugs these cards have had for years, me included. As I type this my 6700XT is currently drawing 35 watts just to render the windows desktop, discord and a web browser. How is it not possible to just reach out to some of the people experiencing these issues and diagnose what's keeping the GPU at such a high power state??  If these were recent issues / caused by other software vendors I'd be more forgiving, I used to daily drive Linux and I'm totally cool with dealing with paper cuts / empty promises every now and then. These have all been issues as far back as I can find (many years) and there's been essentially no communication from AMD on any of them and a lack of any action or *even acknowledgement of the issues existing*. If my time was worth minimum wage, I've easily wasted enough of it to pay for a much higher tier NVIDIA GPU. Right now it just feels like I've bought the store brand equivalent.",Negative
Intel,"Yo, I saw the title and thought this gotta be Gnif2.",Neutral
Intel,"And I'm over here struggling to keep an Nvidia T4 passthrough to work reliably on Hyper-V to Ubuntu 22.04. :(  Is there a specific software combination that works more reliably than others?   Also, what do you think is the core fix here? Is it hardware design, in the firmware, drivers, combination of everything? If it was an easy fix, you'd think AMD would have fixed it.  When Hotz got on Twitter for a particular issue, AMD seemed to jump on it and provide a fix.  But for these larger issues they don't.  Could there be a level here where the issue is really the vendors design and how they implement AMD's hardware?   Some of the most powerful super computers use Instinct.  Seems hard to believe that they would just put up with these issues and go back to AMD for their next upgrade, which Oak Ridge has done.  They working with some kind of magic radiation over there?",Negative
Intel,"I've got a 7900XTX for a year now, and I've not had any stability or performance issues with it, so far at least.  What does bothers me though, is that 1 year later I still cannot connect my 3 monitors to the card without it sucking 100watts at idle, and recent drivers don't even mention that as an issue anymore, so it's not even being recognized as a problem by AMD.  This happens even if my monitors are turned off, I literally have to go under my desk and pull out the cable to resolve this, obviously rendering my extra monitor useless.   So now I'm looking to upgrade my cpu (5800x) to one with an integrated GPU so I can connect my secondary monitors to the iGPU so my system doesn't constantly suck an obscene amount of power doing absolutely nothing.  You're free to guess what vendor om looking at to replace my CPU with. Damn shame really.",Negative
Intel,"Fact: AMD does not give a shit about any of this.   We still have CPU scheduler issues, we still have NUMA issues when dealing with latency sensitive PCIE deployments, the famous reset bug in your OP, lack of Vendor relationships and unification across the platform (IE, Epyc, Radeon/Instinct, AMD Advantage+, ...etc).   In the years since Zen shipped, it took an act of god to get them to move. Maybe Lisa remembers those meetings we pulled with Dell, HP, and VMware back then. Where the cloud providers that adopted Epyc 7001 early were all very pissed off at the over all performance because of the failure of AMD to work with the OEMs to correctly adopt how NUMA changed. Because they did not get any guidance from AMD engineering on the matter until after these SI's were mid/full deployment.   So yes, I doubt AMD is going to take your OP any more serious then they took the NUMA issues until it starts to affect their bottom line. If all CDNA customers switch to NVIDIA and those PO's dropped in volume, it might make them care a little bit.",Negative
Intel,"6600xt reset just fine but my 6800, oh boyyy. amdgpu refuses to unbind it so I can restore it to the host. Thank you for all the great work!",Positive
Intel,"Iâ€™ve been buying ATI / AMD since the ATI Rage 128, and I think my next GPU will be Nvidia. I primarily game on my 6950XT, but sometimes I might try to mess around with an AI tool, or some sort of tool that uses GPU compute. Every. Single. Time. It is a massive PITA and most of the time I end up giving up and moving on. The most recent time it involved using an AI tool to restore a photo. After hours of screwing around on Windows and Linux I ended up just having a friend with a 3080 do it for me. He had it working in 10 minutes.   And when stuff (outside of gaming) does work, itâ€™s usually a day late and a dollar short. Blender on Linux still canâ€™t do hardware RT in Cycles (it can on Linux), and general HIP support tool far too long.   The argument can be made that thereâ€™s no need to worry about this if you only game, but unless price is an issue, you may be locking yourself out from testing a cool piece of software later.   I guess it really depends on if things are improved when it comes time to buy a new GPU, but weâ€™ll have to wait and see.",Neutral
Intel,"I promise you the Vanguard program will yield nothing. ""*AMD Radeon*â„¢ *Software Vanguard* Beta Testers are selected community members with exclusive access to early drivers to provide critical feedback.""  Basically they made a program out of you doing free QA work for AMD. Don't fall for it.  Watch their hands, not their mouth. Docs + firmware source = good. Promises + ""access"" = worthless. I fell for this too, not again.  These issues haven't been fixed for a decade. I doubt AMD is capable of fixing them. I think a lot of community people could with docs and source, but AMD doesn't even seem willing to take that step.",Negative
Intel,"[Wish i could play Hell Divers 2 but when i bought it took 30 seconds to get a driver timeout,](https://i.imgur.com/FqM9MRx.mp4) anyway i decided to not switch NVIDIA cos i also well usually play a lot of World of Warcraft but that game has problems for both AMD in form of freezes and driver timeouts gradually getting worse until you update drivers again, cos shader cache gets reset it stops crashing again for couple of days, then starts crashing more frequently and the frequency varies per user and what they doing as well as if their some sort of memory leak.  Also some other games having driver timeouts to, but i have games that also never timeout.  Speaking of which users started reporting flickering issues in browsers such as chrome, or any chrome based browsers, and their 2 reports of it being fixed after MPO is disabled so i guess MPO issues are back on the menu.  [Also i would love to see AMD Gaming YouTube channel to play and livestream Horizon Zero Dawn with HDR turned on in game using AMD relive ](https://i.imgur.com/1RtZtsi.mp4)  Their also way more issues then i just mentioned i have like 41 commonly reported issues from reddit and forums that not been fixed in 24.3.1 and its still going up, some of my own reported issues as well.  I highly recommend AMD to have public bug tracker for reporting issues also games, allow users filter on games to see all the user reports for that game, have it all consolidated into same issue if its the same issue, allow users only to upvote remove down vote, i do not have any issues does not contribute to fixing problems it encourages ignorance nothing personal against anyone not having issues, i often have no issues to but they are not proof of stable drivers, they are just one user experience not everyone user experience, everyone is allowed to speak for them self, AMD does not require any defending, the only time its appropriate is when AMD is treated unfairly missing from benchmark charts unfairly.  Also not all issues are always caused by AMD but that does not give AMD the right to ignore it, especially considering their plenty of problems usually, it just means AMD is lacking in the compatibility departement and the whole anti-lag+ debacle says enough about that, alto i really liked that feature i would rather blame cheaters, cos without cheaters you would not need anti cheat, and this would be less of a problem, still says more about fact that their probably should be something like api support for features such as anti-lag+ but also AMD enhanced sync or NVIDIA features.  I think developers and studios etc all should work together, instead of trying to sabotage each other for the sake of monopoly i am looking right at you NVIDIA just stop.",Negative
Intel,Long but worth it read; Well Done!,Positive
Intel,"Business opportunity for EEs now: Time to make some custom PCIe adapter boards with a bunch of analog switches for cycling all power and signal lines on the PCIe slot, then sell them for use in corporate AMD GPU deployments. Sure, toggling PCIe signal is expensive, as it's basically a radio signal at ~10 GHz. Toggling the 12 V power input is also expensive due to the high current. But both are ""just"" expensive but doable. The cost, at worst, is an expensive relay for power, and additional PCIe redrivers or switches for signals. ""It's one PCB, What could it cost, $100?"" If corporate users have already paid hundreds of thousands of dollars on AMD GPUs, and now someone's offering a solution to actually make them usable at a fraction of the original hardware cost, it must be selling great.  On second thought, the hardware must be certified and pass PCIe compliance tests and electrical safety tests before they're acceptable for big corporate users. Even then, most are not in a position to do any hardware modification (including adding additional hardware). So the ""proper"" way of doing so would be first contacting a big corporate user first, ask them to request this feature from server vendors like Super Micro. Then you need to pass this design to them, and they pass this design to Super Micro, and it will only appear in a next-gen server... This makes this workaround largely impractical. I guess that's why nobody is already doing it.",Neutral
Intel,I had the same problem with the Vega 64 liquid edition...    On my PC the 6800xt is working ok... The 7600 on my work pc is SHIT ... Same problems with Vega and if you have a second monitor is x2 :(,Negative
Intel,"The reset issues also happen in Windows, even when it recovers after 5 mins (what the hell it's quicker to reboot, nvidia cards reset in 10s max), the card is not fully reset and some issues i personally noticed with display detection/wake-up not working normally;   Also in a crash UEFI portion doesn't load properly so either the bios resets CSM to enabled, or if your mobo/bios doesn't do this it will go without video output until windows loads. This is with 6900xt, huge FAIL in my opinion.",Negative
Intel,"> Those that are not using VFIO, but the general gamer running Windows with AMD GPUs are all too well aware of how unstable your cards are. This issue is plaguing your entire line, from low end cheaper consumer cards to your top tier AMD Instinct accelerators.  Not over here my guy. I switched from a 1080 Ti to a 6800 and it actually fixed crashing issues I was getting in Cyberpunk. Used that 6800 for over 3 years with no issues, and then switched to a 7900 XTX and also no issues.   I also have a used 7600 I bought cheap for one of my TV computers, and that one has also been fine, even when I borrowed it out for a while to a friend so he could run Helldivers 2 without the text graphical glitches he was getting with his old 1080 Ti.  I know there are some issues with AMD drivers, just like there are issues with Nvidia drivers, but I feel like I'm taking crazy pills where the internet is screaming about how incredibly terrible AMD GPU's and drivers are and I'm over here using them for years with no problem.",Neutral
Intel,AMD solftware stack is lacking hard. . . The AI / LLM issues recently and now this. AMD needs to invest in it's software side now.,Negative
Intel,Iâ€™ve been using the 6800xt for almost a year now and from the crashes to the timeouts I decided that im gonna pay the green tax so i paid 900$ for a 4070ti and magically all of my problems disappeared as much as i love AMD i just cannot recommend their GPUs,Negative
Intel,"Thanks for bringing some sense of consumer advocacy towards VFIO.  Very difficult dealing with AMD lately, especially with RMAs on busted CPUs/GPUs (had Vega and 5950X die on me). Let us know how the Vanguard(trash name) program is.",Negative
Intel,Exactly why I got rid of my 7900XT and went back to using a GTX 1080.  The constant crashing was driving me nuts.,Negative
Intel,"why invite to a conference instead of directly contact gnif and fix the problems 5 years ago? why does gnif need to create the reddit post, begging amd to fix their shit? Why can't amd fix the problems without external impetus? It says a lot about the company.",Negative
Intel,"AMD bugs is why my workstation runs Nvidia, I'm hoping Intel moving into the GPU Space is a wake up call to AMD.  I had these issues as well.",Negative
Intel,"Nevermind, you just came to do god's work, and a very good one btw, to find the same fanboys ""I've had Bla Bla years experience and bla bla I game and bla bla never had problems with AMD.""  God damn those guys are just blind. Every time I say the truth about the instability of AMD software, I just get downvoted by people that are just blind. I think they're the defense of a brand like it they are defending their sports club.  We're stuck between the overpriced that just work, and the nightmare the AMD software overall is. I get it for the normal user and some power users, if we look at normal windows usage, adrenalin is such a good attempt to have everything on one software bundle, the overclock, the tuning, the overlay, the recording. All in one GUI that makes it easy. In theory, it is a good attempt.  Note I said attempt...  I'm not debugging the same as you are, I am mostly troubleshooting, I only use regular Linux, normal windows, virtualize one machine I use and some I try also virtualized, and configuring some basic routing through Linux server, but still I bought one AMD card, and I already did more than 6 bug reports to AMD to fix a bug with my specific hardware setup regarding the adrenalin causing stuttering in the OS every few seconds and in my long IT experience not focused on the debugging and coding of things but more on the troubleshoot and fixing of computers, hardware/software wise I must say that what I think is: They tried to do it all in one, they wanted to put the foot on the door to face the overpriced green team, great software/hardware specs, something that would put normal users with a power software suit that could do it all. Except it can't.  Constant thousands of posts regarding crashes, hangouts, reboots, tweaks, registry edits, hotspots over 100Âºc, incompatibilities with the OS, everything is to blame on the system except the AMD GPU. Chipset drivers that can't clean old drivers on install and create registry entries mess, GPU drivers that, will mostly work if you always do clean install, but with a software bundle that causes too much conflicts with the driver itself etc etc  I know Microsoft is complicated, but we're not talking windows millennium here, and if other brands manage to have drivers/programs that actually work with the OS, why can't AMD, and why do the warriors for AMD blame the OS, the PSU, the user, everything except AMD, when it is their favourite brand to blame?  And when you want to factually discuss it to have maybe a fix, a workaround, a solution, some software written by someone like you that actually fixes things, something, what do you get?  ""I have had X AMD GPUs, with Y experience in computers, never had a problem!""  Or even better, ""That is because you suck at computers"" said by some NPC that doesn't even know what an OS is..  I really hope your letter gets where it needs to go, and please keep up the good job. I still hope AMD steers in the right direction so it can put Nvidia to shame(I want to believe poster here). Not because I have something against this brand or the other, but because we need competitors, or else you'll end up paying 600$ for a nice system, and 6000$ for the GPU. Competition between hardware manufacturers is overall good for innovation, and good for our wallets.",Negative
Intel,Lmao as a recent AMD intern I feel this in my bones. I still canâ€™t fathom just how little effort is put into software stability these days.,Negative
Intel,100% all of this...  Love looking glass by the by,Positive
Intel,How does say VMware handle this? Does it kind of just restart shit as needed?,Neutral
Intel,"> Those that are not using VFIO, but the general gamer running Windows with AMD GPUs are all too well aware of how unstable your cards are.   Wait really? How come I never noticed this on over 15-20 amd GPUs since 2016, I game a lot and use them for 3d modeling... Always stable as a rock.",Neutral
Intel,"well you know what, I got a amd 7950x based machine with a 6800xt and 7900xtx with unraid handling 2 windows vm. I agree that rdna3 cards are more difficult to run but man the 6800xt worked well without doing anything and 7900xtx only needed a few clicks. for cards not meant to do this it's quite good. btw build has been running flawlessly since feb 2023",Positive
Intel,"I really think AMD gives users too much control. They've popularized Precision Boost Overdrive and tuning your GPU within the driver which dramatically will increase the issues people have.  For example: black screen restarts will significantly increase when PBO is on during gaming even without curve optimizer. Do you know how many issues I've helped people fix ""with their gpu"" by just resetting their BIOS and turning on XMP?  Also, too many people go online and watch a 5 min tutorial on GPU overclocking. They throw on Fast vram Timings, undervolt their card, overclock the core, and set a fan curve with 0 testing.",Negative
Intel,AMD lost a graphics card sale to me because of this issue -- Went with the 4070 instead of the 7800xt.,Negative
Intel,"As a Linux user I feel your pain!  Even more as there are a lot of programs and game that either don't work at all with compatibility layers or they still have a lot of problems even if they work.  And that's besides the extremele huge amount of time wasted with the ""trial and error"" to find a working combination of configurations.  A properly virtualized Windows would solve so many problems until more programs and games become Linux compatible, either natively or through compatibility layers.  The moment a GPU vendor takes virtualization properly and works on the consumer GPUs and works well, I'm gone!  Price doesn't matter as much for mas the quality!  So AMD, please stop with the bullshit that virtualization is required / needed for enterprise cases only and make it work well for all the consumer GPUs, or get lost!  I'm really tired of this crappy attitude!  I'm already very upset upset that a 30 dollars Raspberry Pi has CEC support to control the programs on it with the TV remote and your 10-20 times more expensive GPUs don't!",Negative
Intel,"> Those that are not using VFIO, but the general gamer running Windows with AMD GPUs are all too well aware of how unstable your cards are.  Hyperbole - most people have few issues - this is one of those perceptions that isn't really matched by reality.  Things like ROCm are definitely still flaky, but gaming is basically fine - it's not as if Nvidia drivers never give people issues. If AMD's drivers were as bad as people make out (for gaming), no one would ever buy them.",Negative
Intel,"does crashing a OC on desktop on GPU, reset CPU PBO settings from bios still ?",Neutral
Intel,"Agree with the post. As someone in the industry (and a homelab), we all know buying amd is a compromise.",Neutral
Intel,"a few years ago I emailed Lisa Su about a big problem with Instinct GPU offerings in Azure because I couldn't figure out who to email the problem to, and the issue made AMD look bad even though it was a microsoft problem.  She cc'd in the correct engineering department, and a week later they rolled out a fix    I'm not suggesting everyone email the CEO for any little thing, however if the problem is severe enough then you could try emailing her and explain why this makes AMD look bad even to AMD supporters and why it should be important to them to care about",Negative
Intel,"""You cant get fired for buying Nvidia"", they dont even need to say it.  This was a old saying back then about IBM",Neutral
Intel,Ever since I switched to an RX 6800 I'm getting a bluescreen maybe once every 100 hours in Windows 10. My GTX 970 was extremely stable in comparison.,Neutral
Intel,"well, after facing annoying blackscreen flickering with my rtx 3070  @4k 120hz iam not ao sure about driver stability in nvidia.",Negative
Intel,"If PSP crashes, the security state of the data on chip and on the board is compromised and it should not be recoverable. I think it opens up the chip to all sorts of vulnerabilities.",Negative
Intel,"It's wild that this is supposed to be such a big issue, but I've been on AMD for nearly a decade and have had ZERO issues.   Methinks that when you power users get into super complex setups, you forget your basics and lead yourself into your own problems.",Negative
Intel,TL;DR. **PEBKAC**.,Neutral
Intel,"Hey OP â€” /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible**, this is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.  Your post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).  Posts regarding purchase advice, PC build questions or technical support will not be approved. If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the pinned megathread.   *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",Neutral
Intel,"While I'd love for AMD to fix its problems, I think that it's simply that smaller, lower visibility markets matter less to AMD. Working to be competitive both for gaming and for AI servers is work enough.",Negative
Intel,maybe stop using consumer grade GPUs for enterprise ML? I'm glad these issues exist.,Negative
Intel,"Gnif is active on the l1t forum. Wendell can't really do much on his own either, root issue is just amd stonewalling and sticking its head in the sand",Negative
Intel,I use my second monitor to check my 9 cameras. They use video hardware acceleration. Every time I open or close a game in the main monitor the client freezes and crashes...  ðŸ˜¤ðŸ˜­,Negative
Intel,"Serious question, why would you not want to buy what just works if you're having problems.  Brand loyalty doesn't compute in this scenario to me.",Negative
Intel,it is the reason i stopped mining to be honest. i had a vfio server that during dead hours i would start hiveos or something to mine on. it was a great automation project and the server had like 4 gpus so i was a good bit of money but the need to have the server reset for the vdi to work in the morning was awful,Negative
Intel,"Thanks mate I appreciate it, glad to see you here :)",Positive
Intel,"Yes, lets fix AMD stuff for them. Im sure they love free labour.",Positive
Intel,"So, did you join the vanguard yet? and are you seeing just how worthless that program is?",Negative
Intel,"I enjoy a variety of hardware with elements from AMD. Such as my ryzen based desktops and laptops. Ps5, ROG ally. But i just wont buy a high performance AMD based GPU. Especially for productivity tasks. Too many software issues and the support just is not there. Steer clear when your livelyhood and income depends on it.",Neutral
Intel,"Boy do I remember some of this. Wasnt even a company I was working at, but they brought us in as a SI to ""help"" fix some of the resolve issues. After working with BlackMagic we just used their PR  to tell the customer ""Sorry, you are shit out of luck. This is not supported and there is nothing that can be done. it's time to rip and replace and eat the cost, unless you do not care about profits and having a functional business."".",Negative
Intel,Lol wow.  People wonder why Nvidia has a $1 trillion dollar market cap....,Positive
Intel,This sounds more like a RIP on black magic than it is AMD... after all AMD hardware works fine for those tasks in other software.,Neutral
Intel,"I agree with most things except VRAM, you have to compare GPUs with the same amount of memory, otherwise it's typical to use more if more is available. Why would you load assets constantly from SSD/RAM instead of keeping them in VRAM for longer. Unused VRAM is wasted VRAM.",Neutral
Intel,>HIP often being several times slower than CUDA  ZLUDA proves that HIP isn't slower... the application's implentation of the algorithms written over HIP are just unoptimized.  HIP has basically 1-1 parity with CUDA feature wise.,Neutral
Intel,"This is honestly why as much as I'm liking my 7800XT, I'll probably go with the ""5070"" or whatever it's called next year",Positive
Intel,"Epic. Thanks for details.  I seen many times how youtube-creator/streamer went for amd gpu, get multiple crashes in first 20 min of using it, and returned it and get replace for nvidia, also vr-support on amd is joke, especially with screen capture.  For me it always was crazy to see how ""tech-youtubers-hardware-reviewers"" never ever test VR or/and ML on AMD, and those who promote amd-for-linux on youtube - they dont even use amd-gpu themselves, and do alll video-editing and AI-ML stuff on Nvidia... for promo video about amd-gpu... ye  I have experience with amdgpu from integrated gpu in Ryzen, and I was thinking to go for amd for compute-ML stuff just last month, but I did research:  [https://www.reddit.com/r/ROCm/comments/1agh38b/is\_everything\_actually\_this\_broken\_especially/](https://www.reddit.com/r/ROCm/comments/1agh38b/is_everything_actually_this_broken_especially/)  Feels like I dodged the bulled.  >AMD's AI game upscaling  Nvidia have RTX voice, they launched upscaling of video in webbrowsers, and now they launching RTX HDR - translation 8bit frames to hdr.  It is crazy to hear from ""youtube-tech-reviewer"" - ""amd good at rasterisation""... we in 2024 - you do need more than just ""rasterisation"" from GPU.",Neutral
Intel,">There are still people suffering from the high idle power draw bugs these cards have had for years, me included. As I type this my 6700XT is currently drawing 35 watts just to render the windows desktop, discord and a web browser. How is it not possible to just reach out to some of the people experiencing these issues and diagnose what's keeping the GPU at such a high power state??  My only fix for this with two monitors is:  1. alternate monitor must me locked at 60hz 2. main monitor needs a custom hz rating, set within ""Custom Resolution"" in AMD Adrenalin.  Basically I set a ""custom resolution"" in 1hz increments from 160-170hz (top 10 hz rating that your monitor is capable of) until I found the highest refresh rate that would give me low idle power.  I found that 162 hz was the highest my main monitor could go with my 2nd monitor sitting at 60hz. If I went with 163hz on the main my idle power goes from 7w to 40w.  That being said, this is typical AMD BS that you have to deal with as an owner of their GPUs. There are countless other examples that users have to do similar to this to get a mostly good experience.",Negative
Intel,"Excellent post, very informative. Would take issue with this though:Â Â  Â    ""Speaking of VRAM, The drivers use VRAM less efficiently. Look atÂ any side-by-side comparison between games on YouTubeÂ between AMD and NVIDIA and you'll often see more VRAM being used on the AMD cards""   Saw a side-by-side video about stuttering in 8gb cards (can find it if you want), the nvidia card was reporting just over 7gb vram used yet hitching really badly. The other card had more than 8gb and wasn't.Â    Point being: How accurate are the vram usage numbers? No way in hell was 0.8 gb vram going unused in the nvidia card, as the pool was clearly saturated, so how accurate are these totals?Â    There is zero (afaik) documentation of the schemes either manufacturer uses to partition vram; what is actually in use & what on top of that is marked as 'this might come in handy later on'.Â    So what do the two brands report? The monitoring apps are reading values from somewhere, but how are those values arrived at? What calculations generate that harvested value to begin with?Â    My own sense is that there's a pretty substantial question mark over the accuracy of these figures.",Neutral
Intel,"Funny, I saw the title and thought the same too!",Positive
Intel,"SR-IOV and MxGPU is edge case. There are far more vGPU deployments powered by NVIDIA and that horrible licensing then there is anything else. AMD is just not a player there. That's the bottom line of the issue here. And VFIO plays heavily in this space, just instead of GPU partitioning its the whole damn GPU shoved into a VM.  So the Instinct GPUs that AMD are selling is being used on metal by large compute arrays, and not for VDI, remote gaming sessions, or consumer space VFIO. This is why they do not need to care, right now.  But if AMD adopted a fully supported and WORKING VDI vGPU solution they could take the spot light from NVIDIA due to cost alone. Currently their MxGPU solution is only fully supported by VMware, it ""can"" work on Redhat but you run into this amazing reset bug and flaky driver support, and just forget Debian powered solutions like Proxmox which is taking the market with Nutanix away from VMware because of Broadcom's ""Brilliance"".  I brought this issue up to AMD a few years ago and they didnt see any reason to deliver a fix, their market share in this space (MxGPU/vGPU, VFIO, Virtualized GPUs) has not moved at all either. So we can't expect them to do anything and spend the man hours to deliver fixes and work with the different projects (QEMU, Redhat, Spice, ...etc).",Negative
Intel,"```Seems hard to believe that they would just put up with these issues and go back to AMD for their next upgrade```   If they're big enough they'll just write their own firmware, drivers, and etc.",Negative
Intel,one of the 2 reasons I refunded my 7900xtx and went back to my 3070,Neutral
Intel,"All of zen 4 has an igpu output. I would try to set some custom resolutions on that 3rd monitor in Adrenalin. For example if that 3rd monitor is rated to 144hz, try custom resolutions from 134-143 hz and see if any one of those settings drops your idle power!",Neutral
Intel,"It's a memclock physics issue and the same threads are on the nvidia forum. Just get one 42/48"" monitor or two max at same res and hz and call it a day. Other combos can work. Plugging 3 different monitors in isn't doing any favours.",Negative
Intel,">I doubt AMD is going to take your OP any more serious then they took the NUMA issues  Not a lot of logic to this.  You are talking about today versus 2018 -- those are not the same companies. The number of employees more than doubled and revenues more than tripled.  Whatever challenges and resource constraints AMD faced back then are not the same as today.  That's not to say they don't still have resource constraints and will be able to immediately fix every issue. It just means you cannot make extrapolations from an experience years ago with CPU/platform all the way to GPUs and accelerators today.    Obviously there's no memo going around which says ""make the customer experience bad. signed, the management""",Negative
Intel,">Watch their hands, not their mouth. Docs + firmware source = good. Promises + ""access"" = worthless. I fell for this too, not again.  Exactly, docs + firmware source code is what matter, not promises!",Negative
Intel,ursohot !  back to discord rants...,Neutral
Intel,I've had issues with Nvidia drivers too where AMD have been fine. Guess it's really situational,Negative
Intel,"```but I feel like I'm taking crazy pills where the internet is screaming about how incredibly terrible AMD GPU's and drivers are```   OP was referencing data center use cases, which can vary wildly, and stress different parts of the GPU depending on the task.   It's why AMD clocksÂ EPYC processors significantly lower than the Ryzen variants. Because a Ryzen CPU isn't intended to be hammered 24/7 @100% utilization for months and sometimes years on end.   Now imagine Radeon's bugs but on the scale of enterprise/data center/servers and that's why OP pretty much typed out a cry for help.",Negative
Intel,"I dunno man. Iâ€™ve been through a few AMD cards, and getting frametimes rock solid has never been possible for me in certain scenarios. That said, and in fairness, I havenâ€™t used anything by team green lately, so it may all be the same shit , different pile.",Negative
Intel,Lol same with me tbh I haven't had any problems ðŸ˜‚ but I guess some do idk ðŸ¤·. I have crashed less with AMD than my old  Nvidia card.,Positive
Intel,"gaming is completely different to compute workloads.  it's also different when you're running multiple of these 24/7 in a single machine at full load and if any one of those hard crashes, having to reboot the whole system is really really bad.  read what others' professional experiences are in this post. AMD GPUs are just terrible in the datacenter.",Negative
Intel,"I've had a fair number of issues with my 6950 xt. System wide stutter from alt tabbing in a game because instant replay is on. Video encoding that looks worse than what my 1050 ti was able to do (seriously fucking disappointing there). Text display issues due to some setting AMD had on by default. AMD has caused me a lot of issues that I shouldn't be getting from a card that cost me Â£540. I get it, it's last gen and my issues are kinda trivial, but it was a huge investment for me at the time and now I'm wishing I'd spent Â£200 more on a second hand 3090 instead of this.",Negative
Intel,"It doesn't handle it, it has the same issue.",Negative
Intel,>never noticed this  search in the internet - `amdgpu ring gfx timeout`  [https://www.reddit.com/r/linux\_gaming/comments/1bq5633/comment/kx14ojy/?utm\_source=share&utm\_medium=web3x&utm\_name=web3xcss&utm\_term=1&utm\_content=share\_button](https://www.reddit.com/r/linux_gaming/comments/1bq5633/comment/kx14ojy/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button),Neutral
Intel,"I personally also never had any major issues with AMD/ATI cards I can think of. One thing is true though, sometimes they do really take a long time to fix certain bugs.",Neutral
Intel,"Same, used a 6800 for over three years with no issues (actually solved crashing issues I was having with my 1080 Ti) and now moved onto a 7900 XTX, also with no issues.",Positive
Intel,Me neither. I use a RX580 8GB since launch and not a single problem.,Positive
Intel,Because they're talking absolute rubbish that's why.,Negative
Intel,You are one of the lucky ones!,Positive
Intel,"How is an AMD feature ""giving users control"". If they advertise something and people use it, it's not the end users fault. It's amd for (once again) coding shit features that break things.",Negative
Intel,"Most people that have issues blame the game because of the way that DirectX debugging works. Unless the developer specifically enables the debug layer, and the user has the SDK installed (it will crash without it), and the user runs software to capture the debug strings, there is simply no indication presented to the user as to the cause of the crash that is actually useful, or even hints at a GPU level fault. The game ends up just crashing with some generic error.  [https://learn.microsoft.com/en-us/windows/win32/direct3d11/overviews-direct3d-11-devices-layers](https://learn.microsoft.com/en-us/windows/win32/direct3d11/overviews-direct3d-11-devices-layers)   [https://learn.microsoft.com/en-us/windows/win32/api/debugapi/nf-debugapi-outputdebugstringw](https://learn.microsoft.com/en-us/windows/win32/api/debugapi/nf-debugapi-outputdebugstringw)",Negative
Intel,"> nooo but amd drivers fine, Reddit told me!   You do realise its possible for people to have had no problems with the drivers right?",Positive
Intel,lol your flair is Please search before asking,Neutral
Intel,"Hey OP â€” Your post has been removed for not complying with Rule 2.  e-Begging (asking for free PCs, sponsorships, components), buying, selling or trading posts (including evaluation posts), retailer or brand disputes and posting referral or affiliate links is not allowed on /r/AMD  Please read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification",Negative
Intel,Looking at it the wrong way will make AGESA reset the BIOS.  That's more of a CPU/platform issue than a GPU issue.,Negative
Intel,Pretty sure gnif2 mentioned once that he had communicated directly with her in an effort to get this problem resolved.,Neutral
Intel,"Then if it's crashed, why doesn't a hardware watchdog send it through a full reset, bringing it back to a known safe state again?  Sorry but this makes no sense, leaving it in a crashed state is not making it ""safer"" but rather in a state that it's behaviour is undefined and could lead to any such secrets being leaked out.",Negative
Intel,"So you have had nearly a decade of experience with GPU passthrough, ROCm, and AMD Instinct compute accelerators?  Methinks you didn't read through the original post.",Negative
Intel,AFAICT OP is the author of [vendor-reset](https://github.com/gnif/vendor-reset) kernel module which was used to work around some of the VFIO reset issues on Vega. I suspect that they have more knowledge of these quirks than anyone else outside of AMD (and certainly more most on this subreddit). Do you have any additional info to confirm that it's a user error?,Neutral
Intel,Maybe read this through again and see that AMD Instinct GPUs are also faulting.,Neutral
Intel,"```what I find absolutely shocking is that your enterprise GPUs also suffer the exact same issues```   This legit killed me lol ðŸ¤£ðŸ¤£ðŸ¤£ðŸ¤£   I hate to say it, but I understand why companies are paying god knows how much for B100 now.   Gamers used to joke about Radeon drivers but this is next level.",Negative
Intel,"If you search for \`vcn\` in drm/amd, there are many similar victims using 6800xt (and navi2x). [https://gitlab.freedesktop.org/drm/amd/-/issues/2156](https://gitlab.freedesktop.org/drm/amd/-/issues/2156)  AMD's video codec IP seems to be heavily influenced by other IP blocks, such as SDMA. And they only have one chance to get it right each time they submit a set of commands to the VCN, otherwise they have to reset the entire GPU and lose your desktop context.     Another interesting fact is that these instabilities may disappear when you switch from Wayland to Xorg.",Neutral
Intel,"I usually stick to AMD because I'm a Linux user and conventionally it has worked better with Linux, and has open source drivers that aren't garbage. My brand loyalty is not absolute, I've used Intel and NVidia before.",Positive
Intel,"I mean, the main reason I wouldn't want to is because it further supports an anti-consumer costing structure...  But if I was buying for enterprise, 100% I'd just buy the thing that works. I just won't personally do it as an individual.",Negative
Intel,"""NVIDIA, it just works""",Positive
Intel,NVIDIA have already demonstrated multiple times over a decade or more of what they do when they have a near monopoly on the market. I do not want to see what their behaviour with a full monopoly looks like.  That and AMD has the better FOSS driver situation.,Negative
Intel,What is the AMD Vanguard?,Neutral
Intel,"I am not fixing anything, this is an incorrect assumption.  I have a setup that is exhibiting these faults, the faults are affecting me and my clients, and as such I am in the ideal position to report the debugging details to AMD in a way that is most useful to the AMD developers to resolve the problem. And because I already have systems experiencing these problems, I am very able to quickly test and report back to AMD on if any fixes they implemented were successful or not.  Do I think AMD should have more rigorous testing so these things get addressed before release? Yes, sure, 100%, but there will always be missed edge cases that are unexpected and not tested for.  A prime example is another issue I have with the AMD drivers that is really not their fault, and they could chose to just say that it's unsupported.  Recently I discovered that it was possible to use a DirectX 12 API to create a texture resource in memory that the user allocated ([https://learn.microsoft.com/en-us/windows/win32/api/d3d12/nf-d3d12-id3d12device3-openexistingheapfromaddress](https://learn.microsoft.com/en-us/windows/win32/api/d3d12/nf-d3d12-id3d12device3-openexistingheapfromaddress) \+ [https://learn.microsoft.com/en-us/windows/win32/api/d3d12/nf-d3d12-id3d12device-createplacedresource](https://learn.microsoft.com/en-us/windows/win32/api/d3d12/nf-d3d12-id3d12device-createplacedresource)), and have the GPU copy into that directly. This API is documented by Microsoft as a diagnostic API, it was never intended to be used in this manner, however it works on NVidia, and mostly works on AMD, improving the performance of Looking Glass by a factor of 2x or more.  Not only is this using a ""diagnostic"" API, we are mapping memory that was mapped into userspace from a virtual PCI device, which is memory that has been mapped on the host system, which then finally maps to physical RAM. To my knowledge there is absolutely no other use case that this would ever be useful for.  I can almost guarantee you that there is no way the developers would have thought to write a test case for this, it is not just off the path a little bit, but instead down a cave, in the dark without a torch, being lead by a deaf mute with only one leg while being chased by a pack of rabid wolves.  The issue here isn't about helping AMD fix their drivers or not, it's about being able to help them in the first place. And if this is a feature that they do not want to support, having the documentation needed to self-support the feature.",Negative
Intel,Definitely not because of lack of those issues but investement in AI.  Frankly speaking going forward I fully expect Nvidia to drop the ball as well. Rest of their business compared to AI is just so miniscule.,Negative
Intel,You misspelled $2.3T market cap....,Neutral
Intel,"Okay yeah fair enough, hadn't considered this. Removed it from my post",Neutral
Intel,"So maybe AMD should sponsor some development on widely used software such as Blender to bring it within a few percent, or embrace ZLUDA and get it to an actually functional state. As an end user I don't want to know who's fault it is, I just want it to work.  Does ZLUDA even bring it close to CUDA? All I see is graphs comparing it to OpenCL, and this sad state of affairs..  https://i.redd.it/mdcvx487vcsc1.gif  From the project's FAQ page.. only further reinforces my point. This is dead and AMD does not care.  * **Why is this project suddenly back after 3 years? What happened to Intel GPU support?**   In  2021 I was contacted by Intel about the development of  ZLUDA. I was an  Intel employee at the time. While we were building a  case for ZLUDA  internally, I was asked for a far-reaching discretion:  not to advertise  the fact that Intel was evaluating ZLUDA and definitely  not to make  any commits to the public ZLUDA repo. After some  deliberation, Intel  decided that there is no business case for running  CUDA applications on  Intel GPUs.Shortly thereafter I got in contact with AMD and in early   2022 I have left Intel and signed a ZLUDA development contract with AMD.   Once again I was asked for a far-reaching discretion: not to advertise   the fact that AMD is evaluating ZLUDA and definitely not to make any   commits to the public ZLUDA repo. After two years of development and   some deliberation, AMD decided that there is no business case for   running CUDA applications on AMD GPUs.One of the terms of my contract  with AMD was that if AMD  did not find it fit for further development, I  could release it. Which  brings us to today. * **What's the future of the project?**   With  neither Intel nor AMD interested, we've run out of  GPU companies. I'm  open though to any offers of that could move the  project  forward.Realistically, it's now abandoned and will only possibly receive  updates to run workloads I am personally interested in (DLSS).",Neutral
Intel,"So HIP isn't written badly because it has ""1-1 parity with CUDA feature wise"".... on this episode of I don't understand what I'm talking about but I have to defend the company I like.",Neutral
Intel,"If you have good raster you dont need upscalers and fake frames via generation. Those ""features"" should be reserved for low to mid range cards to extend the life, not a requirement to run a new game on a high end GPU like we have been seeing lately with non-existent optimization.",Neutral
Intel,This is not a fix. It's a compromise.,Negative
Intel,"Someone else pointed out this is likely just because it has more vram it's using more vram, I think that's the real reason looking at comparisons with both cards at 8gb -- I've removed that point from my post",Neutral
Intel,Any card that has 8 GB of VRAM wont be running a game at settings so high that it would cause a stutter due to lack of VRAM in anything but snythetic youtube tests.,Negative
Intel,"AMD's reputation on VDI seems to be a dumpster fire in homelab scene despite having the first SR-IOV implementation compared to Nvidia and Intel(yes, even Intel is into VDI market!). Sure in homelab setup you're on your own with google-fu, instead of paying for enterprise level support.  But the kind of negligence is different on AMD side. Only the old old old S7150 ever got an outdated open-source repo for Linux KVM support and that's it. This means the documentation and community support are pretty much non-existent, you REALLY are on your own with MxGPU.  Nvidia Grid(meditated vGPU), despite having a notorious reputation on licensing, just works and can be hacked onto consumer cards. Best of all it's pretty much gaming ready with hardware encoders exposed for streaming acceleration(see GeForce Now).  Intel had been providing open source Linux support since their GVT-g(meditated vGPU) days and now SR-IOV on Xe(gen12) architecture. Direct passthrough is also possible without too many hacks like AMD do(*cough* vendor-reset *cough*).  People always consider Intel graphics processors as a laughing stock but you gotta respect them for the accessibility of vGPU solution, directly on integrated graphics that everyone gets. They are even trying to enter VDI market with GPU Flex cards based on Alchemist GPUs(SR-IOV was disabled on discrete ARC consumer cards). Hopefully subscription-free model can make Nvidia a run for its money, at least in entry VDI solutions that Nvidia has no interest in.",Negative
Intel,[https://learn.microsoft.com/en-us/azure/virtual-machines/nvv4-series](https://learn.microsoft.com/en-us/azure/virtual-machines/nvv4-series)  [https://aws.amazon.com/about-aws/whats-new/2021/04/amazon-ec2-g4ad-instances-available-in-additional-regions/](https://aws.amazon.com/about-aws/whats-new/2021/04/amazon-ec2-g4ad-instances-available-in-additional-regions/)  [https://learn.microsoft.com/en-us/azure/virtual-machines/ngads-v-620-series](https://learn.microsoft.com/en-us/azure/virtual-machines/ngads-v-620-series)  [https://wccftech.com/tencent-cloud-launches-xinghai-wisdom-wood-series-ga01-amd-pro-v620-gpu/](https://wccftech.com/tencent-cloud-launches-xinghai-wisdom-wood-series-ga01-amd-pro-v620-gpu/)     AMD's Virtual Graphics products are aimed directly at the cloud service providers now. You'll note that the recent virtual product lines are not available via the channel/distribution.,Neutral
Intel,>AMD is just not a player there.  Except all the playstation streaming is doing from AMD GPUs probably outclassing every other vGPU instance out there. Most of the other streaming platforms were done on AMD as well... of course most of the generally fail due to the entire premise being silly.,Negative
Intel,"It's more that I don't want to reward a business for failing me.  If I bought a car and everytime I drive it the heater jumps on and starts to cook me, and a year later the manufacturer still hasn't resolved it I'm not gonna buy a car from the same brand.   As for possible solutions; at this point I've sunken far too many hours into it to warrant further attempts, I've tried a plethora of drivers, ran DDU multiple times, fiddled with the settings (such as freesync), setup custom resolutions with varying refresh rates etc... If my only issue with AMD was occasionally reverting a driver I wouldn't be complaining, I had to do that with my previous Nvidia card as well, but this is unacceptable tbh.   Anyway, so far nothing has worked, the only time I've seen normal idle power is if all my monitors are turned off (not standby after you press their button, but physically turned off using the powerstrip they're plugged into). If I then remote into the system it's normal, not exactly practical though.  And overall it's not a major issue if it didn't negate the one advantage this card had over the 4090, namely it's value. Some rough napkin math tells me this thing could cost me close to 100 euro's per year extra just in idle power draw, over the course of several years this means a 4090 would've been cheaper despite its absurd price.  As a final note to this, if AMD came out and said they can't fix this issue due to the design of the board or w/e, I could honestly respect that, at least then I know I shouldn't keep on waiting and hoping but I can start looking for a workaround. Instead a couple patches ago they ""improved high idle power with multiple displays for the 7xxx series"" (which did the opposite for me and added a couple watts even) and ever since they don't even mention it anymore, I don't even know if they're still trying to fix it or gave up entirely. And the thing I hate even more then just waiting forever for a fix is being stuck in limbo not knowing.",Negative
Intel,">Not a lot of logic to this.  Look at my other reply  ""SR-IOV and MxGPU is edge case. There are far more vGPU deployments  powered by NVIDIA and that horrible licensing then there is anything  else. AMD is just not a player there. That's the bottom line of the  issue here. And VFIO plays heavily in this space, just instead of GPU  partitioning its the whole damn GPU shoved into a VM.""  ""I brought this issue up to AMD a few years ago and they didnt see any  reason to deliver a fix, their market share in this space (MxGPU/vGPU,  VFIO, Virtualized GPUs) has not moved at all either. So we can't expect  them to do anything and spend the man hours to deliver fixes and work  with the different projects (QEMU, Redhat, Spice, ...etc).""",Negative
Intel,"I'm the same. my issues with Nvidia drivers were so bad it made my gpu and entire windows install functionally bricks. Got rid of my EVGA 760 when the 900 cards and AMD's 300 series came out, jumped to R9 390 and haven't looked back since (R9 390>RX 5700xt>RX 7700xt) The only issue i ever had with AMD was the first few months of the 5700xt and its awful unplayable performance issues in DX9 games, but that was solved within months, and they eventually went on to improve opengl performance on Navi/RDNA as well which was a nice welcome surprise. Ive had a few hiccups that looked like driver issues that turned out to actually be Windows issues, and i always wonder if people are quick to blame AMD for issues because of what they have heard vs actually investigating and finding the real cause of the problem. More often than not any system issues im having end up being the fault of Microsoft, or a specific game wasnt tested on AMD properly and the blame lies with the devs.",Negative
Intel,The comment I quoted was talking about people playing games having issues.,Neutral
Intel,> It's why AMD clocks EPYC processors significantly lower than the Ryzen variants. Because a Ryzen CPU isn't intended to be hammered 24/7 @100% utilization for months and sometimes years on end.  I think that's more about the unreasonably high power they'd use if they boosted the same as ryzen,Neutral
Intel,The thing I quoted was talking about people playing games though.,Neutral
Intel,"I've also had numerous issues with my 6800XT, currently stuck with a 23.11.1 driver version as all newer ones are just trash on my system. This one is usable, newer ones all have a ton of stutter and all that Radeon stuff.   I should have just re-pasted my previous GeForce and ride out the pandemic shortage, but I wanted a faster GPU and thought I'd give a Radeon one final chance. There wasn't a 3080 or 3090 available back then, otherwise I would've rather bought one.   While 6800XT has had some okay drivers here and there, the overall experience remains sub-par; the road still is full of unpaved and rough sections. I've decided to ban Radeons from my household after this one is evicted. It's not worth the driver hassle, not even the numerous Reddit upvotes you get by saying you use a Radeon. :D   It's good that AMD still has the willingness to keep fighting back, it's good to have rivalry. But... I don't know, man. I'm not giving them a consolation prize for a lackluster participation.",Negative
Intel,"I spent 330, you spent 540, we could have spent 1000 in the 7900xtx, it isn't supposed to have these kinds of problems, and all the hours of troubleshooting that comes with it.  OPs not being able to reset the card state without a hardware reboot is just.. bad especially on the server side of things.  We have to start calling things by their true name, and all of these situations are just bad firmware/software/vbios/drivers implementation by AMD.  That and drivers install are just finicky like it happened to me in the latest chipset driver install.. sorry not normal.  Just saying you have no problems won't erase the existence of these thousands of cases of people having problems. And the truth of OPs issue he mentioned in this thread.",Negative
Intel,"Idk, I don't use Linux",Neutral
Intel,"Yeah, they are around 20x smaller than nvidia so kind of expected imho",Neutral
Intel,"RX580 is Polaris, before the big redesign that was Vega and brought the PSP into the mix. Note that none of this is referring to that GPU. Until you upgrade to one of the more modern GPUs, your experience here is exactly zero.",Neutral
Intel,"No I am not, this is 100% the truth, but you can of course think whatever you want and be ignorant.",Negative
Intel,"Hey OP â€” Your post has been removed for not being in compliance with Rule 3.   Be civil and follow side-wide rules, this means no insults, personal attacks, slurs, brigading, mass mentioning users or other rude behaviour  Discussing politics or religion is also not allowed on /r/AMD  Please read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification",Negative
Intel,Keep on living in fairy tale land:   [https://www.digitaltrends.com/computing/amd-driver-windows-crashing-boot-problems/](https://www.digitaltrends.com/computing/amd-driver-windows-crashing-boot-problems/)  [https://www.tweaktown.com/news/96479/amds-latest-radeon-drivers-aims-to-stop-helldivers-2-crashing-and-fix-stuttering-in-many-games/index.html](https://www.tweaktown.com/news/96479/amds-latest-radeon-drivers-aims-to-stop-helldivers-2-crashing-and-fix-stuttering-in-many-games/index.html)  [https://www.pcworld.com/article/2242084/nightingale-removes-fsr-3-pre-launch-for-crashing-too-much.html](https://www.pcworld.com/article/2242084/nightingale-removes-fsr-3-pre-launch-for-crashing-too-much.html)  [https://www.techradar.com/news/amd-fixes-bug-that-freezes-up-windows-11-pcs-but-theres-still-bad-news](https://www.techradar.com/news/amd-fixes-bug-that-freezes-up-windows-11-pcs-but-theres-still-bad-news)  [https://www.extremetech.com/gaming/343132-amds-new-unified-graphics-driver-for-rdna-2-and-3-is-crashing-some-pcs](https://www.extremetech.com/gaming/343132-amds-new-unified-graphics-driver-for-rdna-2-and-3-is-crashing-some-pcs)  [https://www.thephoblographer.com/2017/07/11/driver-fixes-lightroom-amd-gpu-crash-bug-as-adobe-seeks-your-feedback-on-performance/](https://www.thephoblographer.com/2017/07/11/driver-fixes-lightroom-amd-gpu-crash-bug-as-adobe-seeks-your-feedback-on-performance/)  And don't forget that AMD has invested into adding debugging to their drivers so that people like you can submit useful bug reports to try to get to the bottom of why their GPUs are so unstable. When was the last time you saw Intel or NVidia need to resort to adding user debug tools to their drivers!  [https://www.tomshardware.com/news/amd-radeon-gpu-detective-helps-troubleshoot-gpu-crashes](https://www.tomshardware.com/news/amd-radeon-gpu-detective-helps-troubleshoot-gpu-crashes),Neutral
Intel,"I don't know man, most of the people I know that use Radeon have not had issues at all. Some are running 5000, 6000, and 7000 series cards.  Don't mean to downplay the issues with VFIO, just my perspective.",Neutral
Intel,Because adding a feature for a product literally gives users more control for that product.,Neutral
Intel,And If I get no crashes with my AMD graphics cared - how does that fit your narrative?,Neutral
Intel,"> That's more of a CPU/platform issue than a GPU issue.  It happened to me 0 times with an Nvidia card while OCing for hundreds of bios cycles and thousands of hours on AM4/AM5, while Radeon users are experiencing it all of the time. The CPU/platform is fine.  The Radeon graphics drivers hooking into CPU OC and platform controls intimately - or even at all - for no good reason are not fine.",Negative
Intel,"Hey OP â€” Your post has been removed for not being in compliance with Rule 3.   Be civil and follow side-wide rules, this means no insults, personal attacks, slurs, brigading, mass mentioning users or other rude behaviour  Discussing politics or religion is also not allowed on /r/AMD  Please read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification",Negative
Intel,"It should reset, maybe it doesn't know it's crashed in the specific bug you have generated. But your data should not be recoverable. If you have reproduced the bug confidently and sent the report to AMD and they haven't fixed it there is nothing more you can do.",Negative
Intel,Sorry to jump on a random reply - but does this have any relevance? It might just be PR hot air  https://twitter.com/amdradeon/status/1775261152987271614,Negative
Intel,"Yes, I am the author of vendor-reset. This is my third attempt now to get AMD to resolve these issues properly. vendor-reset was supposed to be a temporary stop-gap workaround while we waited for a new generation that was fixed.",Neutral
Intel,"Hey OP â€” Your post has been removed for not being in compliance with Rule 3.   Be civil and follow side-wide rules, this means no insults, personal attacks, slurs, brigading, mass mentioning users or other rude behaviour  Discussing politics or religion is also not allowed on /r/AMD  Please read the [rules](https://www.reddit.com/r/Amd/about/rules/) or message the mods for any further clarification",Negative
Intel,"I get that you are being cheeky, but the use-case is very difference and the professional-demands are far far far higher.  When you run several machines off of a single unit, suddenly there's workloads that has to be completely in due time for things to move ahead.  I just want to contextualize the issue you are making (a tadd) fun of.  So in the basic but common example above, you can't really complete your job because the entire main system has to be shut down. That's like stranding 6 people because the bus broke down. And now all 6 people have to walk. Instead of let's say a gamer: He take his super expensive OR cheap car 10 minutes down the street instead. To and from work, the store. His car 100% for sure will break down, but it's happening so rarely a normal check gets the fault before it's found. OR, he only miss a few hours once a few years if his car break down.  I think it's a decent comparison of the issue here, to use PC hardware in multiple instances, but being forced to restart a system in un-manageable. There need to be a proper high-grade (and low grade) reliable way to avoid that.  Just sucks it took this long, and so much effort to get AMD to pay notice to the issue at hand here. To people that didn't get what the main issue was, hopefully my explanation helps.",Negative
Intel,> Gamers used to joke about Radeon drivers but this is next level.  Getting banned from games is peak driver fail.,Negative
Intel,"Yeah, I always wondered why NV was so huge in datacenter stuff also for compute way before this AI craze. especially in fp64, AMD used to be competitive especially factoring in price.  But reading this explains it all.",Neutral
Intel,"That beeing said, Nvidia's GSP approach and Red Hat recently announcing Nova (Nouveau successor written in Rust), things might change in the future. E.g. AMD's HDMI 2.1 not beeing approved to be open sourced is a perfect example, which works fine in Nvidia's hybrid approach (from a legal/licensing perspective).   AMD has the lead regarding Linux drivers, but they need to keep pushing, if they want to stay ahead.",Neutral
Intel,*wayland users have joined the chat,Neutral
Intel,You're falling for slogans.,Negative
Intel,"To be fair, Noctua do make some of the best fans out there (if you do not want rgb ofc).   From their server grade ones up to consumer grade ones.   They are really expensive, true, but the sound profile is by far one if not the best one.   Pair that with how high the static pressure and airflow are, and yes, its the best out there, for an expensive price.   With half the price you can get 80% of the performance on other brands, I wont deny that, but if you are qilling to spend money, they are the best in the market, period.",Positive
Intel,Unpaid beta test program that has existed since ages... hasn't resulted in any of the complaints in this thread getting fixed though.,Negative
Intel,[https://www.amd.com/en/products/software/adrenalin/amd-vanguard-program.html](https://www.amd.com/en/products/software/adrenalin/amd-vanguard-program.html),Neutral
Intel,"you're kinda missing the point tho, it's because they do pay attention to software and firmware that they were able to establish that foothold.",Neutral
Intel,Honestly after a trillion I kinda stop counting ðŸ˜‚ðŸ¤£,Neutral
Intel,"VRAM usage is specific.  In context of Unity games and VRChat - Nvidia does use less VRAM than AMD... but only in Windows, only Nvidia DX driver in Windows have this ""hidden feature"" and only with DX API. So it may be DX feature. It very common/easy to see it in VRChat large maps, or large Unity games.  In Linux - *in some cases, but it very common* - you get more VRAM usage on Nvidia compare to AMD because this how Vulkan driver implemented in Nvidia and overhead of DXVK.  P.S. For context - Unity VRAM usage is - Unity allocating ""how much it want"" and in case of two different GPU Unity may allocate less or more in DX-API, or DX-API have some internal behavior for Unity case on Nvidia so it allocating less. In Vulkan - DXVK have huge overhead about 1Gb on Nvidia GPUs in many cases, and Unity ""eat all vram possible"" behavior explode difference.",Neutral
Intel,"No its more like, nobody has bothered to optimize or profile HIP applications for performance for a decade like they have those same CUDA applications.  I'm just stating facts. You are the one being aggressive over... some computer hardware good gosh.",Negative
Intel,"Let me tell you some stuff regarding how a GPU works.   Raster performance can only take you so far.   We are in the brink of not being able to add more transistors to the GPU.   Yield rates are incredibly low for high end parts, so you need to improve the space usage for the GPU DIE.   Saying that these ""features"" are useless is like saying AVX512, AVX2, etc are useless for CPUs.   RT performance can take up to 8x same GPU surface on raster cores, or 1x surface on dedicated hardware.   Upscaling using AI can take up to 4x dedicated space on GPU pipeline or 1x on tensor cores.   The list goes on and on with a lot of features like tessellation, advanced mesh rendering, etc.   GPUs cant keep increasing transistor count and performance by raw brute forcing it, unless you want to pay twice for the GPU because the graphics core will take twice as much space.   Upscaling by AI, frame gen, dedicated hardware to complete the tasks the general GPU cores have issues with, etc are the future, and like it or not, they are here to stay.   Consoles had dedicated scaling hardware for years.   No one complained about that. It works.   And as long as it works and looks good, unless you NEED the latency for compwtitive gaming, its all a mind fap, without real world effects.   Im damn sure (and I did this before with people at my home) that if I provide you with a game blind testing it with DLSS and Frame Gen, along with other games with those features on and off, you wont be able to notice at all.",Negative
Intel,"I'm just trying to help, not debate the semantics of what is considered a fix or a compromise. Purchasing an AMD GPU is already a compromise.",Neutral
Intel,It's not a dumpster fire.. you just have to buy an overpriced GPU to even have it... so pretty much a completely utter nothing burger that AMD is not even interested in.,Negative
Intel,"Except the V620/520 are not the only GPUs that support MxGPU, Instinct's line does too and offers the same ""features"" as the V520/620, but the native driver support is more geared towards GPCompute and not 3d rendering, but are also supported by the exact same driver family as the WX workstation, V cloud, and RX GPU lines.   Also, been a lot of offloading of the V520 and V620 ""cloud only"" GPUs on the gray market, and I can CTO HPE servers with V620's by enterprise ordering today.",Neutral
Intel,"This is not at all on the same level as what the OP is talking about.  I can also stream from my RX6600M, RX6600, my Ally,..etc just like you can from the Playstation. But it has nothing to do with VFIO, virtualization, or MxGPU.   What my bitch about, and it aligns with OP perfectly, vGPU support (MxGPU) for VDI setups on non-VMware solutions. AMD has completely dropped the ball here and its never been more important then **right now**.",Neutral
Intel,"Hey, just trying to help your setup right now. I would be frustrated too, I had the same issue with two monitors, not three. I was able to fix the idle power issue by setting the alternate monitor to 60hz and setting my main monitor to 162hz (max 170). Obviously spend your money where you think it's worth it.",Negative
Intel,">It's more that I don't want to reward a business for failing me.  Have your displays continued working reliably? Oh they have? You are over the vblank limit for idling down... so its not and never will be a bug on ANY GPU.  This is far more akin to your car idling up when the AC comes on... you have 3 displays on a certain amount of framebuffer bandwidth is REQUIRED to implement that, + a bit more to account to account for any lite tasks that might be running on the GPU at the same time.  The whole issue here is that your memory bus with 3 monitors active is NOT idle... if you want it to idle down turn your dang monitors off, its that easy.  At some point they may have a solution that just powers up a single memory lane or something and allocates the frame buffers in there, but people complaining about a problem that doesn't have a solution and only affects 0.5% of people is annoying.",Negative
Intel,"AMD is working with [Amazon ](https://aws.amazon.com/ec2/instance-types/g4/)and [Azure](https://www.amd.com/system/files/documents/nvv4-datasheet.pdf) on systems with 1-4 GPUs supporting SR-IOV/MxGPU. This is only with ""Pro"" or ""Instinct"" cards though.   I'm sure there has historically been little incentive to make this rock solid on consumer GPUs. Though that is a shame.  However I see no reason to assume the constraints which led to that choice in the past exist today.",Neutral
Intel,"True, windows had an awful habit of breaking my system by continually trying to uninstall new drivers",Negative
Intel,"What are you talking about? AMD employs 26000 people, NVIDIA has 29000. They're the same size... oh, you mean profits? Well then, yeah...",Neutral
Intel,"Idk bro, had 470', 570', 580', 590, 460, few of vega64, 56, 6700xt, 7900xt.... Never had issues, even with those vegas I abused, overcloccked etc",Neutral
Intel,Oh then just ignore my comment ðŸ˜…,Negative
Intel,"I'll be honest, I've been using AMD GPUs since 2010 and they've been solid.  However the features Nvidia is rolling out is making me consider a 5070 next year",Positive
Intel,Heartbreaking to see you downvoted by bringing these issues up. Reddit is such a terrible place.,Negative
Intel,"Awesome, not biased at all, now pull up a similar list of nvidia and intel driver issues, it wouldn't be any shorter...",Positive
Intel,"And you keep grossly overstating the issue.   Most of which were quickly resolved and/or effected a small number of customers and limited to specific apps, games or usage scenarios.  I've had an AMD gpu in my primary gaming PC for the past three years. Not a single one of the issues you listed effected me or a majority of owners.   And umm yeah, Nvidia also have bug / feedback report tools....  Intel right now are causing me far more issues with their Xe drivers so please. I'm still waiting for Xe to support variable rate refresh on any fucking monitor.",Negative
Intel,"\> Don't mean to downplay the issues with VFIO, just my perspective.  Understood, however you responded to a comment directly related to someone that has been lucky with VFIO.  u/SckarraA I am curious, have you tried simulating a VM crash by force stopping the guest and seeing if the GPU still works? This is usually guaranteed to put the GPU into a unrecoverable state.",Neutral
Intel,It's really weird how many AMD fanboys like yourself are popping up and denying the existence of a well known and documented issue because it either isn't majorly impactful to them or they don't know how to recognize it.  Just because it doesn't affect you doesn't mean it's not a real issue and doesn't mean it shouldn't be addressed.  Quit being so obliviously self-centered.,Negative
Intel,"It was only a few months ago that an amd feature in their drivers literally got massive amounts of people banned in online games, so much so that amd hat to completely pull that feature and no one has heard of it ever since.   How can you claim that amd drivers are in a good position?",Negative
Intel,Also what sucks the most is that such a bios change takes a preboot 40-50 seconds before anything is even displayed on the screen,Negative
Intel,I definitely got it all the time while OCing on nvidia cards. Sometimes it just resets for the hell of it on a reboot where I wasn't even doing anything.  I'm not sure why you think AMD's GPU drivers have some intimate link with the BIOS. They don't.,Negative
Intel,"WTF are you talking about. Do not apply CPU OC from Adrenalin Ryzen Master API, and it won't reset on GPU crash.    Spoiler, if you save preset with GPU OC, while you have CPU OC applied through separate Ryzen Master or BIOS, it won't be affected by Adrenalin OC reset on crash.  How it is that i had never had my CPU PBO reset after dozens of forced GPU crashes (through UV and one bug i found out on occasion)?   There was only one case where it was affecting people. When AMD integrated Ryzen Master API in Adrenalin for the first time, as previously saved GPU OC presets had no CPU data, and forced CPU OC to reset to defaults. After re-saving GPU OC profile, it never happens again.",Negative
Intel,"Yes, it should and when the GPU is still in a semi-functional state we can tell the GPU to perform a reset... which does nothing. So yes, it should reset, but they do not.  \> But your data should not be recoverable.   Correct, we are not talking about recovering data, just getting the GPU back to a working state without rebooting the system.     \> there is nothing more you can do.  Not entirely true, if it was the case the \`vendor-reset\` project would not exist:   [https://github.com/gnif/vendor-reset](https://github.com/gnif/vendor-reset)",Neutral
Intel,"Too soon to tell, but hopes are high.",Positive
Intel,"Your comment has been removed, likely because it contains trollish, antagonistic, rude or uncivil language, such as insults, racist or other derogatory remarks.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",Negative
Intel,"Honestly, the HDMI 2.1 fiasco has pushed me (and many other people) to stay away from HDMI, not AMD.  As for Nova, we'll see how it goes, but it's likely a multi-year endeavour, just like it was many years ago for the Amd open drivers.  Currently, from a consumer and Linux user point of view Nvidia should be avoided whenever that's possible, and I speak from experience since I made the mistake of buying a laptop with hybrid graphics and Nvidia gpu. It was a good deal, but that has cost me *a lot* of hours of troubleshooting of different issues, that never happened with AMD or Intel.   The strange thing about Amd is that they focused a lot, in the past few years, on consumer drivers/software, while from the hardware pov they pushed the accelerator on HPC/AI hardware, so there is some kind of mismatch and often their product either have great hardware or great software, but usually not both.",Negative
Intel,"Agreed, they cannot rest on their laurels.",Negative
Intel,"Execept for when it comes to VFIO usage, NVidia literally just works. They even endorse and support it's usage for VFIO Passthrough, as niche as this is.   [https://nvidia.custhelp.com/app/answers/detail/a\_id/5173](https://nvidia.custhelp.com/app/answers/detail/a_id/5173)",Positive
Intel,"According to theoretical physicists, the numbers are correct as long as they have the correct order of magnitude.  > How Fermi could estimate things! > > Like the well-known Olympic ten rings, > > And the one-hundred states, > > And weeks with ten dates, > > And birds that all fly with one... wings.",Neutral
Intel,console gamers know pcâ€™s are better and donâ€™t really complain about upscaling and 30fps.. youâ€™re right that competitive sacrifices everything else for latency. also may be true that your average casual gamer wouldnâ€™t notice increased input latency. but they have been adding transistors and ppl were willing to pay doubling amount of cost for them. i rmb when a midrange card used to cost 200.,Neutral
Intel,I'm well aware of what VDI desktops are... it effectively the same thing though.  And yes... Sony does use vGPU/MxGPU for streaming PS games.  There really is no ball to drop because no solution has exited outside of VmWare. at least not one that has involved a company actually working with AMD to build any solution.,Neutral
Intel,"Haha dw, just venting a bit.  It's also genuinenly my only gripe with the card and setup, it's just annoying it's not getting fixed and I can't apply any workaround, particularly for the price I've paid.   I would just put in any of the older cards I've got laying around just to drive the other monitors but then I'd have to give up 10gbit networking, and I'd still have higher than ideal idle usage  but it would be cut down a bit.   So I'm mostly miffed that if I wanted to actually resolve this it would be by moving to a cpu with integrated graphics, and that's money I don't want to spend. But if I don't, I'm spending money I don't want to spend.",Negative
Intel,"Apparently 100watts is ""normal"" and to be expected, and I should just be grateful, the fk are you waffling on about? That's 20watts short of the max TDP of a 1060... a card that could run these 3 monitors without trying to burn a hole in my wallet FYI..  And fantastic solution, so I spend over 1000euro's on a GPU but then have to turn my monitors off, genius... Quality stuff, can't make this shit up. Also like I actually typed out:  >the only time I've seen normal idle power is if all my monitors are turned offÂ   so how would that work? Oh maybe I can throw my main monitor in the trash and then the problem is solved I suppose?  >but people complaining about a problem that doesn't have a solution and only affects 0.5% of people is annoying.  Am I supposed to complain about issues that don't affect me? Or are you saying I've got no right to complain? Is me having a bad experience annoying you?  and if not by complaining how am I supposed to know this issue doesn't have a solution? Do you even listen to what you're saying?  You know what's annoying? People dismissing other people's complaints because ""they don't like it"" or they're such fanboys they can't stand someone criticizing their favourite brand.",Negative
Intel,"Sorry but AMD ""working with"" is a joke. I have been working with companies that have hundreds to thousands of AMD Instinct GPUs.  I have been able to interact directly with the AMD support engineers they provide access to, and the support is severely lacking. These issues here have been reported on for over 5 years now, and what has AMD done for these clients?  Until I made my prior posts here on r/AMD, AMD were not interested or even awake when it came to these issues. I have had direct correspondence with John Bridgman where he confirmed that GPU reset was not even considered in prior generations.  Of what use are these support contracts and the high cost of buying these cards if AMD wont provide the resources to make them function in a reliable manner.  Why did it take some random (me) to have to publicly embarrass the company before we saw any action on bugs reported by their loyal paying enterprise clients?",Negative
Intel,">AMD is working with Amazon and Azure on systems with 1-4 GPUs supporting SR-IOV/MxGPU. This is only with ""Pro"" or ""Instinct"" cards though.  and MSFT, but we are not seeing these changes upstream via open standards. We still are lacking working support for the likes of Nutanix and Proxmox (both KVM), where Redhat has some support but there are still unresolved issues there.  Fact of it, the changes AMD is pushing at AWS would upstream to every other KVM install and bring those fixes to mainstream. But this has been going on for well over 6 years that I can recall and still we are no closer to a ODM solution released to the masses. I had hopes for RDNA2 and I have expectations for RDNA3+/CDNA3+ that are just not being met outside of data sciences.",Neutral
Intel,"I am a FOSS software developer, on hand right now I have several examples of every card you just listed, including almost every generation of NVidia since the Pascal, Intel ARC, Intel Flex, AMD Mi-25, AMD Mi-100.  Even the Radeon VII which AMD literally discontinued because it not only made zero commercial sense, but suffered from a silicon bug in it's PSP crippling some of it's core functionality.  I have no horse in this race, I am not picking on AMD vs NVIDIA here, I am trying to get AMD to fix things because we want to use their products.  You state you never had issues, however, how many times have you had a game randomly crash with no error/fault or some random error that is cryptic? How often have you assumed this is the game's fault?  Very often these are caused buy the GPU driver crashing, but due to the design of DirectX, unless you explicitly enable it, and have the Graphics Tools SDK installed, and use a tool that lets you capture the output debug strings, you would never know.  [https://learn.microsoft.com/en-us/windows/win32/direct3d11/overviews-direct3d-11-devices-layers](https://learn.microsoft.com/en-us/windows/win32/direct3d11/overviews-direct3d-11-devices-layers)",Neutral
Intel,Why does every valid criticism of amd has to be dragged down to that tribal stuff? Stop being a fanboy and demand better products.,Negative
Intel,I am not at all stating that NVIDIA GPU do not crash either. You are completely missing the point. NVIDIA GPUs can RECOVER from a crash. AMD GPUs fall flat on their face and require a cold reboot.,Negative
Intel,my dude this is a guy that has worked with both of the other 2 companies and has repeatedly complained about the shit locks and bugs in both intel and nvidia. the software that he has created is basically state of the art.  this is /r/amd not /r/AyyMD,Negative
Intel,"Not at all, you just keep missing the point entirely. You agreed with the post above you where is stated that the GPUs are rock solid. I provided evidence to show that they are not rock solid and do, from time to time have issues.  This is not overstating anything, this is showing you, and the post above you, are provably false in this assertion.  Just because you, a sample size of 1, have had few/no issues, doesn't mean there are clusters of other people experiencing issues with these GPUs.  \> And umm yeah, Nvidia also have bug / feedback report tools....  Yup, but did they need to make a large press release about it like AMD did. You should be worried about any company feeling the need advertise their debugging and crash reporting as a great new feature.  1) It should have been in there from day one.  2) If the software is stable, there should be few/no crashes.  3) You only make a press release about such things if you are trying to regain confidence in your user-base/investors because of the bad PR of your devices crashing. It's basically a ""look, we are fixing things"" release.",Negative
Intel,"My friends don't do VFIO stuff so I cannot say about them, but while I've never forcibly ended the VM (via htop or something) they have crashed repeatedly in the past, [especially this one](https://old.reddit.com/r/VFIO/comments/11c1sj7/single_gpu_passthrough_to_macos_ventura_on_qemu/). I've even got a 7800XT recently and haven't had any issues. Though this might be anecdotal since I am focusing on college right now and haven't put a ton of time into this recently.  EDIT: Also, I love your work, I hope I wasn't coming off as an asshole, I just have autism.",Negative
Intel,Guild Wars doesn't work on 7000 series cards and I assume it never will. a 3rd of the FPS I get with a 2080,Negative
Intel,"I'm not denying the existence of his issues around VFIO, I'm pushing back against him conflating it with gaming, for which there is a known circlejerk around AMD drivers being seen as 'unstable', which is hugely overblown.",Negative
Intel,You mentioned earlier you are diagnosing issues for a corporation related to IOV in GPUs they purchased. Are you refering to Navi based cards or Datacenter parts?,Neutral
Intel,"I partly agree with you there. But unfortunately it's difficult to avoid HDMI 2.1, when you need to hook it up to a 4K TV. I would absolutely *love* to see 4K TV manufacturers offer DisplayPort in future TVs, but that's probably not happening anytime soon.   About Nova you're probably right. But please keep in mind, that its scope is much more narrow than any other open source driver out there. Mostly, it only serves as an adapter between the Linux kernel and GSP firmware. Current Noveau implementations reflect this: GSP features are easier to implement and thus currently more feature complete.Â And since there is an AI/Nvidia hype train at the moment, they will probably also dedicate more resources into it than say stratis-storage.",Neutral
Intel,When did they do this switch? I remember years ago when I configured that their windows drivers werenâ€™t being so nice to the card detected in a VM.,Negative
Intel,"The price of the GPU is not determined by the transistor count, but by the DIE size.   In the past they used to shrink the size WAY faster than now, enabling doubling transistor count per square inch every 2 to 4 years.   Now they barely manage to increase density by a 30%.   And while yes, they can increase the size, the size is what dictates the price of the core.   If they ""just increase the size"", the cost per generation will be 2 times the previous gen cost :)",Neutral
Intel,">I'm well aware of what VDI desktops are... it effectively the same thing though.  Nope, not at all. One is virtual with IOMMU tables and SR-IOV(and a ton of security around hardware layers), the other is a unified platform that runs metal software with no virtual layers. Clearly you do not understand VDI.",Negative
Intel,"You can just stop looking for solutions as it's not a bug. Your setup clearly exceeds the limkts for v-blank interval to perform memory reclocking. In that case  memory stays at 100% and you get a power hog (Navi 31 is especially bad because of MCD design. Deaktop Ryzen suffers from the same thing).  This will never be fixed, as there's nothing to fix. Works as intended and if you try reclocking your memory when eunning such a setup  you'll get screen flicker (happened in linux a month ago because they broke short v-blank detection)",Negative
Intel,"if the monitors run at different resolutions and frequency than each other my power increases. if my monitors match, idle power is normal",Neutral
Intel,100w is normal for the memory bus being clocked up.... yes.'  The exact same problem occurs on Nvidia hardware also since a decade also.,Neutral
Intel,"> You state you never had issues, however, how many times have you had a game randomly crash with no error/fault or some random error that is cryptic? How often have you assumed this is the game's fault?  I'm not the guy you're replying to, but for me, almost never.  I've had exactly one driver-based AMD issue - when I first got my 5700XT on release, there was a weird driver bug that caused the occasional BSOD when viewing video in a browser - this was fixed quickly.  My gaming stability issues were always caused by unstable RAM timings and CPU OC settings - since I upgraded to an AM5 platform with everything stock, I'm solid as a rock. My 7900XTX has been absolutely perfect.  There is an unfair perception in gaming with AMD's drivers where people think they are far worse than they really are - it's a circlejerk at this point.  Your issue is different (and valid), you don't need to conflate the known issues in professional use cases with gaming - it'll just get you pushback because people who use AMD cards for gaming (like me) know the drivers are fine for gaming, which makes you come across as being hyperbolic - and if you're being hyperbolic about the gaming stuff, what else are you being hyperbolic about? Even if you aren't, it calls into question your credibility on the main subject of your complaint.",Negative
Intel,"> You state you never had issues, however, how many times have you had a game randomly crash with no error/fault or some random error that is cryptic? How often have you assumed this is the game's fault?Â    Literally zero. I guess I just have a good pc setup... It is weird how some people always have issues",Negative
Intel,"> You state you never had issues, however, how many times have you had a game randomly crash with no error/fault or some random error that is cryptic? How often have you assumed this is the game's fault?  My aging 5700 XT crashes in games far less often than my friends who are on various Nvidia cards from 2080 Ti to 4090.  Same for when I was on Polarix with RX 470s.  Game crashes are rarely the fault of the graphics driver (or hardware), regardless of brand.  This isn't a good point to be making, because it's just wrong.  > suffered from a silicon bug in it's PSP crippling some of it's core functionality  This again?  No, Radeon VII and other Vega products were killed off because they were very expensive to produce and they weren't moving enough units at any price to justify any further investment or even any meaningful support.  Everyone paying attention called this when they revealed Vega, and even long before with the tragic marketing.  Insert the GIF of Raja partying at the AMD event, complete with cigar.  People love coming up with theories as to what critical flaw or failure point caused a given generation of AMD GPUs to suck, and how those will be fixed in the next generation.  From silicon to firmware to coolers to mounting pressure to bad RAM to unfinished drivers or whatever else.  It's never the case.  There's never any 1 critical point of failure that make or break these products for their intended use case (gaming or workstation).  If you are an actual AMD partner working on things with workstation cards / compute cards, you **do** get actual, meaningful support for major issues.  Does AMD need to improve things?  Of course.  But to act like there's 1 critical flaw, or that something is fundamentally broken and making the cards unusable for a given purpose, or to cite George Hotz as an authority is just way off target.",Negative
Intel,"Part of it is rooting for the underdog, part of it is probably due to people legitimately not having problems.  I was an Nvidia user for several years, and moving to AMD I've had a lot of problems with black screen, full system crashes and driver timeouts that I haven't had on Nvidia.",Neutral
Intel,"Good ol' ""it works on my machine"".  It's a small and niche userbase so it gets downplayed, backed by ""it works on my machine"" when you express your concerns, despite the fact they don't use that feature or have zero knowledge on the topic. Same goes to H.264 hardware encoder being worst of the bunch for years.  And the average joe just doesn't use Linux, if they do, then few of of them actually toy around virtualization, then even fewer of them poke around hypervisors with device passthrough(instead of using emulated devices, which has poor performance and compatibility). It really is the most niche of the niche circle. I'm not looking down on users or playing gatekeeping/elitism but that's just a hard pill to swallow.  But that doesn't mean AMD should be ghosting the issues as people have been expressing their concerns even on datacenter systems where real money flows.  How many r/Ayymd trolls actually know VDI, VFIO and let alone what ""reset"" means? Probably has never google'd them, despite the fact one of the most well-respected FOSS wizards in this scene is trying to communicate with them. I hope gnif2 doesn't get upset from the trolls alone and wish him a good luck on Vanguard program. (I also came across his work on vendor-reset when I was poking around AMD integrated graphics device passthrough.)",Negative
Intel,"Demand what rofl, I have literally zero issues. 99% of criticism is not valid and is extremely biased and overblown, that is why.",Negative
Intel,"No they don't  I've crashed AMD gpu drivers plenty of times while overclocking and it recovered fine  AMD have dramatically improved their driver auto recovery from years ago when such basic crashes did require hard reboots.  Might still be shit in Linux, but what isn't...",Negative
Intel,Oh and XE also have bug feature reporting.  Omfg!!!!,Negative
Intel,Nobody is 100% right ;),Neutral
Intel,Guild Wars 1 or 2 (does Guild Wars 1 even work anymore?? XD),Neutral
Intel,"It's been explained why what you just said is wrong and you appear to be ignoring it.  You don't understand the issue at hand and are just running your mouth making an ill-informed and baseless argument that is irrelevant to what is being discussed here. Either you tried to understand it and failed, or, more likely, you never tried to and just want to whine about Redditors.",Negative
Intel,"Firstly, i am barely even able to find any posts about this issue. Which means that issue is extremely case specific, so you should not categorically blame AMD and Adrenaline. With how many people this happen with, it is not problem of Adrenalin itself (otherwise it would've been reported A LOT more than i can find).   They may have some weird system conflict, or some weird BIOS setup from manufacturer. But Adrenalin installation doesn't OC your CPU just at fact of installation.  For context, if i still would've had my 5600X (now i have 5800X3D, and Adrenalin doesn't see it as CPU it can work with, as it doesn't provide CO option iirc), and had it OC'ed through BIOS, Adrenalin would've seen it as OC'ed. It doesn't mean that Adrenalin OC'ed CPU, but rather that SOMETHING did that.  I also saw reports that after deleting Adrenalin, resetting BIOS to defaults and installing same exact Adrenalin version back, they stopped having OC on their CPU.     From global issues with CPU OC was only one i mentioned. When AMD integrated Ryzen Master, old GPU OC presets did reset CPU OC values to default. To fix that you just needed re-set GPU OC and resave preset after update.",Negative
Intel,"Yes, these are Instinct Mi100 for now, depending on how things go with this GPU it may also be later GPU generations also.",Neutral
Intel,What about using a DP to HDMI 2.1 adapter for that situation?,Neutral
Intel,"2021 my guy, it's right there on the date of the article.",Neutral
Intel,LOL you literally just said this one thing is not like this other thing because its the same as the thing. PS Streaming runs multiple instances of hardware per node... with separate virtualized OS deal with it.,Neutral
Intel,They could do something like relocate video framebuffers to one memory channel and turn the rest off... if idle is detected.  But that would be very complicated.,Neutral
Intel,"I see your point, and perhaps my statement on being so unstable is a bit over the top, however in my personal experience (if that's all we are comparing here), every generation of GPU since Vega I have used, has had crash to desktop issues, or BSOD issues under very standard and common workloads.  In-fact no more then a few days ago I passed on memory dumps to the RTG for a \`VIDEO\_DXGKRNL\_FATAL\_ERROR\` BSOD triggered by simply running a hard disk benchmark in Passmark (which is very odd) on my 7900XT.  ``` 4: kd> !analyze -v ******************************************************************************* *                                                                             * *                        Bugcheck Analysis                                    * *                                                                             * *******************************************************************************  VIDEO_DXGKRNL_FATAL_ERROR (113) The dxgkrnl has detected that a violation has occurred. This resulted in a condition that dxgkrnl can no longer progress.  By crashing, dxgkrnl is attempting to get enough information into the minidump such that somebody can pinpoint the crash cause. Any other values after parameter 1 must be individually examined according to the subtype. Arguments: Arg1: 0000000000000019, The subtype of the BugCheck: Arg2: 0000000000000001 Arg3: 0000000000001234 Arg4: 0000000000001111 ```  Note: There is zero doubt that this is a driver bug, I am running a EPYC workstation with ECC RAM, no overclocking, etc.  At the end of the day here, I am not trying to say ""AMD is bad, do not use them"". I am trying to say that AMD need to   provide an industry standard means to properly and fully reset the GPU when these faults occur.  The amount of man hours wasted in developing and maintaining the reset routines in both the Windows and Linux drivers are insane, and could be put towards more important matters/features/fixes.",Neutral
Intel,And I guess infallible game developers too then. /s,Neutral
Intel,So you decide what criticism is valid and what not? lol,Neutral
Intel,AMD cards don't recover from a crash. This is well known and can be triggered in a repeatable manner on any OS.  You don't understand the issue and are just running your mouth.,Negative
Intel,"Yup, but do you see them making a big press release about it?",Neutral
Intel,that is not how it works but sure,Negative
Intel,2 lol  7900xtx dips to 30fps in combat or around players. 2080 never dips below 70,Neutral
Intel,>whine about Redditors.  The irony.,Negative
Intel,"IF I got an AMD gpu, that would be my only option.   There's mixed reports on that - you have to make sure it's an active adapter - and some of the Display port 2.0 to hdmi 2.1 adapters might work.   Some ppl say a 'Cable Matters' brand works but you might have to update/upgrade the firmware.   But, if you are shopping for a higher tier card - for e.g., a 7900 xtx - that's a pretty expensive risk - especially when you have to factor in the cost of an adapter, too?",Neutral
Intel,learn to comprehend.,Neutral
Intel,Thank you for your response - I actually agree with a lot of what you are saying. AMD is lacking in pro support for quite specific but very important things and you aren't the first professional to point this stuff out. How much of this is down to a lack of resources to pump into software and r&d compared to nvidia over many years or how much of it is just plain incompetence I can't say,Neutral
Intel,">every generation of GPU since Vega I have used, has had crash to desktop issues, or BSOD issues under very standard and common workloads.  I thought it was only me... but ye it is this bad - just watching youtube and doing discord video call at same time - crash  >At the end of the day here, I am not trying to say ""AMD is bad, do not use them"". I am trying to say that AMD need to provide an industry standard means to properly and fully reset the GPU when these faults occur.  I can say - AMD is bad, do not use it, their hardware do not work.  Wasting time to ""debug and fix"" their drivers - it can be fun for ""some time"" until you see that there are infinite amount of bugs, and every kernel driver release make everything randomly even worse than version before.",Negative
Intel,"> Note: There is zero doubt that this is a driver bug, I am running a EPYC workstation with ECC RAM, no overclocking, etc.  Can you replicate the issue?  If so, it could be a driver bug.  If not, have you actually tested your memory?  Being a workstation platform or ECC memory means nothing.  I bought some of the first Zen 2 based servers on the market, and I got one with a faulty CPU with a bad memory controller that affected only a single slot.  Dell had to come out the next day with a new CPU.",Negative
Intel,"No, that would be you obviously /s",Neutral
Intel,Oh so it's only applicable in specific usage scenarios outside of standard usage...  Got it.,Neutral
Intel,"Yea, given the state of XE drivers every major update has come with significant PR.",Neutral
Intel,Why not ;),Positive
Intel,Go word salad elsewhere.,Negative
Intel,"I have replicated the issue reliably yes, and across two different systems.",Neutral
Intel,If discord crashes my drivers.. once every few hours. I have to reboot,Negative
Intel,Discord doesn't crash my drivers  I don't have to reboot.,Positive
Intel,Really love how the 6000 series radeons look.,Positive
Intel,"Why is there is a 6800 and 6800XT pictured, but only results for the 6800XT?",Neutral
Intel,That's a good looking line up,Positive
Intel,"From the article:   >However, temporal upsampling such as AMD FSR or Nvidia DLSS has now become so good that it either matches or **sometimes even exceeds the image quality of native Ultra HD** despite the lower rendering resolution.   Hmmm.. I don't agree with that.",Negative
Intel,"I had a reference 6800 that i sold to my brother when i upgraded to a 7900xt, I miss the design i loved it since the moment it was announced.",Positive
Intel,"In my opinion RX 6000, aswell as RTX 980/1080 Ti are the best looking graphics cards. Notable mentions are Radeon VII, RX 5700 (non-XT) and Intel Arc 770 Limited Edition.",Positive
Intel,Darktide looks&runs way better with FSR2 than native 1080p for me. I don't know how they do it but there is no amount of AA that makes native resolution look better.,Positive
Intel,"Use Radeon Image Sharpening at 50% in the game's Radeon Settings profile when running native. FSR2 has its own sharpening pass. Many TAA implementations are blurry as fuck, which gives the illusion of better image quality when upscaling.",Negative
Intel,Okay fair enough! To me any upscaling has always looked worse than native in the games I've played and I've left it off.  Though it has undoubtedly gotten better recently - to my eyes it's never looked **better** than native resolution.,Negative
Intel,"I've used both FSR (2160p desktop) and DLSS (1080p laptop) and the loss in quality is noticeable to me. Always a softer image with less detail - yes, even DLSS. Performance always has a cost. Temporal upscaling is no different. DLAA and FSRAA actually are better than native, since they replace terrible TAA implementations and render at native.  However, this better than native upscaling narrative seems more like a belief (or a marketing push/tactic) than reality.   - If action is high enough, it probably won't matter much, but in single-player games where I like to look around, I just can't deal with the resolution loss. I'd rather turn RT off, as I did in Control (for AMD and Nvidia HW), which actually has decent RT effects.",Negative
Intel,"Tbf, Darktide is the first game where this was the case. I tried lots of different combinations but nothing worked out. I'll probably try the other suggestiom with the sharpening in Adrenalin later.",Negative
Intel,"Honestly, I wish Intel would give these 'Intel Graphics' model numbers. An Intel Graphics on a N series SKU is going to be far weaker than a B370/B390 masquerading as 'Intel Graphics'. That or just give these ARC iGPUs that don't meet the RAM speed a number like ARC B370e/B390e instead.",Negative
Intel,Is panther lake getting an N series release?,Neutral
Intel,Wildcat Lake for the N Series,Neutral
Intel,iGPUS are replacing the low end discrete graphics. That's incredibly impressive,Positive
Intel,Pat did a good job.,Positive
Intel,Will panther lake pc CPU's have this kinda powerful igpu?,Neutral
Intel,"Have any of the ""regular office worker""-level CPUs been seen yet?  I am hoping we can see 8 to 10 hours of battery life under real usage.  We get 12 to 14 with MacBook Air 13's, so we would like to at least see a full work day with the Intel CPUs.  We were really hoping we would have seen that with Lunar Lake, but we usually see closer to 4 to 7 hours under real usage.",Neutral
Intel,"Stop with these fake benchmarks.  You will see when the benchmarks are not cherry picked, it will be no where near a 4050 lol. They had to gimp the poor 4050 all the way down to 30w, which I donâ€™t even know how it even operates as such low wattages for the b390 to have a chance.  The full wattage 4050 (100w+) is about as fast as a 3060 desktop, this tiny iGPU in real world gaming tests will be at most best case scenario as fast as a full powered 3050, which is still  a massive 50-60% slower than a 4050 laptop.",Negative
Intel,"Because the low end discrete options are non existent or outdated, or bad value. The door is open for anyone to fill in that low end spot.",Negative
Intel,"It has to be cheaper first.  Current pricing of laptops with these chips is looking really high.  Granted they are mostly 'nicer' laptops, but still, really steep.  Check out the XPS pricing for example...",Negative
Intel,yeh its amazing but nvidia and amd did it to themselves...  rtx 3050/4050/x should not be priced as they are currently.,Positive
Intel,Impressive if the cost is good. Not so much if they're priced too high like Strix Halo.,Neutral
Intel,Papaâ€™s here,Positive
Intel,You mean desktop? PTL is mobile only.,Neutral
Intel,"For desktop, we're stuck with Raptor+Arrow Lake until Nova Lake, which uses entirely new P and E cores even from Panther Lake.    So no.",Neutral
Intel,Laptops are pc so yes,Neutral
Intel,No lol,Neutral
Intel,"Lunar lake already gets over 12h battery     I wish people would stop comparing it to Macs, people in businesses and people who use specific programs or even games will never use Macs",Negative
Intel,It trades blows with 65 watt 5050.   And it does that while using less than that full package. (including cpu)Â    No one is saying its better than 130 watt gpus.,Neutral
Intel,[https://www.youtube.com/watch?v=jrygnUnBRNI&t=1s](https://www.youtube.com/watch?v=jrygnUnBRNI&t=1s)  Shows it's like 3050Ti performance.,Neutral
Intel,"Low-end cards don't make sense for anyone involved. the fixed costs are far too high, you have no margin, and it just looks stupid compared to a slightly more expensive card on which you can put twice the GPU.",Negative
Intel,"True, but it's probably the ram situation. Unless intel is asking for a lot to recoup the 18A investment... Theoretically the PTL SOCs themselves shouldn't be the pricing issue",Neutral
Intel,"To be fair...they are priced very cheaply. There was a $600 5050 laptop on sale last year even.  Nvidia volume pricing on 50 tier mobile GPUs seems to be very attractive, it's up to manufacturers how much extra they want to tack on but you can build a very cheap, very capable laptop using this GPU.",Positive
Intel,"This. If 8060S Halo had been available.. at all, but also.. in sub 1600 laptops, or 8050S in sub 1200, it would have been wonderful. Same is true for PTL with B390 + 9600 MT/s RAM. I hope they will be competitively priced (also, hope the RAM pricing doesn't hit them too bad).",Positive
Intel,There is laptop models priced at $1300 with the iGPU you want.  I don't know what the chip pricing is - we never really do with mobile - but it seems low enough that regular priced laptops can include a high end Panther Lake chip.,Neutral
Intel,Until some chinese manufacturer makes a hacky desktop motherboard that is,Negative
Intel,Is the rumored drop by end of 2026 accurate to your knowledge?,Neutral
Intel,Our fleet are the Dell Pro Plus 16-inch.  We can probably eek out 10 hours if we really baby it.,Positive
Intel,"what's ""real usage""? i can do mildly CPU-intensive work on my 14"" premium pro whatever laptop and it won't last more than 10h.",Neutral
Intel,>people in businesses will never use Macs  Wrong.,Negative
Intel,"It does not lolâ€¦.  Once you see the real gaming benchmarks it will be wayyy slower with its low powered small gpu cores. Idk what all you people are smoking, heck the 120w 8060s with its massive die is still 13% slower than a 4060 laptop in a 20+ game average tested by Jarrodâ€™s tech.  Itâ€™s at best case scenario in real uncherry picked games 3050 performance, considering the 140v is about as fast as a 1650, even though that was leaked to be as fast as a 3050 in cherry picked benchmarks.",Negative
Intel,"Exactly, I hate these cherry-picked overhyped tests and claims.   Itâ€™s a small iGPU, you canâ€™t possibly expect 4050 and definitely not 5050 discrete level performance lol, and I get downvoted so hard even though Iâ€™m rightâ€¦ reddit moment.",Negative
Intel,"If that is true, then we should see some spiking up in costs across the space in which case you'll get a collapse in shipments since relatively few people can afford 2k laptops and I'd guess people are more sensitive to a laptop priced at 1200 vs 1500 compared to something priced 2000 vs 2300 since the most price elastic part of the market is going to just give up before they even get to 2000.",Negative
Intel,They put too much CPU in them to get them cheap. Though my 8060s z13 with 64gb ram was $1650 (open box Best Buy a while back) that was a lucky sale unlikely to happen again. Iâ€™d rather have a super thing and light XPs 13 with panther lake though and probably will unload the z13 when I can get the XPs.,Negative
Intel,"the die is like twice the size it will never be cheap, its a scam chip for people buying stuff for LLMs not for gaming/content creation",Negative
Intel,"If you mean the MSI model I'll definitely be skipping that one. Not a fan of MSI.   $1300 certainly isn't terrible. Better than Strix Halo offerings I've seen, but I hope that's not going to be the low end. I'll keep an eye out. Given the price of all electronics these days I won't get my hopes up. I'd love to be pleasantly surprised though.",Negative
Intel,Nova lake will use that as well,Neutral
Intel,"Not a rumor, that's Intel's word.  Which is certainly shaky these days.  Though they do seem to be delivering things on time better nowadays, so I'm cautiously optimistic.",Neutral
Intel,"The 16 might have bigger batery than the 14.  I have a 14 really happy, big upgrade from old Laptitude with 11th gen. Hated the Keyboard at first",Positive
Intel,yeah totally the majority of big businesses with 1000+ employees has a lot of Macs and totally not windows laptops,Neutral
Intel,It was shown to be running RDR2 at 75 FPS on High settings at 1080p and Forza Horizon 5 at 90 FPS on Ultra at 1440p. All while consuming 50 - 70 watts package power.,Neutral
Intel,"Can you confirm what suggests cherry picking in this review? Looking at it they seem like a fairly standard range of tests, 3D mark and a bunch of popular games.",Neutral
Intel,It's the RAM that is going to make them expensive I think... and unfortunately a lot of these with the good chip will have soldered RAM since it's basically a requirement unless they want to use CAMM2.,Negative
Intel,please intel ðŸ™,Positive
Intel,"dang. that's real usage, alright.",Neutral
Intel,Majority?  No.  But that isn't what you said.  Stop being a dumb troll.,Negative
Intel,"Thatâ€™s with upscaling turned all the way to the max and frame gen on lol.   You people are so gullible, itâ€™s best case performance is 3050 perf, which is still decent. Intel deliberately says as fast as a 4050 because they gimped the 4050 to 30w ffs, a full wattage 4050 is in its own league compared to this iGPU, thatâ€™s around 8060s perf.  Inside thin laptops where a majority will have this chip it will be even slower because itâ€™ll be wattage capped so real world perf will be BEST Case 3050 perf or worse.",Neutral
Intel,"They gimped the 4050 to 30w, intelâ€™s official â€œtestsâ€ and even then, in their own cherry picked benchmarks it showed the gimped 30w 4050 was still ahead in a few games lol.    This guy I replied to stating itâ€™s on par with a 65w 5050, is stupid and gullible. At 65w the 5050 laptop loses a few percentage of perf, compared to if it was max 100w+. It is no where close to a 5050, at any wattage, whether the lowest 45w or not. Some people are so gullible.  Like I said the timespy score is inline with a 3050, the 5050 laptop has around 4060 desktop perf for crying out loud. This tiny little iGPU with its low combined package tdp is no where close to a 4050, and especially not even in the same universe as a 5050. The 5050 laptop is literally faster than the desktop 5050 because the laptop has gddr7 and desktop version only has gddr6.",Negative
Intel,Nope. No upscaling -   [Forza Horizon 5 1440p High 100+ FPS](https://youtu.be/AX_rvgsYHJE?si=YxbVFJj2NfiUpD2D&t=633)  [RDR2 1080p High/Ultra mix 70+ FPS](https://youtu.be/AX_rvgsYHJE?si=F4oig0C6V8SoFY1F&t=689)  With Upscaling -   [Spiderman 2 1080p High XeSS Quality](https://youtu.be/AX_rvgsYHJE?si=QatQtMt2flikdvMB&t=738) 75+ FPS  [CP2077 1080p High Xess Quality ](https://youtu.be/AX_rvgsYHJE?si=6s7MvEGrUMjWa3-r&t=753)80+ FPS,Neutral
Intel,"The article doesn't do this though, and even discusses it?   >Slower versions of the Nvidia GeForce RTX 4050 Laptop GPU up to 60 W are also in the range of the B390 â€” you need a fast version with a 90 W TGP, for example, as in the Lenovo IdeaPad Pro 5, to have a clear advantage.   The article is in the context of laptop components so obviously they aren't running at desktop TDPs, but your commentary seems... misplaced? Especially given that these aren't official Intel benchmarks.",Neutral
Intel,"In the very review this thread is on, they have the 4050 60W as 40% faster. The review itself is very sketch, having the 4050 30W as the same fps as the 4050 60W in Baldur's Gate 3. It's not trading blows with the 5050 65W. It's getting creamed by the 4050 60W.   That means if you have a laptop with a B390, it would/could actually make sense to pair it with the lowest end dgpu from 2023 if one valued performance. The RTX 4050 6GB which isn't even being made anymore.",Negative
Intel,"You will see in real world gaming tests, itâ€™ll lag behind a 60w 4050 laptop by quite a lot, mark my word.",Negative
Intel,"Ahh, yes, real world gaming tests. As opposed to these tests of games by an independent third-party that (now I've had a bit more time to look) align with all the other reviews coming out and which were also conducted by third-parties.  People that get super emotional about certain brands are weird. Don't be those people.",Negative
Intel,"dudes dense, id stop bothering. i have a lunar lake device, the GPU is nuts for its power envelope.",Negative
Intel,Dual gpu? Huh? Havenâ€™t seen one of those since gtx 690. It used to be useless because memory wasnâ€™t shared. I wonder how it will work this time,Negative
Intel,"lol. Six months late and $300 (60%) over the announced price.  If the dual GPU version was really available for $999 right now (as announced), then Intel would make significant inroads into the local AI market.  As it is, buying this for $800 over a used 3090 is a really hard sell. Compared to a B60, the 3090 is readily available for $1100, and provides the same VRAM, double the compute and memory bandwidth, better perf/watt, and CUDA support.  With the dual GPU cards even at $2k each this does have one single niche - being able to get 144 GB of VRAM in a server at under 1500W for under $10k -  which is legitimately useful for LLM inference.  It's really sad that Intel didn't put in the investment a year ago to have a lot of capacity to produce these now. For the prices to be so high they seriously must be making like 10 chips a week.",Neutral
Intel,NAND SHORTAGE WHO?,Neutral
Intel,"> Unlike Sparkle, Maxsun has two cards in its arsenal: the regular 24GB VRAM model with a dual-fan design, and the dual-GPU 48GB model with a blower-style fan  seems nice",Positive
Intel,One card $799? Two cards $1598...,Neutral
Intel,It's no different. Not even an SLI/Crossfire bridge.,Negative
Intel,"To use this card you need your motherboard to support bifurcation. Without it only sees 1 GPU and 24GB VRAM  That wasn't the case with the likes of GTX690, R9 295 etc which the system saw them via SLI/Crossfire and could work on any mobo without supporting bifurcation.",Neutral
Intel,Those were also kinda useless as they only really handled sync as far as I understood,Negative
Intel,"What do you mean? They were a proper data bus, iirc.",Neutral
Intel,"i'm no expert but i dove in to Wiki      it was a [1GB/s to 3.25GB/s](https://en.wikipedia.org/wiki/Scalable_Link_Interface) interface. For refference PCI-E 2.0 was 1GB/s and 3.0 was 2GB/s BUT per lane so 16 and 32GB/s.  For refference HDMI 1.4 has 10.2Gbit/s  So as i understood it most of the data bandwidth were used for tossing the image output back and forth as only a single card were the one outputting the image (assuming you weren't running tripple monitor widescreen setup on SLI GPU's....) and our image data could more or less saturate the link  someone correct my math if i'm totally bonkers, but 2560x1440p = 3.686 million pixels. each using 24 bit (8-bit color on 3 chanels) which is 88Mbit/s. if you output 60 of those that is 5.3Gbit/s. 1GB/s = 8Gbit/s. Okay okay you wouldn't always throw a full image so lets call it 2.5Gbit. You were still using quite a lot of the bandwidth on the image alone, so from my understanding most of the interface communication was more related to ""who did what"".  and in AFR you would be handing over a full frame.",Neutral
Intel,"It was used purely to transfer rendered images, correct.",Neutral
Intel,"phew! my understanding was correct! And this is why the new nvlink is different. It's not just image data transfere. But also a LOT faster. NVlink 4.0 is 900BG/s. that is 300x faster than the FASTEST sli bridge recommended for 4K monitors. and that link is 15x faster than PCI-E 5.0 at a full 16 lanes. 15 times! the old sli was only the speed of a single or two pci-e lane. not 225 lanes equivalent speed  edit. One is numbered as unidirectional and the other bidirectional, so half the numbers above. But that is still VERY fast, even if it's a bit slower than the memory bus speed.",Positive
Intel,"It wasn't used differently on 20- and 30-series, and it's discontinued for the 40- and 50-series.",Negative
Intel,what do you mean by that?,Neutral
Intel,I'm saying NVLink did the same job as an SLI bridge for SLI setups. There's a reason it was discontinued,Neutral
Intel,"The fact that it can even compare to AMDs halo product, which the avg consumer canâ€™t afford is a win for Intel. Intel has plenty on leg room to expand the GPU too.",Positive
Intel,This suffers from bandwidth bottleneck. Strix halo is Quad channel while panther lake is dual. An igpu would benifit greatly with a quad channel,Negative
Intel,"This thing is absolutely nuts  AMD BTFO unironically, I'm floored. I never, ever would have considered an Intel chip before 2025, now this is the most obvious laptop part ever. AMD is surely sorely regretting recycling the same 780M and 890M chips for another entire gen, betting that Intel would continue stagnating.  This thing is gonna be a monster in handhelds.  I really, really wanted a Strix Halo laptop, but the lack of SKUs, price and the inflexibility with RAM kind of make it unappealing to say the least, not to mention the power draw compared to Panther Lake is unwelcome. These laptops are gonna be probably the best x86 in mobile has eaten in a very long time.  On top of that, it's almost making the 5050 look like a stupid part in a laptop. Why bother when you have a vastly more power efficient iGPU that will handle every desktop workload on top of being viable for gaming?",Negative
Intel,"â€œTakes on strict haloâ€ at about half the performance (:  Title aside, this looks pretty great.",Positive
Intel,"Amd hasnâ€™t even reached 30% market share mobile yet (oscillating between 20% and 26% since 2020) and are about to be almost wiped from existence again save some low end designs using Ryzen â€œAI 7â€ 445 (6 core, 2+4, 4CU iGP).",Negative
Intel,"The performance looks fantastic for high end $1k handhelds.    But the ""80% faster than AMD's 890M"" claim is absolute bullshit.  They tested against the HX370 with LPDDR5 5600.  That said, against an 890M that *hasn't* been crippled, it should still be 40-50% faster which is great.",Positive
Intel,"Will intel make it affordable for consumers though, or price it like LNL (2000+ USD laptops and up)",Neutral
Intel,"""compare"", it is half the performance. Still good for what it is, assuming it is priced right",Positive
Intel,"Well it's not just memory bandwidth. It's got about as much bandwidth as it needs to feed the Xe3 cores.   Panther Lake's GPU tile size is only 54mm^2 while Strix Halo's GPU is 308mm^2. For Panther Lake to compete with Strix Halo it would need 2-4Â times as many Xe3 cores probably. That'd be expensive. There's a reason Strix Halo is so expensive and kind of low volume, bigger CPU more RAM and more expensive motherboard aside.",Neutral
Intel,DDR6 can't come too soon for igpus too. But in reality memory bandwidth will stay an issue for a long time. Of course cramping enough compute power in such a format is an issue too,Negative
Intel,Framework desktop motherboard?  https://frame.work/products/framework-desktop-mainboard-amd-ryzen-ai-max-300-series?v=FRAFMK0004,Neutral
Intel,"Half the performance, half the power, (more than) half the price.",Neutral
Intel,I preordered X7 358H laptop for 1300,Neutral
Intel,Bro nothing's going to be affordable in computer hardware at this rate,Negative
Intel,There are plenty of LNL laptops around 1000 what you on about,Neutral
Intel,Lunar lake is in sub 800$ laptops now and 12xe cpus are available for sale 1300$ despite the ram and cpu shortage.   The comparison is good even before likely price hikes for strix halo,Positive
Intel,"Weâ€™re talking mobile chipsets here, strix halo is what happens when you throw efficiency out the window, with Power (TDP) range, typically from 55W up to 120W. The ultra H 300 has default TDP of 25W, with Maximum Turbo Power (MTP) going up to 65W-80W. Intel has a better design, if they threw 40 XeSS3 cores on it, it would prolly run circles around Strix.",Neutral
Intel,"Strix Halo is double the die size, this should be compared to Strix Point.  But price will tell everything.",Neutral
Intel,"> It's got about as much bandwidth as it needs to feed the Xe3 cores.  GPU's will take all the bandwidth you can feed them. It won't help EVERY benchmark, but it will help many.  I'd rather see 256-bit bus on something like this. maybe 192 since you can do that with LPDDR5X etc.",Neutral
Intel,">Panther Lake's GPU tile size is only 54mm^(2)  is this confirmed for the bigger tile?  edit: also, Halo has all the IO, en-/decoders, etc. in the ""GPU"" tile, so the comparison isn't quite valid",Neutral
Intel,And about four orders of magnitude more availability.,Neutral
Intel,"> (more than) half the price  Have we seen pricing? Not doubting it, I just haven't seen anything personally but probably missed it.  Strix Halo does seem to be a pretty mythical chip due to its price.",Neutral
Intel,Keep in mind that each Xe3 core is about as wide as an AMD WGP. We're looking at 1536 vs 2560 shaders. The B390 is 60% as wide as the 8060S. 20 Xe3 cores would match the 8060S in width. 40x Xe3 is as wide as the 7900GRE.,Neutral
Intel,"Bingo  Strix is also limited by being RDNA 3.5 and no FSR4, so it's rather dependent on raw throughput, and it can't possibly fit in a comfortable handheld that would last for more than an hour and a half under load.  I really, really appreciate what AMD has done historically in the APU space, but it is genuinely time for vendors to start considering Intel. The strides here are absolutely immense. They went from an iGPU being a thing that can do basic graphics and 2D gaming to something that competes against lower end NVIDIA parts at less power draw and can actually legitimately game. It's bonkers. In mobile it's a no brainer.  Of course, it's going to be interesting seeing AMD's next UDNA architecture and what they can pull off, but competition never hurt nobody, and it was sad seeing AMD stagnate in the APU space of all things, their bread and butter that gave them pretty much the entire console market plus the Steamdeck. The entire Windows and Linux handheld market has been nothing but AMD for years. This is even better than Lunar Lake.  We're getting to the point where Intel could legitimately compete in the home console space and make a really great product, but realistically they can't undermine AMD's relationship with vendors at this stage. I hope they keep it up, it would really be cool to see an AMD vs Intel APU console war generation.",Neutral
Intel,It's about 50% bigger die with 1 CCD (which seems comparable CPU performance),Neutral
Intel,https://youtu.be/X9eYQTkzxqU?si=Uzdz-E3QJzzVM42N  Not the only one comparing. Intel actually outperforms at lower wattage.,Neutral
Intel,">GPU's will take all the bandwidth you can feed them.Â   Didn't deny that. But 12 Xe cores is presumably considered the sweet spot, that's all I'm saying. And Strix Halo only has twice as much bandwidth to feed a GPU die 6 times the size of Panther. I'm sure it has more cache, but still. I think Intel would consider triple or quad channel memory not worth the costs. It would require new i/o, new pins, new motherboard, more RAM, and all, for what's essentially the lowest volume product.  Besides, Intel already has Nova Lake AX in the backlog, or whatever it's going to be called. Practically intel's strix halo. It'll have Xe3P cores, more powerful than Xe3, thus deemed more worthy of the halo treatment.",Neutral
Intel,"This is a big of exaggeration, as you can see with Nvidia moving to gddr7. While bandwidth has increased substantially, performance is clearly limited by lack of compute power",Negative
Intel,"No official confirmation yet, but JayKihn leaked the tile size for the 12Xe SKU last year. Another user somewhere else said the 4Xe GPU is 33mm2.Â Â  https://x.com/jaykihn0/status/1812898063502938260   And even without the PHYs and NPU, from what I see, Halo's GPU tile is still like almost 3 times as big. So yeah, it's on another class, that's my whole point.",Neutral
Intel,Yep,Positive
Intel,"I have a pre-order in for an MSI 14"" at B&H for $1300. 358H, 32GB LPDDR5X-9600, 2TB, 1200p OLED. I've seen some lower-end PTL laptops rumored around the $900-$1k starting range, but those are likely the 4Xe chips. Wildcat lake with its tiny 2Xe GPU is probably going directly into the budget sector.",Neutral
Intel,Good catch.,Positive
Intel,AMD is dormant on the APU space since it had basically the monopoly for x86 because Intel was just bad.  They are taking one of the old Intel's book by releasing rebrands and reashes,Negative
Intel,"> But 12 Xe cores is presumably considered the sweet spot  By what? much larger Xe3 GPU's exist.  We have nothing to compare against in Intel-iGPU-land that has 256bit memory.  Strix Halo die size isn't the metric you want either. It's only 2x the fps (and who knows, panther lake could be 2x its own fps with doubled memory bus, but we'll never know, because Intel won't release a strix halo competitor)",Neutral
Intel,"Halo's die is still quite a bit bigger, but from the Intel side, you need to include IO, GPU and about half of the compute die which has the MCs, encoders / decoders, etc. to match the ""GPU"" die of Halo, so it is more like 200mmÂ² to 300mmÂ² when compared",Neutral
Intel,AMD is paying more attention to NVIDIA for sure. ESP on the data center side.,Neutral
Intel,">much larger Xe3 GPU's exist.  The biggest one for the moment is on Panther Lake X CPUs. I wouldn't know if there's something bigger tbh.  >Strix Halo die size isn't the metric you want either.\\  Sure you can't compare two different architectures. But all I need to know is it's faaar bigger.  >panther lake could be 2x its own fps with doubled memory bus  That would be within Strix Halo territory. I highly doubt it. A GPU with bigger bandwidth will access things and perform raster operations faster, but it won't get much faster at actually processing vectors and other calculations. Gotta need more cores for that.",Neutral
Intel,"Well Panther uses mixed processes, and hybrid tiles are bound to be a bit less space efficient than putting everything on a single die. And to be fair, Halo GPU uses N4P process while Panther GPU uses N3E So, still not directly comparable.   Gotta say though, Arc's PPA has improved a lot since Alchemist and Battlemage.",Neutral
Intel,"> That would be within Strix Halo territory. I highly doubt it. A GPU with bigger bandwidth will access things and perform raster operations faster, but it won't get much faster at actually processing vectors and other calculations. Gotta need more cores for that.  Yeah, it doesn't matter how much memory bandwidth you have if the GPU doesn't have the raster performance to keep up with the flow of data. Case and point, AMD's R9 Fury X. Released with 4096bit bus HBM. Had a total memory bandwidth of 512GB/s. Yet the GTX 980 Ti released with a 384bit bus and 336GB/s memory bandwidth and it out performed the Fury X in pretty much everything.   That said, I have no idea how close the iGPU is to being bandwidth bottlenecked at 1080p. But I very much doubt doubling it would also double the frame rate.",Negative
Intel,"Yeah, I think Intel has done a great job with the improvements, I just don't want to overhype things.",Positive
Intel,"I wonder if Valve would be considering Panther Lake for a Steam Deck 2. It sounds like a generational leap from RDNA2 (which is what they were looking for), and can be cheap enough for valve to slightly subsidize the cost.   I guess the main thing is the power envelope. I think Valve is only interested in making handhelds that deal with a 15W TDP or lower",Neutral
Intel,"Series 3 seems like the biggest Intel W in a long while.   Plays AAA games at 45-60fps with upscaling, and all other games at native at 60+. Not to mention this is 50% faster than AMD's equivalent HX370 while being massively more power efficient.   There's also already laptops listed on sites like Best Buy for reasonable prices (sub $1300). Compare this to the AI 395 from AMD that can't be found for less than $2500 while being significantly less power efficient. Granted, that APU isn't really comparable.",Positive
Intel,"the handhelds with these chips are going to slap. Also people gotta remember that using upscaling on smaller screens especially 7-9 inch screens is a lot more tolerable.  and these benchmarks are of triple A titles, monster hunter wilds is a dogshit unoptimized game, and people will be playing a mixture of game from older titles, indies, emulation etc.",Positive
Intel,"So remind me, the ARC B390 is not a discrete GPU?  although the ARC B580, and B570 are discrete GPUs?  and the ARC A380 is a discrete GPU?",Neutral
Intel,"That should say ""playable at 540p""",Neutral
Intel,"Linux driver support is the only problem at the moment. Lunar lake is already competitive with Z2 extreme in gaming in windows, but not even close in Linux. Hopefully this changes by the time handhelds with panther lake come around",Negative
Intel,There's an Xbox project within the coming years apparently.,Neutral
Intel,I think Valve is looking for an ARM chip. Intel could dip their toes in this market before Qualcomm catches up to Apple.,Neutral
Intel,"Yeah, amd went to extremely greedy!",Negative
Intel,AMD should have made a RDNA4 igpu... RDNA5 igpu is gonna be a huge boost.,Positive
Intel,AMD should have made an igpu from rdna4...  but nope... the engineers are too busy making AI gpus.,Negative
Intel,"In a year or two,when they can get panther lake for cheap, this could be resolved. They could even get more efficiency with a refined 18a for the CPU and whatever node is available for the GPU. With the current RAM prices I wouldnâ€™t expect any major console style updates until 2027 anyways",Neutral
Intel,Do you think there's any particular reason why they would want to go with ARM? Quite sure Intel proved here that efficiency is essentially equal between both ARM and x86 here,Neutral
Intel,It's hilarious to think Steam would work with Qualcomm.,Neutral
Intel,"Very unlikely. Proton and DXVK work alright with x86 but adding ARM conversion on top is, uh, a **very** poor experience. In fact that first generation of Snapdragon laptops had among the highest return rate of laptops I have ever seen. Amazon [literally warns potential customers](https://www.tomshardware.com/laptops/snapdragon-x-powered-surface-laptop-7-gets-frequently-returned-item-warning-on-amazon) about it.  Valve definitely wants a wider adoption rate of SteamOS and ditching x86 is not going to help that. They are **not** Nintendo that can ask devs to target their architecture. It's going well so far because for most games you can just make a standard Windows version, slap Proton and it works within 10% of native performance under optimal circumstances. Anything that can increase incompatibility rate (and it VERY well can, ARM **does not** support AVX2 natively for instance meaning [a lot of games that might have issues](https://www.reddit.com/r/macgaming/comments/1dekmtz/avx2_game_list/) even starting or underperform).",Negative
Intel,i'm so tired of people throwing ARM around for everything. superficial much?,Negative
Intel,"Intel and AMD especially have this habit honestly, they hit the lead and stagnate *bad* and the catch up for whatever company stagnated takes a hot minute, though hopefully this level of pushing boundaries in the handheld PC space keeps both of them moving at a steadier pace for a while rather than one team moving way the fuck forward",Negative
Intel,why didn't they do one? Why use tech that is so old?,Negative
Intel,Yep AMD ces presentation dry as a bone until that rack announcement when ceo turned giddy.,Neutral
Intel,"Even more efficiency that doesn't exist yet. Snapdragon elite can do some heavy workloads for several hours at a time, but it's not powerful enough for heavy gaming. Valve says they know what they want, it's just not ready yet. I think as great as Panther Lake benchmarks are, the biggest complaint of the Steam Deck is still the 2ish hours of battery life in more demanding titles.  With the existence of other handhelds already, I don't think Valve is trying to aim for the beefier spec department here, if it means the same battery life.",Negative
Intel,"I'm not sure if this is sarcastic or if you missed the memo, but their new VR headset coming later this year is powered by a Snapdragon 8 gen 3.  [https://store.steampowered.com/sale/steamframe](https://store.steampowered.com/sale/steamframe)  A Qualcomm based steam deck isn't out of the question.",Neutral
Intel,"Valve's stand-alone VR headset uses Snapdragon, and x86 emulation, so will be interesting to see how well it performs",Positive
Intel,"It depends. For a PC, yes. For a handheld, I don't think so. For the future of enterprise notebooks, probably, especially since Apple has been doing it for a while.",Neutral
Intel,Save cost. AMD's assessment is that no one in mobile cares about gaming and if they do they should just get Strix Halo or build a PC.   cheapskate AMD as always.,Negative
Intel,"probably didn't want to bother redesigning the APU without also having a CPU upgrade, it's expensive after all, and takes resources from other projects",Negative
Intel,"""Even more efficiency that doesn't exist yet.""??????????????",Negative
Intel,"But Qualcomm drivers on Linux are even worse than Intel lol. The custom AMD APU on the Steam Deck had the advantage of great Linux driver support for gaming(not just being able to support the GPU hardware and benchmarks, but run games at good performance which Intel still can't match). No other company has both high performance GPU and good Linux graphics drivers",Negative
Intel,isn't the APU a modular unit where they could just put the new one into the same die space?,Neutral
Intel,"Not my words. I'm taking Valve's. They said they know what they want, and if it was Panther Lake, we'd know already.",Neutral
Intel,"The Strix Halo is that basically, but the normal Strix Point APUs (e.g. HX 370) are not. The Strix Halo follow-up, Medusa Halo, is slated for 2027, and to use Zen 6 and RDNA5. While the Strix Halo could benefit from FSR4 if it got an RDNA4 update, it's still way stronger than the B390, even at similar power.",Neutral
Intel,Medusa Halo = 2028,Neutral
Intel,"Hopefully they deliver. Amd needs a shake up in the APU market, mostly the GPU side of it.",Positive
Intel,That article claims it on par with the 4050 laptop. Jesus christ,Negative
Intel,this is nice but the handheld market could use less ultra 9 and 7s and more ultra 3s.  the closer they can get to the nintendo 2DS XL in size while being under $400 the better.,Positive
Intel,I am definitely looking to get a gaming handheld PC with PTL in it. Gonna cost a fortune probably but it's my first and intend to stick with it for a long time  The only thing that would stop me is if they skimp on ram... Which might be a very real problem,Positive
Intel,77% faster while using 80% more power.  I rather see power matched benchmarks.,Neutral
Intel,"happy about more handheld focus, genuinely have put in more hours on my steam deck than my pc setup this year. i have my eyes on ARM going forward as well",Positive
Intel,fun to see them tout XeSS MFG on mobile gpus while the B580 still doesnt have it....,Neutral
Intel,Really excited to see these chips on handhelds.,Positive
Intel,"Iâ€™ll always want a really good handheld besides my PC. Currently own a Legion Go S and the Switch 2 so this is good for everyone. AMD stays on their toes and if intel is good and gives us a SteamOS native device, Iâ€™ll definitely try them next upgrade. The",Positive
Intel,"I'm looking forward to this, especially for a gaming handheld/mini pc device, having a gpu that is nearly capable of a RTX 4050 with that power profile could be game changing.  Plus all the existing Intel XESS features are icing on the cake, although support for that scaler is flakey. I'm just hopeful that more games will support XESS.",Positive
Intel,"Can anyone say real life performance diff, and how much increase in battery life in real laptops, Because I feel many times those ppt numbers don't nearly match real usage (especially when ppt numbers are huge).   Can I get Mac like battery(or atleast 7hrs with no performance drop) and how much does it compare to Mac m1/a18 air performance with them on a $600 laptop.(Assuming fedora/mint as OS)",Neutral
Intel,"I don't understand, we need to see the price of this thing, because otherwise we have to compare it to the AMD 8060s which will be more powerful, but even the cheapest machine with that costs â‚¬1500/â‚¬2000. We just need to see what price point this chip will be offered at.",Neutral
Intel,"On just 2 channel / 128 bit RAM, well done Intel!",Positive
Intel,An ancient Chinese proverb (roughly) states: *'Talk...* does not make rice...' ðŸ¤”,Neutral
Intel,Steam deck 2??? Take my money gaben.,Negative
Intel,It does look like an amazing performer. I hope the Linux drivers are up to the taskâ€¦ Windows based handhelds have been pretty bad because of Windows.,Positive
Intel,Waiting for this since AMD 890M was disappointing,Negative
Intel,"Who cares, gives cheaper powerful GPUs for 2k, 4k gaming",Neutral
Intel,"Yeah, RDNA 3.5 lasted way too long. Admittedly, RDNA4 was a special case where they gave up on a mobile version in favour of getting UDNA ready but that's their own fault. Hopefully, this pushes them to make UDNA a mobile focused architecture as well and perhaps push more cores in igpus to take back the integrated graphics crown. Competition is very good for the consumer.",Negative
Intel,agreed. these rehashed mobile chips with bad upscaling are well beyond their lifespan.,Negative
Intel,"I looked at the benchmark scores they put out and it looks pretty promising, apparently the 12XE core variant can score somewhere around 6300 on Time Spy graphics (https://www.notebookcheck.net/Early-Intel-Panther-Lake-iGPU-benchmark-impresses-with-50-faster-performance-vs-Lunar-Lake.1138923.0.html).  Intel is comparing a 4050 with low wattage (60W system TDP IIRC) so it's not as good as the full powered 4050 which scores around 8000 on Time Spy. On low powered 4050s though like the one in the XPS and other thin and lights it will compare pretty evenly. It also outscores basically any 3050 on the market since the highest powered ones get around 4500-5000 on Time Spy (which was already matched pretty decently by the old 8XE core GPUs)",Positive
Intel,"It will depend on game to game basis. Some perform well on iGPUs, some tank hard due to memory bandwidth or whatever issue they have with it.",Neutral
Intel,"A quick Google says 9 TFLOPS or the equivalent to an RTX 1080, 2070, 3060, 4050 give or take.",Neutral
Intel,They did against the 285h and it's a similar margin. Lunar lake has a power burst max wattage below panther lakes max sustain power here so they can't compare 1:1 properly,Neutral
Intel,>77% faster while using 80% more power.  Are you following CES at all?  The top feature of that architecture so far has been power reduction,Positive
Intel,82% faster than 890M with 30% more power draw with native resolutions,Positive
Intel,rdna? dude their vega lasted too long they got very complacent in their igpu department,Negative
Intel,"At this point, we'll be lucky if they even care about consumer cards at all.  It's AI all the way these days.",Negative
Intel,"And then UDNA has been nowhere to be found, probably coming next year. AMD completely blew their lead in the APU space.",Negative
Intel,Panther Lake with an iGPU being able to play the newest games on medium/high settings in a thin notebook is pretty crazy,Neutral
Intel,Mfg on or off? The article wasnâ€™t clear on that.,Neutral
Intel,their Zen 5 desktop iGPU still use RDNA2; a 5 yr old architecture let that sink in...,Neutral
Intel,"AMD didn't have money when they were using Vega iGPUs, and they were still the best iGPUs around",Positive
Intel,"Unlike Nvidia they actually can make a lot of money relative to what they do right now if they get consumer marketshare. Iirc, Nvidias gaming revenue still beats AMDs enterprise earnings.",Positive
Intel,"Eh, they will still have the best igpus on the market for a while. If they price the 388 well there is hope for them. But it's never going to sell the volumes Intel will.  UDNA is a major architecture overhaul on par with the the introduction of Ryzen and RDNA. A year is a long time but AMD only really needs a single gen to recover this gap if they so wish. But UDNA will need to be made with versatility and low power application in mind.",Neutral
Intel,"Low to medium , not high",Neutral
Intel,native rendering,Neutral
Intel,Those weren't good though.  They didn't get close to the 1050ish equivalent that's a decent min spec card until the steam deck.,Negative
Intel,"High with XESS maybe at â€˜okayâ€™ frame rates. Still, crazy.",Neutral
Intel,And Intel steps back into the game. The next generation of handhelds is upon us.,Positive
Intel,"despite me using amd, please let intel succeed",Positive
Intel,"7200 DDR5 support out of the box slaps. the IMC should be bonkers, like the RAM prices(I know I know.,..)",Positive
Intel,This is insane for a ultrabook without a dedicated dGPU. Intel cooked! AMD brought us the same thing refreshed.,Negative
Intel,"intel cooked, amd socked. I cant wait to replace my old aging i7-9750h laptop",Positive
Intel,can't wait to get my hand on this in handheld PC.,Positive
Intel,Wonder why they haven't announced Wildcat Lake yet,Neutral
Intel,Is this meant for the Strix Point or Strix Halo price segment ?,Neutral
Intel,"I'm curious to see if framework will have Panther Lake options, but I'm not sure if these are compatible with SODIMM or not.",Neutral
Intel,I want this in my nuc.,Positive
Intel,"So it's available at Jan 27th, but is that only for laptops or is it for desktops as well?",Neutral
Intel,ok but can we talk about how the ultra 5 332 is worse than the ultra 5 325? i mean wtf did they do to the names?,Negative
Intel,I am neither intel or amd biased...hope competition stays alive..and reduce prices..which i doubt,Neutral
Intel,"Iâ€™m confused, is cooked good or bad? ELI5",Neutral
Intel,"Strix Point, but we'll see what happens with the RAM situation.",Neutral
Intel,"Isnâ€™t much point buying strix point if you can get this instead. Better chips and a faster iGPU, and better battery. Issue is whether you want to buy any laptop this year given the price of componentsâ€¦",Neutral
Intel,The Arc B390 parts are LP-DDR5x only.,Neutral
Intel,"No Sodimm on the existing X series parts, LPCAMM2 for DDR5 seems dead still so I only expect to see good use of it with DDR6.",Neutral
Intel,Its a BGA mobile part - you might see some desktops using it (particularly in SFF NUC type designs or All-in-Ones) but its not a socketed desktop part.,Neutral
Intel,Desktop version drops next year like usual with intel. First laptop then pc.,Neutral
Intel,Both have and had their ups and downs. If the competition is alive it's better for everyone.,Positive
Intel,"Usually when someone cooks its good, but if they are cooked its bad.  Intel/AMD cooked/ is cooking = good Intel/AMD is cooked/ they are cooked = bad  At least that's how i differentiate it.",Negative
Intel,"Cooking is good.  Getting cooked is bad.  One has you as the victim, the other as the victor",Negative
Intel,SÃ¤g mig du Ã¤r pensionÃ¤r utan att sÃ¤ga att du Ã¤r pensionÃ¤r.,Neutral
Intel,"There could be if I can get it far cheaper.  This kind of performance should melt good part of premiums off Strix Halo, too.",Positive
Intel,Its probably LPCAMM memory.,Neutral
Intel,"Yeah I certainly don't expect a smaller company like FW to adopt a niche standard like LPCAMM2 for DDR5, probably DDR6 given I doubt SODIMM can support the speeds that DDR6 will have.",Negative
Intel,"desktop version will be novo lake, later this year or early next year.  It will a significant upgrade.",Positive
Intel,So in 2027? It takes them a whole year to release the desktop versions?,Neutral
Intel,Strix halo is irrelevant because that shit isnâ€™t and wonâ€™t be available in mainstream laptops regardless of its pricing. Even in amd marketing material just now itâ€™s the same asus tablet and hp Zbook nothing else.,Negative
Intel,"Nah the love of Strix Halo is it's 256 bit bus and 128GB of memory, which this doesn't address at all. It's good groundwork though, you could imagine an update that grows the current design with two Xe4 12 core chiplets connected to the I/O die that then goes to DDR6 192 bit bus being good enough to compete with an RTX5060.",Positive
Intel,"I get downvoted, but it literally shows on the chart that the 388H, 368H, 358H and 338H are LP-DDR5x only: [INTEL-PANTHER-LAKE-1.jpg (2629Ã—1341)](https://cdn.videocardz.com/1/2026/01/INTEL-PANTHER-LAKE-1.jpg)  You won't see Intel supporting consumer designs which use DDR5 with these parts, and if you do make a product running it you'll lose the Arc branding - same as if you do an Arrow Lake-H design with single channel memory, or a Lunar Lake with a sub-17W PL1.",Neutral
Intel,LPCAMM2 is still LP-DDR5x.,Neutral
Intel,"I mean they tried for Strix Halo, but AMD did not validation or design work in mind to support it sadly so framework couldn't risk it. Intel tends to be better, but still.",Negative
Intel,"No, I have no idea what u/kazuviking is talking about.   Panther Lake won't have desktop chips. The mobile chips might get used in some mini PCs or whatever, but PTL is a mobile architecture.   What is coming late 2026 though, near the end of the year, is Nova Lake, a completely different arch than Panther Lake. And then we will likely see Nova Lake for laptops at CES next year.",Neutral
Intel,"It was always like this, release new gen on laptop then a year later on pc.",Neutral
Intel,It is going to be in the Asus Tuff A14 this year.,Neutral
Intel,Yeah but completely different standard.,Neutral
Intel,"That's a bit of a different case, because they are designing a new product either way they might as well look into supporting something like LPCAMM2. They already have a mainboard for the FW13 that can support these newer CPUs, so there has to be a very compelling reason to spend money to redesign that, which I think a single Intel SKU is not unfortunately.",Neutral
Intel,Do we know if we are getting real Nova Lake mobile chips or just a BGA version of desktop parts with a panther lake refresh?,Neutral
Intel,"The DRAM standard between LPCAMM2 and LP-DDR5x is the same - that's the point. LPCAMM2 is a replaceable implementation of LP-DDR5x memory.  But LPCAMM2 is completely different from SO-DIMM. SO-DIMM is DDR5. LPCAMM2 is LP-DDR5x.  You will see Arc B390 designs with LP-DDR5x memory down on the mainboard, and you'll see (some) LPCAMM2 designs, but they'll be far less common.  But you won't see DDR5 SO-DIMM designs - if they claim to be DDR5 SO-DIMM and Arc B390 then its wrong.",Neutral
Intel,"It certainly sounds like we will get dedicated NVL-H, and that's what the rumors claim as well. Here's an excerpt from an Intel executive at an Intel BoA conference:   >Yeah, so maybe just baseline everybody on Panther Lake, so Panther Lake is a product thatâ€™s going to launch in the second half of this year, and it is all built on Intel 18A. Really, Panther Lake is an all mobile stack. When you get to the next generation Nova Lake it is both a mobile stack and a desktop stack",Positive
Intel,"Looks like some folks are saying Nova Lake replaces panther lake stack exactly while also having a really big H chip at top, missed that cause I thought it was just the big 8+16+4 design",Neutral
Intel,How is the AI running on the B50?,Neutral
Intel,Where did you purchase the B50?,Neutral
Intel,nice case,Positive
Intel,"love the size of it. love the psu, are there any psus in this formfactor that are more powerful?",Positive
Intel,100Â°C,Neutral
Intel,"cute fan lol  like other user, how is the B50 performance?",Positive
Intel,"surprisingly fast, it has its own suite on windows, but i want to use it in linux, trying to figure out how as im not that good ta linux.",Neutral
Intel,"weird comparison. the mac mini is the real beast and its in part thanks to not having to cater to OEMs, but the 48gb mini pro is $1800 vs this $350 drop in card so that's a strange comparison.   m5 in the ipad has only about 150gb/s of bandwidth. good for light inference but I really doubt its practical for actual scale production.",Negative
Intel,"As an ardent and lifelong Apple hater, I must admit that they will probably come out much stronger and on the very top of the current chaotic situation if they manage to keep the current price/perf ratio of their offerings. Even with the Apple tax, they are unmatched right now.",Positive
Intel,"apple stuff is hard to get used to for many pc nerds and mechanical engineers and engineers in this field. When pro software like catia/nx nativly will work nativly on arm then maybe the big car/air/motorcycle/""every day crap all around us"", then product developers will adopt arm/apple. but right now x86 is the king for these guys/this sector that design all stuff u see around u.",Neutral
Intel,"its not hard, you can literally just buy them on newegg",Positive
Intel,"[https://www.newegg.com/intel-arc-pro-b50-16gb-workstation-sff-graphics-card/p/N82E16814883007](https://www.newegg.com/intel-arc-pro-b50-16gb-workstation-sff-graphics-card/p/N82E16814883007)  They're finally back in stock as of this reply, though likely not for long.",Positive
Intel,"It's the Flex ATX form factor. I think the most powerful one that is also reputable is the Enhance ENP-7660L, which is 600w.",Positive
Intel,Around 65c-75c under load,Neutral
Intel,"a lot of commercial software also just does not give a shit about improving, and I don't mean that as a defense for apple.  after effects is just ass for a 2025 product. basic filters are still using legacy code and memory management is horrible. like you're not going to clean 64gb of memory until I hit 96gb utilization, then you're going to slow to a crawl and maybe crash because of threadlock? why even bring back MT rendering? 3rd party scripts people wrote in their basements outperform this stupid thing. spoofing multiple instances and then stitching the results works better than just running the software, its baffling.  anyway yeah, there's a lot of good to x86 and not having to reinvent the wheel, but god damn if so many companies are using it as an excuse to resell garbage.",Negative
Intel,"It's not exactly weird. They went PPC before Intel because powerpc was more effective for workloads most people used macs for. The switch to Intel was just because Intel had node leadership and performance leadership. Instead stick to A-chips for low power mobile where intel gave up on servicing. Intel loses node leadership to TSMC for a long time, Apple moves on to everything in-house is a pretty logical progression.  Apple having bespoke solutions isn't new either. they've been doing it since their G workstation days. Their current situation is pretty much on brand for apple, but the difference is the huge mistakes intel made (particularly firing so many top engineers) that led to staff fleeing to other companies, including leadership at Apple processor design.  basically apple did their own thing as usual and did a great job don't get me wrong, not taking anything away from apple. the biggest difference however was intel's CEO and board destroying the company.",Neutral
Intel,"> Memory - The Core Ultra X9 will feature soldered Dual Channel LPDDR5x 9600 MT/s memory up to 96GB   96GB of RAM? So it's $20,000?",Neutral
Intel,"Great, want one!",Positive
Intel,any plan for Wildcat Lake variant for very cost effictive mini PC solution?,Neutral
Intel,Hadn't noticed this on the first read: there are separate SKUs for HDMI vs DisplayPort. Will all of the models (X9/X7/U7/U5) be available with both options?,Neutral
Intel,It will be very interesting to compare it with the Nuc 15 pro. I am currently reviewing this model with a U5 225H processor. And I know what this processor is capable of in combination with ARC 130T.,Positive
Intel,any word on availability?,Neutral
Intel,I hope it costs under 1600.,Neutral
Intel,5x4 nopeâ€¦ stick with the 4x4 thatâ€™s been around for a decade at this point.  Any increase in size just dilutes the meaning of NUC,Negative
Intel,Man I wish they'd move on to 10Gb NIC already. I would be all over these for lab and canary. Using a thunderbolt dongle is miserable.,Negative
Intel,"Am I seeing correctly ...your specs say Bluetooth 6, but your event photo shows Bluetooth 5.4 ðŸ˜¬",Neutral
Intel,"This looks like a nice NUC for Home Assistant, Frigate, Openvino to run local LLM and Detection because of the Nvidia 4050'ish performing iGPU and AI focused optimizations.  Something I can leave on like an appliance for the cameras and IoT smart home integration.  But if it's priced too high and I can build a desktop with a dedicated GPU for the same money that will be easily upgradeable using standard ATX parts... it might not be worth it.",Positive
Intel,"Ok atleast this doesn't have co pilot button,plus one to that",Negative
Intel,"Nothing to share about that. I see some news about that platform, but nothing has been shared with me internally to say one way or the other. For these ASUS NUC models, they are all listed from the Intel Core Ultra 5 and higher.",Neutral
Intel,"I suspect this would wind up being ""NUC 16 Essential"" to replace the Twin Lake-equipped NUC 14 Essential.",Neutral
Intel,"It's mentioned in there, but late Q1 - early Q2 is our current target.",Neutral
Intel,"5x4 yes, high TDP no",Neutral
Intel,"Ah, I see the issue. I took these snaps from one of our product videos at the show. The display was featuring all of our products, and the one that lists BT5.4 was for the ExpertCenter PN55 (you can see the copilot button on it to compare). The other information, including the spec one-pager below lists BT6.",Neutral
Intel,"If I were to buy one, are these like just hardware or do they include an OS with all the drivers installed out of the box?",Neutral
Intel,"Thanks, is that for global availability or just US? Also any word on what the lowest spec SKU will start at?",Neutral
Intel,Talk about a poorly timed photo ðŸ§,Negative
Intel,"Apologies, this is not a Nuc question, but any idea when the Zenbook Duo's with Panther Lake might ship? And any thoughts to a version with 64GB RAM? I use After Effects a lot, and AE is RAM hungry.  I was going to get a Mac, but I just saw these Zenbook Duo's today and I could be tempted... they look quite cool.",Neutral
Intel,"They will be available in both types of models. I don't have a full breakdown on which hardware will be included with the complete Mini PC (e.g. with memory, storage and OS), or the Barebone kit (no memory, storage, or OS), but you'll be able to purchase it in either configuration.",Neutral
Intel,"I would expect US availability to be around global availability, but that different barebone kits sometimes are configured a bit later.   To your second question, pricing information isn't available at this time, but if you're just asking the specs, I would follow what I posted above.   However, if you go to our global product page, you'll usually find a download link for our spec datasheet (sometimes this doesn't show on mobile + plus the document isn't available yet). This will be a better way to see this. I'll ask our team when the datasheet will be available.",Neutral
Intel,"We do what we can. Thanks for noticing, however.",Positive
Intel,"If only Intel had stayed in the memory business!   They'd be enjoying Micron valuations and wild profits and performance from copackaged CPU+GPU+LPDDR of their own design and manufacture...     But no, they'd rather invest billions in buying donuts as a service, or whatever their crazy investements went into.",Positive
Intel,"damn an iGPU using 32GB of vRAM, I wonder if they're testing a Panther Lake laptop with 48GB RAM or even more (since X7 & X9 Panther Lake only accepts soldered memory)",Neutral
Intel,"If Intel is really about to release a B770, honestly the **only thing that could make it competitive is the price**. (FOR ME, competitive in 2026 means <400â‚¬) From a performance standpoint, it would need to undercut existing GPUs quite aggressively to make sense, especially given how crowded the mid-range already is.  That said, Iâ€™m pretty skeptical about how realistic that is. **With the recent RAM shortages and rising memory costs**, pricing a new card competitively while still keeping margins doesnâ€™t sound easy at all. Memory is a huge part of the BOM, and weâ€™ve already seen how shortages can push prices up across the board.  So unless Intel is willing to take a serious hit on margins (which seems unlikely), Iâ€™m not convinced the B770 will land at a price point that truly shakes up the market. Happy to be proven wrong, but for now the pricing question is the big unknown for me.",Neutral
Intel,So there's a 20GB variant. A 28GB variant and a 32 GB variant?,Neutral
Intel,Optane was practically **built** for the type of AI workloads that they're shoveling money at.  If Intel didn't give up literally only a matter of months before GPT released and the bubble began in earnest lol,Neutral
Intel,"If Intel stayed in memory business, it would be long dead in the 80s and killed by Japanese memory companies. CPU remains the top niche area with less competition and deeper moat. See how China has quickly come up with their GPU designs? Well it will take at least another decade for them to make 2nm CPUs",Neutral
Intel,"are people high or something? intel was losing money on optane and their SSD business became irrelevant the minute regular memory manufacturers slammed the market. don't get me wrong, they were some of the most durable on the market, but they were no where near printing money on the memory business.  optane may have survived if their nodes were on schedule, keeping CXL support on schedule, but not because it was profitable.",Negative
Intel,CXL killed octane itâ€™s that simple. No one wanted to be locked to just Intel. CXL was and is just better,Positive
Intel,"I feel like the price has to be more than competitive. If they can undercut competition cards of the same performance by 100 or so (or maybe offer rebates or freebies) they could potentially steal the market in that category. With Nvidia and amd cards being tried and true for many many years, I feel like their marketing needs to grab the attention of consumers in a somewhat drastic way.",Neutral
Intel,If the b770 is 5060ti levels even â‚¬500 is competitive,Neutral
Intel,Yeah sure it wouldâ€™ve been perfect but CXL killed octane and offers pretty much everything it did while not being loved to just Intel lol,Positive
Intel,"it's not like any of this AI garbage right now is profitable for anyone except nvidia and the hardware companies anyway, it's not stopping everyone from shoveling money into it",Negative
Intel,"Hi everyone if I'm upgrading my Dell vostro 3670 i5 8400 @32gb ram to an i7 9700, would I be able to upgrade the RAM it's still being ddr4? To 64 or 128?",Neutral
Intel,"Hi there I have an xps 15 9530 laptop with two gpus: one is an arc a370m and the other is an iris xe graphics and in the Intel system it says I can use rebar, but I've tried and searched everywhere in the BIOS and followed countless guides and can't seem to find the setting. Can someone help me with enabling it please. I've searched the bios and done everything and can't seem to find it",Neutral
Intel,"With the crazy RAM prices, I'm looking to move to a 13600K or 14600K to keep using the 64GB of DDR4 from my ancient 7700K build. Do we users generally consider Vmin Shift Instability to be fixed at this point through the series of BIOS and microcode updates?  Related: Should I expect something in the range of a 10% performance drop from any of the reputable reviews, due to the fixes? Also, are efficiency-cores pretty much working as intended at this point, or is thread scheduling still a concern on them where your high performance thread ends up on an e-core?  Thanks all!  Note: This question is not for Intel\_Support. The answer from your side would obviously be ""Yes!"". :)",Neutral
Intel,Is Tiber cloud gone forever?  https://console.cloud.intel.com/ just gives a DNS error now.,Negative
Intel,"I have installed new Intel Wi-Fi 6 AX210.NGWG.NV in my ASUS laptop, bcz the old one died and couldnt connect to bluetooth since, WIFI works perfectly fine tho, so i dont know if problem is with drivers or not. Also i would just instal them from Intel, but i live in russia and i dont know any trustworthy sites, so if anybody knows, i would be really gratefull",Neutral
Intel,"How do I know the legitimacy of an Intel wifi card, model AX210? I've been searching for it in Amazon and most are manufactured in Vietnam and China, with varying prices.",Neutral
Intel,"I keep seeing mentions of TPM in our system requirements and I'm honestly a bit lost on what it actually does for our security, so who is the best person in the org to chat with to get the full rundown?",Neutral
Intel,"i've got an i7-14700kf on an asus rog strix b760-a with a corsair h100i elite capellix xt (240mm aio) and when i run after effects my cpu temps shoot up to 90 degrees, it probably wouldve gotten higher but i closed it cause it felt too high for what i was doing, i'm looking to undervolt my cpu but i dont know anything about it. i just want something safe and simple (im not looking for an extreme undervolt, just one that would lower my temps & possibly keep the same performance)",Negative
Intel,"u/Chelostyles Thank you for your inquiry regarding the CPU and RAM upgrade for your Dell Vostro 3670. As much as I'd like to provide my technical insights on this upgrade path, I'm not in a position to provide specific suggestions since this involves hardware modifications to an OEM system.  For the best compatibility outcome and to ensure optimal system performance, I strongly recommend reaching out to your system manufacturer directly. They can provide definitive guidance on supported CPU upgrades (i5-8400 to i7-9700) and maximum RAM configurations for your specific model. We don't want to inadvertently bypass any warranty terms and conditions on your system by providing modification recommendations that might affect your coverage.  Your system manufacturer's technical support team will have access to the exact specifications, BIOS compatibility matrices, and supported hardware configurations for your Vostro 3670 model. They can confirm whether the motherboard supports the i7-9700, the maximum RAM capacity (64GB vs 128GB), and any potential limitations or requirements for these upgrades.  This approach ensures you get accurate, manufacturer-validated information while maintaining your system's warranty protection.",Neutral
Intel,"u/I_like_carsyay  XPS 15 9530 hardware does support Resizable BAR, which is why Intel's system detection shows it as available for both your Arc A370M and Iris Xe graphics. However, the system manufacturer has designed their BIOS interface to prioritize stability and user-friendliness, often managing advanced PCIe features like ReBAR automatically in the background rather than exposing manual configuration options. This approach ensures optimal system performance while reducing complexity for users. I recommend checking for the latest BIOS updates from your OEM's support site and contacting their technical support team, as they would have the most current information about how ReBAR is implemented on your specific model and whether any additional configuration steps are needed to fully utilize this feature.     I've posted an article below in case you haven't yet come across it:  **Helpful Resources:**  *  [What Is Resizable BAR and How Do I Enable It?](https://www.intel.com/content/www/us/en/support/articles/000090831/graphics.html)",Neutral
Intel,"u/QunatumLeader Hi, thanks for your interest!Â  You can find and apply for all of our jobs online atÂ [http://](http://jobs.intel.com/)[j](http://jobs.intel.com/)[obs.intel.com](http://jobs.intel.com/). We donâ€™t currently accept submissions via social.Â  Good luck!",Positive
Intel,"Late to this, but I'm a 13900K owner. I have not had any issues with stability since applying the BIOS update and haven't noticed any performance loss, so I think this is fine. I did not thoroughly benchmark before and after though, partially because of how high peak temperatures were before the update. I am using a Noctua NH-D15 and a contact frame to reduce CPU temperatures.  Up until a few days ago I would have said that thread scheduling isn't an issue, but then I played the game Maneater and it's basically unplayable unless you use launch options to force the game to only P-cores. There's the Intel ""Application Optimizer (APO)"" utility but it seems abandoned and you can't add your own games if Intel hasn't added a profile. I was a big proponent of E-cores but honestly it seems like a half-baked technology that Intel never put the effort in to support properly. That said I guess I could just entirely disable them if I cared so much, but that's a non-trivial amount of performance to just give up.",Neutral
Intel,Hi u/ConspiracyPhD **Post**Â a question onÂ [IntelÂ® Tiber Developer Cloud Community](https://community.intel.com/t5/Intel-Developer-Cloud/bd-p/developer-cloud)Â forum for further investigation.,Neutral
Intel,"u/Far-Common2207 In this case, we suggest buying the wireless module from authorized Distributors to mitigate the legit concerns. Other than that, the OEM module warranty is not covered by Intel. For more details, you need to work with the Distributor or place of purchase for support to further verify if the wireless card is legitimate.  Check this article: [Where to find the Serial Number for IntelÂ® Wireless Cards](https://www.intel.com/content/www/us/en/support/articles/000092302/wireless.html)",Neutral
Intel,"[**Plenty-Solution-3692**](https://www.reddit.com/user/Plenty-Solution-3692/)**, TPM (Trusted Platform Module)** is builtâ€‘in security hardware that helps protect important data on your PC using encryption**. Intel PTT** is Intelâ€™s TPM that lives in the system firmware instead of being a separate chip, but it works the same way. Most PCs from the last few years already have TPM 2.0, sometimes it just needs to be turned on in the system settings. . If youâ€™re not sure how to do that, your motherboard or PC manufacturer should be able to help.  You can check this article for more information: [What Is Trusted Platform Model (TPM) and Its Relation to IntelÂ® Platform Trust Technology (IntelÂ® Pâ€¦](https://www.intel.com/content/www/us/en/support/articles/000094205/processors/intel-core-processors.html)",Neutral
Intel,"Individual\_War\_129, we do not provide typical temperature operating ranges for each processor or each core, as it can vary based on the system design and workload. Processors have internal protections to prevent against excessive temperatures. Operating ranges below the protection points are highly dependent on system configuration and workload.  In case you haven't come across it yet, you may check the articles below:  [Information about Temperature for IntelÂ® Processors](https://www.intel.com/content/www/us/en/support/articles/000005597/processors.html)  [What Is Undervolt Protection and How Does It Affect Overclocking in IntelÂ® Extreme Tuning Utility (â€¦](https://www.intel.com/content/www/us/en/support/articles/000094219/processors.html)  [Thermal Design Power (TDP) in IntelÂ® Processors](https://www.intel.com/content/www/us/en/support/articles/000055611/processors.html)",Neutral
Intel,Forum doesn't exist or access denied.  I guess Tiber is just gone now.,Negative
Intel,Do you know any authorized distributors here in the Philippines?,Neutral
Intel,"I see, all good thanks for your support!",Positive
Intel,u/ConspiracyPhD I just checked the forum and it looks like itâ€™s up and running. Could you try accessing it again using your Intel account?  [IntelÂ® Tiber Developer Cloud - Intel Community](https://community.intel.com/t5/Intel-Tiber-Developer-Cloud/bd-p/developer-cloud)  [](javascript:void(0);),Neutral
Intel,"u/Far-Common2207 According to the directory, these are the distributors in the Philippines. [Distributor Partners](https://www.intel.com/content/www/us/en/partner/showcase/partner-directory/distributor.html#sort=relevancy&f:@sfdisticountry_en=[Philippine,Philippines,Phillippines])",Neutral
Intel,"Nope.  https://imgur.com/a/tYRhYoV  Access denied and a nice ""This content is no longer available.""  Guess it's a completely dead project and should be removed from Intel's website.  http://console.cloud.intel.com/ is not accessible.",Negative
Intel,"u/ConspiracyPhD Please check your inbox, Iâ€™ve sent you a personal message. Iâ€™ve already coordinated your concern with the respective team, and as per their instructions, youâ€™ll need to email them directly.  [](javascript:void(0);)",Neutral
Intel,"> With up to 192GB of VRAM across eight GPUs in a single system, Battlematrix positions itself as a relatively cost-effective alternative to other professional GPU ecosystems for AI inference workloads.",Positive
Intel,Hope they do some image and video generation benchmarking as well. Nice to see someone testing AI rigs out there.,Positive
Intel,Wish theyâ€™d give prompt processing speeds. AI coding generates very few tokens compared to input. Nvidia seem to dominate here.,Neutral
Intel,"How many concurrent users will this serve, 30 devs would be nice",Neutral
Intel,:),Neutral
Intel,"These 12Xe3 cores are pretty neat, and because it fits in a normal socket it isn't ludicrously expensive to make.  I suspect we'll see a ton of these different form factors for this chipset.",Positive
Intel,Mac Pro Trashcan 2.0 is crazy,Negative
Intel,"> These 12Xe3 cores are pretty neat  have there been any leaked benchmarks or gaming FPS?  on paper they look good, but... some synthetic benchmarks suck",Positive
Intel,No one knows. Synthetics seem to put it roughly at a 3050m.,Neutral
Intel,"3050 to 3050ti mobile if leaks are to be believed. Could get a bit better than that if software is still not mature, so I'm calling a max of 3060M performance.",Neutral
Intel,"The fact 890M is that much faster than 140V shows this benchmark is terrible anyway. In real gaming performance, 140V performs very close to 890M and does so at usually superior efficiency.",Negative
Intel,Is panther lake on the intel process considered better perf than lunar lake on tsmc process? Or is it lateral,Neutral
Intel,I hope it comes to desktop CPUs,Positive
Intel,Almost 7600m performance ie stream machine. From a igpu . Hoping a handheld with this igpu under 1000usd,Positive
Intel,"yeah it says   ""We should also make it clear that these benchmarks seem to undermine the performance of Intel's Xe2 architecture. The Arc 140V is shown much slower than the Radeon 890M, but in reality, it ends up close to or faster in actual games. So it looks like this benchmark suite is not optimized for older Arc GPUs, but the new Arc Xe3 architecture is doing well, and we can see further improvement once the finalized drivers roll out.""",Negative
Intel,Yeah this headline doesn't add up based on my own testing,Negative
Intel,Yeah that's a strange result. Makes me think the 16% will be for PL improvement over LL.,Negative
Intel,"So imagine how much faster it is in actual practice.  These iGPUs Intel are putting out are great, it's a good time for lower-power handhelds!  And insane power handhelds too, with Strix Halo getting in them, the Ryzen 388 (8c16t with 40CU iGPU) allegedly coming, and I'm sure Intel is working on an answer to Strix Halo which if it uses this kind of uArch, will probably be deadly.  Good friggin times.",Positive
Intel,concur  some benchmarks are biased,Negative
Intel,lateral,Neutral
Intel,If itâ€™s just â€œ16% faster than 890mâ€ itâ€™s nowhere close to 7600m. You have to be over twice as fast as the 890m.,Negative
Intel,"Isn't 140T also faster than 140V in benchmarks, despite being Xe+?",Neutral
Intel,"Yeah the 388 makes a lot of sense, a worthy sacrifice of a cpu tile for cheaper more efficient gaming cpu.",Positive
Intel,Answer to strix halo was the partnership with nvidia,Neutral
Intel,Did is you see the link? Passmark graphics score? 10999 for 7600m and 9500 for b390.,Neutral
Intel,"since the 140T has 20 watts for the GPU itself, how can it be otherwise?",Neutral
Intel,"I feel like the partnership was an answer to a much broader question concerning both companies, none of it really being an implicit answer to Strix Halo beyond a vague promise to develop custom chips with Intel cores and RTX cores fuse together using nvlink.     I mean, if they actually launch something, cool. But as of now, we don't really have any information that directly points to a competing product.Â      In fact, I might be crazy but I feel like it is more likely that the actual answer to Strix Halo will be all Intel silicon, because Nvidia is very horny for all things ai and all things datacenter.",Neutral
Intel,"I mean no offense, but Passmark is irrelevant.Â  Even comparing the 890m to the 7600m (non-xt), the 7600m is usually twice as fast, with dips down to ~60% faster, and lifts up to ~170% faster.     NoteBookCheck has an extremely robust dataset of benchmarks in games for both the 890m and the 7600m (non-xt) at various resolutions, and they show not only a clear winner, but a very large difference in the performance of these devices.      Now I'm not trashing what the B390 will be, because we need an iGPU fight here.Â  But thinking that the 7600m (non-xt) is only ~15.7% faster than the B390 ((new-old)/old gives percent change) because of Passmark is erroneous.",Neutral
Intel,">I feel like the partnership was an answer to a much broader question concerning both companies, none of it really being an implicit answer to Strix Halo beyond a vague promise to develop custom chips with Intel cores and RTX cores fuse together using nvlink.  They explicitly talk about a client product that will have Intel cores and Nvidia iGPU tiles. It's not especially vague.   >In fact, I might be crazy but I feel like it is more likely that the actual answer to Strix Halo will be all Intel silicon, because Nvidia is very horny for all things ai and all things datacenter.  Despite that, Nvidia has already provided a custom iGPU tile for their Mediatek + Nvidia iGPU solution.   They have both the resources and financial incentive to do this. Plus, this should be better than any all intel silicon solution anyway.",Neutral
Intel,Yup and Jensen himself said the high powered SOCs is a $30 billion untapped market,Neutral
Intel,"I guess we'll see more when we get actual info about the potential devices.Â  Right now, I haven't read about a device coming to market.",Neutral
Intel,"should have a 3y warranty on it. submit an RMA ticket  regarding the actual query though, the silicon is the same the 14900ks is just a slightly better bin. you wouldn't notice the difference at stock let alone normalized for energy consumption",Neutral
Intel,"I have i9 14900ks, what I did is that I reset bios settings to optimized defaults and then I limit pl1 and pl2 to 150w and enabled XMP, these are the only two settings i changed, the rest is default, and temperatures are in check, i still get the same performance, and itâ€™s very efficient in gaming that way, the extra heat and power consumption of 253 or 320 are not worth it, I recommend just get the ks and make these two changes and forget it.",Neutral
Intel,The performance difference will be tiny and definitely not noticeable with a 3090. Go for the cheaper chip.,Neutral
Intel,"Get the KS for better silicon quality only limit power , set pl1/2 253w and set it to 350 or 325A, definitely want the better 14900ks silicon quality itâ€™s overall better and better IMC as well. Itâ€™s a better bin and typically only the best 14900k will run stable 6.2ghz and at lower voltages even if you limit your chip to 6ghz",Positive
Intel,"A 14900KS is nothing more then a binned 14900K. Running a 320W/400A extreme setting is not advisable with a AIO. I run my 14900KS on custom loop with 320W/307A performance setting and it does not thermal throttle at all. If you get lucky, you could get a 14900K that can run KS settings. Performance in that case is( should be) identical. Without benchmarks i can't really tell the difference between 125/253/307 and 320/320/400 except the heating of my room.",Negative
Intel,"As an update - I went ahead with the 14900ks and also changed my cooler to a 420mm AIO.   Ensured latest bios update then set Intel presets (performance) but also went ahead and reduced PL to 150w, set temp limits to 70c, system agent voltage to 1.12, 307A, and I was blown away by the temps!! I am getting basically identical performance (+ few fps) to my previous 13900ks, but a whole whopping 30Â°c cooler in game!!! I would average 80-85, now itâ€™s sitting super chill with same in-game settings on BF6 & ARC at 50-60c.   Thank you everyone for your inputs, I sincerely appreciate it and Iâ€™m extremely happy with the outcome!",Positive
Intel,I also PL1/2 at 150. My temps stay under 60c when gaming.,Neutral
Intel,"if the cooling wasn't sufficient disable HT(useless for gaming) and undervolt it this lower CPU temperature by 20c, in games the CPU temperature should be around 65c.",Neutral
Intel,Im using a duel air tower for my 14900k game temps are at 60 to 70,Neutral
Intel,"14900KS is just a better binned 14900K. All things equal, you should have lower temps/voltage/power draw for the same exact workload/clocks on a 14900ks vs a 14900k. How big of a delta between the two comes down to how well you struck the silicon lottery with the KS.",Neutral
Intel,"I have the K version only because of the onboard gpu. In case my GPU gives issues and I'll still be able to boot. But otherwise there is almost no performance gain. I ran my i9-14900k pl on 320 watt and did a cinebench benchmark, temps were ok: average 94c, max 98c with a 360 aio.  That said, go for the cheaper version if you don't need onboard gpu.  Edit: I have my pl on 253w now. No need to go any higher.",Neutral
Intel,5 years warranty on 13 and 14gens now.    I have the 13900ks. Run it at 253w. Clock locked at 5.5ghz. Temp 80c and cinebench 23 39k,Neutral
Intel,Why not keep pl2 at 253 and 1 at 150/185 ? Did you try undervolting? Most of them can take 50mv offset with 75 /85 needing a bit more stability testing. Can also cap the vr limit and iccmax. I feel like going 150 pl2 makes you miss some performance in games unless you had thermal issues and doing it to keep it from thermal throttle.,Neutral
Intel,"Thank you for the feedback. Forgive me for the dumb question; if I ran either a 14900ks or a 14900k at these settings, would they both have the same temps? Or would the KS still run hotter?",Neutral
Intel,"Dropped the voltage further down by -0.10000 and now Iâ€™m getting 58Â°c core temp and max 65Â°c package temp under load. Really happy with this, and with some tweaks to my in-game video settings Iâ€™m able to still maintain a framerate that matches my screen refresh rate.",Positive
Intel,This post is about the K and KS. Both have the same iGPU,Neutral
Intel,even better. i take it they extended tbe warranty period for those products?,Positive
Intel,For 5.5 39k in CB23 is a little low,Neutral
Intel,"I have tried and tested all my games, i saw absolutely no difference between 253w, 150w, 125w or even 100w, the fps were exactly the same, the only difference was in temperatures, performance wise i saw no difference between any of them, i was using 100w before but then I switched to 150w because I thought it was too low, even though the performance is still the same as 100w, just higher temperatures, my cooler is pretty good kraken elite 360, it never goes above 80 even on 253w but I just like to keep temperatures between 50-70 while gaming.",Neutral
Intel,"Yeah your method is better, itâ€™s what I do.",Positive
Intel,"Oh shit, I thought only the K had an igpu! Should have gone for the ks version lmao",Negative
Intel,Yes because of the degrading issue.,Negative
Intel,Lol stock is 5.8ghz lol and most stock after the update get 35k,Neutral
Intel,All core cinebench is not 5.8... I get 39k stock what are you talking about lol,Negative
Intel,"That is a little on the lower end, my 12900K gets 30K. Also in single core a little below 285K, multicore just below 9900X, top of 13700K. Back to it :)",Positive
Intel,Search on reddit on 13900-14900k.  After the code update stock most 13-14k can barely do 35k. Dont like to your ego brother.   So millions on reddit are getting those score and you are the special bin whose getting a higher score.   Mr 1 post and 7 comment history lollllllllllllllllllll,Negative
Intel,LOLOLOLOLOLOL HAHAHAAHAHAHAH ARE YOU DUMB? This really shows you don't have a 13900k or 14900k,Negative
Intel,"My guy what are you talking about? 5.5 ghz for 39k is a good score on 13900k. My 14900KS completely stock does 41.5k and downclocks to about 5.5-5.6 ghz with hyperthreading on. If he's got HT off, his score is even better.   You have to be rage baiting.",Neutral
Intel,Talk to him not me... The guy said 35k is the score ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚,Neutral
AMD,"Its not perfect   ""The test shows visible artifacts, and 3x multi-frame generation can look worse than expected in motion. You can get similar trade-offs with other third-party tools""",Negative
AMD,"Horrible artifacting at 4X, frame pacing issues and unnecessary high lattency at 3x, making only 2x viable, at this point why install it even?   No disrespect to the makers of the mod, I respect your work, time and effort, but for me it doesn't make sense to use.",Negative
AMD,man i hate when people mod in a Kinda working feature and instantly its claimed that they do what amd wont. Brother fsr dll swaps and multi frame gen are possible but if amd released them in the state that these mod are they would get dumbstered. They get shit on for way less.,Negative
AMD,Did AMD fix the broken VRR FSR redstone FG release?,Neutral
AMD,"Is this the AI driven frame generation, in Redstone? Or the the FSR3",Neutral
AMD,This is INT8 FSR4 presumably?,Neutral
AMD,"Hmm, will have to investigate, but hopefully this help with some of the frame pacing issues certain games were reportedly having using FSR FG.",Neutral
AMD,"Hello NeroClaudius199907! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
AMD,lol There was no â€œbeatingâ€ anyone here.   AMD did it and discovered it to be poopoo on 7000 seriesâ€™s and didnâ€™t release it.   Modders did it and also discovered its poopoo on 7000 series and released anyways because why not?   Now imagine if AMD released it in this state and called it a â€œreleaseâ€ product? Itâ€™s not even good enough yet to be added an optional feature by AMD.,Negative
AMD,"There may a limited point in doubling the frame rate, using whatever tech, but more than that is just a fucking stupid idea, and it's really bad, even on the RTX 50 series. Fake Frames are not the future.",Negative
AMD,"I always have a lot of respect for these kinds of third party projects. They have far fewer resources and less time to dedicate than AMD/Nvidia, but they often do make a lot of people happy during the interim before official releases",Positive
AMD,"Yeah but if it can be done by modders it can be done better by AMD """"soon""""",Positive
AMD,"Might be a good 2x FG solution for certain DX12 games that lack it (RDR2, KCD2)",Neutral
AMD,"AMD even got (kind of rightful) flak for their FSR once released, when it wasn't to everyone's liking anyway â€¦",Negative
AMD,You are 100% right and unfortunately what you mentioned is 90% of the comments around. And the person liking the mod most likely is the same person that would complain (correctly) if AMD launched a broken feature,Negative
AMD,"But they do what AMD wont, because they are competing with official developer too lazy to actually release a feature at all.",Negative
AMD,"No, that's probably higher in priority than them bringing more forms of frame gen to other cards.",Neutral
AMD,Not AI driven FG. Just slightly better lossless scaling.,Neutral
AMD,Its try it for yourself. 1 min install,Neutral
AMD,doubling framerate is great when i have a base 80 fps and framegen it for my 144 hz monitor. Its only bad if your base framerate is low.,Positive
AMD,Dont use it then,Negative
AMD,I think thats underselling it because quite often you end up with third party tools being the only option as the interim quickly becomes never official release.,Negative
AMD,> I always have a lot of respect for these kinds of third party projects.  â¤ï¸,Positive
AMD,"Yeah, about that â€¦ We all usually do â€” *Commercial thieves not so much*.  It's always fine, when guys doing such things out of fun and pure dedication in their spare time, yet \*never\* being rewarded for it, when it gets used commercially by big MegaCorpses afterwards â€¦  There have been countless instances, where corporations blatantly stole open-source stuff, and always got away with it afterwards, reaping the very fruits of some guy's tedious months and years of spare-time labour â€¦  ---- I mean, remember when Nvidia back then stole the code of open-source *SweetFX*/ReShade shader-techniques, integrating it literally 1:1 (with the open-source modders' verbatim comments included in official nVidia-drivers), then tout it as a graphics-revolution *of their own making* as their high-praised **Nvidia&nbsp;Ansel**, only to then blatantly lie about it being stolen to begin with afterwards when it came to light?",Negative
AMD,"it wasnt done by modders... if it is broken, it means nothing. you can have cyberpunk on win 98, but will never not throw an error.",Negative
AMD,XeSS DP4A FG is already there for RDNA3 users.  If framepacing issue in Redstone is not fixed it might even be better.,Positive
AMD,Whatâ€™s the best option for 7900xtx and ue5 games?,Neutral
AMD,"Dude, no, you can shit out a broken feature as a mod no problem, nobody expects anything from you. If you release the feature as AMD, Intel, Nvidia, Google, Apple and who ever else you need to have outreach teams, support teams, maintenance, marketing and implementation support teams at the ready. If you fuck up at any of these things people will hear about it and it will make you look like a fool.",Negative
AMD,"not everything is doable. even if modders did it, the fact that it is broken, shows that it may not be possible in the first place. forcing smth to run, but broken, doesnt help anyone",Negative
AMD,"It is based on XeFG I believe (since it requires you to have XeSS dlls). Which is AI driven, but it can't use specialized hardware on NVIDIA cards and relies on the CUDA cores instead (with DP4a)  Even the non-AI FSR3 is leagues above lossless scaling, because it has access to temporal information.",Neutral
AMD,Lol how unhelpful,Negative
AMD,"XeFG has the same frame pacing issues as fsr fg - that is, with either, you should enable vsync and / or set an fps limiter depending on the game. XeFG with XeLL works really well in cyberpunk, but it looked and felt awful until I forced vsync on to both smooth out frame pacing and keep it under 240 fps to prevent tearing. Basically identical to FSR fg ml.",Negative
AMD,DP4A FG is picking the worst option of the ones available.,Negative
AMD,"Margin of error improvements...seems like a pointless release, the $30 price premium presumably reflects this.",Negative
AMD,tl;dr  +1-2% stock   +2-4% PBO  [worse than expected](https://old.reddit.com/r/hardware/comments/1qi35je/machines_more_9850x3d_vs_9800x3d_whats_in_400_mhz/o0oe2co/),Negative
AMD,11% extra $$$ for ONE % extra performance on average (2.5% best case) ?\ F*#k that.,Negative
AMD,"Finally, I will be able to play Stalker 2 at 103.6 fps instead of 103.1.",Positive
AMD,"Lmao. So hertz. Much improvements. Wow  Still, I'm not against these special editions, like the 9900KS, 8086K. It's nice for collectors and see how far the tech can go, even if it doesn't make much sense.",Positive
AMD,AMD in its 14nm+++ era,Neutral
AMD,The heck is wrong with AMD lately??? This....rdna++++++.... gorgon point....,Negative
AMD,Doesn't hurt. Personally if I was buying a new top end PC I'd want more than 8c/16t though. The 7950X3D and 9950X3D are the best of both worlds.,Positive
AMD,"AMD Ryzen R7 9850X3DMILK, because AMD wanted to reset their 14 months old CPU MSRP. So now you pay 499$ for 1-2% more than 9800X3D and 9800X3D will probably stop production and slowly vanishes from stores.",Negative
AMD,"More power draw, hotter temps, 4 percent increase in performance. Welcome back 14900ks.",Positive
AMD,"I will be interested to see how these dies undervolt, mind.",Neutral
AMD,"id be much more interested in a 12/24 x3d chip vs a better binned 8/16, which is all i really see this as",Neutral
AMD,Seems like a pointless product with such a small uplift in performance.,Negative
AMD,"That's not a new CPU, that's an overclock.  My r7 7700 also gets a 3-5% boost in certain games while overclocked (more in synthetic benchmarks or multi threaded workloads).",Neutral
AMD,"9850x3d?  Itâ€™s a pass for me, Bob.",Neutral
AMD,"This got to be AMD's Skylake - Kaby Lake moment, no wonder why even AMD themselves was so bored and not excited at all when they revealed it on their AI focused CES 2026 lol. I really hope that Zen 6 is much better than Zen 5, and offers new higher per tier core counts and provides decent ipc uplift over Zen 4 - Zen 5,   if it doesn't then AMD truly has lost it, and i can clearly see Intel will retake their throne soon, especially with how promising panther lake is looking on the laptop side.",Positive
AMD,"When comparing average gaming performance to gaming power consumption: \~2% more FPS for \~28% more power, so about \~20% worse efficiency.   Keep in mind, this is an average, actual gains and power use vary by game so some titles may show bigger or smaller differences, but you get the idea of how minimal the gain is relative to the efficiency penalty.",Negative
AMD,I do wonder how many people would purchase this over 9800X3D simply due to latterâ€™s failure concern on Asrock/Asus mobos,Neutral
AMD,Draws way more power and with increased thermals so you can barely see a difference playing at 1080p medium settings on a freaking 5090 ???? must be an AMD joke.,Negative
AMD,"Seems like they did this just to have something, so people cant say that they did nothing",Negative
AMD,"yeah fr, not seeing the value for such a small bump. marketing move maybe...",Negative
AMD,"Yeah, Zen 6 needs that new effing IO die.",Negative
AMD,kinda disappointing tbh was expecting more from the x3d tech hope next gen's better,Negative
AMD,">11% extra $$$ for ONE % extra performance on average (2.5% best case) ?\ F*#k that.   If a PC with 9800x3d cost $2000 and a PC with 9850x3d cost $2030, it would be 1.5% extra $$$ for the 1-4% performance increase",Negative
AMD,"This is going to sell like hot buns.  No wait, they need some software with this, ideally one that adds barely no difference with the previous version but change the letters for tuning presets.",Negative
AMD,You don't have to buy it.,Neutral
AMD,"I wish they actually made the i3 7360X. Stupid? Yes, but Kaby Lake X was stupid and it would have been cool for overclocking or benchmark records.",Negative
AMD,"Nothing is wrong with AMD. It's just this sub that is extremely anti-AMD.   If it was Intel releasing another KS product, it would be greeted more positively.",Negative
AMD,"Intel's going to do their down desktop refresh in a few week/months as well, and not just one new SKU. And everyone knows Zen 6 is coming some time this year.",Neutral
AMD,"You do take a hit on gaming performance since those each only have 3D Vcache on 1 CCD. If gaming is your top prio, then 9800x3D is still king (or at least a much better deal)  But with 9950x3D2 coming, that will probably be the new GOAT CPU",Neutral
AMD,"More point to it than Intel's KS series, but yeah.",Neutral
AMD,not to mention it draws a lot more power and it runs hotter compared to the 9800X3D just to gain a few percent increase in performance at 1080p,Positive
AMD,I doubt the 9850X3D is different enough to avoid the problems unless AMD has been selling 9800X3Ds so poorly binned they fail,Negative
AMD,"There is a point there, since the rate is strongly biased toward certain batches. It may well be free of a manufacturing failure, possibly even unintentionally.",Neutral
AMD,To be fair 9800x3d dies also on MSI and Gigabyte boards.,Negative
AMD,"Yup, both this and the mobile lineup which is at most +100mhz. Just to say there is something at all at ces.",Neutral
AMD,AMD needs to deliver at faster pace... They're too damn slow.,Negative
AMD,"It's a +400mhz, I would've been surprised if it's actually more. Heck, you can try overclocking your own CPU, any CPU, by 7-8% higher clocks and you'd probably see similar uplift.",Neutral
AMD,"Why stop there ? You also need a monitor, keyboard, mouse, chair and table, headphones, even room/flat/house to have this all in.  Within a whole value of in tens or huindreds of thousand $$, $50 extra is not even a spit in a bucket.",Neutral
AMD,"It's always interesting to see how Intel tried to wipe KBL-X from history (I remember the Threadripper panic, the Linus roast video, the updates removing support...) but overclockers didn't let it happen. Harvested desktop die on a HEDT platform was certainly something.",Negative
AMD,"KS SKUs are routinely clowned on, what are you on about?",Negative
AMD,"Pretty small. My 7950X3D was cheaper than a 9800X3D and I'd take it any day for the way better multithreaded performance. Even if your use case is just 'gaming', the extra cores help with any background tasks there as well as making a massive difference to things like installing/compressing/decompressing/compiling shaders/etc that are part of running/modding games and supporting applications.",Positive
AMD,Itâ€™s the exact same thing.,Negative
AMD,Theyâ€™re very fast and delivering yearly upgrades on leading nodesâ€¦â€¦â€¦â€¦in data centre gpus,Positive
AMD,"Yes, I agree that I used a conservative number, and the value gets better the more other costs you add. I am glad that you agree with me",Positive
AMD,"Not really, 7950x3d is still way worse than 9800x3d in gaming even if you count background tasks. You've made a bad choice and now just try to justify it.",Negative
AMD,KS series have ridiculous prices,Negative
AMD,"The original point I was going for was just that if you're getting a brand new high end CPU, it's probably overkill anyway unless you have a 5090, and to me being overkill in multi threaded stuff is more interesting than being overkill in games.  I was talking generically in that situation, arguing even for people that do primarily just play games being overkill in multithread is more fun than being overkill in single thread.  For me *personally* the choice was very easy because I don't play competitive games at all and have a 4K/120hz monitor and DO do a lot of workstation-y stuff like hosting servers in the background, seeding torrents, running VMs, etc.",Neutral
AMD,"I play at 4K/120hz even my 5900x was fine, I am happy with my choice.",Positive
AMD,To be fair 5900x was also weak compared to 5800x3d.,Negative
AMD,"Haha, true.",Positive
AMD,The ram cost more than the high end CPU,Negative
AMD,"Interesting, I was incidentally telling my brother, whose rig I just built using DDR5-4800 spares to avoid the current RAMageddon, that in gaming they performed just the same. These tests confirm that it's just about the extra 0.X%, I don't remember it being this clear-cut for previous generations.",Neutral
AMD,Love how they used all the irrelevant presets on Cyberpunk except the bandwidth intensive ones ðŸ¤£,Positive
AMD,The RawTherapee benchmarks are nice to see.,Positive
AMD,"The conclusion that is mostly the same, is not true for all the games  tarkov for example changes a lot, like a 10%  https://www.youtube.com/watch?v=gbfjfuE1ZRM  and hardwareunboxed had a video with the 7800x3d which works just the same as 9800, and there's huge difference, over 10% in some games between 6000cl30 and 5200cl40  https://www.youtube.com/watch?v=aD-4ScpDSo8  Memories with low latency have better 0.1 and framepacing in a lot of games. There's a reason why before the rampocalipse, people started using on top tier gaming pcs the new cl26 kits. It outperformed everything on am5.",Neutral
AMD,I tested 9800X3D( vs 14900KS ) in CPU heavy games with RT on a 5090 4k Ultra Performance and got 10% improvement with RAM tuning from 6000C30 XMP to 8000C36 manual.   You can check my profile for the overclocking sub threads.,Positive
AMD,"I would be curious what the 1% lows are between the two. They didn't test that or at least didn't report on it.   Probably not much difference since it's an X3D chip, but my understanding is worse 1% lows, the worse the framerate will feel. More hitches/tears.",Negative
AMD,"What I hate about all the gazillions benchmarks done by reviewers and tech influencers about how important RAM speed is that they never test manually tweaked RAM, they only test EXPO/XMP, which is considerably slower than even loose but manually tweaked timings. So people get the impression that RAM speed doesnâ€™t matter because reviewers are comparing slow RAM with slow RAM. It seems like people also ignore that fast RAM smoothes out the frame pacing and can be the difference between a stutter-less experience and a stuttery mess even if the average frame rate stays the same. The linked test didnâ€™t even attempt to show the 0.1% lows, so itâ€™s worthless.   Buildzoid said a million times that gamers are unable to understand how RAM works and it always checks out.",Negative
AMD,"totally agree, unless you're doing something super demanding, an older pc can still handle most stuff just fine",Neutral
AMD,TL;DR: Doesn't matter. Take the 4800.,Neutral
AMD,"Ryzen AM5 CPUs are way cooler using DDR5 4800, even using DDR5 5200 at JEDEC speed and voltage is hotter than DDR5 4800.   This first generation of AM5 CPUs are better from a power and heat production point of view using DDR5 4800 at JEDEC speed and voltage.",Positive
AMD,If I sell my 64GB kit I could but 2 or 3 9800X3D.,Neutral
AMD,"The Linux advantage is that the system uses less than 1gb of ram on idle, unlike windows 5gb. So 16gb ram is enough for most people.",Positive
AMD,It's just the 9000X3D series has so much L3 cache that what's needed NOW for a frame to be computed can be accessed in L3 like that.,Neutral
AMD,Pretty sure it was the same for the 7800X3D,Neutral
AMD,For non x3d chips difference is slightly bigger,Neutral
AMD,"From personal experience I've only ever seen a major uplift upgrading from DDR3 to DDR4 (observed in OW 1), which seemed to give me about a 10% uplift. I've upgraded to RAM with a higher clock speed afterward and didn't really notice much- it doesn't seem like the juice is worth the squeeze at a certain point.",Neutral
AMD,"Idk. I have seen serious in depth tests by overclockers, and it seems, 6400 1:1 is the sweet spot. The caveat is, it only makes a serious difference when it's running FPS unlocked and the CPU is near 100%, then the fps gains are very much worthy, like from 120 to 160 and low 1% get better as well. The thing about ram overclocking is that you only really see real gains when the CPU is near max, since the 3XD cache gets full and needs to access memory more (like the other comments clarified).     I like tinkering a little (not an overclocker) and since ram was cheap back then (lol) I got a 6400 kit and run at 1:1. Took time and testing, but I had fun, I guess :P     I think for the most part, the fun part was learning. Now I know a lot more about ram and their settings. However, if I was time constrained and had less patience, I would just run 6000mhz and the lowest CAS I could find at an affordable range.    I play on 4k, doing 6400 1:1 probably didn't even get any fps gains, was just the fun of tinkering and getting my PC to be as good as possible    I avoided Infinity Fabric overclocking and going too low at the secondaries and tertiaries. Plus I ran the SOC at 1.3. The amount of extra time testing everything would take too much time.",Neutral
AMD,"IIRC back in the DDR3 days, as long as you are on at least 1600, you were good, anything above like 1866 and 2133 were deemed waste of money. 1600 was the vast vast majority of ddr3 around the time of intel 3rd/4th gen, they were cheap and very available. I think it was only after the release of Zen1, people started to put more focus on ram, because Zen really benefits from it due to fclk, on 6th gen intel, which was also ddr4, people just bought whatever is the cheapest.",Neutral
AMD,This is more related to the X3D more than anything.,Neutral
AMD,There are heavy multiplayer scenarios that overload the 3D VCACHE and have to fallback on memory. Marvel rivals time square is a perfect example of this. Or bf6 with a really big fight.,Neutral
AMD,">https://www.youtube.com/watch?v=aD-4ScpDSo8&t=731s  > You really shouldn't be building a zen4 based system without using ddr5 6000 CL30 memory, as a 32GB kit costs as little as $85   https://imgur.com/a/eRlwlkr",Negative
AMD,It's not so simple though. Most people set a memory profile because it's easy and just works most the time. Manually tweaking RAM is a time consuming process and can have consequences such as corrupt files. The time for that and the risk involved isn't on most peoples table.,Negative
AMD,"> they never test manually tweaked RAM  because diminishingly small number of people manually tweak RAM. Like, so small they are not worth mentioning as an option.",Negative
AMD,Ain't nobody got time for that and the amount of people that will unknowingly insert instabilities because they don't know enough is just going to be too high.Â    Reviewers aren't going to review something that an exceedingly small portion of the audience will do. Especially one that is so unrepeatable.,Negative
AMD,> 2 or 3 9800X3D  If only there were X3D models with 2-3 times the extra cache of the existing X3D CPUs. Now that would be a proper refresh.,Neutral
AMD,"And then all the software is using some kind of web wrapper (forgot the name, but it's hated) and ends up using the same as Windows.  edit: Electron! thanks for the answers :)",Neutral
AMD,"Windows can and will free memory in case other programs need it. Okay, Linux uses less than 1 gb on idle, and? How exactly is it an advantage? What matters is how responsive the system is during actual workload that uses lots of RAM...",Neutral
AMD,"Maybe if you have a bloated Windows setup with loads of apps set to 'start on Windows launch' or something, but mine is only about 3GB for a normal idle state.  Used to be more like 2.4GB, but I guess over a dozen years on the same OS will cause some bloat to come in.  EDIT: I guess it's important to mention I'm still on W10.  I guess W11 might be different.",Neutral
AMD,Windows kernel uses 600 MB. everything else is optional.,Neutral
AMD,"Yeah no. 16GB is definitely not enough for most people, even with Linux being less of a memory hog.   Most distros definitely don't use less than 1GB when idle unless you remove a bunch of stuff and use very lightweight DEs like xfce or lxqt, and by default Linux is set to use swap whenever memory usage is greater than 60% - which needs a single line of config edit added to the grub bootloader to have it apply persistently.   This is not something your noob user will know about if they switched to Linux recently.",Negative
AMD,"Pepperidge Farm remembers when there were those who argued that throwing a sufficiently fast enough RAM kit (e.g. buy a DDR5-8400 or higher and manually tune it) at a non-X3D CPU could make it competitive against X3D CPUs in gaming.  Well the recent RAM pricing has changed that equation significantly.  EDIT: I'm not sure where to start with finding the post again, but years ago I have seen someone post about their DDR5 kit being run at 9,000 or 10,000 MHz with tight timings and that X3D CPUs were overrated. Turns out they went through multiple 14900Ks on a +$700 Apex motherboard (2-DIMM board specifically designed for RAM OCing) to obtain the result. And they were comparing it against a stock X3D. This was also before the Raptor Lake degradation became widely known.",Neutral
AMD,"It can actually be quite big with non-Vcache chips.  Depends on the specific kit of course, there's more to it than just the MT/s.  Generally the bigger problem with low MT/s kits is that they're some of the lowest quality DDR5 out there and will usually have poor latency as well for overall poor performance.  Like straight up, you can nerf your performance by a whole generation of CPU performance(10-15%) with poor RAM in certain cases.",Neutral
AMD,HUB did some videos proving pretty definitely that DDR5 is a worthwhile upgrade on DDR4 at this point.  It always takes a bit of time for the memory standard to mature and then performance gains become quite real.,Positive
AMD,DDR3 to DDR4 is twice the bandwidth (assuming same timings).,Neutral
AMD,"Even with Zen 2/3, it was still plenty to simply be on 3200Mhz, and anything more was for overclockers/tinkerers.  So not really that much different.    Just like with DDR5, usually 6000Mhz is considered a good sweetspot for affordability and performance.",Neutral
AMD,"None of what you said addresses anything I said, but okay.",Negative
AMD,Wrong.,Negative
AMD,Why do reviewers review the RTX 5090 when only a small portion of the audience will buy it?   Just assume youâ€™re stupid. Be honest.,Negative
AMD,Let's hope the L2 stack will give a hefty boost too.,Positive
AMD,"The word you're looking for is ""Electron"" but yes.",Neutral
AMD,electron?,Neutral
AMD,"I didn't do any official benchmarks, but my sister's old laptop with 4GB of RAM was extremely slow in Win10. After putting Lubuntu it was way faster using Chrome, and was able to open many tabs without slowing down. And that was even before I enabled zRam.",Neutral
AMD,"W11 is the same, it's just that some RAM is allocated and people not in the know see ""hey, 8GB of 32GB is used while idling Windows bad reeee"". It's like they don't want to use any of the RAM they bought.",Negative
AMD,"16gb is fine for most people.  I don't currently build or buy anything with less than 32, but 16 is still fine for gaming.",Positive
AMD,"> Yeah no. 16GB is definitely not enough for most people, even with Linux being less of a memory hog.  16GB is fine for 99%+ of people",Negative
AMD,"I can back you up on there being a group of people who made that argument. They werenâ€™t completely wrong, but ram tuning is pretty hardcore itâ€™s not like enabling pbo.",Neutral
AMD,The X3D cache operates at 2.5 TB/s and DDR5-8400 memory at 67 GB/s per channel.  So you would need DDR5-20000 in an 8 channel setup to match it. It simply is impossible and not even takes into account that much of the X3D performance comes from 10x reduced latency not bandwidth.,Negative
AMD,Friend you're missing a huge asterisks as that uplift is only precent in a very small select number of games.  That reddit is still clueless on RAM scaling baffles me when it's been a discussed topic for as long as I can remember.  I'm of the generation when you bought slower RAM because it was cheaper and OC'd it. Today people just drop hundreds extra for minimal gains on both their CPU and RAM while ignoring their GPUs and worst their PSUs.,Negative
AMD,I experimented on this myself with Overwatch and Rivals:  https://www.reddit.com/r/buildapc/comments/1lluich/14900kks_vs_99509800x3d_4090_vs_5090_some/,Neutral
AMD,"I tested 9800X3D vs 14900KS in 5 high CPU usage games with RT, and 14900KS w8400 RAM was faster overall. Started a firestorm in the overclocking sub where I posted it November.  RAM tuning on 9800X3D 8000C36 made it faster overall in averages, but 14900KS still leads in 1%.  14900KS is on Asrock Z790I Lightning, arguably the best memory OC motherboard for Intel 13/14 series and 9800X3D is on the 2DIMM Apex X870E",Neutral
AMD,"you can get most of the performance by just messing with timings a bit as long as you're not donig bandwidth constrained workloads, though like oyu said there's a higher chance of running into a chip that you can't push that much further even manually",Neutral
AMD,I managed to buy DDR3 right after DDR4 came out and upgraded to DDR4 right when DDR5 was rolling around. Hopefully I can get on the right side of the curve next time I upgrade,Positive
AMD,"Thanks, certainly sounds like something to trust over my anecdotal experience.",Positive
AMD,"I remember Zen2 and especially Zen3 people were pushing more for 3600MT, I don't remember witch gen, but it's the gen they started to let fclk to decouple with ram mhz by letting it run 1:2 or 1:1, and people find out the sweet spot was 3600 and stay 1:1.",Neutral
AMD,I mean my point is why do such a test and use it as an argument when it's not something most people can or even want to attempt.Â    I'd still like to see it of course don't get me wrong. Like OCing a CPU on custom loop or liquid nitrogen. Fun to push the limits but lets not pretend it is achievable by most users.,Neutral
AMD,"The amount of people that buy 5090 is significantly higher than the amount of people that tune memory. You could ask instead why they review Intel GPUs. My guess is because Intel sends them hardware for free to review and because even that market is larger.Â     If there's really an untapped audience for it, why not capitalize on it?   The fact that your argument is calling names, shows a lot about who you are.",Neutral
AMD,"You can use earlyoom to keep them in check, no ?",Neutral
AMD,"4GB will definitely be very easy to run into problems on Windows, for sure.   But regardless, 1-2GB either way isn't making much of any difference on a bigger scale here.  Wont make 16GB 'ok' on Linux when it's not on Windows outside of some fringe cases.",Negative
AMD,"100% of the time when people throw around comments like 'something is true for 99% people', then it is not a statement of fact, but an opinion.",Negative
AMD,"It took me maybe 2 days to find a fully stable PBO.  It took me 2 **months** to find a fully stable manual DDR4 tuning setting (including manually setting the secondary and tertiary timings, and all of the various voltage and resistance settings), because it wasn't uncommon for a 24 hour RAM stability test to miss something and I get a crash about a week later while watching a Youtube video.  Next time I have to build a new PC, I'm only going to test XMP/EXPO stability and that's it.",Negative
AMD,"X3D is still limited by Infinity Fabric speed ~70GB/s, so when cache is exhausted (RT, LLMs) the X3D chips are limited by their fabric speed pretty heavily. 14900K will be over 100GB/s with fast ram.  X3D with stuff that can fit in its L3 will dominate, but there are some niches where the old 14900k can out perform due to better available memory bandwidth.",Neutral
AMD,"Honestly i've always overprovisioned my CPU because it's too much of a pain in the ass to upgrade/replace, and by the time i actually upgrade (5+ year cycles) chances are we're on a different socket already so there's no point in upgrading it, so time to get another board+CPU.  That being said, yeah, IMO the PSU is something you should *never* cheap out on. Shitty PSUs take more than just themselves with them to the grave more often than not, absolutely not worth the pittance it costs to just get a good one. Plus you can carry it across multiple builds too.",Negative
AMD,"Yeah, I recommended a 5600MT/s kit to my brother because it was half the price of a 6000MT/s kit 3 years ago. The FPS for a Ryzen 7600X / RX 7800 XT between those RAM kits were really close, at most 10% but in average 3% iirc.",Neutral
AMD,That actually means you're very much on the same ideal curve.  You're just not as far along on the time axis as some others.  Not a bad place to be really.,Positive
AMD,"Well that's the same as 6400Mhz with DDR5.  Ideally if you could overclock both memory and IF to the same factor, there's a small reward, but 3200Mhz got you most of the way to what DDR4 was gonna deliver for you.",Neutral
AMD,Because quality discussion should not be limited by what the average Joe wants or can do. I thought this was obvious. Building a computer is also not something most people want or can do yet here we are.,Neutral
AMD,"Eh, just use zram/zswap/swap. No reason to sit there running task killers for what are web browsers and videos games. We've long since solved OOM issues on normal desktops with normal applications. With 16GB and a browser, most times you'll only push a few hundred MB of RAM into any sort of swap unless something is reaalllly choking you out.",Neutral
AMD,"I would be very interested to see benchmarks, and I think with zRam there are probably a few games where memory usage could make a real difference for 16GB computers",Positive
AMD,yeah id say its about bellow 6 GB where it becomes hard to use windows.,Neutral
AMD,Make sure you do. DDR5 tuning makes DDR4 tuning look like a walk in the park. Had to update bios on two machines just to get rated expo to boot.,Neutral
AMD,Ram OC is a young mans game and a hobby for the unemployed (its a joke),Negative
AMD,"In my case a 4x3733 XMP DDR4 kept crashing until I pushed in the RAM sticks a bit harder. Literally all it took to fix the crashing was to just push them in a bit more, even though they did click in before.",Negative
AMD,"I hear you, and I raise you my home server running jedec 4800 because I don't wanna mess with it",Neutral
AMD,Sure that is true it depends on the workload. If the workload is load from ram use once and never use again like LLMs (but who runs them on a CPU?) then benefit from X3D cache is none. But most stuff like game engines run a loop thousands of times on the similar data. It does not have to fit in the cache - even if half of it fits this half is already there. So this also benefits the non-fitting half by not competing for memory transfer with it.,Neutral
AMD,"> That being said, yeah, IMO the PSU is something you should never cheap out on.   I did this back in 2015 and now I'm wondering if a PSU ever ages out...",Neutral
AMD,When it comes to gaming i play genres that are CPU bottlenecked so i spend more on CPU than on GPU most of the time.,Neutral
AMD,"Its very interesting to see game engines with x3D. when the model fits entirely inside the 3D cache it runs great, once it exeeds the size and you need to start swapping from memory performance drops off a cliff.",Positive
AMD,"For LLMs or image gen running locally on consumer hardware, you often have to blend the workload and split layers between GPU and CPU (ex: Flux dev FP16 or non quantized models / bigger LLMs) even on a 4090. This uses your CPU and GPU, and then becomes reliant on system RAM bandwidth, while also still giving pretty high performance. It's why people can run huge models on a 4090 and it still be pretty fast. 14900k is better in this case.   Same with RT - in RT games, they seem to miss L3 cache and hit system memory (I don't know why). Granted, most people are GPU bound for RT, so they'll never notice, but technically here the 14900k can also perform better.   Niche stuff that most people won't care about or notice, but still a thing.",Neutral
AMD,"If it isn't sufficient for new capacity needs or if it fails...that's pretty much it.  I've had maybe one PSU failure in 20+ years of building my own PCs, usually I am replacing when I need more powaaa",Negative
AMD,Bad PSUs are definitely still a thing.,Negative
AMD,"They certainly can, capacitor degradation is a real thing, especially if you are having many transient loads. Also the RTX 30 series and newer are more prone to transient spikes of 2x their rated wattage (e.g. 350W to 600W+ for a microsecond) that can cause Over Current Protection to engage. Not *quite* the same as aging out, but PSUs are subject to the same time decay as everything else and feature enhancement. If you have a newer GPU, it's worht getting a ATX 3.0 or newer PSU, for that plus the native cable to deliver 600W in a single cable for high power GPUs.",Neutral
AMD,the only PSU failures i experienced was noncritical. Mostly just the fan stops spinning and you replace it because you dont want to risk it overheating. Never an actual cease to work failure. Ive been building since 1995.,Negative
AMD,TLDW:     14 game average:    9850X3D was:    - 5% faster than the 9800X3D     - 15% faster than the 7800X3D when CPU limited    - 28% faster than the 14900K    - 34% faster than the 9700X   - 43% faster than the 5800X3D,Neutral
AMD,5% faster for 20+% more powerusage - yay,Positive
AMD,Hardware Canucks ripped AMD a new one lol.,Neutral
AMD,"Not related to the 9850X3D, but I am extremely curious what has happened with the Battlefield 6 results because there are massive differences compared to the ""33 CPU benchmark"" video released a couple of months ago.  The 14900K now sits just below the 7800X3D, with higher 1% lows even, while in the 33 CPU test it was reported to be worse than the 9700X. 14900K's average FPS is 26% higher compared to in the 33 CPU test video, and 1% lows are 10% higher. The 14600K and 285K show similar improvements.  The 9700X also shows good improvement in average FPS, but 1% lows actually decreased.   The 5800X3D shows huge improvements too - from 124 avg FPS to 158; and 1% lows from 89 to 106.   The 7800X3D now achieved \~10fps higher compared to 9800X3D's result in the 33 CPU test video.   The 9800X3D has also improved, but to a much lesser extent, which is probably partially due to GPU bottleneck at this point.  **Timestamed graphs:**   Battlefield 6: Multiplayer CPU Test, 33 CPU Benchmark: [https://youtu.be/nA72xZmUSzc?si=6NgiSgpCH5l9p4eU&t=313](https://youtu.be/nA72xZmUSzc?si=6NgiSgpCH5l9p4eU&t=313)  AMD Ryzen 7 9850X3D Review & Benchmarks vs. 9800X3D, 7800X3D, 285K, 14900K: [https://youtu.be/d2hGLaQQpUk?si=RxV13wBgD0Dg609j&t=436](https://youtu.be/d2hGLaQQpUk?si=RxV13wBgD0Dg609j&t=436)",Neutral
AMD,Power consumption not looking good in pcgh review.,Negative
AMD,"Draws way more power and with increased thermals so you can barely see a difference playing at 1080p medium settings on a freaking 5090 ???? SUPER PASS, this is just an overclock, lmao.",Negative
AMD,"So basically the fastest ZEN 5 gaming CPU is now 15% faster than the fastest ZEN 4 gaming CPU. That's not terrible.  EDIT: Guys I'm just talking about the improvement in performance gen over gen. I didn't once mentioned the price or if it is good or bad value for the money. I'm just comparing tech, not deals and 15% per gen seems solid to me.",Positive
AMD,7800x3d needs to drop in price,Negative
AMD,"I bought an AMD 7900X3D on a dip a long time ago, it seems",Neutral
AMD,Apple when they have the fastest chip = 20%+ year on year improvements   Amd when they have the fastest chip = sit around scarching their ballsacks and then smelling their hand,Neutral
AMD,Man 7800x3d was such a good GPU to launch. Been 3 years and still identical 1% lows and average FPS at 1440p and above.,Positive
AMD,What's the tl;dw?  A 27 minute video is pointless.  *edit* nvm TPU has a nice text review.,Negative
AMD,"Watching this in my recent upgrade $280 R7 7800X3D feels kinda pretty good tbh, especially comparing to how a lot more these newer 9800X3D - 9850X3D costs compared to what i got my 7800X3D for.  We are reaching the point of AMD's Skylake era stagnation where they only release CPUs that offers very little performance uplift over last generation for a lot more power consumption and costs, which is also another reason led me to choose the 7800X3D as my upgrade path from my previous R5 7600.  I think i will be staying on this beast of a gaming cpu until at the least Zen 6 3D or tbh even until AM6 at this point, and i think everyone else with similar gaming performance should as well.",Positive
AMD,"I think the real TL:DR is that you get about 4-5% higher clocks for 25% more power consumption and 10 degrees hotter temperatures than the 9800X3D.  At least when being fully pushed.   We already knew what the baseline was gonna be here, just a matter of what small incremental improvements you got for it, and what it costs you to do so.",Neutral
AMD,"Honestly, I'm pretty happy (as a 5800X3D owner) that what appears to be the best gaming CPU on the market is only 40% faster than my 5800X3D. A 10% gain annually for four years isn't *insanely* huge and reassures me I can be quite happy with my CPU for another few years or more.",Positive
AMD,i kinda wish they would show off vs older cpus with these tests. like yeah knowing how well a 9850x3d performs vs a 5800x3d is cool but its only a ~4 year old cpu. show us how well it would run vs something like a 9900k or a 3800xt,Neutral
AMD,">43% faster than the 5800X3D  Well, that also means it is also 40%+ faster than my laptop CPU 8745HX which is just a Ryzen 7700 non-X that is as fast as 5800X3D.",Positive
AMD,"Death, taxes, and the V/F curve",Negative
AMD,Interesting to see if they still randomly die. Could be more often with that power usage.,Neutral
AMD,"TPU has it at equal power usage in synthetic tests, and 7% more in gaming. Haven't seen HUB's yet, but that's a massive difference between reviews.",Neutral
AMD,Ain't called Zen 5% for nothing.,Neutral
AMD,"Truly an Intel Kaby Lake moment right there lol. I also don't like how the Ryzen 5's core counts has been the same for nearly a decade at this point, I really hope that Zen 6 will be different this time around.",Negative
AMD,That's how it always is for high end hardware. I'd say AMD won this one,Neutral
AMD,"This isnt Intel, i think its at most 10-20W more",Neutral
AMD,They made a video recently about how finally win11 is consistently faster than win10 at gaming. Maybe thatÂ´s it.,Neutral
AMD,"Yeah, it's an overclock with a warranty. The decision tree is pretty simple:  - If you're upgrading from a previous generation to this one, you might as well go for this part since it's a marginal cost increase for a marginal performance increase over the other parts in the generation. - If you're already on on a current generation, there's no reason to get it.",Neutral
AMD,"It's the same situation as Lovelace / Blackwell, which everyone said was shit  More performance at the cost of more power with a higher price",Negative
AMD,"It's downright terrible value if you compare the price between them though, you can get 7800X3D at around $300 on sale for a while now, just recently got mine brand new at $280 compared to this which likely will retail at $500+ it's a terrible value gaming cpu aimed to squeezing more money from gamers who only wants the best gaming cpu but doesn't care about money / value.",Negative
AMD,It's still frustrating that Zen 5 seems to \*need\* a lot more than 32MB of L3 to see bigger gains over Zen 4.  At least for gaming.  Basically makes all the Zen 5 lineup except the Vcache parts kind of pointless unless you can get them for roughly the same price as a Zen 4 equivalent.  Hoping Zen 6 ups the L3 as standard and/or does other optimizations to help bring out the potential of Zen 5's wider architecture without needing to buy the later and more expensive Vcache variants.,Negative
AMD,"Yeah, but it's a huge premium. Like it's 80% more for 15% gains. Not good.",Negative
AMD,The 7800X3D is to these what the 5700X3D was to the 5800X3D. Zen 5 is a pretty flawed architecture because it's gains are limited by some bottlenecks. Zen 6 should alleviate it and addore cores.,Negative
AMD,"Iâ€™m unironically shopping for a 14700kf because I have DDR4 and an old LGA1700 mobo laying around  Massive improvement in ST, MT, and about 10% faster in games over my 5800x3dâ€¦ which doesnâ€™t matter anyway as I play at 4k",Positive
AMD,Do commenters ever not whine?  There are bar graphs you can pause and it's a picture no longer a 27 min video.  You can also just watch the conclusion and that's like a 3 minute video.,Negative
AMD,Such nonsense. It has been 1 release and despite the uplift being relatively low in games compared to other zen releases the 9800X3D is still double digits faster than the 7800X3D. Something that did not happen in the Intel Stagnation Era which went from Sandy Bridge through to Rocket Lake. 11 gens of upgrades.  This is 1 release and a mid cycle refresh because they are getting enough top bins to make it worth selling a marginally higher tier part for a marginally higher price. It is effectively a KS variant but without the huge cost increase.  So saying 1 gen and a KS bin equates to the stagnation era is just absurd.,Neutral
AMD,"Right, but 7800X3D was  450$ on release, every new CPU is going to be terrible value compared to older generations, thankfully AMD isn't Intel so both are on AM5. Prediction time: 10800X3D on release is also going to be bad value compared to 9800X3D",Negative
AMD,"So, AMD releasing a binned CPU for a bit more.... is stagnation.   Meanwhile Intel with the KS series or now the Core 300S aka 200k OC edition, charging 150-300 bucks more per CPU....is innovation in your eyes? Tells me enough lol",Neutral
AMD,"25% more power for 5% more performance looks like a mediocre overclock. Hardware Canucks' review shows how much hotter the 9850X3D is at gaming for barely any performance increase, including the aforementioned power draw increase.  I guess a lot of early 9800X3D buyers might have a sample that can be overclocked to achieve the same or better performance than the 9850X3D, during the launch window they were not binning any CPU whatsoever so there should be a lot of silicon lottery winners out there.",Neutral
AMD,"I bought a 5700X3D from Aliexpress for $131 mid-2024. Its a shame, the lowest i can do now is $325",Negative
AMD,"CPUs have historically been a ""buy one and pair with 2-3 GPUs"", with how small the improvements right now it still is true I think. Like if you bought one of the legendary CPUs of its time 4770k,  you could've paired it with a GTX 780, 980, then an RTX 2080 without much problem. That's also what I plan with my 5700X3D, first with a 6700 XT, now with an RX 9070, probably next GPU because of the prices is either 8000-series Nvidia or three gens from now AMD.",Neutral
AMD,"Yeah Iâ€™m hoping to hold onto my 5800X3D until AM6. I know thatâ€™s still quite a few years away, but getting in on the start of AM6 and having so many more years of potential upgrades is a lot more appealing than upgrading to one of the last gens on AM5.",Positive
AMD,"I get it, but you should also be able to extrapolate that information from seeing comparisons of say a 5800X3D vs a 9900k in 5800X3D reviews, which is probably easier information to find.",Neutral
AMD,"After a quick look, the 5800x3d was (is) about 20% faster than the 3800xt for single threaded benchmarks, so you could do 20% times 43% (1.2 * 1.43) and reasonably expect the 9850x3d to be 71.6% faster than the 3800xt.  Sure, measuring things directly would be better, but you get a general idea this way.",Positive
AMD,"It's a \~0.65% failure rate based on the biggest retailers with RMA data, hardly novel, and only a bit above the 7800X3D.",Negative
AMD,"TPU also has just 1-2% more performance on the 9850X3D, could HUB be using a mobo that has more aggressive PBO ?",Neutral
AMD,"Derbauer's results are in line with HUB's generally.    TPU can be great for GPU testing, but they are not great at CPU testing.  If the CPU is not being fully utilized and you're regularly GPU limited, you will probably not see much if any difference in power consumption on average.  They \*are\* the same CPU at the end of the day, after all.",Neutral
AMD,"Well, it's Zen 15% now.",Neutral
AMD,"Even though IDGAF about the V/F curve, the only thing keeping me from putting my 9800x3d in a box to put the 9850x3d into service are the rumors that Zen 6 will be > 8 cores per ccd.   Best part of holding off for that is that if that doesn't pan out I won't be bothered to make a change until the next platform.Â  If it does I'll make the switch the (x?)x950x3d variant for general compute purposes more than anything (folding @ home mostly).Â  Either way I'll feel like a winner.   I am a winner, right?",Neutral
AMD,atleast watch the videos,Neutral
AMD,Simply not true.  HUB: 4% increase  LTT: 4% increase  Level1Tech: 7% increase  DerBauer: 4% increase  GamersNexus: 4% increase   I've seen your name on here so many times. Do you ever get tired of spreading misinformation?,Negative
AMD,"LTT was also ""pleased"" with the results",Positive
AMD,"What about the decision for me, whoâ€™s building their first pc $ has not bought their cpu yet? I just bought an ASUS 5080 16gb TUF Gaming with Corsair 6000mhz 32gb ddr5 ram. Stuck between the 9800X3D or the 9850X3D",Neutral
AMD,"I would prefer a cheaper, cooler and more efficient 9800X3D with the same performance at 1440p ultra as the 9850X3D.",Neutral
AMD,I got a 7800X3D in AliExpress 11.11 sales for â‚¬232.78,Neutral
AMD,">it's a terrible value gaming cpu aimed to squeezing more money from gamers who only wants the best gaming cpu but doesn't care about money / value.  That's true of almost every high-end product. Value is subjective. I don't particularly care about the difference between $300 and $500 on a CPU for a build I'll use for 2-3 years. There's a pretty broad spectrum of price/performance options right now, though, so no one should feel squeezed into paying up for the best, since it's a pretty marginal improvement.  That said, I just bought a 9800X3D and don't regret not waiting a few weeks for the 9850X3D.",Negative
AMD,"Zen has been pretty heavily limited by the performance of the memory controller on the consumer side for a while now, which is why having a large cache really helps.  If Zen 6 brings a new and improved one, I'd expect the gap between the X3D and the regular parts to drop as the masking effect of the large cache becomes less critical.",Neutral
AMD,>80% more   Wtf are you talking about?,Negative
AMD,"At least in Amazon, I'm seeing the 7800X3D at around $380 to $400. Nowhere near 80% higher price.",Neutral
AMD,"It does suck that so much authoritative content is moving to youtube. Even with an adblocker, I ainâ€™t gonna watch a half hour video when I can skim an article in a minute or less for the info I want.  I miss Anandtech, but I understand why that business model has (mostly) died",Negative
AMD,I hope they always whine when its a video. Video is the worst format for this.,Negative
AMD,Not WHINE? ON REDDIT? GTFO,Negative
AMD,"I just feel sad for the reviewers.  If they had access to the (China-exclusive) [DDR5+Hyper 612 bundle](https://www.techpowerup.com/345648/unusual-collaborative-ryzen-7-9850x3d-ddr5-kit-cooler-bundle-turns-up-in-china), that would've made for interesting content.  This is just an OC'd 9800X3D.  At least the 9950X3D2 is something cool (3D V-cache on both CCDs).",Neutral
AMD,"10800x3d is going to be way faster, at least 25%",Positive
AMD,">Meanwhile Intel with the KS series or now the Core 300S aka 200k OC edition, charging 150-300 bucks more per CPU....is innovation in your eyes? Tells me enough lol  I think you missed the point of my comment, in no way i was praising Intel with their history of stagnation in my comment lol, i was criticizing AMD for doing the same thing as Intel did nearly a decade ago back with Skylake - Kaby Lake, because Zen 5 certainly feels like it over Zen 4 which i felt was a decent uplift over Zen 3 and same can be said with Zen 3 over Zen 2 and then prior.  The point is AMD felt innovative with respective performance jump prior Zen 1 - Zen 2 - Zen 3 up until Zen 4 and then Zen 5% comes out and suddenly all of that track record of theirs is broken even the X3D version which everyone liked was not a worthy uplift enough to upgrade from the likes of 7800X3D, and same can be said with 9850X3D compared to 9800X3D - 7800X3D.",Neutral
AMD,Its just the better bined died being sold as a different SKU with a pre-overclock. No wonder it looks exactly like what it is.,Neutral
AMD,"I was so mad i missed this boat. They were $200 in February on Ali when i was shopping. Then suddenly $250 a few days later. Settled on a 5800xt for $125, and even thats price hiked now.",Negative
AMD,It depends on what you use it for. My 4560k was obsolete long before i got my 1070.,Neutral
AMD,"That was true in the past, but lately GPUs have improved significantly faster than CPUs, the improvement from 4770k to 9850X3D is much smaller than from GTX 780 to RTX 5090. I don't think you will upgrade to new GPU that late, by that point CPU will be slow, 9070 with 5700X3D is pretty balanced setup anyway.",Positive
AMD,"My idea exactly, going from AM4 to 6 will hopefully be a massive jump.",Positive
AMD,"For synthetic benchmarks, but I'm pretty sure it's much more in games.Â    5000 non-3D vs 3000 was already 15% in games, no? So I'd imagine the X3D pushes that beyond 30% uplift.Â    Edit: quick check, Computerbase's 5800X3D review puts it at geomean 53% ahead of 3800XT in games...",Neutral
AMD,"That's about the same failure rate as the 12VHPWR connector, funny how the response is so different.",Negative
AMD,"Overall it looks just like really an overclocked 9800X3D, with some tests I see that limit to 5.2Ghz being actually identical to 9800X3Ds lmao. AMD just overclocked 9800X3Ds for $30, presumably being more stable than a manual overclock. It's up to buyers if they consider that worth the $30 more.",Neutral
AMD,Zen 5% x3(D).,Neutral
AMD,"Just did, HU and GN reported like 20W, as i thought",Neutral
AMD,anyone did comparison with OCed 9800?,Neutral
AMD,"Hey DwarfPaladin84, your comment has been removed because it is not a trustworthy benchmark website. Consider using another website instead.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Negative
AMD,"Look at your total system cost, the relative cost of the CPU, and the net impact on performance.  You're looking at a total system cost of... mmm... call it about $3000 for the whole rig. Let's say you're paying $20 more for the 9850X3D than the 9800X3D. That's a 0.7% increase in cost for a ~4% increase in performance, _and_ with that GPU you'll actually be CPU bound enough of the time to make it worth considering.  I would say the 9850X3D is worth it for your rig.  However, it's not a universal truth - if you're running a much older GPU, or have a lower system budget, then something like the 7800X3D makes more sense. On the flip side, if you're playing simulation games like Stellaris or Factorio, then it might be worth the higher end CPU even if you're running older GPUs or lower cost hardware.",Neutral
AMD,"I'm holding out till tomorrow when it releases. Figure why not, but I'm either going this or 9800x3d",Neutral
AMD,"undervolting is always an option. wrangling modern boost not to actually boost above what you want is a bit harder. Modern chips think ""its running low temperature? lets boost something insane to make sure its running high temperature""",Neutral
AMD,"Yep, i have noticed the 7800X3D is getting a lot cheaper these days, especially on sale, that even i can't ignore. it's an absolute no brainer choice over the likes of 9800X3D - 9850X3D which offers very little performance uplift for significantly more cost.",Positive
AMD,AMD really need to put a larger L4 cache on the I/O die.,Neutral
AMD,There's also the potential that Zen 6 may be like the Strix Halo APUs and the higher end RDNA3 parts in that they use Infinity Link (Fanout with 1:1 connections between the chiplets) vs Infinity Fabric (serializes/deserializers which narrow down the communication pathways between chiplets to allow communication over fewer traces).  That would help the communication bottleneck.,Neutral
AMD,Prices can vary a lot by region.,Neutral
AMD,"At least on asian market, you can get a tray type version of 7800X3D at less than $300 even cheaper than that if you have coupons.",Positive
AMD,The same way you skim through text you can also skip 27 minutes of the video to just check the final graphs.,Neutral
AMD,"Sure if the rumours about them increasing the cache even further are true, but its not going to be a good deal, because by that point 9800x3d (and 9850x3d) is going to be heavily discounted and 10800x3d is going to be atleast 600$ if recent price increases in HW are anything to go by.",Negative
AMD,"Zen 5 isnt a stagnation per se, nor is the Core stagnant itself.   If it truly were Intels Sky/Kabylake era... A Ryzen 5 wouldnt have been around 10-20% faster in MT/ST every fucking Gen except Zen 5 since that was only a major core and arch overhaul that should have been delayed a year for the overhauled IO Die that comes with Zen 6. Would even say it makes sense its a stagnation in performance in gaming and workloads that DONT use AVX512 instructions.   Stuff that uses AVX512 instructions is a major uplift Zen 4 vs 5 since they broadened the pipelines, as well as doing a true AVX512 implementation.    You could also say, why didnt they use Zen 4/5 Dense instead of the normal Zen Core structure, since it iant missing anything the Big Zen has...  I can tell you, because the performance uplift came from a combination of frequency and architecture itself.  Zen Dense clocks alot lower in some cases, which sure, gives you more cores, but in turn ruins the gains the Arch ITSELF has to offer, which scales with frequency to a certain point.   Then there is also the issue with Zen 5 lacking internal bandwidth and external (DDR5) in 1:1 mode. Which shows up, since a 9950X3D despite lower max boost clock, is faster than the non 3D. Same will be with the 9950X3D2, will be faster, since both CCDs will have access to a big chunk of extremely fast and low latency brick of storage.  Zen 6 will definitely be a massive change, since it comes with a 12 Core CCX, the reworked IO die for alot higher memory speed aka more bandwidth from the get go and a refreshed Arch which takes the groundwork of Zen 5 and iterates on it.   Zen 5 is a stopgap and rework of the old Zen 2/3 Arch.  Its basically what Zen/Zen+ to Zen 2 was. A major groundwork rework, but nothing spectacular for performance.   Imo, calling AMD stagnant like Kaby Lake-Skylake Era is not fair. Especially looking at all the facts, Kaby Lake to Skylake you were lucky to get single digit improvements evey Gen. Which is only true for Zen 5 and only when forgetting that Zen 5 is also used in stuff more than just gaming.",Neutral
AMD,"Ali has lowkey become a decent place to get cheap parts. There are still â€œfakeâ€ parts on there, but if you get a reputable seller who ships from a local warehouse (for easy returns) you avoid all of the issues.",Negative
AMD,"If the 58003d was 53% faster then that would make the 9850x3d over 118% faster (2.18x) than the 3800xt, ""in theory"".",Neutral
AMD,i'll give you two guesses on that one,Neutral
AMD,We got lulled into a good decade of basically zero failure rates with CPUs that probably make them having a low failure rate more prominent than components that do fail regularly.,Negative
AMD,"I agree with the premise of your comment. However, devils advocate. We dont really know why AMD CPUs are failing, but we know that the connector is failing because its just a bad design.",Negative
AMD,"Does limiting the 9850X3D to 5.2â€¯GHz improve power efficiency compared to a stock 9800X3D? If not, then itâ€™s basically just a factory overclocked 9800X3D.",Neutral
AMD,The fact that it's only 30 bucks for that is surprising/nice at least,Positive
AMD,"yea, thats 20% more for 4-5%",Neutral
AMD,Not in any of the ones i listed.   But GN noted that you could quite easily OC the 9800X3D reliably to 5.4ghz so it'd be even less of a performance increase between the two.,Neutral
AMD,>Everyone but HuB had poor results  I've just given you 4 extra reviewers that had the exact same or higher.. so this comment was bullshit.,Negative
AMD,"More honest assessment: HUB was exactly in line with every single other one, except one whose results were actually higher.    You are proving you are out to bash HUB with completely dishonest intentions.  It could not be more clear at this point.    Basically, you are not here in this sub in good faith in general.",Negative
AMD,User benchmark fan confirmed,Neutral
AMD,"Obviously, but the implication is that a 7800X3D is $277 when that isn't remotely true even on the used market.",Negative
AMD,"Just curious about these tray CPUs, is there any issue with warranty due to being grey market?",Neutral
AMD,So buy that,Neutral
AMD,"Thereâ€™s a huge difference between skimming an article or paper vs randomly seeking thru a video, hoping you find something useful, while still having to listen to people talk at 100 WPM when you can read at 600 WPM",Neutral
AMD,"Itâ€™s not the cache, they are rumoured to support way faster memory and have crazy high clock speeds. If the 9800X3D could do that then the gains would be massive, these CPUâ€™s are extremely gimped by the IO die.",Positive
AMD,You missed the point and are showing your bias. Is it bad design if itâ€™s within typical hardware failure rate?,Negative
AMD,"gotcha, thanks. Weird that noone did test with OC'd 9800, but considering abysmal level of Tech Bloggers on youtube - not surprising",Negative
AMD,The account is anti-AMD to the extreme. Look at their history.,Negative
AMD,As reported by another user that very much can be the case. In my country there's typically a 50% or more gap between a 78 and 9800X3D. A 20 USD gap at that point would be fairly big and it will actually be a bigger gap due to import taxes on products and the fact that I don't believe there's official AMD sellers here.,Neutral
AMD,"They still come with warranty but shorter than the retail version only 1 year instead of 2 - 3 years that comes with retail, but with my history of buying tray type cpus i never had any problems with them whatsoever, they feel like retail version and even comes with their own coolers depending on certain model of cpus.",Positive
AMD,if its a legitimate retailer you get warranty through retailer as required by law (lenght varies by country). If its some ali express shell company then no warranty.,Neutral
AMD,Already did at $280 way better value than 9800X3D at $480,Positive
AMD,"I usually just click on the ""X game average"" shortcut in the description, since HUB is good about putting those in their videos.",Positive
AMD,"Yes? Failure rate is not a necessary requirement for a design to be bad. Merging all lines at the card end would be bad design even if failure rate was 0, for example.",Negative
AMD,"everyone was comparing it to OCed 9800 before the release, and then turns out noone actually tested what they talked about. Typical techfluencers.",Negative
AMD,"I know, that's why i said i'd seen him on here so many times. Often in HWUB threads getting mad about their 7800XT review from 2 and a half years ago.",Neutral
AMD,"Iâ€™ve lost all respect when they all forgot about 7600/7700 non X variants, which they tested, when they fell for AMD marketing trick about 9600/9700x efficiency. It was shocking, honestly",Negative
AMD,"This one stands out from the other 9850X3D reviews for testing it with slow DDR5-4800 to see if it makes any difference. It barely does, so you might want to save some money there.",Neutral
AMD,All those people that complained about GN's other content and said he should just review hardware... Where are you now? Barely any engagement on this video.,Negative
AMD,"HUB also tested with 4800 memory (well, 6000 memory with EXPO disabled), but also threw intel cpus with both memory profiles for comparison. HUB also did RT tests showing Intel getting ahead (but comically couldn't explain it).",Neutral
AMD,"Same outcome as it was found reviewing 5800x3d, bigger cache reduces frequency of  data fetches from RAM and increasing effective bandwidth.",Neutral
AMD,"The HUB review was posted first on this subreddit. This post came 20 minutes later. The first review post gets all the discussion. Nothing overly suspicious here.  Then again, the der8auer post came after this post and got much discussion. Probably because der8auer used a clickbait title, so people discussed the actual efficiency claims.",Neutral
AMD,Havenâ€™t been reading this sub for a while. Do people actually complain about GNâ€™s other content? Itâ€™s been great to see someone exposing the corrupt side of tech. Raising awareness through well researched content canâ€™t possibly be a bad thing.,Neutral
AMD,I guess they had no obligation to give him another chance.,Neutral
AMD,Because BVH cache in rt fills the cache easily and the 9800x3d has to do fetches from memory and slow infinity fabric chokes it again,Neutral
AMD,"Donâ€™t forget that EXPO does a lot more than XMP does on Intel systems. It doesnâ€™t just overclock the RAM but also the IF which has a huge impact.   You can get like 80-90% of the uplift from EXPO by overclocking the IF manually.   In most reviews that use stock settings for both, AMD almost always underperformed.  Itâ€™s just normal that ""reviewers"" Test with overclocked CPUs.",Neutral
AMD,">Do people actually complain about GNâ€™s other content?  yeah, sadly. especially when GN is attacking their favourite brand.",Negative
AMD,"The unfortunate reality is that this sub is increasingly plagued with tribal mindsets who refuse to value a piece of content on its own and hold grudges indefinitely.  I love how all aspects of the hardware industry are covered here, but would leave in a heartbeat to get away from the endless price complainer posts and personal gamer vendettas.  Turns out, the other tech subs are either too niche or even more tribal.",Negative
AMD,"Oof, so it actually does matter, amd just conveniently leaves out RT benchmarks in their launch showcase",Negative
AMD,"Yeah I know. I mean, I'm nowhere near knowledgeable about the rendering pipelines, but on a high level this stuff can be explained and understood easily enough I think.",Neutral
AMD,"i don't think that is true, at least on zen4 or zen5. the EXPO profile doesn't contain FCLK, nor is FCLK linked to MCLK.",Negative
AMD,EXPO and XMP have the same behaviour for FCLK. Regardless FCLK is always 2000mhz on zen5 unless manually set.,Neutral
AMD,"We're quiet because this is finally a review, why would we bash?  Just look at his last 2 months of content, 2 reviews by my count, the others are some sort of hype building or some sort of tours. Look at the view count. Any video where he's bashing a company has 2-3x the views of all the other videos. Do you really think he isn't leaning into that especially when there's so little to review?  Instead of being creative and coming up with cool things to review, he's just leaning into drama.  Compare the last 2 months of videos with 8 months ago. Review, review, review, review, lots of interesting product videos, interesting collab with L1, and a bunch of news. 21 reviews or interesting product videos in just 1 month. No bashing, no ragebait, no bullshit. We're talking shit because I used to watch the videos within hours of release, and are tired of more ragebait in our feed.",Neutral
AMD,"Question is, why isnt this more widely talked about? Honestly first time ive heard about it",Neutral
AMD,"The expo profile doesn't but mainboards usually use an ""auto"" setting that automatically overclocks the if.",Neutral
AMD,"> We're quiet because this is finally a review, why would we bash?  In nearly every GN post there's a sizeable group calling for more reviews, neutral tones and technical content and less drama. Yet when one finally arrives, it sits at +20 with a measly <60% upvote ratio.  That's not being quiet, that's quiet disapproval from those who dislike anything this channel does.  Ironically, the derBauer review with the more dramatic, accusatory tone got the most engagement among all 9850X3D reviews.",Negative
AMD,"Then its not EXPO doing it  XMP 3.0 also makes the intel MBs do some weird voodoo with vccsa, tx vddq, vdd2, etc. But its not the memory profile, it is the motherboard itself.",Negative
AMD,Correlation is not causation. Nobody is disapproving anything out of spite. Nobody is here making comments.,Negative
AMD,"Note the perf / W chart for Cinebench nT does not start at 0-0 and the two axes are not commensurate, so a bit of a doozy.",Negative
AMD,The funniest thing is that based on announced laptops AMD seems to refuse to lower the price on this rebrandeon thing compared to strix point despite being on an ancient node NOT used by their upcoming Epyc/Instinct. OEMs simply switched to offering more of the lower end skus like 465 over 470 and 445 over 450 and no lower prices.  So now you have a upper mid range chassis like the Lenovo Yoga Slim 7a......topping out at the 445 with 2+4 core config and 4CU (comparable to circa 2020 Tiger Lake Xe performance)......,Neutral
AMD,AMD is a shit company.,Negative
AMD,"Hello -protonsandneutrons-! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
AMD,"It's important to remember that AMDâ€™s SoC engineering resources are finite. While Strix Point was an impressive milestone, a massive portion of their design man-hours is currently dedicated to the 2027 console cycle. Between the PS6, its rumored portable counterpart, and the next-gen Xbox ecosystem (including their own handheld), the semi-custom division is likely consuming the bulk of their top-tier APU integration and development talent.",Positive
AMD,"I wonder if 4+0+4+4 Panther Lake can target lower end Gorgon Point. that said, 226V/228V could easily target that level of perf if what intel need is to shift inventory and the OEM require soldered memory.",Neutral
AMD,"it's no longer a small company if it can acquire lots of startup and most importantly, Xilinx. It just shows that mobile client has been AMD's least priority, something that has been proven for years.   At least now they have a reason to push RDNA5-based APU, or maybe prioritize RDNA4 APU if they still haven't cancelled that yet",Neutral
AMD,32 billion revenue and itâ€™s still a smol bean indie company incapable of multi tasking and all the physical limitations in the world exclusively affect amd and not everybody else.,Negative
AMD,"Who said AMD is a small company? If they acquired other companies for other purposes, that doesn't mean AMD can now design and launch **each year 3-4 new chips**.",Neutral
AMD,"By your silly logic, NVIDIA with a 200 B yearly revenue should design and lunch 20 chips each year. It took you a long time to come up with that? The limitation is man hours, number of engineers!!!",Negative
AMD,"Whether they can design so many chips is not the concern, it's just mobile client is being treated as third class now rather than third (Rack scale / Epyc, Ryzen, Ryzen Mobile) while it used to be the preview for scaled up solutions like intel still does today.",Neutral
AMD,What stops them from hiring me? They only have themselves to blame,Negative
AMD,"Nothing had changed in the last 6 years in AMD's APU launch strategy. Client is not a third class. Since Strix Halo AMD has actually accelerated the development of client products.  Picasso is a rebrand of Raven Ridge  Hawk Point is a refresh of Phoenix  Gorgon Point is a refresh of Strix Point.  CES 2021 -Â **new**Â Cezanne die +Â **new**Â RTX 30   CES 2022 -Â **rebranded**Â Cezanne (Rembrandt) + RTX 30Â **Refresh**   CES 2023 -Â **new**Â Phoenix die +Â **new**Â RTX 40   CES 2024 -Â **rebranded**Â Phoenix (Hawk Point) + RTX 40Â **Refresh**   CES 2025 -Â **new**Â Strix Point die +Â **new**Â RTX 50 (Strix Point was found in just a few laptop models in 2024, 2025 was it's major release in 100+ design wins)   CES 2026 -Â **rebranded**Â Strix Point die (Gorgon Point) + RTX 50Â **Refresh**Â (canceled because of VRAM shortage)   CES 2027 -Â **new**Â Medusa Point die +Â **new**Â RTX 60  CES 2028 AMD will launch aÂ **rebranded**Â Medusa Point to go with aÂ **refreshed**Â RTX 60.. There won't be a new APU design.",Neutral
AMD,">What stops them from hiring me?  If you ask genuinely, you will get the answer as to why high tech companies in semi find it hard to hire good talent and then scale design/test/delivery products. You have no idea",Negative
AMD,Its sarcasm bro,Neutral
AMD,Sounds great [for Chinese market],Positive
AMD,Neat. Cooler Master is the OEM for the boxed coolers IIRC. Considering that they are pushing the 9800X3D quite hard it makes sense to have a boxed option for those who want a complete package that just works without having to do research.,Neutral
AMD,Wish AMD could give the global markets a similar level of loveâ€¦,Positive
AMD,"Hello kikimaru024! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
AMD,Does anyone know where / when will it be avaliable? A friend of my is going to China soon and I'm quite interested in that. Sadly couldn't find anything similar in Europe,Neutral
AMD,Is it going to blow up like 9800x3D?,Neutral
AMD,I shudder to think of the mark-ups for Western market if this shipped lol,Negative
AMD,"More than that, it is a model that just released (Hyper 612 Apex PRO).",Neutral
AMD,">ASUS has confirmed that it has started an â€œinternal reviewâ€ following recent reports of Ryzen 7 9800X3D CPU failures on their 800-series AMD AM5 motherboards.  >In their statement, ASUS has not unveiled why there is a spike in reports of 9800X3D CPU failures on ASUS motherboards. However, ASUS claims it is working closely with AMD to validate recent reports and ensure stability and quality. It is also working to ensure it delivers â€œtimely solutionsâ€ to these reported issues.  >For now, ASUS recommends that 800-series motherboard users update their boards to the latest BIOS revisions. ASUS has also asked affected users to contact ASUSâ€™ customer service for direct assistance. ASUS also linked to an FAQ post to help users update their motherboardâ€™s BIOS.  >Official ASUS statement on recent ASUS AMD 800-series motherboard and AMD Ryzen 9800X3D concerns  >*We are aware of recent reports concerning AMD Ryzenâ„¢ 7 9800X3D CPUs and ASUS AMD 800-series motherboards, and we have initiated an immediate internal review. Our teams are conducting preventive checks on product compatibility and performance, working closely with AMD to validate reported cases and ensure ongoing stability and quality. We are looking to provide timely solutions to ensure our products and services meet expected standards.*  >*Users are also advised to update their ASUS AMD 800-series motherboard to the latest BIOS via ASUS EZ Flash or BIOS Flashback to help ensure system stability; we provide an official technical support FAQ with detailed instructions.*  >*Customers who are affected or have concerns are encouraged to contact ASUS customer service for direct assistance. We take this matter seriously and value our customersâ€™ trust, and we remain committed to transparency and to ensuring our products can be used with confidence.*  >â€“ ASUS",Neutral
AMD,"My 9800X3D died after 1 year on ASUS 870e-e Strix. I posted it here a few weeks ago. Was on the September bios version. Went to sleep mode and never woke up. AMD shipped out a new one, but I already bought a 9950X3D to replace it.  No burn marks, temps never got above 70-75c on water cooling. My only guess is something to do with BIOS, tiny undervolt, and/or sleep mode.  To be safe, donâ€™t use sleep mode, just shut down. Do not use PBO or undervolt, performance improvement is tiny. Update to the latest 1804 Bios.",Negative
AMD,Hope that they don't take as long as Asrock and we actually get some info soon.,Neutral
AMD,"My 9800x3D recently got fried on an ASRock. Got a replacement, bought a new motherboard... from ASUS. I want to scream.",Negative
AMD,Wasn't the guy who killed his 9800X3D on the latest bios??,Neutral
AMD,Weird there doesnâ€™t seem to be problems with the non X3D chips.,Neutral
AMD,Is this like the internal review theyâ€™re doing with their laptop stuttering/UEFI issues where there havenâ€™t been any meaningful updates or bug fixes since? Cool.,Neutral
AMD,"ASUS subsequently whacked the internal review with a pipe, said it was damaged in shipping, and engaged the auto email system demanding out of warranty payment for the internal review within 72 hours or it will be returned to the customer.",Negative
AMD,"Let's see if tech media applies the same level of scrutiny now that AMD has failing cpus. Also, the new 9850x3d could be a new stepping to mitigate whatever this is.",Neutral
AMD,are any of these failures running stock without enabling pbo or other oc options?,Negative
AMD,"It isnâ€™t just 9800x3d  I had 2 asus b850e rog strix boards that once you updated bios it over volted the 9700x and killed it.  2 boards, 2 9700x, swapped to msi x870e edge ti and zero problems.",Negative
AMD,Impossible. I've been assured it's only an Asrock issue.,Negative
AMD,"ASRock, GigaByte and ASUS having problems with these chips. I think it's time for AMD to issue a recall.",Negative
AMD,So all my efforts in buying a Gigabyte Motherboard specifically to avoid this problem were for naught?,Negative
AMD,"Just bought all my parts for my first pc build, including an asus b850 mobo. Now Iâ€™m scared to even put the thing togetherâ€¦",Negative
AMD,maybe 9850x3D exists because 9800x3D is just flawed.,Negative
AMD,Wonder why the 9950x3d isnt mentioned i have gone through 2 of them with no overclock no over heating. Died in 4 months on asus x870 tuf. Maybe its just less people have these ones. Luckily their rma was very quick. Amazing service. Recieved the new ones in less than 2 weeks.,Negative
AMD,"is this issue limited only to the Ryzen 7 9800X3D, or does it affect non-X3D Ryzen CPUs as well? What steps can I take to prevent this kind of problem?",Neutral
AMD,I am sooooo fucking glad I ditched Asus after 20+ years and went with my first MSI mobo for my 9800X3D build a few months ago,Positive
AMD,Why am I not surprised it's aSus again,Negative
AMD,Instability I understand but can undervolting destroy a chip?,Negative
AMD,"Could be something with the chips too. My 7800X3D died recently, after 2 years in an MSI board. Was already acting wonky for a few months with a few failed boots and all sorts of issues waking up from sleep.",Negative
AMD,"> To be safe, donâ€™t use sleep mode, just shut down.  This is an extremely cucked way to operate a computer. Semi-custom server parts or engineering samples would be one thing, but on a production chip the power saving features are expected to *work*.",Negative
AMD,"I had 5700X3D and it died after 9 months of usage, on Gigabyte motherboard.",Negative
AMD,I have seen other suggestions that sleep mode is involved.,Neutral
AMD,"This also raises a slight possibility that the failure mode can be blamed on some windows 11 fuckup, and we all know such a thing is entirely plausible.",Negative
AMD,"What do you mean, donâ€™t undervolt? Arenâ€™t the best guesses for why the 9800X3Ds dying that the VSoC was too high (1.3V or more)?",Neutral
AMD,"Iâ€™m on the Pro Art motherboard and on a older bios, wondering if I should just leave it as it is",Neutral
AMD,"I have a 9950X3D on the X870e-e R2, have you heard if these issues are present on the R2 version of the board at all? I can't seem to find any reason why they even made a new revision.",Negative
AMD,I bought the same board last week waiting on pricing/availability of the x3d 9850. What m2 slots are you using? The ones covered by the heatpipe are sharing lanes with the x16 slot for some reason,Neutral
AMD,"ASRock has been pretty open about reaching out to AMD, it's just they haven't been receiving any word back. The fact ASUS is involved now, is finally pushing AMD to (hopefully) do something.",Neutral
AMD,"ASRock is taking long because they don't know and can't find the cause. Gamers' Nexus and Wendell from Level 1 Techs are both looking at it as well, more emphasis on Wendell. They can't find anything solid. They can't even reproduce the issue with motherboards that have had CPUs die in them already.",Negative
AMD,Indeed. I am nervous about my Tuf Gaming B650 Plus Wifi potentially frying my new 9800x3d...,Negative
AMD,"It's Karma, stop kicking puppies!",Negative
AMD,"I updated the BIOS on my MSI board due to memory instability issues, but now thereâ€™s another problem with cold boot stutters. I wonder if AORUS/Gigabyte is doing better.  At least ASUS is acknowledging the issue unlike MSI.",Negative
AMD,Friend of mine just updated his BIOS on a Gigabyte x870 which didn't post afterwards. Thought his was another victim of this issue but luckily he was able to do a BIOS recovery and then was able to flash the newest BIOS afterwards. Super strange series of events there and he is a computer guy so I'm sure he didn't grab the wrong file or something dumb.,Neutral
AMD,Why?,Neutral
AMD,"It all depends on numbers.  The Intel issues were big enough that they were noticed by multiple independent third parties, and pretty quickly after release.  And the target reliability can never be 100% perfection, 0.1% of a large number sold can still be a large number of cases.  This is why I'd love people to actually publish numbers, so we can really get an idea of the *real* chances of things going wrong, and not just a collection of anecdotes that may be amplified or ignored depending on the media cycle at the time.",Negative
AMD,"They didnt when it was 1800, they didnt when it was 5800, they didnt when it was 7800, but now that its 9800 they surely will!",Neutral
AMD,Same level of scrutiny as what?,Neutral
AMD,IDK about ASUS but in the case of the Asrock failures they have PBO pie-charted on their thread about it: [https://www.reddit.com/r/ASRock/comments/1oqzli4/9000series\_cpu\_failuresdeaths\_megathread\_3/](https://www.reddit.com/r/ASRock/comments/1oqzli4/9000series_cpu_failuresdeaths_megathread_3/)  Last chart on the OP.,Neutral
AMD,My 9950x3d died twice less than 6 months. No overclock only thing I touched was ram expo enabled. On asus 870 tuf,Negative
AMD,>I think it's time for AMD to issue a recall.  How many are faulty vs how many have been sold?,Neutral
AMD,Source on the gigabyte? My search didnt yield anything substantial. Only asus and asrock are dying in bulk. In which asrock bios 3.25 or newer is recommended. Mindfactory rma rate for 9800x3d is close to 0.5% which isnt close to a full recall and nominal.  But my take is that just SoC overvoltage madness that also killed intel chips (which was substantially worse from crash report data)  Edit: found one x870 gigabyte board dead. And in the comments 4 asus motherboards who was RMA'd and bios updated.,Negative
AMD,"They still seem to have a lower rate of reports, which is better than nothing.",Neutral
AMD,"MSI isnâ€™t immune either. My X870 MSI board started having issues with cold boot stutters after a BIOS update, and a lot of people are experiencing the same problem while MSI is ignoring it.",Negative
AMD,Itâ€™s AMD lol,Neutral
AMD,"It's possible.  If you run a power-limit-saturating workload with an undervolt, the chip is drawing more current than it does at stock. [Current density drives electromigration](https://en.wikipedia.org/wiki/Electromigration#Electromigration_reliability_of_a_wire_(Black's_equation\))",Neutral
AMD,"Yeh highly highly unlikely, less voltage and lower temps really ain't gonna hurt a CPU.  So if you use PBO and a negative voltage curve offset like most people who know what they are doing will, I was be shocked if it caused ant issues outside of stability of you push it too far.  I run -40 negative curve offset on my 9800x3d and it sits at 55c in games non stop and 5.4ghz all day",Negative
AMD,This post here says no undervolt and chip burned [https://www.reddit.com/r/hardware/comments/1qkr8ve/asus\_issues\_internal\_review\_after\_amd\_ryzen\_7/o1f7x9z/?context=1](https://www.reddit.com/r/hardware/comments/1qkr8ve/asus_issues_internal_review_after_amd_ryzen_7/o1f7x9z/?context=1),Neutral
AMD,"Many motherboards have had issues with sleep and wake modes for as long as I can remember going back to the early 2010s and they still do today.  I remember dealing with sleep mode issues on my Sandy Bridge PC back in 2011 and all the way up to current gen itâ€™s still been wonky for some reason. My current MSI motherboard has issues with randomly stuttering on cold boot, and MSI doesnâ€™t even acknowledge or say anything about the issue.",Negative
AMD,"Wait by ""Sleep Mode"" is that just putting the PC to sleep/suspend thru the OS?",Neutral
AMD,Sleep mode was always fucked due to how much software is allowed to issue random wakes for no good reason. I found it to be a hundred times simpler to just go into idle monitors off mode and leave it spinning.,Negative
AMD,"Sleep is great on my 12600. It used to not wake up rarely in the past, but doesn't do that any more.  But I've also disabled fast shutdown and stopped Windows from updating. So I have a much more stable system.",Positive
AMD,"I had one die too.  I got lucky though, AMD replaced it with a 5800X3D.  Hope that doesnâ€™t die now.",Negative
AMD,which motherboard u are using? B550,Neutral
AMD,Nope. It doesn't matter if you undervolt or put a higher voltage.,Neutral
AMD,I had VSoC set to 1.2. Just hard set it to 1.2 then disable PBO and dont use Curve Optimizer/Shaper - it's really not worth it.,Negative
AMD,Isn't ASUS a major shareholder in AsRock and share many components?,Neutral
AMD,"> Our teams are conducting preventive checks on product compatibility and performance, working closely with AMD to validate reported cases and ensure ongoing stability and quality.  ...means ""they haven't been receiving any word back."" to you? /r/hardware really grasps at any straw to trash AMD.",Neutral
AMD,Are the 600 series board affected? I got the ASUS X670E last year; pretty happy with it.,Positive
AMD,"It's got a decent warranty, no?",Neutral
AMD,I seem to remember ive read something about a particularity/glitch in gigabyte boards and a particular setting in bios that had been giving problems to the point of fucking up some boards for the bunch of people who had to update or modify something in the bios in order to have secure boot and be able to play battlefield 6. I think it was actually 2 settings in there and once you triggered the board would be stuck or some shit like that  I have a gigabyte board and im not planning to update the bios or change anything anytime soon but if I had to I would head down to the gigabyte reddit to ask first because Im pretty sure ive read they have some kind of unique glitch to them  maybe that was the issue your friend was having cause he somehow triggered it,Neutral
AMD,"Intel 13th/14th gen issues hit volume customers, and that's why it gained traction - it had very little to do with the average consumer PC builder's experience, other than it mimicked the kinds of experiences larger datacenter operators and OEMs experienced in their own operations.  Unless the AMD issues rise to that level of impact for any extended period of time, it will likely stay quiet.",Neutral
AMD,Likely intel's microcode killing 13th and 14th gen. It's popular in here to drag 'techtubers' because they say mean things about the mega corps.,Negative
AMD,"So, most weren't using PBO.  I was hoping that wasn't the case, so we could simply not use it and have a bit of piece of mind.",Negative
AMD,"Itâ€™s always been the PBO defaults IMHO. Also, the x3d boost crap as well.  The cache makes everything more sensitive to issues obviously. Happy with my b650 choice over the 850 and the offset/undervolt.",Negative
AMD,"Literally thousands 9800x3d CPUs died on Gigabyte boards, same as AsRock, Asus or MSI.",Negative
AMD,Guess we just die then,Negative
AMD,"I hope it isn't AMD because I would be really fucking pissed if I'm sitting on a $3,000 time bomb with an arbitrary fuse.",Negative
AMD,and it was intel not too long ago also.... its almost like they are pre overclocking all the CPU with a boosts and increase voltages to hit peak clock speeds and win benchmarks in the consumer space.  We dont hear about this from either vendor in the server space as they are much more conservative in that regard as stability is #1 priority.  Sadly I think its going to become the new norm.,Negative
AMD,"The undervolting on amd is pretty insignificant, -30millivolt is less than 3%, i highly doubt that would produce significant increases in electromigration",Negative
AMD,"Ah, thx.",Positive
AMD,"Thanks, makes more sense now.",Positive
AMD,I never have problem with sleep since 2010s on desktop.,Positive
AMD,"Oh, I do not doubt that poor testing and underinvestment in firmware are common, but that doesn't excuse it. A $250 motherboard shouldn't have stupid firmware bugs that cost the user an extra $25/year in electricity (in cheap places...) or alternately several minutes a day recreating context.",Negative
AMD,"I assume that is what we are all talking about. The same part of the UI that used to expose ACPI S3 suspend when that was the only way to do it, but now exposes S0iX (except when it doesn't).",Neutral
AMD,The only software waking up the computer is Windows trying to do updates at 3AM.  Disable schedule updates and everything is fine.,Neutral
AMD,Sleep mode (S4) and modern standby (S0) are obviously far more useful for laptops.,Positive
AMD,lmao if someone in this thread scores a free 9850X3D if it goes belly up on them.,Negative
AMD,"I know it may sound weird, but I don't remember what model was in that build.  It's been like 6 months since that CPU died and I've replaced almost all things",Negative
AMD,of course it doesnt when the sock will randomly run the CPU at 1.55V whatever your settings are.,Neutral
AMD,this is what i did. i set it to 1.22 then disabled PBO.,Neutral
AMD,"Exactly. The issue stems beyond the motherboard manufactures, whether the issue lies within a flaw of the chip or in the AGESA coding for the BIOS.   Edit: Downvote all you want, the issue is on AMDs side when the BIOS updates clearly aren't doing anything to stop the chips from dying.",Negative
AMD,Isn't this stuff the reason they're releasing the 9850x3d?  With the 7800x3d we didn't need a year plus of bios updates or a 7850x3d to fix it since it was genuinely board vendors over-juicing their boards.,Negative
AMD,Everyone? ASRock(Asus) teamed up with Asus to do something? Are we being fr?,Neutral
AMD,"Not since 2007/2008. ASRock was spun off from ASUS around that time period, and became their own company. Both operate under their parent (Pegatron) but are independent from one another.",Neutral
AMD,What does ASUS PR statement have to do with ASRock?,Neutral
AMD,"If you go back and read my first comment, I was talking about ASRock being upfront about reaching out to AMD and not hearing anything back. All you did was quote an *ASUS* comment from the article, which doesn't pertain to ASRock.   So let me get this straight....ASRock, ASUS, MSI, and Gigabyte (few posts but nothing too substantial) are all experiencing issues with the 9000 series CPUs dying right? AMD was blaming motherboard manufactures over the Summer, and each one has released several BIOS revisions that...guess what? Aren't stopping the chips from dying.   Are you going to really sit here, and throw out the excuse that ""Ohhhh r/hardware is just trying to find any reason to blame AMD and throw trash at them!!!"". The fact of the matter is, the motherboard manufacturers don't know what the issue is. So clearly the issue definitely falls on AMD, because nobody knows what the hell is happening.",Negative
AMD,"Reading comprehension is an essential skill for becoming a functional adult and joining the workforce.Â You will struggle significantly in your professional life if this is how you respond on impulse.   I highly encourage you to read books, then think about what you read, write a report for yourself, and then read more books.",Neutral
AMD,https://youtu.be/jiEv6VTDt5c?feature=shared  Start here buddy.,Neutral
AMD,"I am using ASUS TUF Gaming X670E-Plus WiFi, my 9800x3d died in October after being installed in February of last year. First CPU I have ever had die in 25y building personal computers...  Oddly, the CPU had some dark marks on pin contacts like it was starting to scorch, i took pictures,  I cleaned it up with alcohol to see if it'd work but that didnt fix it. Temps were ~65C under load with AIO cooler. Corsair 1000w shift PSU. Stock PSU cables.   https://imgur.com/a/vMDaEl8",Negative
AMD,"I'd prefer not to actually test how the Asus e-store where i bought my motherboard and Amazon where i bought my CPU, would coordinate liability in case both pieces of hardware get fried.",Negative
AMD,"What are the PBO offsets, if you know? Iâ€™m on MSI which donâ€™t seem to be having as many problems (and a 7800X3D), but Iâ€™m trying to be extra cautious lol.",Neutral
AMD,"Thousands? Got any reporting for that? Because that sounds like an incredibly large number.  But also, the kind of number someone would just throw out there.",Negative
AMD,Do you have a source for the thousands?  I've seen a bunch myself but wasn't aware of that many.,Neutral
AMD,If its failing on all motherboards whats the common factor?,Negative
AMD,Only way to run CPUâ€™s safely is the tried and tested method of static Vcore with a droopy LLC. Any other method clearly isnâ€™t safe,Negative
AMD,They have to buy ram though. 50/50,Neutral
AMD,"They're still a major shareholder, like they said.",Neutral
AMD,I meant like yes they were spun off but still are quite related. Hell sometimes their boards have very similar defects.,Negative
AMD,did you undervolt or overclocked your cpu?,Neutral
AMD,Now I'm a little worried. I have the X670E-PRO and 9800X3D ... for about 10 months. I have a little bit of undervolt -10mv for a bit of performance boost.,Negative
AMD,Haha. That's why I used overclockers for all my purchases LOL.  3-year warranty!,Positive
AMD,Obviously but it's not like you're stuck with a dead cpu if it's a problematic unit,Negative
AMD,"MSI have the same issues like any other board maker, it's just not as popular in US and A so you have to find informations about it's issues outside reddit or twitter.",Negative
AMD,I really hope you're wrong.,Negative
AMD,"Nope. It literally does not matter, your CPU can die on stock settings.",Negative
AMD,"That hasn't been true since 2009, when ASUS sold off its last shares of Pegatron. They are not a shareholder.",Negative
AMD,"Their relation ends at the parent company, otherwise, that's pretty much it. Which defects are you referring to, outside of the current ongoing problem?  Edit: ASUS sold off its stake in Pegatron (finalized in 2012), which means they are not a major shareholder.  [Asianometry](https://www.asianometry.com/p/asus-explained-a-rare-taiwanese-global) did a mini doc/article back in 2021 going over ASUS(tek)/Pegatron separation/spin-off.   [Techpowerup](https://www.techpowerup.com/163250/asus-to-release-its-stake-in-pegatron) wrote a brief article confirming the finalization of ASUS releasing its stake of Pegatron in 2012.",Neutral
AMD,"No longer true, ASUS sold their stake in Pegatron in 2009. They don't have a stake in ownership of ASRock.",Neutral
AMD,Kept the bios default except changing RAM from 5600 to 6000. Crucial Pro 96GB (2x48) kit.   The only undervolt I did was to the GPU when i had an AMD 9070xt. Swapped this out after a month when i was able to source a 5070ti. I dont think that would affect the CPU at all.,Neutral
AMD,"RMA process wasnt bad with AMD, I'd only worry if you bought it used or dont have a valid warranty for some other reason. They ask for proof of purchase and a photo of the product. I gave them a PDF from a downloaded invoice from Microcenter, and a photo of the CPU on its retail box. Turnaround time was 2 weeks.",Neutral
AMD,stock settings are strongly overvolted nowadays.,Negative
AMD,Yeah?? Iâ€™m saying static Vcore with a droopy LLC is the only safe way to run CPUâ€™s,Neutral
AMD,"Thatâ€™s like saying â€œthey are brother and sisterâ€¦ their relation ends at their parents, thatâ€™s pretty much itâ€.  You donâ€™t get much more related as 2 companies than having the same parent company.",Neutral
AMD,Pegatron is *not* Asus' patent company. Your initial comment is incorrect.,Negative
AMD,bios default has PBO turned on and soc on auto right? i set a static 1.2v on my soc and turned of pbo due to this. i hope that helps.,Neutral
AMD,Nope. Doesn't matter at all.,Neutral
AMD,I don't think PBO is enabled by default. You have to agree to overclocking when you go to the PBO BIOS page if I remember correctly,Neutral
AMD,It does.,Neutral
AMD,Nope.,Neutral
AMD,Standard mid-cycle MSRP reset.,Neutral
AMD,6-7% price jump for even 5% performance would still be well under the usual premium charged for Halo products. I'm ok with it.,Positive
AMD,"From what I can see the cheapest 9800X3D right now online (no Microcenter deals) is $469. 6-7% price increase is fine I guess for a rumoured 7%-10% perf jump (usually value decreases for more expensive parts). Then again, I'm sure that the 9800X3D price will drop when this launches, which is welcome I guess. Maybe $400 9800X3Ds? Though that will make the 9850X3D basically DOA.   Checked, and it's at $449 in the Philippines but I guess that's more on our currency dropping in value and stores not updating prices yet lmao.",Neutral
AMD,"Might as well throw out this old R7 7800X3D, there's an entire 10 extra Minecraft FPS out there for the taking now!",Neutral
AMD,Hopefully the suicide rate for these will be lower than the 9800X3D,Neutral
AMD,So Iâ€™m not sad that I spend 260â‚¬ two weeks ago for a 7800x3d.,Negative
AMD,I am skeptical that would actually be the price on shelves,Negative
AMD,What is the likelihood that Nova Lake equals or surpasses the 9850?,Neutral
AMD,"It seems that memory performance has improved, but since Infinity Fabric has not kept up, it's actually just an improvement in CPU clock speed. $499 is reasonable.",Neutral
AMD,Anyone preorder on Amazon? If so what was your delivery date?,Neutral
AMD,It shows in stock at amazon now: [https://instockalert.io/us/ds/amd-ryzen-7-9850x3d](https://instockalert.io/us/ds/amd-ryzen-7-9850x3d),Neutral
AMD,Why is that guy smiling? It is not about the price.,Negative
AMD,What about the 9800X3Ds dying?,Negative
AMD,Might get this and check how well it does in the CPU limited scenarios that I have used for testing 14900KS vs 9800X3D.    9800X3D saw good gains with just RAM tuning and I believe 9850X3D will do better.,Positive
AMD,"I kinda did a stupid, got a 870e-e strix relatively cheap and now im waiting for this to hit stores. Hoping my xmp 6400 ram will work without much hastle",Neutral
AMD,Gonna ride out my 7800X3D till AM6 comes out.,Neutral
AMD,bro i just bought a 9800x3d................!!!,Neutral
AMD,Hmm. Not good. Price of 9800X3D will still be $450 then.,Negative
AMD,Yeah cool - still hasn't launched in Australia despite it now being the 30th (so 29th anywhere else) lameeee,Negative
AMD,Would it make sense as an upgrade from a Ryzen 7 7700X or would a 9800X3D be better since prices will most likely drop?,Neutral
AMD,Wasn't this CPU already out?  A step above the 9800X3D?,Neutral
AMD,"What is the actual difference between a 9800X3D and a 9850X3D? What is the purpose of this product?  Better to wait for the ""11800X3D"" or whatever it'll end up being called.",Negative
AMD,"Really wonder if I should upgrade my 3 month old 9800X3D while these ""exist"" before Ai shitshow makes them impossible to find and probably delays the Zen6 into 2027",Negative
AMD,"That's cheaper than I expected.   I already have a 9800X3D though, so I'm waiting to see if Zen 6 will be worth upgrading to. The rumor mill says they will have +50% cores, so the 10800X3D will have 12 cores and 24 threads, that is going to be upgrade worthy for sure if the price is somewhat similar to current gen.",Positive
AMD,The people who would consider upgrading are priced out of DDR5 so this CPU is DOA.,Neutral
AMD,"Yea, I thought there was no way they'd do 499 -  I mean for one, it's AMD, but a product like this, like a KS, normally has a stupid premium attached.  I'm surprised at anything below 549.",Negative
AMD,"They're hedging against ram prices, good move.",Positive
AMD,>Maybe $400 9800X3Ds? Though that will make the 9850X3D basically DOA.  Products like this are never DOA if they are the best thing available. Plenty of people bought 12/13/14900KS's even though it was the same thing with slightly better binning/clock speeds.,Neutral
AMD,There is zero chance this thing is anywhere NEAR 10% faster unless AMD is putting like twice the power through it.,Negative
AMD,think 3%,Neutral
AMD,It's a \~3% gaming performance improvement even by AMD's own slides.  Productivity might be closer to 7% but that's about the theoretical max what you'd see.,Positive
AMD,dude 400mhz boost (200 if you count pbo) is not going to be in the same universe with 7-10% perf jump LOL,Negative
AMD,"No it won't, it was reported this replaces the 9800X3D.",Neutral
AMD,30->40 great  290->300 meh,Positive
AMD,"Same, I'll probably ride my 7800X3D until Zen 7 releases ( apparently still on AM5 if the rumors are true ), then I'll probably grab a CPU in the X3D Zen 7 lineup and ride that until AM7.",Neutral
AMD,"Yeah depending on your GPU and resolution, and the games you play, you probably get 95% of the gaming performance in real world FPS of the 9850X3D for half the price.  That's money well spent.",Positive
AMD,Well the expensive thing will be DDR5 so the price of this is irrelevant.,Neutral
AMD,"I donâ€™t think there will be much demand, itâ€™s basically just a replacement/refresh of the 9800X3D and most people that wanted one of those already have one.",Neutral
AMD,Amazon drop their stock today and still in stock. That is the price. Delivery date February 1st.,Neutral
AMD,"Nova Lake will basically be a full node advantage.  So in power efficiency, certainty.  In productivity, almost a certainty. You have to go to 9950 to be competitive against the 285HX (although that's on N3B)  In gaming performance, it depends, esp. on how much cache they're going to put on and how much latency their design has.  In terms of price/performance, depends on their yields.",Positive
AMD,"unless Intel has an alternative for 3d cache, it's not happening lol",Neutral
AMD,Mine is supposed to come in on the 5th,Neutral
AMD,Did you preorder? Mine says delivery 2/6-2/13. Wondering if others who preordered before me show 1/29,Neutral
AMD,Someone must be new to marketing,Neutral
AMD,Me too! ðŸ¥¹ should be a problem with this? I hope not. Sheesh..,Negative
AMD,All the â€œtestsâ€ of it were just people overclocking 9800X3Ds to match the new speed of this,Neutral
AMD,Are you thinking of the 9**9**50x3D?,Neutral
AMD,AMDâ€™s product cycle for Zen has been pretty consistent at around 18 months. This is confirmation Zen 6 is going to be a little delayed compared to the usual cycle.,Neutral
AMD,"The purpose is that improvements in binning have allowed a clockspeed to only be achieved by a % of 9800X3D's when overclocked can now be achieved by most, so it'll be relaunched with that new clockspeed.  This gives a ""new"" product from AMD to have for the press cycle to cover because we're still several quarters away from Zen 6 (it's no coincidence review embargo for 9850X3D comes the day after PTL's)  It'll also reset ASPs on this product up by $20 without ""raising"" prices",Neutral
AMD,It serves the same purpose as what Intel's i9-KS products did.,Neutral
AMD,> What is the purpose of this product?  Make money,Neutral
AMD,The biggest mistake someone can make is waiting for next generation.,Negative
AMD,sounds like a waste of money to me,Negative
AMD,"imo, the only way that would make sense is if you could use your old cpu in another system.",Neutral
AMD,"The only one that might be worth it is the 9950X3D2 when it comes out, with dual CCD. But even then youre pretty far into niche territory. Youd have to be hitting your CPU pretty hard to max out the 3D V-cache and need a 2nd one.",Neutral
AMD,"Why do you wonder that? Of course you shouldn't. It's not even worth the effort it would take to physically swap the CPU out, let alone the money that will be wasted.",Negative
AMD,People who will spend $500 on a CPU are absolutely not 'priced out' because of memory. :/,Negative
AMD,So people who are already on AM5 but not using X3D yet don't exist?,Neutral
AMD,"I am on 7700X and happy, but I might upgrade to this chip one day",Positive
AMD,"12900K is a different chip (less cache, less E-cores, won't destroy itself, etc.). 13900K/14900K/KS/etc. are the same chip with different binning.",Neutral
AMD,"It wont be 10%, PC's scale more or less pretty linear with performance under normal conditions, a jump from 5.2Ghz all core to 5.6Ghz is a difference of 7-8% at most and that ofc only goes if the CPU is the bottleneck.",Neutral
AMD,productivity is the only reason you would get this CPU in the first place.,Neutral
AMD,"400 with PBO still, you can PBO both chips.",Neutral
AMD,"It's hard to imagine it won't, but that is still rumor.  2-4% gaming improvement and 5-7% productivity improvement isn't exactly a product segmentation step.",Neutral
AMD,8.3 ms vs 0.1 ms reduction in input lag,Neutral
AMD,"Same boat. The 78x3D doesn't get the same praise as the 58x3d, but it's a considerable bump in performance and it uses so little power.   I will run this until whatever the last gen x3d on AM5 is, then probably be able to run that for 3-5 more years.",Neutral
AMD,"Just put 5 times as much DDR1 then, lmao",Neutral
AMD,Zen 6 x3D just needs a 32 GB cache.,Neutral
AMD,"Yeah I would upgrade (from 5800X) and buy this, but not with the current RAM situation.  I bet these companies are pissed too. Like AMD/Intel (CPU sales), Valve (new steam machine), potentially even Apple?",Negative
AMD,"Yeah, the only real market I see for this (other than people strongly affected by FOMO who need the absolute best of the best for their system and upgrade every single time a new part comes out) are people who are just building a new system from scratch and do want the best of the best. And I don't think many people are keen on building with this current market.",Negative
AMD,"I believe they were talking about gaming performance specifically. Since you don't compare 1 SKU to an entire generation like Nova Lake.   But by the time Nova Lake releases, Zen 6 comes under contention as well.",Neutral
AMD,Do you mean 285K? Because from the reports I've seen that's what the 9950x competes with. The 9900x for 265k and such.,Neutral
AMD,"I think Nova Lake is supposed to have an equivalent, bLLC or something like that.",Neutral
AMD,"Nova Lake is supposed to have a large cache variant, although it is not 3D stacked, so the latency advantage of 3D stacking remains to be seen.",Neutral
AMD,Last rumors has Nova-Lake with 144-288 MB of bLLC depending on the model.,Neutral
AMD,"I just want to know if I should wait for Nova Lake or get a 9850. For gaming, ofc",Neutral
AMD,I just saw performance uplift it ainâ€™t worth the return process for it.,Negative
AMD,Maybe so.  All the naming is confusing.  Why would they release a 9950 and 9800 but not a 9850?,Negative
AMD,"Maybe, maybe not. Zen 4 and 5 haven't stopped the seemingly endless Zen 3 releases.",Neutral
AMD,"No? Where did this myth come from, anyway? The idea of constantly waiting for whatever someone thinks the ""next gen"" is, that doesn't make any sense.  I have a 9600X now. A 9800X3D isn't that great when I know that a perfectly good upgrade is coming relatively soon. Zen 6 will also likely be the last gen on AM5, so it's not likely to get better than this. Unless society simply implodes within 2026~2027, we'll be fine.",Negative
AMD,"Nope, I would just sell the 9800x3d for $400",Neutral
AMD,"It's not a matter of how hard you're hitting it, it's the nature of the applications hitting it. Cross CCD latency is [about as ""bad"" as that of going out to RAM](https://www.overclock.net/threads/official-zen-5-owners-club-9600x-9700x-9900x-9950x.1811777/page-53?post_id=29367748#post-29367748) (both are roughly around 75ns or so, vs ~12ns for local L3 Cache), defeating the benefit of the X3D cache entirely. [There are ways to make applications that are able to intelligently allocate their own threads within a given physical CCD](https://chipsandcheese.com/p/evaluating-uniform-memory-access), but as far as I know, the means for that feature set isn't included in AMD consumer chips (there *are* multi-X3D-CCD Epyc CPUs for niche applications). Adding those features to a consumer product would mean AMD undercutting their enterprise products by thousands of dollars per unit.  That's why I'm skeptical of a dual-X3D-CCD consumer part every time it comes up. Even if they do release it, it will have to be aggressively gimped to avoid losing them a ton of money while also being a major disappointment to the people that think they want it. The more likely move would be a 9950X3D with better binned silicon like the 9850X3D is (something akin to AMD's old ""XT"" refresh skews or Intel's ""KS"" models).",Negative
AMD,Says you,Neutral
AMD,"That has nothing to do with what I said. There is a 12900KS, which is  a better binned 12900K.",Neutral
AMD,You wouldn't get a 9850X3D over a 9900X3D or 9950X3D if productivity is the thing you care about.  The 9850 would be for people who would want to pay a premium to have the marginally fastest gaming CPU.,Neutral
AMD,If you care about productivity then this is not the chip for you.  285K is 69% faster MT | 15% faster ST  9950X3D is 76% faster MT | 7% faster ST  Even 265K and 9900X3D are much better options closer to that price range.,Negative
AMD,"is this, like, confirmed?",Neutral
AMD,33% increase in frames v.s 3% increase in frames is another good way to understand why the returns diminish the further you go,Neutral
AMD,"I mean, I don't think thats true. The 7800X3D was unanimously the most praised AM5 chip when it came out and its efficiency was a core reason as to why. It's not as glazed relatively speaking because the 5800X3D was just such an anomaly. It offered 7600X performance to users that didn't want to upgrade to AM5, was very power efficient going against the 12900K, was fairly cheap for what you got AND was dropped mid cycle for AM5 when everyone would've thought AM4 was dead + people were complaining about DDR5 pricing when AM5 launched and this was a saviour.  Like, the 5800x3D really caught a perfect storm. And the 7800 did get surpassed a few years later (even if by a fairly small margin) so it loses that Halo effect for people.",Neutral
AMD,"you need to double the bandwidth for each gen (not exactly so, but a general approximation). So for DDR1 you would need 16 times as much running in 32 channel mode.",Neutral
AMD,"You could also see people who were putting off upgrading from a 7000 series part finally decide to pull the trigger. It's obviously not worth going from the 9800X3D to the 9850X3D, but if you're moving up a generation having a little bump like this can push you over the threshold to buy.",Neutral
AMD,"I'm still rocking a 5800x3d, so yes, I'm considering it. Only if I can get a nice combo deal with the ram though. Maybe won't at all lol",Positive
AMD,"Yeah, likely X3D Zen 6 will be quite a bit after Nova Lake.  So they might take the crown, but that's the one that they have the least chance at IMO.",Neutral
AMD,"Yes, sorry, brain fart. I am so sick of the terrible marketing names.",Negative
AMD,wouldnt a side cache introduce same latency issues as going to read the cache from the second CCD? in which case we know this has actual impact.,Neutral
AMD,nova lake is launching in like late 2026 and is a complete unknown  go for 9800x3d/9850x3d,Neutral
AMD,"Just wait, soon we'll have the 9950X3D2",Positive
AMD,"The 9850X3D is just a better binned 9800X3D.  The step above the 9800X3D is the 9900X3D. You get more threads, but lower boost as it's contained within 120 W TDP.  You get 45% more productivity for 7% lower gaming performance or  90% more productivity for like 2% lower gaming performance.",Neutral
AMD,"The Zen 3 parts that are getting released were all manufactured years ago. They just didn't hit requirements, so once enough defective inventory built up, they were released as a new SKU in small numbers",Negative
AMD,Iâ€™m in the same exact scenario. I think we can get $400 for our 9800 cpu.,Neutral
AMD,"I mean... yes? That is literally correct, I did say that.  That not withstanding, how do you justify spending ~$100 (provided you get ~$400 for your 9800X3D, and ignoring potential selling fees) for maybe 8% more FPS in the best case scenario? Are you even stressing the 9800X3D with your 9070 XT, or would you land at literally the same performance after the swap?",Neutral
AMD,"No, gaming gains here are irrelevant. Productivity gains of 7% can make enough difference to pay for itself. Productivity is the only scenario where this is useful.",Positive
AMD,Nah but id be very surprised if they weren't like all other Zen 5 chips are able to do.,Neutral
AMD,"Even then, going from 290 FPS to 386 FPS (33% increase) is a much less noticeable change than going from 30 to 40 because it's still a much lower decrease in input lag.",Neutral
AMD,"Makes sense. The 78x3d was certainly very well received. It got buy recommendations from reviewers and it was the top of the line during it's run. I got mine at the low point in it's price history for ~$300, which was a steal imo. I can't imagine anyone with this cpu will feel the need to upgrade (for gaming) for a long time.   I agree that the 58x3d was the perfect cpu for a perfect situation.",Positive
AMD,"Well, then just don't put any DDR ICs on your board, boot up from on-chip memory with a minimal bootloader, and download some more RAM onto the board from one of those webpages.",Neutral
AMD,No problem. Laptop SKUs are especially confusing.,Negative
AMD,Depends on the interconnect no? From what I know infinity fabric is the only thing that prevents cross die memory access for AMD.,Neutral
AMD,"I mean this is the same thing, they just built up enough inventory of good 9800X3D bins.",Neutral
AMD,Productivity more so cares about multi core performance and you wouldn't pick a 8 core CPU with somewhat better single core performance over a 16 core CPU like the 9950 with more than 50% higher performance.  Gaming gains are marginal/irrelevant but they will be the reason people will buy it for and it is also how it is being marketed.,Neutral
AMD,"True, I just think the raw percentages are easier for most people to understand.   Modern computing really is a marvel man. If you would've told 14yo me that one day I'd have a CPU / GPU that crushed basically everything at 1440p 180Hz and wasn't even technically the top end I would've shit lol",Neutral
AMD,"Definitely a steal. That's near 5700X3D cheap for like 30% better performance and more upgrades available.  I wouldn't be surprised if the 7800X3D lasts a decade. Though, the rumoured increase in core counts for the next gen does make it a tad less likely. It's still gonna last a damn long time though.",Positive
AMD,"Also bought it at around its all time low, had no idea. It was in May 2024 if I remember well.  Bought it because the relatively recently released Helldivers 2 was obliterating my ole trusty i7-8700, the GPU was twiddling its thumbs at as low as 35% usage.  I was considering waiting for the 9800X3D, glad I didn't.",Negative
AMD,"Considering ArrowLake has increased latency issues even inside the same CCD, im not so certain Intel is going to solve this issue.",Negative
AMD,My old child self running the CRT at 85hz back in the day dreamed of beating 100 hz on the screen. Now i got  a 144hz monitor :),Positive
AMD,"Summary:  â€œWhile the Ryzen AI Max+ 395 was faster overall, the Framework Desktop was consuming more power than the Dell Pro Max GB10. On average the Framework Desktop over this entire span of CPU benchmarks saw an average wall power reading of 133 Watts with a recorded peak of 227 Watts. The Dell Pro Max GB10 meanwhile had a 103 Watt average with a recorded 164 Watt peak for all of these benchmarks. So while the Framework Desktop performance geo mean was at 1.285x, the total system power consumption was 1.29x higher on average and the peak was 1.38x.  If you are investing in the Dell Pro Max GB10 or any other GB10 platform, chances are though you are running AI workloads and other software fully engaging both the CPU and GPU. The Blackwell GPU with the GB10 offers a lot more compute potential over the Radeon 8060S graphics but similarly the Dell Pro Max GB10 pricing is around $4139 USD as of writing and the Framework Desktop around $2928 USD if going for the same RAM and storage capacity. More GB10 GPU benchmarks are on the way at Phoronix.â€",Neutral
AMD,I have GB10 in my lab. The real issue with my unit is thermal throttling.  When it reaches 70C throttling kicks in and the performance drops a lot. Forcing additional air using a mini blower it maintains much higher interference tokens/s.,Negative
AMD,The GPU portion will be the juicy bit,Neutral
AMD,"As someone who's mostly into applied math and stats research rather than hardware, I'm always a bit confused as to how to parse these for my own use cases. Which of these benchmarks correspond to decomposing thousands of large matrices/arrays in parallel using Python or R (which I suppose use LAPACK or something like that in the backend)?",Neutral
AMD,"Not mentioned here, but when you start going concurrent performance testing, via vLLM, the GB10 ends up being 4x to 5x faster than the Strix Halo (which itself can be quite faster with concurrency).",Positive
AMD,"The lack of a real efficiency advantage was baffling given Nvidia/Mediatek are using an N3 node. You'd expect higher efficiency, not the same (Halo has +28% geomean performance at +29% avg power consumption).   Obviously the Nvidia chip focus is more on the GPU though.",Negative
AMD,[That was the prior article](https://www.phoronix.com/review/dell-pro-max-gb10-llama-cpp).,Neutral
AMD,"PETSc is functionally somewhat in that field: https://petsc.org/release/manualpages/   Video encoding is a massive matrix calculation session, but usually using heavily optimized assembly over standard libraries that you'd use.      You can check open benchmark for full results, to see if some libraries are familiar: https://openbenchmarking.org/result/2601218-NE-DELLPROMA02&sgm=1&asm=1&ppw=1&sor=1&scalar#results",Neutral
AMD,"That might simply be due to the fact that Strix Halo has a much wider CPU. It's 16 Big Cores + SMT. So at a given wattage, Strix Halo can run at lower clock speeds and thus match the efficiency of GB10.  It also does not help that GB10 is using a generation older ARM CPU cores, with less cache and a strange cluster arrangement to top it all.",Neutral
AMD,The GB10 devices come with ConnectX card that is probably responsible for some 5-10W of base load.,Neutral
AMD,DGX Spark power management is uhh a tad lacking and comes with... oddities.  It has a tendency of putting itself in really deep power states too eagerly while taking a while to wake back up: https://forums.developer.nvidia.com/t/connectx-7-nic-in-dgx-spark/350417/51  Wonder how much that might have affected perf results for some subtests. It _should_ have no impact on number crunching style workloads though.,Negative
AMD,Perhaps better optimisation of x86 code?,Neutral
AMD,I think you are underestimating Mediateks architectural prowess here. They know how to make tiny microcontrollers. They dont have good record with CPUs. And Nvidia here is likely not doing the designs outside of the GPU.,Negative
AMD,"I know, it deserved its own thread on here too. I think it didnâ€™t get one.",Negative
AMD,"Video encode uses simd on cpus, but doesn't do much where fast matrix multiplies would be helpful.",Negative
AMD,"GB10 has 20 cores, although it's fair to point out half of those are small-ish A725 cores.",Neutral
AMD,You're forgetting 1 thing. Finflex.,Negative
AMD,"5-10W sounds low to me. Removing the DAC cables only strips off 4W right now, it's more in the 20W range eaten by the NIC.  That said the next major kernel update for it will address things hopefully by allowing the NIC to actually go in a lower power state: https://github.com/NVIDIA/NV-Kernels/commit/18a062fe0c4965eb6a2ddddfe8de8e465d05a98e",Neutral
AMD,The ConnectX card is the big difference maker in value as well. Connecting two is a pretty easy upgrade. If you were going to get only one then Strix Halo would be a better pick if you don't need something Nvidia specific. Even more so before the RAM prices really drove up pricing on the Framework.,Positive
AMD,">Â although it's fair to point out half of those are small-ish A725 cores.  More than fair. An A725 in the GB10 has half the ST perf of their X925s, though the gap may close in nT workloads depending on how high each core is boosting there.",Neutral
AMD,Which is offset somewhat by lack of SMT and IPC of an older arm architecture,Negative
AMD,what about it?,Neutral
AMD,"Yep, the GB10's A725 are only paired with 0.5MB L2, that'd be barely larger than 1mm2, i.e. far smaller than Zen5C, similar to Intel's Mont cores  That's the same L2 MediaTek uses for the E-Cores/little-Cores (A720/C1-Pro) in their D9400/D9500  Also the GB10 has a weird asymmetric L3 cache. One X925+A725 cluster has access to 16MB L3, the other X925+A725 cluster has access to only 8MB L3. Whereas [each of Strix Halo's 8C clusters has their own 32MB L3 each](https://substackcdn.com/image/fetch/$s_!OGNa!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbc6d88c-c362-4ea6-8a86-f677313342a1_1600x1016.png)  Don't think they've released die shots yet, but the GB10's is probably around 50mm2 (estimated from the D9400/D9500). Strix Halo's CPU probably is about 2.5x larger with about 1.5-2x more transistors once accounting for N3 vs N4",Neutral
AMD,"I mean, the reality is that it is just a quick and lazy refresh right? the two chips are pretty much identical, just with higher clocks.     You'd assume that as a ""flagship"" level chip initially, AMD didn't leave too much performance on the table",Neutral
AMD,to the surprise of no one. on the plus side the msrp  is only an extra 20,Positive
AMD,"Intel KS-style refresh, as expected. Just wish they also binned the IOD.",Neutral
AMD,Performance uplift doesn't even matter for me. I'm more interested in durability and quality. How long we can use it before sending a warranty claim.,Neutral
AMD,I'm pretty happy I didn't wait for this and just bought the 9800X3D at a lower MSRP.,Positive
AMD,4% faster 20% more power - AMD back at it again,Positive
AMD,Cool beans my over clocked 9800x3d is essentially the same thing. FOMO avoided.,Neutral
AMD,Isn't that a kind of stupid take coming from a channel mostly dedicated to OCing???,Negative
AMD,Sure. Who cares though? It's like saying the 5090 would be a lot more efficient at 450-500W for 5% less performance. People who bought it don't give a shit. People who will buy this won't give a shit either.  Almost everyone would be much better served with a 7500F or 9600X and putting the spare $250 to almost $400 in the 7500F's case towards a way faster GPU. That's the difference between a 9060 XT 8GB and a 9070 XT.,Negative
AMD,"those ""new"" products like Ryzen 9850X3D or Gorgon Point are just stupid and pointless and it's an objective fact  they are only making bad press for themselves, people then saying they release same thing twice under different names",Negative
AMD,It's a cycle eh? Sometimes intel sometimes amd. Seem to be on the opposite swings this time,Neutral
AMD,50% less likely to fail probably.,Neutral
AMD,Amd the masters of doing the bare minimum when they're ahead.,Neutral
AMD,when they start releasing bioses for it ?,Neutral
AMD,AMD stagnation in full view. Only took them 5 years of minimal competition to turn into an old Intel mirror.,Negative
AMD,Top end of GPUs and CPUs has usually been like this.  The only way companies might not create a product that operates far beyond the efficient range of the architecture is if they lack competition for the performance crown.,Negative
AMD,"I bet you still get to tune it. I don't see a problem with offering more choice. Not for me, but I don't mind that it exists. I'm perfectly happy with my 7950x3d and my 7800x3d.",Positive
AMD,"Sounds good to me. Unless you live in a third world country power is cheap. I'm paying 10 cents per kilowatt hour, I don't need to worry about a CPU.",Positive
AMD,"Truly AMD's Kaby Lake moment right here lol, undeniably so.. But the sad truth is this product is aimed at people who doesn't care about their money / value and wants the best of the best no matter what, will still buy this, especially over the current 9800X3D which was also a poor value compared to its predecessor 7800X3D that is often on sale around less than $300.",Negative
AMD,"It's not a huge performance uplift, but it's still better than when Intel does their KS CPU's, that only offer 1-2% uplift for $110 more.  AMD gets a little respect for only charging $30 more than the 9800X3D at launch. And simultaneously lowering the MSRP of the 9800X3D.",Neutral
AMD,A very pre 2020 Intel release by AMD.,Neutral
AMD,Could of told you that months ago it's the same chip with a different name,Neutral
AMD,"And yet people are still wanking AMD so bad that Intel decided to just leave the consumer market.   Congratulations, you played yourselves gamers",Negative
AMD,I wonder how the 9900x3d2 will be,Neutral
AMD,"Still better than when Intel does KS CPU's, with just 1-2% performance improvement. AMD's CPU's are at least efficient as standard, when Intel ""wrecks efficiency"", it's on a CPU that already uses 250+ watts as standard.",Positive
AMD,"It's not really a refersh, just catching up with the boost clocks of non-X3D processors. And due to that, the CPU also catches up wit he inefficiency of those boosts clocks.",Neutral
AMD,its like 8700k vs 8086k moment. at least the 8086k had a special part number to commemorate something.,Neutral
AMD,"There is nothing ""lazy"" in a refresh  It's a refresh. Point.",Neutral
AMD,The flagship is the Ryzen 9 tbh,Neutral
AMD,"Its just the same chip but factory overclocked.  As for leaving performance on the table, remmeber x3D memory usually had heat dissipation issues which made AMD be more conversative on all the x3D chip clocks.",Neutral
AMD,If ram prices weren't apocalyptic I would definitely upgrade to this from my am4 build.,Positive
AMD,"Yeah, if this was available for my build I'd have probably gone for it figuring it would be worth seeing how it undervolts once the warranty's done.",Neutral
AMD,"There was some rumor of AMD improving the max memory clocks on the 9850X3D and 9950X3D2 due to suspected delays to TSMCâ€™s process node planned for Zen 6. Not that it would have mattered due to DRAM prices but still, AMD could have at least tried",Neutral
AMD,KS-style refreshes came with an increase of $100-150 costs. AMD went with $20.,Neutral
AMD,Same silicon,Neutral
AMD,Hopefully this doesn't have the same exploding problems.,Negative
AMD,You could undervolt and underclock it to regular 9800X3D spec and if AMD's been better binning these 9850X3D CPU's you'll get a more durable 9800X3D.,Neutral
AMD,You would have to be bit mental to think that there was any fomo to be had in the first place,Negative
AMD,"Yeah even a slight UV + curve optimizer will get you there. Perhaps at a better power consumption also.  At least you know you are getting a better bin of the same chip, if you are an OC or even UV maniac. And it's not $80+ more.  I watched an LTT vid of the same 9800x3d having wildly different variance between their samples they used for benchmarking.",Positive
AMD,A lot of his review content isn't just for some OC audience but relates to usefulness for everyday people.,Positive
AMD,"I'm sure detailed testing videos will follow, it's just a short day one review which is supposed to be informative for people eager to find out if they pull the trigger or or not on buying.  I think his second or third video dedicated to the 5090 was also showing the efficiency gains simply by reducing the power target.  And he has a point. High end hardware releases are just stupidly inefficient. GPUs have been like that since Ampere and RDNA2, Intel went crazy with Alder Lake and threw sanity out of the window with Raptor Lake (S) and this just points out how pointless this CPU is for 99.5% of people, it's just a factory overclock.",Neutral
AMD,the statement is equivalent to there's no oc headspace on the silicon so it's piss poor efficiency. that's not stupid at all.,Negative
AMD,"He said in the video he ran out of time to do that, but it is coming in the next video.",Neutral
AMD,Yes. He has to twerk for Zaddy Bu and Jensen (by shitting on AMD) otherwise they won't give him free shit,Neutral
AMD,"I mean... there is a reason why OCing is done PER CHIP and PER YOUR SETUP no?  you tweak your own chip to perform the best under that condition with your desired parameters, some does outright ghz battle, others prefer lower volts and heat for xyz perf, others want a certain level of performance and then tweak the other stuff.  when you do something like this, you have to hit EVERY CHIP in EVERY SET UP with a hammer to try and squeeze out that bit of performance, it can be on some dinky air cooler that barely cool the thing, or an AIO that can cool it fine, or its on a custom cold plate for the chip in a custom loop and maybe even de-lid and all that.  its more like hey, this is kind of stupid, if you want to OC, do it the proper way with this kind of tuning and if you DO need 25% more power to hit 4% gains, maybe reconsider.",Neutral
AMD,â€œItâ€™s like saying the 5090 at 450w-500w would be much more power efficient at maybe 5% slowerâ€  Der8auer has also made videos directly stating that as well.,Neutral
AMD,"He literally reviewed the 5090 Matrix and said he loved it and ""bought one himself"" when all that was was a hugely overclocked 5090 that used almost TWICE the power and costs 50% more than stock. Somehow that is a great product but a faster CPU for almost the same price is ""inefficient"" lmao.   He's knows where his bread is buttered and it's not by AMD",Positive
AMD,or compared to the 13/14900kf,Neutral
AMD,Iâ€™ll argue the 7800x3d is best investment for 100 more than a 7500f and never have to upgrade until am6 or even mid am6,Positive
AMD,"> It's like saying the 5090 would be a lot more efficient at 450-500W for 5% less performance.  That 5% performance is the entire foundation of any hobby. Athletes are chasing fractions of seconds. If spending $300 on shoes will help, they'll do it.",Neutral
AMD,"this is an overclocking channel, why would he not give a shit about potential OC headroom or lack of it?",Negative
AMD,"Wdym? Itâ€™s just a refresh a year later offering a little more performance at the cost of power efficiency, Intel did this plenty with the KS skus. Itâ€™s not like theyâ€™re taking your 9800X3D away and forcing you to buy this.",Neutral
AMD,Intel's going to do basically the same thing with an entire lineup of ARL-S refreshes soon enough.,Neutral
AMD,"Unlike Intelâ€™s KS SKUs, these arenâ€™t sold for stupidly higher prices",Neutral
AMD,"Not really, the price has barely gone up.",Neutral
AMD,"It could be worse, the zen 2 XT cpu:s where +$50 for a letter in the name.",Negative
AMD,"Itâ€™s almost as if companies are capitalistic and move for money, not to give customers the best experience they can (unless they earn more from doing so).",Negative
AMD,It's a good plan.  No one will be building systems for the next 2 years thanks to ram and storage prices.  A zen6 drop in for existing systems is all we can hope for.  And zen6 on AM4 would be above and beyond.,Neutral
AMD,Are you expecting them to release a new architecture every year? Since when has that been the standard?,Neutral
AMD,"Eh, to be fair they're not advertising this as a new generation like Intel has done multiple times.  9850x3d's name alone shows that it's just a tuned 9800x3d and the price matches that.  The #1 best of anything always has a premium since you can't get to that level of performance otherwise.  I got a 7800x3d at first, returned it, and got a used 9800x3d for $400 since it couldn't maintain 480+ fps on my 480hz monitor in Valorant.",Neutral
AMD,> especially over the current 9800X3D which was also a poor value  Not sure if actually serious or genuinely that stupid,Negative
AMD,Kaby lake clock a lot better than Skylake did. It wasn't just skylake binned harder.,Neutral
AMD,"Kaby Lake wasn't OC'd to the moon from the factory.   I'm sure you meant Raptor Lake that threw efficiency out the window, just to keep Ryzen in its crosshairs.  A CPU pushing 350W at stock is **NOT** normal.",Negative
AMD,"you have to be delusional to think 98xxx3d are bad value, lmao",Negative
AMD,"my friend bought i7-2600k and run with it on 4.8 GHz (yep!) for about 10 years until he bought Ryzen 5700X, which is \~4x faster in practice and uses less energy (this time he doesn't even oc)  however, Kaby Lake could oc sometimes even to 5.1 GHz on air",Positive
AMD,Factory OC.,Neutral
AMD,Gorgon Point is a pretty lazy refresh compared to Hawk Point lol,Negative
AMD,"Because of the chiplet design it doesn't work quite as linear for AMD. They have A tier chiplets, which are used for 8 core chiplet products, then B tier chiplets used for 6 core chiplet products. This makes the 9800 the gaming A tier product, and the 9950 the productivity A tier product.",Neutral
AMD,why after the warranty for just an undervolt lol,Neutral
AMD,Not all silicon is made equal. X58 Westmere Xeons are generally less durable to higher voltage than what was binned for 990X for example.,Neutral
AMD,The same silicon wonâ€™t survive as long if itâ€™s running voltage differently or more of it.,Negative
AMD,"I mean it's the exact same design except it uses higher voltage.  If anything, the issue will probably be slightly worse with this one.",Negative
AMD,Undervolted CPUs are also among those getting wrecked.  I've gone back to stock in the hopes I can avoid ruin on my 9800X3D with x870e Carbon.,Negative
AMD,"really it's wild for anyone to think that like.. if you already are on ryzen 9 you're fine for the next X years.   I'm only now upgrading from a 9900K build to the latest and greatest, and it's only because my 9900K system has went through 3 gpu upgrades and the CPU itself has degraded substantially lol",Negative
AMD,"If you took that sarcasm seriously, you might be the mental one.",Negative
AMD,Polaris also did inefficency.    GPU | node | Typ board power ---|---|---| RX 480|14nm|150W RX 580|14nm|185W RX 590|12nm|235W,Negative
AMD,What? He shits on Intel & Nvidia all the time if not more.,Negative
AMD,"That's a tad disingenuous towards German Jimmy Neutron.  He's an engineer. He gushed over the design, the overbuilt power delivery, the visual flairs, and the raw power of having something that can burn his house down tamed.  He never recommended it, and even said the price was stupid high, but it tickled his fancy.",Neutral
AMD,"[""Just from an objective standpoint, this is a card you can't recommend.""](https://youtu.be/00-9w3uhbpk&t=934)  He bought it because it's a way-over-the-top, limited run, enthusiast, halo product. The 9850X3D is just a mainstream part - a bit over the top for most people actually buying, but nowhere near the same category as a limited edition 800W 5090.",Negative
AMD,"I don't think this is some corruption thing. Both of those can coexist.  The 5090 Matrix is a rare, special anniversary edition of the current best GPU on the market. It's unique and (in my opinion) quite pretty. It also has features that any competitive overclocker would love. Massively overbuilt cooling and power delivery for example. If I were him, I'd probably buy one too.  At the same time, a review can and should talk about efficiency on parts. His regular 5090 review covered this as well.",Positive
AMD,I would never be able to justify purchasing a phallic GPU just for 10% more performance. Get that penis away from my build lol.,Negative
AMD,"In my region you can buy both, a 9600X and a 7500F as backup for a shade less than the 7800X3D. We don't get the same deals on parts as Americans do, but the 7500F is absurdly cheap here. Barely more than the 5600X",Neutral
AMD,"Intel *did* get flack for that. And now AMD is getting flack for it. However, I think people getting upset are annoying: they just bumped clockspeeds as binning improved inbetween generations. The alternative to a refresh is just releasing nothing, and I dont really see how that's preferable either.",Negative
AMD,ARL-S at least has more cores (i7) and higher memory bandwidth,Positive
AMD,XT models were 100-200 MHz faster,Positive
AMD,what would you change?,Neutral
AMD,"Just built my new high end pc yesterday, loving it so far but Iâ€™m still setting it up and getting everything to work properly.  But I spent 700-800 euro more than I would have a few months ago, mainly due to RAM, 64GB cl30 6000mhz. That was with me going crazy to scour everywhere for products that hadnâ€™t hiked in price yet, managed to get a 4tb nvme for the original price although it was the gen5 so it was still expensive, got my PNY 5080 for pretty close to the lowest price it ever was at (1200 euro instead of 1100 euro). RAM was 680 instead of 200 but itâ€™s still hiking so got a relatively good deal as most RAM had already increased beyond that.  The rest didnâ€™t really increase much in price. Searched as much as I could and managed to get some well known quality components for lower than normal price.  So, I spent around 700-800 more now, but ig I had waited a month or two, Iâ€™d have to spend 1000-2000 euro more for the exact same build in addition to thatâ€¦Â   crazy that a mere 64GB RAM is getting as expensive as a 5080â€¦",Positive
AMD,"its the perfect example actually. 14900KS vibes.  Its not like some 9800X3Ds are burning out and we dont knows why, so why not pump even more wattage/voltage through these things, that will SURELY help.",Positive
AMD,Thats the problem,Negative
AMD,"They could increase core count, PCIe lanes, memory bandwidth, but nah theyd rather make that for the rich folks that can afford 10K Epyc parts.",Neutral
AMD,"9800X3D vs 7800X3D barely matters until you put a 5090 in there, or are talking about productivity/AVX-512.",Neutral
AMD,"Not stupid at all, just look at the fps per dollar between 7800X3D at discounted price vs 9800X3D - 9850X3D even most reviewers such as HUB pointed out that if somebody wants high end value cpu, the 7800X3D still holds that title, the 9850X3D are for people who want the bests gaming cpu but doesn't care about value because it costs a lot more than what it provides over the likes of 7800X3D.",Neutral
AMD,"[https://hwbot.org/hardware/processor/core\_i7\_6700k/](https://hwbot.org/hardware/processor/core_i7_6700k/)   [https://hwbot.org/hardware/processor/core\_i7\_7700k/](https://hwbot.org/hardware/processor/core_i7_7700k/)   7700K usually gets more points than 6700K, for example 7760 points in GB6 compared to 7313 points (\~6% more), not much but slightly better than the ""new"" 9850X3D",Neutral
AMD,Stock on Raptor Lake was 253W. Even for the  [14900KS](https://www.intel.com/content/www/us/en/products/sku/237504/intel-core-i9-processor-14900ks-36m-cache-up-to-6-20-ghz/specifications.html).,Neutral
AMD,how many watts?? that's like my 13900k+5070ti combined,Neutral
AMD,It is bad value compared to a 7800X3D that is not that much slower but can be had for much cheaper. I can think of many other ways of getting the 7800X3D instead and spend that extra $150 - $200 on a better GPU or other more important pc parts instead.,Negative
AMD,"well, it isn't good value in terms of ""fps per dollar""",Negative
AMD,High end anything is bad value to be frank.,Negative
AMD,Theyâ€™re pretty bad value considering theyâ€™re much more expensive than 7800X3D. Also thereâ€™s the non zero chance they go poof.,Negative
AMD,How you know me ?,Neutral
AMD,Moore's law is dead,Negative
AMD,Ryzen 9 9950X3D has exact same performance as Ryzen 7 9850X3D.,Neutral
AMD,"And the dying CPUs are heavily correlated to batch, IIRC. AMD may have unknowingly already solved whatever was causing the dying 9800X3Ds here.",Negative
AMD,There is that but also AMD themselves said as much. it's just slightly higher clocked 9800X3D so what did you expect.... it's going to be 20% faster ? HOW ? it's exactly what it says on the tin aka slightly overclocked 9800X3D.,Neutral
AMD,Depends how much of your hobby it is. Also if you upgrade more frequently you can recoup quite a bit of the cost in reselling your relatively new parts.,Neutral
AMD,"Yes there's been examples for ages, but I feel like its been the new norm these days. To come back to the 9850X3D: I understand the release from a business standpoint, but for the consumer it's not a good product, the 9800X3D was already not efficient compared to the 7800X3D, I feel like this might become a slippery slope for AMD now.",Negative
AMD,And besides the matrix was clearly means as a flex card by Asus for their 30th anniversary and as kinda â€œwe can push this amount of power through gpu while itâ€™s air cooled and while temperatures are goodâ€ itâ€™s literally not meant for your average consumer and is more of a collectors item. Which it did itâ€™s trick since my country itâ€™s no longer in stock.,Negative
AMD,"I mean Iâ€™ve never had a problem with the KS skus nor this, more options for customers so long as they keep selling all of them.",Neutral
AMD,Intel got flack for it because it used 400W and needed really expensive memory whilst costing a lot more so the value was insanely bad. Here you are still under 120w and are getting an uplift without needing insanely expensive memory for only $30 more.,Negative
AMD,"Nothing capitalism is amazing its what got us the first CPU's and now these, its not like windows/x86 is the only choice for CPU's or gaming either.",Positive
AMD,"Well clearly if it's so simple that they could just do it, you should go and work for AMD and show them how it's done.",Neutral
AMD,"Zen 6 is rumored to offer 50% more cores per die, so you'll get what you ask for next gen.",Positive
AMD,Depends on the games too. I noticed a difference immediately with PoE2.,Neutral
AMD,Iâ€™d assume most people thinking of 9800X3D and 7800X3D are the 4090/5090 crowd.,Neutral
AMD,"True, at the resolutions and settings people actually play games at you are GPU bound, 4K high on a 5600X produces same fps as a 9800X3D.",Neutral
AMD,"if you are in CPU bottlenecked games theres a difference to be seen even on a 4070. Though personally i didnt consider that ""worth the money"" and am ""stuck"" on a 7800x3D.",Neutral
AMD,"Using MSRP and HUB's game averages, the 9850X3D is only about 8.7% (1080p Medium) to 12.6% (1080p High) higher in price per fps. So it's a worse value, but I don't know that I would call it a ""poor value"". For flagship products I would expect to pay somewhat of a premium.  Sales obviously bring the 7800X3D lower, but I would say that just makes it a good/great value as opposed to the other way around.",Neutral
AMD,"Nobody cares about FPS per dollar, its a worthless metric",Negative
AMD,[i9-14900K Stock vs Undervolted Peak Power Consumption : r/intel](https://www.reddit.com/r/intel/comments/199dyud/i914900k_stock_vs_undervolted_peak_power/),Neutral
AMD,"Absolutely. It is even bad value compared to ""regular"" CPUs, like the 9600X or especially, the 7500F. The 9800X3D is more than 3x the price of the 7500F in my market. There will never be a time when it becomes 3x as fast. Even from the 8-core 7700X, you need to jump up 65% to get to the 9800X3D.  It is not good value by any measure. It just doesn't cop any flak because it is the best of the best for people who want nothing but the best. Kinda like the 4090, except because it is *only* $500 and not $1600, it doesn't appear to be as egregious, even though it is way worse.",Negative
AMD,"Eh, I'd counter that with the improvements in many productivity workloads, and I build my rigs to be able to do those well if called on to.",Neutral
AMD,> It is bad value compared to a 7800X3D that is not that much slower  around 15-20% slower. Definitely worth the small investment. The difference is like 5% of the whole PC price,Negative
AMD,"Wow a 3 year old  slower CPU is cheaper, what a revelation! You're so smart to figure that out",Positive
AMD,"7800x3d is barely cheaper than 9800x3d, there is like â‚¬10-20 difference between them.",Negative
AMD,"the thing that people always miss is that ""fps per dollar"" is meaningless if you don't consider a full working setup. When you're paying $1000 for a computer (which is pretty low these days, mind it), paying 15% more for 20% more performance by getting a better CPU is great value",Negative
AMD,"in *video games*, just not productivity",Neutral
AMD,Thatâ€™s because they both have 1 X3D CCD.,Neutral
AMD,"Yup, because they both utilise the ""A tier"" 8 core chiplets, 9800 has one, 9950 has two. If you have things that need the most powerful cores, the 9950 is the best, otherwise the 9800 is enough.",Positive
AMD,turns out buying CPU that is 1year old after release is not a bad idea after all. At least you have dodge that launch issue.,Neutral
AMD,"14900KS was just a high binned 14900K overclocked out of the box. People were *upset* that it existed, in many ways to how people are upset the 9850X exists. Forget about specific wattage figures - both sacrifice efficiency such a small performance improvement, you have to measure it to detect it.  The performance and efficiency we see shouldn't even require testing - as soon as we got leaks of a 9800X getting a mild clock speed bump, we already knew exactly what this part was gonna be.  But also, so what? Neither Intel nor AMD are forgoing other products because products like this exist. They're just bins of existing production. Their existence required very minimal effort, without any effort from the design team, and if they didnt exist, that wouldn't accelerate the timeline of next gen any faster.",Negative
AMD,People overbuy CPU routinely. 9800X3D is literally the top selling CPU on Amazon.,Positive
AMD,">Iâ€™d assume most people thinking of 9800X3D and 7800X3D are the 4090/5090 crowd.   No?   I paired it with an RX 9070 XT.   Look on ""Completed Builds"" of PCPartPicker and you'll see [~4,320 published builds with a 7800X3D](https://pcpartpicker.com/builds/?using=3hyH99), with the 4090/5090 being less than 10% of those.",Neutral
AMD,"*""You don't care about it.""*  There corrected it for ya",Negative
AMD,"ohh u meant that, yeah, oob raptor was idiotic",Negative
AMD,"True, but X3D CPUs are genuinely noticeably faster on gaming  than the non 3D V Cache CPUs though, as a person who went from AM4 - AM5 both standard Zen 2 - Zen 3 - Zen 4 and their respective 3D V Cache versions.  There is a noticeable performance upgrade going from 5600 - 5700X3D and 7600 - 7800X3D. that makes the upgrade worthwhile and therefore still value oriented, I highly doubt i can say the same going from 7800X3D - 9800X3D - 9850X3D. That upgrade path simply feels like throwing money straight down the drainage.",Positive
AMD,"I was choosing between both 9800X3D and 7800X3D as upgrade from my previous 7600, couldn't be happier with the 7800X3D at very big discount of $280 instead, almost makes the 9800X3D at $480 look like a laughably bad value compared to it.  But of course, i also understand completely why people like that CPU too much, it was the fastest CPU in the market and therefore the want the best of the best  and fuck money / value crowd will cherish on that one.  That is what the 9850X3D is exactly aiming for, and it seems like its defender here are on that side of the crowd as well.",Positive
AMD,"Well, yeah.   Ryzen 9 is the S-tier chips that also boost the highest.",Positive
AMD,"I skipped firstgen AM5 for a reason; if the situation allowed, I might have waited longer if only to be a CAMM2 early adopter.",Neutral
AMD,"Like, if you like GSG or indiejank, it's worth whatever sacrifices you have to make to get a 3D CPU into your build.  I too paired mine with that GPU, not least so that hot rod CPU is using its cycles to power through GSG sim work and indiejank rather then doing work the GPU ought to be doing for itself!",Positive
AMD,> I don't care about you because I'm anally opinionated and your refusal to accept this metric makes my penis smaller   More corrected,Negative
AMD,"strategy, sim, mmo are genres where most games will be CPU bottlenecked on a 7800x3d, no matter the GPU.",Neutral
AMD,"It wasn't a biased advice, my advice was simply based off value focused perspective which is where the 9800X3D - 9850X3D absolutely does terribly quite obviously.  That doesn't mean they are pointless products though  This is the reason why i kept clarifying in my previous comments what these CPUs are for, if they are after the best of the best, then by all means get those CPUs. they are in fact better but prepare to pay a huge premium for it.  If they want the best high end value that still gets high fps and can go head to head against the best and is only marginal slower? the 7800X3D simply is a far better deal out of the other options, even HUB said this very same thing on the conclusion of their 9850X3D review.",Neutral
AMD,"Considering my favorite games are indiejank, strategy, sims and indiejank versions of the latter two... there was no question, my system was going to have a 3D CPU.",Positive
AMD,Before Nuvia he was the chip lead on the legendary Apple A7.,Neutral
AMD,Did bro retire a billionaire?,Neutral
AMD,"Probably not a sudden change. Been what, 5 years since the acquisition? Sounds just long enough for the initial ""golden handcuffs"" stock grant to fully vest. Likely has been unofficially retired for a while now.",Neutral
AMD,"Arg. Leave it to AI to get stuff radically wrong.  ""After completing his education, Williams began his career at Intel, where he worked on the Xilinx 3000""  No. Xilinx was never a part of Intel. Williams worked at Intel ""developing performance gathering hardware for the 66MHz and 100MHz Pentium chips"". He used a Xilinx 3000 to do so.",Neutral
AMD,"Will be excited to see where he ends up eventually. His dream (per messages released in the Apple vs William lawsuit that Apple later withdrew) was to design a server / datacenter CPU. NUVIA was acquired before anything released; Qualcomm maybe has something in the pipeline, but it'll now release after his departure.  >**DDay.it:** With the first Oryon core, I call it that because it doesn't seem to have an official name, you chose to have a flexible core that can cover a wide range of frequencies and therefore also power. Yet historically you have always worked on big.Little architectures and now on Snapdragon 8 Elite there are two different types of cores, prime and performance. Why this change? Is it a choice related to smartphones or do you think your future designs will follow this path?  >**Gerard Williams III:** *""We need to consider what happened when Qualcomm acquired my company. When I joined Qualcomm, I was asked to develop a product for computing. I told them I could do it, after all, I have experience in laptops, desktops, mobile phones, smartwatches, IoT, practically everything.""*  //  >**DDay.it:** Also servers, if I'm not mistaken your Phoenix core was intended for datacenters.  >**Gerard Williams III:** ""*Yes, exactly. Anyway, when we were instructed to make a computer processor, we organized the schedule and determined that the only way to meet the deadlines was to build a single optimized core. The team was structured to do one thing at a time, so time dictated the design of the first Oryon core. We didn't even have infinite resources*"".  The full [late 2024 interview here](https://global.dday.it/2024/10/25/309/gerard-williams-iii-the-transistor-artist-let-me-tell-you-how-oryon-was-born).",Positive
AMD,Pretty sure he will end up at Intel,Neutral
AMD,What does this bode for Qualcomm and the future of Oryon?,Neutral
AMD,Recently their GPU lead also left;  [https://www.tomshardware.com/pc-components/gpus/eric-demers-leaves-for-intel-after-14-years-at-qualcomm-father-of-radeon-and-adreno-gpus-now-sits-at-lip-bu-tans-table](https://www.tomshardware.com/pc-components/gpus/eric-demers-leaves-for-intel-after-14-years-at-qualcomm-father-of-radeon-and-adreno-gpus-now-sits-at-lip-bu-tans-table)  Now the CPU lead leaves. Possibly linked?,Neutral
AMD,He might consider jumping onto the Mill CPU team.,Neutral
AMD,Wasn't the purpose of the company to just be a licensing vehicle of Arm chips to Qualcomm?,Neutral
AMD,"Wow people retire, shocking",Negative
AMD,"Also the lead architect for the Apple A12x, the precursor chip to the Apple M1  Unquestionably one of the most important people in Appleâ€™s history",Positive
AMD,"Apple A7 was way ahead of its time, being a 6-wide ultra low power CPU, on 28nm (how?). Just look at the benchmarks, 2x Cyclone (A7 core) at 1.3 Ghz matched 4x Qualcomm Krait at 2.7 Ghz. That's like 4 times the IPC of their strongest competitor.",Positive
AMD,"Most likely centi millionaire, from the acquisition of Nuvia, he most likely got 300M$ no? He was a co founder but venture capital had invested several times into them   But its possible his deal at QC might have pushed him towards thatÂ    Edit: if he didnt retire a billionaire,Â  Intel or AMD most likely have a billion to spend on him ðŸ˜… if they so wanted   Edit2: Samsung too would spend that Billion so fast",Neutral
AMD,Not likely.   But also he ain't hurting for cash either.,Neutral
AMD,And ponder that slop like this makes most of the top search results these days instead of actual articles and takes written by people with brain or at least an excuse for it.  We are currently killing our collective knowledge base and replacing it with random lies.,Negative
AMD,At Intel i built a set of FPGAs using the Xilinx XC3195a chips for a set of trace capture cards for the Pentium 66 and 100Mhz cpus. This was in 1995.,Neutral
AMD,Thanks for pointing. Edited it out.,Neutral
AMD,"Wow, that's a fantastic read.  >DDay.it: *How difficult is it for people like you, who work across different companies and create designs for each of them, to erase everything and start anew from scratch? Every time you changed companies, you had to leave your work behind and start over with a blank sheet*.  > Gerard Williams III: *""For someone who has never done it, it might seem like a miracle. But for those who have done it many times, it's simply like waking up and creating something new.""*",Positive
AMD,Qualcomm CPU will be fine. Just like how Apple is fine without him.,Neutral
AMD,"I haven't thought about that for a long, long time.",Neutral
AMD,"The guy is 54. These types of engineers are workaholics that will continue to work until they're 80. There is zero chance in hell he's retired. Either he's starting a new company, he's decided to become a professor or he's been poached by one of the big dogs",Negative
AMD,"Also, the Cortex-A8 he led at ARM is what powered the Apple A4/Samsung Hummingbird in the iPhone 4, OG iPad, and OG Galaxy S.",Positive
AMD,"*And* the M1 P-cores, too.  >Chief Architect for all Apple CPU and SOC development. For CPU, lead the Cyclone, Typhoon, Twister, Hurricane, Monsoon, Vortex, Lightning and **Firestorm** architecture work. Chief Architect for the Apple MAC hardware platform M1 Pro, M1 Max and the M1 Ultra.",Neutral
AMD,"yeah crazy impact. those chips were game changers fr. curious what he'll do next, seems like a big loss for qualcomm",Neutral
AMD,"lowkey yeah, his work with apple was insane. really wonder what he'll cook up next now that he's moving on",Positive
AMD,>ahead of its* time,Neutral
AMD,"honestly if intel or amd throw a billion at him, he'd be crazy not to consider it lol",Negative
AMD,Kind of wild to think that ~2019 will forever be the last year where information can be considered human based.,Negative
AMD,"I never thought this thread would get a response from the man himself. Thank you for the clarification, Mr. Williams!",Neutral
AMD,"Certainly. Curious how the next few gens of Oryon will perform (which certainly have been built with his leadership). Right now it's matching Apple for performance, while being a gen or two behind in efficiency (as per Geekerwan). And perhaps that server CPU might finally see the light of the day...",Positive
AMD,"yeha def not retired, prob already planning his next move. dude's resume is insane, can't see him slowing down anytime soon",Positive
AMD,"It's a pity that Apple doesn't expose CPU codenames anymore. Those were epic.  Meanwhile Oryon V1/V2 is Phoenix, V3 is called Pegasus, and what's next is anybody's guess.",Negative
AMD,On ARM he made the most important 32 bit CPUs as well,Positive
AMD,Fixed,Neutral
AMD,"There's a point where an extra billion doesn't make a difference, while having free time always does. Having 2 billion is basically the same life as having one really.",Neutral
AMD,He most likely worked on everything till Oryon v5 so we will only know in late 2028,Neutral
AMD,"TLDW: DLSS4 already had a lead over FSR4 and DLSS4.5 only nudged it a little bit further. But not by too much. All three are solid overall, and the gap isn't nearly as extreme as the FSR2-3.1 days.",Positive
AMD,"I can't let go of DLSS 4.5 simply because of the particle retention. There are certainly issues with it, as HUB and DF have pointed out, but actually seeing particles that are supposed to be there makes certain effects much more pleasing.  DLSS 4 certainly has less firework particles in MHWilds in the gathering hub for example. . Basically if you're playing a game with tons of particles 4.5 might feel more dynamic.",Negative
AMD,"Still no DLSS 4.5 Preset L comparisons which is disappointing, but as expected DLSS wins once again but not perfectly as it also comes with its own issues, also they didn't mention the Preset M added noise problem when turning on Ray Tracing like what Digital Foundry has found on their own video analysis, i wonder if FSR 4 also suffers the same though.  I would like them to compare DLSS 4.5 Preset L Ultra Performance vs FSR 4 Ultra Performance - Performance at 4K - 1440p in their future video, also add in XeSS 2 XMX / D4a to the mix as well.",Negative
AMD,"Biggest issue with FSR is how few games support it, only reason I would lean towards nvidia",Negative
AMD,"I swear Iâ€™m blind. I watch these videos and until itâ€™s slowed down, I donâ€™t see anything! They all look fine. The comparisons look the same at normal game speed.   On my own computer Iâ€™ve tried turning DLSS on and off. I still canâ€™t tell a difference without watching the FPS counter.   I play single player games, on a relatively high end computer so my native FPS is fine to begin with.   Iâ€™m not the target audience for these technologies, but the way people gush over them puts me right back to my original statement.   Iâ€™m blind.",Negative
AMD,DLSS 4.5 wins the majority of times but also has some issues of its own.  FRS4 and DLSS4 are generaly worse and trade blows depending on circumstances. FSR4 does some stuff better. Even close to DLSS4.5 while in others its even behind DLSS4. There's even cases where the choice literally comes down to prefference.  Either way I think at this point all 3 upscalers are more than good enough for general use purposes and your average person will not really notice most artifacts in them without really focusing on them.  It also seems to me like upscaling is slowly reaching a point of diminishing returns with the current techniques.,Negative
AMD,has anyone compared xess with fsr4,Neutral
AMD,"im not one to pause frames and try find issues, but only from their video  I prefer dlss.",Neutral
AMD,"DLSS 4 and especially 4.5 are clearly oversharpened, you can see the grain artifacts on almost all pieces of vegetation and hair, especially when zoomed in.  I dislike that approach, cause you can use RIS 2 or rCAS via ReShade to make FSR 4 just as, or even more (over)sharpened, but there's no good way to remove the oversharpening DLSS 4 and 4.5 introduce.  AMD needs to clean up the fence and stair stuff though. Those are very obvious problems with the upscaler, and improve the ghosting in future iterations.  DLSS 4.5 also has some problems with global illumination flickering in dark environments, which oddly weren't mentioned here. Not sure HUB is aware of those shortcomings of DLSS 4.5.",Negative
AMD,Weird how everyone keeps refusing to test preset L. Gotta wonder why,Negative
AMD,"For those with 1440p and 4k monitors, how does DLSS 4.5 look in person? Because from every video it looks deep fried to hell, and I generally dislike sharpened images, but this is looking at zoomed in images",Negative
AMD,You just need to ask anyone who has DLSS 4.5 if they would have preferred FSR 4 and you got your answer,Neutral
AMD,"Haven't seen the video yet, but I know first hand based on the visual quality in BL4, that AMD still has a long, long way to go and I think it's pretty bad there hasn't been any major FSR4 Updates so far. Not sure if AMD can effort being that slow.",Negative
AMD,"So, where did they get the DLSS source code to come up with an answer to that question?",Neutral
AMD,"By the time AMD catches up with DLSS 4/4.5, NVIDIA Will have a DLSS version that upscales 144p to 4K perfectly",Positive
AMD,"FSR 4 is more than good enough, and I personally think DLSS is literally just over sharpening to fake more detail where it otherwise wouldnâ€™t always have the lead (but it definitely does have more real detail sometimes). I officially donâ€™t care about upscaling any more",Negative
AMD,AMD unboxed strikes again,Neutral
AMD,Can't go wrong with any of these upscaler models honestly. Modern upscaling has come a long way.,Positive
AMD,Using fsr 4 on 9070 xt and no complaints at all. And I saved $300 going w AMD vs overpriced nvidia,Positive
AMD,"I noticed the same thing when playing KDC2 during night gameplay. Torches have more particles, and thanks to the highlight improvements, the stars in the sky are way more visible. Its a pretty big difference once you notice it.",Positive
AMD,Seriously I haven't seen a single one of these upscaling analysis videos include preset L. I want to know if preset L ultra performance or even performance looks better than K/M quality.,Negative
AMD,I personally hope they do some testing for model L on the weaker 5050/5060 cards vs 3000 series and FSR 4 on the 9060 8GB. People with less money would benefit from knowing if Model L enables them to accept a upgrade from a 3070 to a 5060ti while seeing additional framerate improvements due to more capable tensor cores.,Neutral
AMD,At the end of vid HUB Tim basically said he would test it at a later date.,Neutral
AMD,"Comparing the L Ultra Performance preset with the FSR4 Ultra Performance preset is pointless. The L preset has a significantly higher performance penalty than the M preset. As a result, for a fair comparison based on performance, you'll have to compare the L Ultra Performance preset with the FSR4 performance preset. Even so, the FSR4 will be faster.",Negative
AMD,"Yep, it's been over a year and we still have to rely on a third party software in able to use it. I'd say too that is the current biggest drawback of FSR 4 right now is only supporting very minority RDNA 4 only GPU architectures, compared to DLSS's much bigger all generations of RTX GPU from 20 - 50 series generations.  This reason alone In the perspective of majority of game developers makes them a lot more focused on implementing DLSS Upscaler tech more than FSR 4 which probably barely has over 1% who can officially use it into their games.",Negative
AMD,"""But Optiscaler""   Yeah wait until you touch online games with anticheat. Arknights: Endfield released a week ago, only DLSS available, and no way to inject FSR because of anticheat",Negative
AMD,"That was a bigger decision for me going with a 5060Ti over a 9060XT than DLSS simply being better.  FSR4 will probably be pretty well supported going forward, but I still think DLSS2 is pretty good and support for that exists in games going back quite a while now, while FSR4 is limited to very recent games only.",Positive
AMD,"1 month after the launch of the RX 9070 XT, there should have already been a plugin for UE5 and UE4, with a plugin for Unity by the summer of 2025.",Neutral
AMD,YouTube obliterates fine detail and can soften up a lot of aliasing which can make even FSR 3 look passable in comparisons.,Negative
AMD,"Being blind can be a blessing. If you don't see it, then it doesn't matter",Neutral
AMD,Me too,Neutral
AMD,if you were watching uncompressed video youd notice instantly. Youtube is a bad place for such comparisons.,Negative
AMD,"Well also youtube encode and whatever device you're watching on hides most of it. It's way more obvious when you actually play the game, especially on high res screens.",Neutral
AMD,"You're perfectly normal. There's a reason all these comparison slow down and zoom everything (not that I've watched this one, but I assume it conforms to all the others).",Neutral
AMD,"Yeah, diminishing returns is for sure happening, especially as better techniques have so far been going side by side with a need for more compute power.   I think we are going to continue to see new models that improve things, but I think this 4.0/4.5 dilemma is always going to be there, a ""pick your poison"" in the type of artifacting you're willing to accept in order to eliminate the other types of artifacting.   The Digital Foundry assessment kind of demonstrates this when they surmise that the ""over-sharpening"" in some titles may be a side effect of training the models to eliminate ghosting.",Neutral
AMD,"I'd put DLSS 4 pretty decently ahead of FSR 4 as a current 9070 owner upgrading from an RTX 3080, having a lot of time spent looking at both. FSR 4 feels much more comparable to DLSS 3, I really hope AMD brings us something big with FSR 5.",Positive
AMD,">Either way I think at this point all 3 upscalers are more than good enough for general use purposes and your average person will not really notice most artifacts in them without really focusing on them.  This is probably true on 4K but on resolution like 1080p - 1440p i personally can still easily distinguish the difference between these upscalers, heck even with DLSS 4, the 4.5 is a noticeable visual upgrade when comparing the newer 4.5 Preset L / M Ultra / Performance mode vs older DLSS 4 Preset J / K Balanced / Quality mode.",Positive
AMD,"I also think that DLSS 4.5 is a step in the right direction, but there are a few stuff that needs to be fixed, which most likely will be in DLSS 5.0",Positive
AMD,"I've tested it in Cyberpunk on the 9070 XT and FSR4 is noticeably better. A couple times I installed OptiScaler which defaults to XeSS output and forgot to change the setting at first and thought WTH is wrong with setup this looks like crap, then remembered to toggle FSR4 output in OptiScaler. It's really not even close.  Edit: I just took an imgsli to show the difference, but it's hard to make out a lot from the screenshot. What you'll see is that FSR4 is generally more detailed, but it's subtle. Anything in movement though, which of course the imgsli does not capture, is much more detailed on FSR4 with no ""TAA blur"" where XeSS is extremely soft as soon as you move. https://imgsli.com/NDQ1Nzcw",Neutral
AMD,[ DLSS 4.5 vs FSR 4 vs XeSS 2.1 â€“ In-Depth Comparison & Honest Review](https://youtu.be/ET6pq7ig3Ck),Neutral
AMD,> but there's no good way to remove the oversharpening DLSS 4 and 4.5 introduce  DLSSTweaks has an option for that.,Negative
AMD,"The oversharpening truly is horrible and I don't see it being mentioned enough. HU also disappointingly called 4.5 ""even sharper"" when it's just ""sharpening filter"" being applied with little actual texture clarity being introduced. Rachet and Horizon examples are especially outrageous at how much of a downgrade 4.5 is if you don't want any of this being applied (all other improvements put aside).",Negative
AMD,Its not oversharpened. Its just that you are used to everything being blurry before we got DLSS to fix that.,Neutral
AMD,"27:01 *""I have heard from some people that would like us to look into Preset L with DLSS 4.5 as well so hopefully at some point we'll be getting to that looking at it compared to preset M and also FSR4""*  HUB will test it when they have the time. When that'll be who knows.",Neutral
AMD,"It looks sharp, but not oversharpened IMO, at least in few examples I've tried. Anecdotal - in RDR2 on 1440p Preset L made Ultra Performance (480p internally) look pretty adequate, even if with some noticeable artifacts here and there. But overall image coherency is astonishing, and I can see myself playing that way if required.",Positive
AMD,"Game dependent. Even when you set the in game sharpness to 0, DLSS 4.5's artificial sharpening filter may still introduce oversharpening and ringing artifacts in some games. It's a mixed bag really. I'd say if the game already looked sharp enough with DLSS 4.0 then 4.5 will definitely look oversharpened. If you don't wanna worry about it just stick to preset K until NVIDIA adds a sharpness slider or tones down the sharpness in a future update.",Neutral
AMD,"Video will give you a good idea already.   Just dont use Balanced/Quality.  Performance mode seems to generally be ok in most games, though can still be slightly oversharpened in certain games.",Positive
AMD,"1440p monitor here (i use my 4ks only for productivity because they are low refresh rate). It looks fine, better than native for me.",Positive
AMD,"Yep, it does really not look good from videos. I don't know if it's genuinely less noticeable in person or people just love oversharpened images. I have a feeling it's the latter, hence every TV and phone camera oversharpening every image by default.",Negative
AMD,I don't think AMD cares too much about the GPU gaming division anymore,Neutral
AMD,"This has been a never ending story with DLSS and FSR lol. Even Intel, a newbie in the DGPU industry managed to beat AMD in the upscaling game.",Neutral
AMD,"Funny, the 117p upscaled to 1080 actually looks playable on DLSS 4.5",Positive
AMD,"But once you get to a good enough stage, any more wouldnt sway people much",Neutral
AMD,This is a massive hyperbole considering FSR4 already trades blows with DLSS4 in most cases. Its even better than DLSS4 in certain instances.  You comment would be more fitting for when AMD only had FSR3. That one really was a generation behind.,Neutral
AMD,"And the problem is that fsr4 is built on a hybrid between CNN and transformer, and we know the CNN model is limited, while dlss's full transformer model has very high potential",Negative
AMD,"It feels wrong to say this, but: kudos to NVIDIA for taking that mess of AA techniques and setting a new standard regarding visual quality, along with a performance boost.",Positive
AMD,5070ti was $300 more in your area?,Neutral
AMD,"I have two 9070XTs and had a 5070Ti for a while, and the two upscalers prioritise different things like DLSS looks better on the horizon and fine detail in far midrange, but FSR4 looks better close to the camera especially in fast motion. Nvidia have other advantages like less flickering shadows in trees in some games. But in a blind test most people will not see the difference between FSR4 and Dlss4  I personally preferred FSR4 in third person games and dlss in first person games, but generally I turn off upscaling, or use downscaling in those anyway. Edit: also the oversharpening on Nvidia is too much for me",Neutral
AMD,Overpriced is an opinion,Negative
AMD,2kliksphilip video?,Neutral
AMD,"I'm running L balanced or performance at 1440p on most games with a 5060 ti 8gb. The card has plenty of tensor core power to run the heaviest DLSS model. Then framegen gets my 60 fps up to my monitors 200hz.  Honestly DLSS is a godsend for low vram cards, as the newer models allow much lower resolutions while somehow looking better than older models at quality. It gives the card something to use its muscle on instead of just being vram constrained and running at 70% utilization.   I still have to turn textures down sometimes but the lower resolution from DLSS is often the difference between medium and high textures running smoothly.  Everyone dumped on the 8gb card but if you look at what cards are actually going for now (not the msrp) it's actually not bad. The 8gb version is available for $330 while the 16gb is $520. That's a $200 difference and in well optimized games there is literally no performance difference. For heavy games you have to compromise on textures vs the 16gb version, so that's what you lose for your $200. For $330 and combined with dlss it's not terrible, especially if you want an esports card it will easily get you 200+ native fps on cs/fortnite/valorant etc.",Positive
AMD,"Huh? it has no way to inject FSR 4 on vk because it's Vulkan, not because of AC. People are running Opti with VK spoofing and dx11-on-12 just fine. FSR 4 with dx11 on 12 also works, but wonky to my eyes and I can't put a finger on it",Negative
AMD,I've been using optiscaler in that game just fine. The devs don't really care you can use it.,Positive
AMD,"Been using OptiScaler with Diablo 4 for 80 hours across 3 months and no anti-cheat issue. Of course there's a risk, but I honestly have not heard of a single confirmed case of somebody being banned for anti-cheat detection of optiscaler.",Neutral
AMD,You can update dlss to the newest one in the nvidia app,Neutral
AMD,"I wonder what will happen when PSSR2 comes to consoles. That should significantly expand support and might even get FSR 4 some much needed attention when implementing it. Currently, FSR suffers from issues in its implementations not due to the quality of the upscaler itself but because devs won't fine tune it like they do DLSS.",Neutral
AMD,>FSR4 will probably be pretty well supported going forward  Will it? Games keep coming out with DLSS but not FSR and this does not seem to be stopping.,Neutral
AMD,">but I think this 4.0/4.5 dilemma is always going to be there, a ""pick your poison"" in the type of artifacting you're willing to accept in order to eliminate the other types of artifacting.  But if we look back to the DLSS2/FSR2 days, it's pretty clear that whichever 'poison' you pick, things have definitely still improved a lot and you'll be dealing with less artifacting overall.   So long as progress keeps going, I think the actual compromises you have to make going with one or other will become increasingly negligible as well.",Neutral
AMD,The returns are in extreme scales. There were tests done where they upscaled from 480p and DLSS 4.5 handled that just fine. Even upscaling from 117p looked playable. The returns are now in how far we can scale rather than image quality.,Neutral
AMD,DLSS 4 is definitely sharper but FSR 4 is more consistent for me. A few games have issues with transformer DLSS. Not really an issue with so many models available on the NVIDIA side though.,Neutral
AMD,We have enough video evidence to believe FSR4 is closer to DLSS4 that we don't have to go with your anecdote or vibes.,Neutral
AMD,"I'd probably put it as:  DLSS Transformer Gen 2 > DLSS Transformer Gen 1 >> FSR4 >> DLSS CNN >>> FSR 3.x  Imo overall FSR4 is decently better than FSR4, but it's definitely not on the same level as DLSS 4",Neutral
AMD,FSR5 is coming already?,Neutral
AMD,"Who upvotes these anecdotes that everyone knows are just wrong? Every single comparison by HUB or anyone else between DLSS3 and FSR4 has put the latter far ahead but sure I guess we ignore the testing and trust you ""as a 9070 owner"" lol  In most cases FSR4 is as good as DLSS4 and there are occasions where it is as good as 4.5",Negative
AMD,"That's not true, FSR4 is significantly superior to DLSS3. You just like the sharpness of DLSS4... Turn on RIS2 Adrenaline in the global profile to about 50%.",Neutral
AMD,"As someone who finds disocclusion artifacts very annoying, FSR4 places massively ahead of DLSS 4 for me. DLSS 4.5 does look like a decent step up from FSR4 though.",Neutral
AMD,"He said the average person. If you're posting on a tech enthusiast forum and watching videos about upscalers, you are not the average person.    Ever talk to a truly casual PC gamer? They buy prebuilts and don't even attempt to mess with visual settings. You could show them DLSS 4.5 vs TAA side by side and they'll say something like ""ehhh it looks a bit sharper I guess"". This is not a dig at them btw, they just prioritize vastly different things when playing games.",Negative
AMD,XeSS on Intel is better but still slightly behind FSR4 (I think),Neutral
AMD,"Doesn't HUB already disable sharpening in their videos? Pretty sure they've said they set it to zero in all their comparison videos. If it was a default options, wouldn't DLSS CNN be oversharpened too in their 3 vs 4 comparisons, since they use the same settings there?",Neutral
AMD,"It is. If you compare it to brute force supersampling, it doesn't look like that. All the vegetation has clear oversharpening grain artifacts, they are very easy to spot if you've dealt with them before.  There's no way you can tell me the TLOU1 and HFW foliage isn't oversharpened. It looks horrible. I'd honestly prefer it being a bit soft than oversharpened.",Negative
AMD,"Probably never, just saying something to try and shut up people calling them out for it.",Negative
AMD,"funny how everyone is saying they will do it later, but noone actually did it :)",Neutral
AMD,"Itâ€™s actually an amazing piece of AI. Iâ€™m getting a LOT more life out of my 3060 than I ever expected to, with DLSS and upgrades.",Positive
AMD,Some games ignore your sharpness settings if you set it to 0.,Neutral
AMD,"People have been saying this for so long, but RDNA4 and FSR4 are two of their best improvements since like 2020.",Positive
AMD,It's really fucking weird how slow AMD is with FSR. Like whoever is buying AMD is like what? A year or so behind NVidia in terms of features... Absolutely crazy.,Negative
AMD,Well not really because it still means you can gain more performance without losing qualify.,Neutral
AMD,"FSR4 trade blows with DLSS3, not 4.",Negative
AMD,"Hmm, no. FSR4 is closer to DLSS 3 than it is to DLSS 4 Transformer.",Neutral
AMD,Models are tools. Its about hoe you use them that makes or breaks models.,Neutral
AMD,At my nearest microcenter it's averaging $200-250 more.,Neutral
AMD,Last time I checked here in Finland it's 400-500â‚¬ more,Neutral
AMD,Yes it was. I paid $1000 for my 9070 xt and 5070 ti was $1300 both after tax. Cheapest models.,Positive
AMD,"Youâ€™re probably fine but Blizzard tend to do ban waves, so itâ€™s hard to know. Biggest risk is some cheat or bot program doing something that looks similar to their detection system.",Negative
AMD,Anything with FSR 3.1 gets updated to FSR 4.xx (whatever latest) via AMD drivers as well.,Neutral
AMD,"It's not Playstation, they have their own implementation libraries for PSSR, even though the underlying model and algorithm will be shared with FSR/Redstone.  It's Xbox. When they move to be just a windows PC - using PC versions of games with PC graphics settings, there should be a big push to get FSR4 on everything to make it ""Xbox"" ready.",Neutral
AMD,"For the most part, yes.  Occasional new games dont have FSR, but most do.",Neutral
AMD,"Oh yeah, when I say diminishing returns, I just mean in the scale of inconsistencies will likely always exist no matter how much power you throw at it, and we will likely never see a leap with DLSS 5 like we did with past models. But by the same lot I can see DLSS 5 or 6 being a case where you need to really focus on select cases to still see shimmering or incorrect particle effects.  Realistically, we've already past the point of ""good enough"" as far as I'm concerned. In most games already, the issues are minor enough and a good tradeoff of forced TAA that I am always trying to decide whether to play in Native or DLSS depending on the title. Three years ago I wouldn't even consider it.",Neutral
AMD,the evidence suggests FSR4 is a bit better than DLSS3 but not encroaching on DLSS4.,Neutral
AMD,"Not yet and they're probably gonna call it something else. FSR4 was already renamed to ""FSR Redstone"".",Neutral
AMD,"No, they just mean whatever comes next.  They will obviously keep improving FSR.  Reconstruction is going to be a mainstay of 3d graphics going forward now and clearly has a lot of value.",Positive
AMD,"Not true. Every review put it at ""Between 3 and 4 but closer to 3"" from what I remember.",Neutral
AMD,They upvote it because they like the way it makes them feel.,Neutral
AMD,"Not true, FSR4 is slightly superior to DLSS3, but closer to it than DLSS4.  Sharpness is good. Sharpness used to be known as actually being able to see the details. That is before TAA smearing vaseline on the screen became popular.",Positive
AMD,"Some games DO NOT allow you to adjust the sharpening filter that devs apply for DLSS. Some games allow it in settings, others bury it in the config files for the game and for some it's hardcoded and has no setting or config. DLSSTweaks (maybe even SpecialK) allows you to change it no matter what.",Negative
AMD,Some games ignore your sharpening settings. Remmeber that all those settings we have used to just not be accessible by players and ran on developer defaults. Some developers still dont want users to have a choice.,Negative
AMD,"Did DF also talk about this?   Can't blame them when NVIDIA said the model is recommended for UP, and HUB Tim has been critical of DLSS4 TF performance mode.  Hopefully not too long of a wait.",Neutral
AMD,"I prefer DLSS  model M at 1440p over  most of the native TAA implementations . I don't even use DLAA anymore , as it just uses more resources and I don't notice any difference vs DLSS quality",Neutral
AMD,"And they have been steadily losing dGPU marketshare for equally long.   It took them this long to get an AI upscaler out and didn't even bother to implement it for older GPUs, so people need to use 3rd party injectors",Negative
AMD,which came after Sony kicked AMD in the ass to get on and enter the 2020 decade finally.,Neutral
AMD,"Try 4 years. AMD still has not released something equivalent to DLDSR, they only have an alternative to DSR. When you look at the overall package of features, itâ€™s easy to understand why nobody wants to buy Radeon.",Negative
AMD,"Yes, until you hit CPU bottlenecks because your resolution is so low GPU does not have to work so hard.",Neutral
AMD,Sometimes FSR 4 is even worse than DLSS 3 when you are rendering from lower resolution such as what is shown [here ](https://youtu.be/g05Fs3I1qkg?t=422)by 2kliksphilip with his own analysis of Upscalers.,Negative
AMD,"dlss4 had some issue when characters stand over grass/tree/water . When you spin camera around it leave some of the worse ghost trail in dlss history . 1st person game it less apparent tho .  7:56 on the left . And around the character too . https://youtu.be/9th1e74u3Ng?t=475  I seen it in LOU ,dragon dogma, ff7 rebirth .",Negative
AMD,Pls dont call me a hoe,Negative
AMD,"Well, if I get banned then no more countless hours dropped on farming ancestral uniques. I did avoid overwriting the Diablo 4 provided XeSS libs just to be safe.",Negative
AMD,I'm pretty sure Hardware Unboxed (but might have been Digital Foundry) said this almost verbatim,Neutral
AMD,Literally the OP of this thread is a 20 minute video that has FSR4 as neck and neck with DLSS4 and matching 4.5 in some cases. You people live in your own fantasy world where nvidia just wins everything and no facts can ever change that.,Neutral
AMD,"But it is the same sharpening filter that is exposed in-game when games offer the option, right?",Neutral
AMD,"That's true, but idk about those specific games they used in the video. I know UE5 has forced sharpening by default, of the devs don't expose the sharpening slider (very annoying in Arc Raiders).",Negative
AMD,"DF said its ""something for another time"" in the article version.",Neutral
AMD,Nonsense claim.,Negative
AMD,The solution is increase gpu load by using path tracing + frame gen to alleviate cpu bottleneck,Neutral
AMD,The AMD bots will angrily downvote you for bringing facts to the table.,Negative
AMD,"And everybody in the comment pointed out that the instability from DLSS3 was far worse than any detail gained by DLSS3 over FSR4. Furthermore, DLSS4 isn't considered a direct upgrade over 3 either. It's better in most areas but worse in others.",Negative
AMD,DLSS4 does have ghosting issue. DLSS 4.5 seems to fix most of it though.,Neutral
AMD,Sorry i cri every tim,Negative
AMD,">Literally the OP of this thread is a 20 minute video that has FSR4 as neck and neck with DLSS4 and matching 4.5 in some cases. You people live in your own fantasy world  I don't know why you're trying to use this video as proof of your point when in the same video Hardware Unboxed literally outright says ""Given that DLSS 4 was already delivering better image quality than FSR4, it's no surprise that DLSS 4.5 is also better than FSR4, and the gap has somewhat widened with this latest release"".   How could you possibly listen to that and then come to the conclusion that ""The video is literally proving that FSR4 matches DLSS4 and if you disagree you're living in a fantasy land"" when the video is outright stating the opposite",Negative
AMD,"Not always, some games just have forced sharpening when you're using DLSS/Upscaling, even if the in-game sharpening slider is off or all the way down.",Neutral
AMD,Yeah.,Neutral
AMD,Ah yes Leadbetter said that I forgot. Can be 1 week - 1 year from now xD.,Positive
AMD,"True , but dlss4.5 quality mode cost too much perf for my liking , perf mode look good at first but after playing for a while I realized it have some issue with effect that scale with resolution (lumen/ lighting/vol fog/ray tracing/reflection,etc) and a bit of shimmering  , so I go back to dlss4 Q(most game) and dlss 3.8 Q ( 3rd person game ) .",Negative
AMD,Some games sharpen all the time no matter what because they always have a temporal AA running. If you get an upscaler to solve any temporal softness that sharpen will be a problem.,Negative
AMD,A bit early for April Foolâ€™sâ€¦,Neutral
AMD,"So no non-""premium"" laptops with AMD APUs or handhelds with AMD APUs will support FSR 4 until 2029?  That seems quite pointless. If there's any laptops that would need upscaling the most, it'd be the lower-end ones with *less* iGPU performance. The ones doing 60 are fine as is.  Does Intel support all of their new Panther Lake mobile CPUs/iGPUs with XeSS 2?  Edit: Meant XeSS 3. Thought I was forgetting something.",Negative
AMD,"Rdna3.5 until 2029â€¦ big wow there. This is why intel saying amd uses ancient gpu tech in the mobile space is true.   You would figure they would want to innovate and include their newest architecture as itâ€™s ready but nope, theyd rather give you lowly 3.5.   Meanwhile, nvidia is gearing up their own arm chip for laptops, intel has panther lake and amd hasâ€¦ 3.5 or maybe evenâ€¦ 3.6!!!   Boooooo",Positive
AMD,"I donâ€™t think any of AMDâ€™s competitors (Intel, Apple, Qualcomm, maybe even Nvidia) are remaining this stagnant in the mobile graphics space. Intel and Apple will have much, much more compelling mid range and budget options for laptops for the foreseeable future",Neutral
AMD,This is what stagnation looks like.,Negative
AMD,This surprises anyone? AMD today still sells 7000 series laptop processors with GCN5 in them.,Neutral
AMD,"I donâ€™t get it, just use RDNA4. You made it for a reason",Negative
AMD,Yay maintenance mode gpu's till 2029!!!!,Positive
AMD,Panther Lake 12EU available in laptops as low as $1100-$1200 LAUNCH PRICE at the <35w class that can idle at very low power unlike strix halo. What kind of â€œpremiumâ€ are we talking about here?,Neutral
AMD,"What's crazy to me is that one of RDNA3's biggest issues was how inefficient it was in utilizing its theoretical compute and bandwidth advantages.  And RDNA4 fixes that!  You'd think this would be perfect for a bandwidth-limited processor like an iGPU.  My best guess is still that they didn't realize how good RDNA4 would actually be, and perhaps thought their RDNA3 issues would take more to deal with.  The fact that the desktop lineup is basically only one GPU die, and then another GPU that's essentially just the one copy/pasted and glued together, along with this constant reuse of RDNA3.5 for mobile/APU's tells me they really didn't invest much into RDNA4's success at all.  Which is especially lousy for people who are really enjoying the PC handheld stuff nowadays.  I'm not one of them, but still, I'm sure RDNA4 would have been a nice improvement on this side of things.  But now it seems like Intel might be able to come in and scoop up attention for people wanting something newer and better.",Negative
AMD,"Advanced Marketing Disaster at it again!   RDNA3.5 wasnâ€™t even properly supported in 2025 (no official support for FSR4, meanwhile NVIDIA lets you run DLSS 4.5 on an RTX 2050). Who in their right mind would buy those devices in 2029?",Negative
AMD,"I said it before, you will see an Intel chip with Nvidia iGPU before you see RDNA 4 in APU.",Neutral
AMD,Intel could actually beat AMD by the time this AI garbage ends.,Negative
AMD,"But why though? Is there something inherent in RDNA 4 that prevents it from being included in APU designs, or is this just AMD not wanting to put in the work?  I personally lost interest in the new Steam Machine when I saw that it had RDNA 3.5 instead of 4. I am only one data point but there must be others like me out there.",Negative
AMD,"Quoting myself:  > My guess, based on what AMD has said about RDNA4 and UDNA, is that they didn't put the R&D into cutting RDNA4 down any smaller for iGPU usage. So far RDNA4 only has 2 die configs, 64 and 32cu. The 32cu config is exactly just 1/2 of the symmetrical 64cu config. And if you look at the die diagrams, it would take significant redesign to cut the size down further, far enough to fit into the space of 8-12cu RDNA3.5 spaces. >  > My guess is that UDNA is being designed for all sorts of configs, but has caused problem after problem for them... Just like every new GPU uArch family does for them. TeraScale, GCN, RDNA1. Each first iteration was a mess. I'm betting they wanted to get UDNA into iGPUs a lot sooner, and launch dGPU UDNA afterward. A guess.",Neutral
AMD,Itâ€™s idiotic to keep the newest fsr releases from the devices that could benefit the most so of course thatâ€™s what amd is going to do,Negative
AMD,No way this rumor is true no? RDNA 3.5 came out 2024?      You telling me AMD will keep running this architecture out for 5 years? Even in the bad old days of Intel HD graphics they were never that bad!,Negative
AMD,How does this affect the future Steam Deck?,Neutral
AMD,It's clear AMD is abandoning the PC market in favor of the server market.   Market share in both GPU and mobile is near nil and they are clearly in no hurry to change that.,Negative
AMD,Itâ€™s interesting how the leaker is implying that Intel plans to continue developing Xe separately to NVIDIA integrated.     Iâ€™m guessing this is basically going to be Intel for lower end stuff and NVIDIA for higher end stuff,Neutral
AMD,"AMD is becoming Intel when they got very complacent.  Intel iGPU is rapidly improving.  NVIDIA is supposed to enter with an ARM CPU.  Qualcomm is desperate to have a competitive product.  Just when AMD starting to have interesting products for mobile devices, they decide to pull this move.",Neutral
AMD,Just like with Vega. Milking old process nodes for as long as possible. RDA5 and beyond can only be fabbed on higher-end TSMC processes and there is way too much AI demand to make low margin APUs/iGPUs on any kind of fancy wafers for the foreseeable future.,Neutral
AMD,"I wonder if it's just not worth the effort and investment in a time when AI is more profitable, or if RDNA4 just doesn't scale well down to low power applications.",Negative
AMD,"Before you all get your pitchforks out, take a look at the bottom right corner of the attached slide. It has a Gemini watermark, so at the minimum take this with a heavy grain of salt.",Neutral
AMD,That's certainly a choice. We'll have to see how ARC Celestial fares.,Neutral
AMD,"And since most if all premium AMD APUs based Laptops have dGPUs, it will go to waste.....",Negative
AMD,"The source tweet isn't as doom and gloom as it seems.  RDNA3.5 is for non gaming laptops and laptops with separate GPU.  RDNA4 APU is still a thing, the word premium is wildly open to speculation.",Neutral
AMD,So all G series get RDNA5 and the regular 2cu igpu for the X and non X are 3.5?,Neutral
AMD,RDNA 5 iGPU starting in 2027?,Neutral
AMD,Failure is an active choice by AMD.,Negative
AMD,RDNA4 not having a mobile component/focus seems so bizarre as it seems to be competitive with the 5000 series in a good chunk of games and has ML upscaling (useful in a context of a handheld). Maybe power draw could be a concern with lower end skews?,Negative
AMD,"Not surprising. In 2026 they are still shipping Zen 2 cores... That's a 7 year old design.  As soon as AMD started getting money they immediately stopped bringing value to consumers and started renaming old outdated architectures to resell them year after year, abandoning the consumers who dug them out of their grave to focus on data center and AI.",Negative
AMD,Makes me happy with how long my HX370 will likely be well supported.,Positive
AMD,"Thatâ€™s crazy, they gotta back port FSR4 or N1X and upcoming Intel chips will eat them alive for lunch.  NVIDIA is ramping up N1X/N1V soon and Iâ€™m starting to see some things moving on the n2 front, quite excited to see this upcoming Valve ARM translation layer paired with these chips.   At this point I think AMD doesnâ€™t care outside of console APU space   No wonder Valve has said they would wait for something more substantial for Deck 2.",Positive
AMD,"Unless they put 860s, 880s and 890s in the low end, I don't see how they can compete with Intel",Negative
AMD,So no Steam Deck 2 until 2029 got it ðŸ‘ðŸ»  I wonder if this also mean PS6 2029 ðŸ«¡,Neutral
AMD,"Just great. Took only like 3 years for them to stagnate in the iGPU marked, after getting wings basically with the Steam Deck.  Now Intel is overtaking them before even coming to the point where Nvidia iGPU are mentioned.  Smh",Positive
AMD,"Well this should mean that AMD promises to provide driver updates to 2029 Nd beyond for RDNA 3/3.5... RIGHT? ðŸ™„  But in most likelihood all focus is on FSR/RDNA 4. One would hope that coming iterations of their ""Halo"" SKU gets the latest architecture... But who knows?",Neutral
AMD,"I currently use an old laptop for recording game replays. I want to get one that can encode AV1 well, but I've read that RDNA 4 is really where AMD caught up with Intel and Nvidia on quality.  I wonder what embedded APU or iGPU solutions Intel has nowadays...",Neutral
AMD,"at least bring fsr4 for rdna 3 and 3,5...",Neutral
AMD,Seems strange to me that AMD would do this while at the same time licensing out RDNA 4 IP (Juno/Xclipse 960) for Samsung to rebrand as a GPU for Exynos chipsets.,Neutral
AMD,i hope this is a joke (a bad one),Negative
AMD,RDNA3.5 TILL 2029!?  Intel will win the igpu segment.,Positive
AMD,"Hello KARMAAACS! Please **double check that this submission is original reporting and is not an unverified rumor or repost** that does not rise to the standards of /r/hardware. If this link is reporting on the work of another site/source or is an unverified rumor, please delete this submission. If this warning is in error, please report this comment and we will remove it.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/hardware) if you have any questions or concerns.*",Neutral
AMD,"Lol what a stupid article, itâ€™s like saying that the water is wet. Even Intel still sells laptops with igpu from years ago, itâ€™s normal they are market segments",Negative
AMD,Not sure who cares about iGPU's at all?! Discrete cards are completely different story.,Negative
AMD,"All Arc products with XMX cores get full XeSS features (eventually. Apparently XeSS 3 isn't coming to Alchemist just yet), and if it's at all possible they'll bring those features to other vendors too. Intel is not Nvidia.",Neutral
AMD,All PTL and WCL SoCs support XeSS 2 and XeSS 2 Frame Generation.,Neutral
AMD,"AMD is gonna rapidly lose their competitive edge to Intel. In the handheld space, the 140V came out 10 months before Z2 Extreme and still beats its performance. Panther Lake looks primed to eat AMD for breakfast.",Negative
AMD,"I doubt a 2-8 CU RDNA4 iGPU would have enough machine learning to run FSR4 effectively. Maybe the Ryzen AI Z**3** Extreme APU would have 12-16 of RDNA5, and that would make it viable.",Neutral
AMD,Low end will get low end shit like always. It's not surprising.,Negative
AMD,AMD is wafer constrained. They want people buying fewer overall chips from them in consumer segment but more of them to be premium chips.,Neutral
AMD,"I don't see what the problem is. Those laptops, if for gamers at all, will have a dGPU.  And for the low end APUs, even if they were a newer RDNA version, they wouldn't be fast enough to run FSR4 well.  (not enough compute power).  Though maybe they could actually have some sort of light weight INT8 version that works by then.  Or just run Linux where the int8 version works now.  Perhaps another option is to use the ""AI"" coprocessor?",Negative
AMD,Sounds like how Intel used to be.Â   Red and Blue always be switching it up,Neutral
AMD,"If Intel were at the top of their game, AMD would be giving you the newest rdna. Since Intel is weak, marketing dept gets to run things and they always want to give you the least for the most while conning you into believing they got your back.",Negative
AMD,Depends what is their actual intent. They can move HX 370 to a lower price point and release RDNA 5 new thing at it original price point. That way you get more performance for budget options and more performance at the high end. Both companies refresh old generations within their new generation to have lower price options available.  Also it may be that they want to prioritize raster performance instead of DXR or fancy AI upscaling for their lower tier solutions. RDNA 3.5 got a lot of ISA changes also present in RDNA 4 but not all of them so it looks like some tailored solution.,Neutral
AMD,It might also be that PS5 Pro is expected to be supported until 2029 with new games. Project amethyst is keeping the old support going rdna 3 since it gets some rdna 4 features backported to it.,Neutral
AMD,"This amounts to saying they're bowing out of the consumer GPU race, that's a *lot* of end users & developers who won't be feeding the beast of driver/compiler improvements & mindshare.",Negative
AMD,"AMD seems to just not be interested in this market, Intel bigs it up here because this is the only market they have left.",Negative
AMD,"First time? I remember like ten years ago when AMD just rebranded the exact same cards as part of the new generation, year after year even.",Neutral
AMD,"I thought AMD in laptops were quite rare to begin with.  edit/ I'm referring to GPU's being rare, for clarification. I realize that's not what the article was about though..",Neutral
AMD,"It is already rumored that Nova Lake Xe3p will bring +%25 over IPL Xe3 which is reportedly +70 over 890M/RDNA 3.5 (will see results in a couple of days with review). If AMD insists on RDNA 3.5 for core portfolio so the products with majority of the audience than it will lose the whole ground to XE iGpus refreshed in Intel 18A/14A. Nvidia N1/X arm laptops/devices are apparently in the pipeline as well.  If the current IT scene was not ridiculously hostile for us end-users then these times would be exhilarating with powerful ultrabooks, mini PCs, handhelds, consoles with real 4K60 support, VR/AR sets and higher fidelity&quality graphics with ray/path tracing.  I am not against software based upscaling but I am more in favor of affordable pure (computation/rendering/storage) capacity.  To be honest neither Strix Halo nor very expensive IPL/B390 devices do not appeal to me. Therefore I would criticize IPL/B390 if most of the units that include that SoC is like is over 1.5K (seems to be case for now)  IPL products will be officially released in 2 days so we will see how much they will ""saturate"" the market.",Neutral
AMD,"qualcomm GPU's are absolute garbage, biggest obstacle to WoA being a real competitor",Negative
AMD,If they able to release product at reasonable price.,Neutral
AMD,"eh, didnt these 780M and 880M came out relatively recently and they pack quite a punch, so its not some horror story that they are planned to be used for a long in budget categories...  and arent these APUs / igpus really limited by ram speeds anyway..",Neutral
AMD,"Gonna love my new ""out of support"" Vega 7 igpu , wait ...",Positive
AMD,"Mobile is power constrained design based on sales. The market wants ""Series X/PS5 tier games"" on the go. That's what everyone is planning for the next couple years. RDNA 4 uses newer RT engine that uses a lot of power, and there isn't a huge demand for RT performance on mobile so the 3.5 core design is a better fit for raster heavy gaming.",Neutral
AMD,RDNA4 only scales down to 32CUs.,Neutral
AMD,probably strix halo prices,Neutral
AMD,> Panther Lake 12EU available in laptops as low as $1100-$1200 LAUNCH PRICE  That's a screaming deal; TBH. There's really no reason to consider AMD offerings within ~<$300 of that price point if they're pricing like that.,Negative
AMD,">  What kind of â€œpremiumâ€ are we talking about here?Â   Sounds like they're referring to Intel's X7/X9 tier, what they used to call -P series. Intel's also giving the lower end (-U/-H) a greatly reduced GPU config.",Neutral
AMD,"Or they underestimated Intel and didnâ€™t think they could pull off a win, so didnâ€™t want to pay the extra money to port RDNA4 to mobile. Not a bad assumption, Meteor Lakeâ€™s GPU was solid but underperformed what Intel was selling it as (â€œ50 series GPU replacement!!â€)  Unfortunately for AMD it seems like Intel has actually locked in for Panther Lake.",Negative
AMD,Surely who have no idea what's FSR and DLSS  (loads of people),Negative
AMD,"Well DLSS4/4.5 running on older GPU's makes sense in that there's no real work that needs to be done for it.  You just run it on FP16 instead of FP8.  It's slower, but it ultimately works the same way.    Though it's still bizarre because it does seem AMD has \*already done\* the work to get FSR4 working on FSR3, even it might have been more effort to do so.    I can also see that maybe FSR4 on an architecture with a bigger performance penalty might not make as much sense in a mobile device where you really need upscaling to be efficient to be worth it.",Neutral
AMD,"Fsr4 will on the ps5 pro by march, which is RDNA3.5, so surely itll also be on these products, if not, that would be a disaster",Negative
AMD,NVIDIA does own a piece of Intel so it makes sense.,Neutral
AMD,"I think those are expected 2028 so yeah, probably correct.",Neutral
AMD,"Those are Strix Halo competitors. Intel is not using small Nvidia GPUs here but yeah   (Small and medium = Intel, high end = Nvidia is what it seems and it will be a winning strategy, AMD will be the worst option in laptops soon)",Neutral
AMD,"Nothing â€œinherentâ€, but perhaps not worth the effort.  RDNA4 adds more transistors over RDNA3 and improves RT performance in an â€œarea inefficientâ€ method. (Second intersection engine) Out of order memory returns also is RT centric feature.  So on a product where you donâ€™t care about RT, rdna4 gives little benefit for its increased transistor usage, but it did still improve raster somewhat.  Whereas RDNA3.5 vs 3 focussed exclusivity on mobile perf/watt features given that itâ€™s not available on desktop.  Donâ€™t think of RDNA3.5 as a sort of â€œhalf measureâ€ between RDNA3 and 4.  Itâ€™s more of an independent evolution over 3 adding mobile centric perf/watt features and dropping the features that improve â€œscalabilityâ€ for large configs.   There is also the market, where despite all of us wanting to see these â€œlarge iGPUâ€ products, most of the mobile stuff really doesnâ€™t care.  Krackan (8core 4WGP) vastly outsells Strix (12C 8WGP).  And the largest RDNA4 on mobile would be 8WGP again due to memory BW. (half configuration of 9060XT)   Intels iGPU is VERY impressive given how lacklustre their desktop iGPUs were. But I guess thatâ€™s expected when youâ€™re using TSMC N3.",Neutral
AMD,"iâ€™m in the same boat. amd hasnâ€™t done anything exciting since the the og steam hardware, so thereâ€™s no point to consider any of this new amd tech. iâ€™ve loved my lunar lake device but it doesnâ€™t play as well with linux, which is becoming more and more important to me",Negative
AMD,You're not alone. I'm not really the target audience for it but I totally checked out on the Steam Machine after learning about the gpu. The controller looks fantastic though.,Positive
AMD,"That makes sense, and checks out what Radeon usually does.",Neutral
AMD,Rdna3.5 itself was already only 10-15% faster than the 780m due to memory bottleneck. 780m came out in CES 2023. 780m itself was around 20% faster than 680m that came out in 2022. So in 2022 to 2029 there will not even be a cumulative 40% improvement in their mainstream iGP.Â   Intel HD 2000 to HD 530 had bigger % gain from 2011 to 2015.,Neutral
AMD,"My guy, Cezanne (5000G series) had GCN based models release in 2024, _five years_ after the first RDNA card.",Neutral
AMD,"Mate, AMD still sells Zen 2 architecture in 2026, that's 7 years old now. 5 years won't even be AMDs worst offender.",Negative
AMD,"most likely they'll either go with something else or use the premium iGPU, but it's really  hard to make predictions right now about anything because the consumer PC market is basically SOL and I'm not sure there is an end in sight TBH.",Negative
AMD,"Valve has been pushing arm architecture for SteamFrame, maybe SteamDeck 2 will be arm-based.",Neutral
AMD,Hopefully it will be an Intel chip and use Xess,Positive
AMD,Steam Deck 2 could use an ARM SoC  [https://www.tomsguide.com/computing/valve-just-dropped-a-massive-hint-that-the-steam-deck-2-could-switch-to-arm-heres-why](https://www.tomsguide.com/computing/valve-just-dropped-a-massive-hint-that-the-steam-deck-2-could-switch-to-arm-heres-why)  [https://frvr.com/blog/news/steam-deck-lead-reveals-valve-is-funding-arm-compatibility-of-windows-games-to-expand-pc-gaming-and-release-ultraportables-in-the-future/](https://frvr.com/blog/news/steam-deck-lead-reveals-valve-is-funding-arm-compatibility-of-windows-games-to-expand-pc-gaming-and-release-ultraportables-in-the-future/),Neutral
AMD,"It'll be Intel, or more likely, Qualcomm/MediaTek/custom ARM.",Neutral
AMD,That'll depend on the success of the Steam Frame. If the Windows to ARM translation is good enough we could see a Steam Deck Mini,Positive
AMD,"Not a whole lot IMHO. I think the old statements from Valve about wanting a meaningful improvement within low power envelope and reasonable cost still hold. So far whether it's RDNA3, 3.5 or 4 as well as new Zen architectures *and* manufacturing nodes, progress in this regard has been very slow.  Unless something changes about target price or power envelope of the Deck, I don't see it having any possibility of releasing in immediate future.",Negative
AMD,"The Steam Deck 2, if it's another x64 AMD APU will likely be using a 'premium' design.",Neutral
AMD,"PC market does not really use APUs, except for the really low-budget ones. Main market for APUs are handhelds, laptops, consoles. In the CPU market AMD is dominating, vast majority of newly sold CPUs are AMD Ryzens",Neutral
AMD,"I think Intel has to keep developing most of GPU/multimedia IP either way, because if they didn't, they couldn't release any CPU without nvidia in a few years, which would spell trouble for client (not that client really matters for anyone atm, even though if Intel can capture that they'd be a bit happier)   The question is how much Intel is willing to invest more compared to their pre-Xe time.",Neutral
AMD,"No, it's because Intel knows nVidia couldn't maintain a semicustom partnership with guns to the heads of the leadership and thus knows this won't last.",Negative
AMD,"Mixture of that, software dev and do we have a definition of 'premium APU'? 3.5 is perfectly adequate for low end laptops and CPU iGPUs that exist as a fallback for when there's not a dGPU around, why add potential validation headaches?  Edit: Anything more then a 3.5 in my 13850X3D that I buy when it's EOL/used a few years down the line is a waste of time IMO because it's just adding extra validation work and thus waiting for me before it's launched and EOL/used when it's going to be running with a decent DGPU",Neutral
AMD,"I still remember AMDâ€™s marketing from a few years back, dragging Intel for â€œforcing you to choose between cpu and integrated graphicsâ€ but not giving you both at the same time. It was when 14nm Comet Lake-U with 6 core/12 thread and 10nm quad core Tiger Lake-U but with much better Xe graphics co-existed.",Neutral
AMD,"Rumour would have it the ""mainstream"" APU getting 8CU rdna 3.5. Which will be the successor to Gorgon Point, which currently has 16CU rdna 3.5.  We're not even talking about the desktop or desktop replacement 2CU tier.",Neutral
AMD,"No.   Halo tier (strix halo successor, ""ryzen ai max"" product line) will get RDNA5, and everything below will remain on RDNA 3.5. Basically Ryzen 9 HX 370 and everything below is not getting an upgrade. In fact they're downgrading everything in those tiers to 8 CU or less",Neutral
AMD,"Just because AMD will still be selling chips with old architecture doesn't mean they'll keep supporting them software wise unfortunately, like they were still selling the Zen3+Vega APUs as part of the ""Ryzen 7000 series"" when they kicked Vega support out of their latest drivers. Not to mention the recent debacle with them reducing support for RDNA1/2 when they are not only still making RDNA2 stuff in the form of the iGPUs on the desktop side but also as the Ryzen Z2 Go, not to mention they were also selling RDNA2 APUs as part of the Ryzen 7000 series right next to the Vega stuff.",Negative
AMD,"They were still putting Vega in iGPUs long after they degraded support for dGPUs.  I still have my old 56 on the shelf, btw.",Neutral
AMD,They can update their codec ip while keeping RDNA 3.5,Neutral
AMD,"They do sell laptops with iGPUs from years ago, but pairing their iGPU from years ago onto their newest CPUs (and I donâ€™t mean refreshes) is not something theyâ€™ve done yet.     The closest is Arrow Lake which had Alchemist iGPUs instead of Battlemage iGPUs, but even then, they were still somewhat different from the original Alchemist iGPUs with the addition of XMX.",Neutral
AMD,"Anyone who is interested in handheld gaming, such as the millions of people who bought Steam Decks...",Neutral
AMD,That would be fun,Positive
AMD,Do it to the HDD and SSD markets too!,Neutral
AMD,The april fools is amd getting their current gpu architecture into a mobile chip in a timely manner.,Neutral
AMD,"I mean it would just crash to where it was before. The whole issue is that not only would it take many years for Samsung and SK and Micron to ramp up RAM production, they are currently not planning to, since they believe this to be a temporary spike in demand.   So if that were to reverse, it's not like there would suddenly be an oversupply of RAM. There would just be how much RAM there was before the demand spike.",Negative
AMD,With all the manipulation going on.. that actually wouldn't surprise me one bit.,Negative
AMD,I actually wouldn't be surprised if they make deals with strategic important US companies to provide memory.,Neutral
AMD,If Openai backs out it barely moves the needle on the dram market.,Negative
AMD,"All AMD SOCs with RDNA3.5 graphics also support XeSS 2 and XeSS 2 Frame Generation, funnily enough.",Positive
AMD,"For there to be a new Z3 chip there has to be a low power (15-45w) APU with the corresponding iGP first. Z2 extreme is just a cut down strix point, and Z1 extreme Phoenix after all.",Neutral
AMD,"So in order to get people to buy less premium chips, they... restrict their modern features to the premium chips.",Neutral
AMD,"more like self impose constrained. TSMC has enough capacity to book.  I have not see a company that just happy with minority market share & hamstrung themselves.  if we give nvidia with only 30% market share, they will be running at their full speed to increase it because selling 80unit at $100 profit margin is better than selling 20unit at $200.",Neutral
AMD,At least the market dominance is only ever temporary. The shit part is it's only temporary because of the terrible job the leader does.,Negative
AMD,"AMD has never had the market share Intel had. They're *just now* getting to the share that Intel established in the early 2010s.   Intel held that market share for nearly a decade. So AMD will have to hold this for another 7-8 years before they've officially ""pulled an Intel.""   Zen 6 desktop is due for a late 2026 launch. We all know that Zen5 was a bit of a let down for the consumer market, but Zen 6 looks to include much larger improvements on paper.   Basically, AMD has to fuck around and do nothing impressive for a few years before they've reached ""Intel Stagnation"" levels of bullshit.",Neutral
AMD,Crazy that it took Intel almost filing for bankruptcy to wake up.,Negative
AMD,"Intel is still destroying them in laptop sales, itâ€™s really not the time to let off the gas.",Negative
AMD,> Since Intel is weak  B390 looks very promising.,Positive
AMD,"> If Intel were at the top of their game, AMD would be giving you the newest rdna  Pretty sure that's not the problem. The problem is RDNA4 was designed (physically) as a single die layout. They have a 64cu die, which looks like an hourglass, and 32cu die, which is 1/2 of the hourglass. It's clear that from the start it was a stop-gap design for the desktop market.   They've said it's also the end of ""RDNA,"" and the next uArch will be UDNA, a ""merger of CDNA and RDNA.""   So they didn't design RDNA4 to be modular beyond 64/32cu designs. They intended UDNA to be the follow up, and I previous wagered that since it's a ground-up uArch (like RDNA was to GCN), they're building it from the ground up to be used in any applications.   The issue is UDNA is taking longer to cook. Is that intentional? Who knows. It could be that they pulled resources to push Instinct Compute development, could be that they're having Development Hell problems, could be anything. I don't doubt AI market bullshit is to blame.   But either way, UDNA wasn't likely to be in this years APUs either way, even if UDNA dGPUs were to release.",Neutral
AMD,"Except Intel isn't weak, not in laptops at least. Their last generation was already as good as RDNA3.5. Imagine what they'll have in 2029 with Xe4 or 5.",Positive
AMD,Intel's last gen lunar lake already beat out amd for the most part.   Panther lake is really just the nail in the coffin making amd the budget laptop chip option,Neutral
AMD,"People continually act surprised when businesses prioritize profit.   There is rarely a need to make something the best it possibly can, it just has to be slightly better than the competition. In fact, a lot of what nVidia has done in recent times has pretty much been along the lines of: ""well, what else are you going to do, buy AMD?""",Neutral
AMD,"Surely everyone who criticized 14nm intel will do the same when amd does it too...right?..  Like core count is literally stale, igpu got stale, only good things are in super premium products. It's all over that intel did during it's worst years",Negative
AMD,They simply arenâ€™t prioritizing it. All the rnd goes to datacenter and cpu,Negative
AMD,Rebrandeon,Neutral
AMD,"Amd dGPUs are super rare in laptops, but not amd cpu/apu.",Neutral
AMD,21% of the market isnâ€™t rare,Neutral
AMD,"> It is already rumored that Nova Lake Xe3p will bring +%25 over IPL Xe3  PTL/NVL-P (the bigger iGPU die which they've since merged into the -H branding) counts as ""premium"", and that's the only one getting the Xe3p treatment with NVL. The lower end will likely remain Xe3 through at least RZL, maybe TTL. Same deal with WCL.",Neutral
AMD,"itâ€™s strange because snapdragons mobile processors are really good, but the desktop class processors are pretty garbage. Youâ€™d think they would just scale up the architecture like apple does",Negative
AMD,"Sure, RT on mobile doesn't make much sense, FSR4 on the other hand absolutely would be especially given the garbage state of game optimization relying on upscaling as a crutch, not to mention games showing up that requires RT no matter what like the new Indiana Jones and DOOM games so you need half decent RT performance anyway.",Negative
AMD,A constraint that is exclusive to AMD but not to Intel or Apple it would seem.,Neutral
AMD,Samsung is using it for their new Exynos chips.,Neutral
AMD,"And what will be their answer to Panther, at Panther prices, providing Panther battery life and at Panther TDP range (15-45w) under load?",Neutral
AMD,"Medusa Halo will probably be even more expensive, but Medusa Premium (128b memory bus) should be much cheaper",Neutral
AMD,"And we all know how well Strix Halo is doing in laptop sales...  Non-existent.  It has its niche, but it's also a top 3 paper launch for AMD.",Positive
AMD,"Eh rather than underestimated Intel, it's just Radeon division that are slow and probably need more experienced manpower. They really need that ""tick-tock"" team strategy from AMD CPU division.  For example, they took years with FSR4 and Raytracing Redstone still barely in any games, RDNA3 have hardware encoding bugs, bad driver for years until recently, poor marketing, and etc.  Like did you really think they ""underestimated"" Nvidia?",Negative
AMD,"But people who have no idea what FSR,DLSS or XESS is, are also people who will just buy laptop that says Intel inside, cause that's what they have been doing for past 20 years. So AMD will just be losing on both fronts",Negative
AMD,Rdna3 does support fp16 tho,Neutral
AMD,Neither PS5 is a straight 1:1 to an RDNA version.,Neutral
AMD,"That is a fantastic response, thank you!",Positive
AMD,"> Krackan (8core 4WGP) vastly outsells Strix (12C 8WGP).  Part of this is cost/market segment, Strix is priced *way* up there. We're back at a point where budget/mid level Intel makes the most sense to purchase, which is where AMD was when it was burning market share. They *really* need to get their engineering & finances together to make it work if they actually want to grow.  >Intels iGPU is VERY impressive given how lacklustre their desktop iGPUs were. But I guess thatâ€™s expected when youâ€™re using TSMC N3.  Battlemage (and soon, Celestial) launched a lot of technologies (that are, as far as I know, new and unique to Intel) and implementations (of things other vendors have had for a while). It really did put them much closer to parity--and they never had the memory bandwidth limits RDNA seems to have anyway. They really could have put in a larger GPU in if they wanted to--it seems like they will--and AMD is now announcing they won't be changing anything. TBH, I don't know what exactly possessed AMD to announce they are going to let Intel rest and recover during their nadir for the next 3 years. Only developing 1 or 2 actual iGPU's and leaving them up for the $1600+ market segment just means almost everything below that will be using Intel instead. Like... there's no imagined configuration where a dGPU model that fits in below that price would be CPU bottlenecked enough to justify reaching for the RDNA 3.5 parts, *and* using Intel means they get a better iGPU & more profit anyway.  Unless the margins on their RDNA 3.5 parts are razor thin (and TBH judging by Minisforum's PC's that's not the case!), there's just no world where they're going to be gaining market share.",Neutral
AMD,"I'm surprised it was given such a pass. A 2022 GPU that had some big performance gotchas even when it was released... being sold in 2026 and it's expected to last for how long? And they are going to want over $800 for it?  It's a very poor decision, it really needed RDNA4 to be a realistic machine that can last.",Negative
AMD,"If they go the premium iGPU route they will kill their sales, as value is the main reason to buy a Steam Deck, since they heavily subsidize it (to grow the market) compared to the competition. But long term I don't think Valve even wants to be in the hardware market, they only make devices to try and create a new market for Steam and then after 5+ years they leave the market themselves.  My guess is the Deck 2 will be a price increase but still using lower end hardware compared to other manufacturers, and it will be their last push before they let the hardware companies take over",Negative
AMD,Meh,Neutral
AMD,"I'd love to see them using an Intel chip just so they can help whip Intel's Linux Vulkan drivers into shape like they've done for AMD, but then there's the question if they would bother doing that and effectively starting over rather than just continuing the work they've already done on the AMD drivers. Not to mention that the Steam Frame is using a Qualcomm chip so they're already split on working with both the AMD and Qualcomm drivers, adding Intel into the mix would probably just cause more of a headache.  Although it's not like Valve is opposed to doing things that wouldn't directly benefit their own devices, like the guy leading the work on getting the GCN 1.0/1.1 GPUs (as in the Radeon HD 7000 series plus the Radeon R9 200 series plus rebrands) to move to the latest Linux driver and enabling Vulkan out of the box (rather than using the same old driver as the TeraScale stuff) is from Valve (https://indico.freedesktop.org/event/10/contributions/429/attachments/246/332/xdc2025_old_gpus.pdf) so if Intel's GPUs gain enough momentum they may very well decide it's worth investing into.",Neutral
AMD,Would be funny to eventually see some YouTuber buy a Redmi or something and install Steam OS on it.,Neutral
AMD,Will be very curious how they will plan to price it when the current SD uses a bottom of the barrel outdated-at-launch Zen 2/rdna2 chip.,Neutral
AMD,[Intel still has about 2/3 of the cpu market](https://cdn.mos.cms.futurecdn.net/8XDu42DyqzyDEbYPEjdAw7-1200-80.png.webp),Neutral
AMD,AMD still doesn't dominate desktop CPU market as a whole.  >[AMD] now ships over 33% (one-third) of desktop x86 CPUs.  https://www.tomshardware.com/pc-components/cpus/amd-continues-to-chip-away-at-intels-x86-market-share-company-now-sells-over-25-percent-of-all-x86-chips-and-powers-33-percent-of-all-desktop-systems,Neutral
AMD,"> In the CPU market AMD is dominating, vast majority of newly sold CPUs are AMD Ryzens  My guy, you need to get your facts right. This statement is only true for the enthusiast gaming segment, which is a drop in the ocean as far as total CPU's sold.",Neutral
AMD,"Right, the handheld market that AMD absolutely dominates in, yet have inexplicably decided to completely abandon? That handheld market?",Negative
AMD,"It's possible that Intel+Nvidia combo could be primarily targeting AI even on desktop. I.e. an x86 version of DGX Spark. The official statements seems to imply that:  >This historic collaboration tightly couples NVIDIAâ€™s AI and accelerated computing stack with Intelâ€™s CPUs and the vast x86 ecosystem   Jensen Huang  >Intelâ€™s leading data center and client computing platforms, combined with our process technology, manufacturing and advanced packaging capabilities, will complement NVIDIAâ€™s AI and accelerated computing leadership to enable new breakthroughs for the industry.   Lip-Bu Tan  [https://nvidianews.nvidia.com/news/nvidia-and-intel-to-develop-ai-infrastructure-and-personal-computing-products](https://nvidianews.nvidia.com/news/nvidia-and-intel-to-develop-ai-infrastructure-and-personal-computing-products)",Neutral
AMD,And yet the Switch 2 exists.,Neutral
AMD,They just recently released the second rebrand of 6800H and called it â€œRyzen 100 seriesâ€.Â   Itâ€™s based on Zen 3 and rdna2 which came out on desktop in 2020.,Neutral
AMD,"â€œPairing their gpu from years ago onto their newest cpu is not something theyâ€™ve done yetâ€.  And that would be a bad thing? LOL There is talk of selling products based on non-recent architecture and this is also done by Intel naturally and in a worse way. There are many laptops released in the last year that use igpu xe from 3 years ago with a cpu from 3 years ago.  Amd instead inserts an updated cpu with a less updated igpu and this is a pro unlike offering cpu as old as Intel.  There are many use cases in which it is very useful, for example for those who work in the office and do not need dedicated igpu and can buy an updated laptop under the cpu profile with igpu rdna3 at a fair price.  For the enthusiast segment there will be the due offers certainly with rdna5.  If AMD sells apu based on rdna3 architecture it doesnâ€™t mean it doesnâ€™t also sell rdna5, they simply offer more options.  Sometimes I read incredible things, then itâ€™s a rumor with a slide made by Gemini holy god what a world of ignorant people",Neutral
AMD,"It is just a little bit of negative cash flow and analysts asking: ""who would be willing to pay for the current and foreseeable AI capabilities while the company is burning money/energy at the same rate as NVIDIA makes last years AI GPUs obsolete?""   Grok had its CSAM moment, so there is a customer segment there which Elon would be happy to serve.",Negative
AMD,That would mean I could upgrade my AM4 system. I'm all for it.,Positive
AMD,"Each of the big players is delivering unprecedented amounts of new capacity in the next 3 years :  - Samsung P5 is on track to be Samsung's biggest and most advanced memory mega-fab. It was halted in 2024 during a memory bust, and resurrected to be delivered in 2028 100% due to the desire to catch up to the AI datacenter demand.  - SK Hynix fab cluster. $90 billion USD of memory fab capacity in 2027 and 2028 phases.  - The Micron $100 Billion megafab coming live in 2030, but the smaller $15 billion Idaho fabs are coming live this and next year.  - The CXMT massive Shanghai HBM fabs coming live later this year, and their $42 billion DRAM expansion is underway. They also aim to aggressively take over 15% of the global DRAM market by next year while the big three are leaving a gap in to prioritize data center.  Everyone is saying ""the biggest risk for the market is that we overshoot"" signaling to others to stop building, but they themselves are building because what they're scared of is missing on supplying a massive demand at historically high profit margins.  The global DRAM bit demand growth is currently hovering in the 20-25% range (per Micron and IDC), despite the dramatic headlines. If we don't get AGI or something crazy like that to actually pay for all that RAM, we're about to produce massive amounts of memory on an unsustainable blip in demand.",Positive
AMD,"China is really good at repurposing silicon. Their low-end market is full of new ""X99"" motherboards with recycled Intel chipsets that supports only server Xeons because they're actually C612.  Repurposing DDR5 ICs from 3DS/LR/RDIMM for desktop UDIMM would take less engineering than designing and manufacturing consumer motherboards around a server chipset.  HBM on the other hand would be tough, and I don't know if OpenAI buys any GDDR products.",Positive
AMD,"No, sell more premium chips but less overall chips. Send the value customers to competitors. As long as the AI boom keeps chugging.  I edited my original post, hopefully it makes sense now.",Neutral
AMD,The topic at hand is mobile integrated graphics.,Neutral
AMD,"This is a bit of an exaggeration, isn't it?",Negative
AMD,they've been doing some cool shit since lip-bu tan came into office tbf,Positive
AMD,"we can only hope. Real competition is good for the consumer. Right now AMD definitely resting on its laurels and coasting. I don't think it is a good choice. And if they keep this arch until 2029 ... wow, Nvidia is going to cream them in the consumer space.",Negative
AMD,Too early to tell without a price reference.,Neutral
AMD,"They're coming out of their slump but certainly not in their glory days. I hope they completely recover, including their fans, cause we need the competition. It's the only thing that keeps these guys in check.",Neutral
AMD,Is it really prioritize  profit when your market share drops from 30% to below 10%? And when the new competitor is eating from your market share than the big one!,Negative
AMD,"prioritize profit means selling three times as many chips at half the price.   sitting at 20-30% market share is dumb, infact AMD market share is even worst in mobile segment.",Negative
AMD,yup. i criticized intel and will absolutely criticize AMD.  brand loyalty is stupid. tribalism gets you nowhere. these mega-corps donâ€™t give a damn about anything but the almighty dollar. why anyone would be loyal to a corp is just beyond me.,Negative
AMD,"Yes, they already are. But just like the criticism of Intel, it won't make any difference.",Negative
AMD,When intel was on 14nm they had over 80% of market share. Does AMD laptop now has 80% market share?,Neutral
AMD,"Intel is still in their worst years imo. Their new laptop chips are awful for gaming, so all the best gaming laptops are pairing new rtx5 series gpus with 14th gen Intel chips.",Negative
AMD,"Yeah, that's what I meant.",Neutral
AMD,"But itâ€™s quite funny once you see that the 21% has essentially been flat since Cezanne (2021, zen 3). It isnâ€™t a steady growth like in the data centre for amd, they just been stagnating at 20-25% for years.",Neutral
AMD,"21% is abysmal considering that AMD HAD the better iGPU, power efficiency, and CPU for years.  Now they've absolutely lost power efficiency by a mile, lost iGPU in every segment that actually sells, and only are really a contender in workstation laptops.  That 21% is going to shrink long before AMD gets a new mobile platform out (2027).",Negative
AMD,Better than their GPU market share in this era :/,Neutral
AMD,"Yep they are and this ""premium"" segmentation for iGPUs are just boring for me.  1.5K-2.5K premium Windows laptops don't make sense to me. I get Macbook Pro. If I want Windows on it there are still options (Parallels, Fusion, UTM etc). This is just me tho. It is good to have alternatives but it sucks because alternatives are also not cheap :)",Negative
AMD,"Apple, unlike Qualcomm, has the power of vertical integration.  and Apple, unlike Qualcomm, is much more competent in software.",Positive
AMD,"Dark Ages requires ray tracing for some effects, but looking at benchmarks, it appears to be limited by memory and raster performance first and foremost. People even got it to run on non-raytracing GPUs, with only a few visual glitches.",Neutral
AMD,"nothing, they just rebranded zen 5",Neutral
AMD,"I'm sure they'll put Zen 6 and so on into APUs, but it sounds like RDNA3.5 is the new Vega and they'll probably still be selling APUs with it after the driver for it goes EOL just like Vega.",Neutral
AMD,How can Radeon need more experienced manpower when theyâ€™ve literally built GPUs for 20+ years? Itâ€™s just incompetence,Negative
AMD,"That's great, but this isn't DLSS.    AI-based FSR is INT-based.    That's kind of the whole point.  You cant just interchange these things like you can with the same operands.",Neutral
AMD,"Valve's strategy is to make SteamOS viable not just on the Deck. They are supporting third party products now, and aim to do so more broadly as a reference PC is now launching with SteamOS. It is inevitable that they move on to Intel drivers as well to ensure any device running Intel chips is capable of using SteamOS as their gaming platform.    It's not just Intel's massive market share that is surely appealing to Valve. They have to with how quickly Intel is moving with their iGPU, and Intel's callout in the Panther Lake announcement that with this product they are serious about their handheld platform, with more ""news"" coming later this year. I will not even be too surprised if ""news"" is a Panther Lake Deck 2. Valve will finally find their ""generational"" bump in <20W performance in that range. Intel suddenly looks like it's made for handhelds with their ecores and the iGPU efficiency progress.",Positive
AMD,you should check out r/EmulationOnAndroid,Neutral
AMD,Probably when those premium designs are in a similar boat.,Neutral
AMD,"And is notable for being probably the only time nVidia's not beefed one of these, Nintendo has an earned rep for... weird... hardware and it's coinflip at best if nVidia reaches Switch 3.",Neutral
AMD,">Grok had its CSAM moment, so there is a customer segment there which Elon would be happy to serve.  Demn I had to google what CSAM means and now I'm probably on some kind of a list",Positive
AMD,"The collapse can't happen soon enough. The bigger the bubble, the worse the aftereffects",Negative
AMD,"The comment I'm replying to says   >Sounds like how Intel used to be.   >Red and Blue always be switching it up   AMD never had usable onboard graphics, not until Phoenix, which was very recent and not very well distributed. So clearly the person I'm responding to is talking about Intel/AMD product stagnation as a whole.",Negative
AMD,All the cool stuff was developed under the old CEO. Too bad they fired him,Negative
AMD,Doesn't AMD have a bandwidth problem to solve - presumably intel to going to face the same challenge,Negative
AMD,"[Ultra X7 358H will be the cheapest chip with full B390 iGPU](https://www.intel.com/content/www/us/en/products/compare.html?productIds=245523,245526,245527,245531), and only a minor clock speed reduction compared to the top end X9.   ~~[Cheapest laptop with the 358H is $1450](https://www.bestbuy.com/product/hp-omnibook-x-copilot-pc-16-2k-oled-touchscreen-laptop-intel-core-ultra-x7-358h-2026-32gb-memory-1tb-ssd-meteor-silver/JJGW34X2K5) with 32GB RAM/1TB SSD and generally premium looking specs otherwise.~~ **See reply below for 358H laptop at $1300.**  338H will probably be the sweet spot for ultraportables and handhelds with 83.3% of the Xe Cores of the B390 and missing 4 of the regular E-cores, but no products with prices yet.",Positive
AMD,"Intel dominates the laptop market.  >  Their new laptop chips are awful for gaming, so all the best gaming laptops are pairing new rtx5 series gpus with 14th gen Intel chips.  Doesn't that also say something about AMD when laptop manufacturers will go for older Intel CPUs than their latest?",Negative
AMD,"It's a zero sum game, if one goes up one goes down. You can't just grow in % infinitely. 20-25% market share isn't bad.",Negative
AMD,"FSR4 is FP8, and you can actually already run it (unofficially) on FP16 on Linux with RDNA3.",Neutral
AMD,"Huh? FSR 4 on RDN4 is using FP8, just like DLSS4, the leaked version that AMD hasnt made official uses INT8",Neutral
AMD,"That is old news, would be more fun to have a Steam OS phone.",Neutral
AMD,"So, 2030",Neutral
AMD,Nvidia might actually have met their match in the pure arrogance in Nintendo,Neutral
AMD,MS used NVIDIA in the zune and surface after the Xbox. Sony currently uses NVIDIA in their pro reality display and for AI.  It's just fan fiction to say they don't continue to work with companies,Neutral
AMD,"I don't remember when we started using this instead of the universally known cp, internet moves fast",Neutral
AMD,"The bigger the bubble, the more investment goes into the fabrication capabilities and design pace of products that we will inevitably be buying when it pops. This bubble has an unprecedented downstream upside for our hobby. The companies that everyone pours astronomical amounts of money into make GPUs, memory sticks, and cutting edge chip fabrication.",Positive
AMD,Problem is this bubble has been going since 2008.  AI is just the latest version of it.    The dollar is the bubble now....few understand except the rich.  Look at gold.,Negative
AMD,"358H for $1299, also with 32GB/1TB: [https://www.bhphotovideo.com/c/product/1939343-REG/msi\_prestige\_14\_flip\_ai\_d3mtg\_001us\_prestige\_14\_flip\_ai.html](https://www.bhphotovideo.com/c/product/1939343-REG/msi_prestige_14_flip_ai_d3mtg_001us_prestige_14_flip_ai.html)",Neutral
AMD,"They're ignoring the current gen chips from both manufacturers because they don't perform as well. The reason? The only improvements they've made is to power efficiency (but they're severely limiting power, so no performance gains, just longer battery life) and ai workloads. Because apparently that's all that matters anymore even though no one wants it taking up a third of their cpu die. Both companies suck.",Negative
AMD,Lmao what. No lol. There is so much space to grow.  Markets grow and expand. Marketshare can grow too.,Positive
AMD,I guess â€œisnâ€™t badâ€ is the best one can hope for for AMDâ€™s stagnating client side in this day and date,Neutral
AMD,"Yeah, if anyone could outunreasonable them enough to get decent results, it's them.",Negative
AMD,Their â€œarroganceâ€ lead to a trillion dollar company. Maybe looking at chasing low margin console chips and instead investing in GeForce and then cuda was the right move? Rather than be a tiny sticker at the bottom of the console and live in obscurity nvidia chose to invest in their own brand.,Negative
AMD,"I agree, but it has an even more unprecedented downstream downside to my life, livelihood, and most of humanity as a whole.",Negative
AMD,"> .few understand except the rich. Look at gold    It's funny that you say this, because your premise is completely wrong. The rich aren't actually invested in gold.",Negative
AMD,whats the point of having a strong igpu for a flip computer with 60hz 1200 monitor though. i'd rather the one mountain linked.,Negative
AMD,"Marketshare % is always out of 100%. One company can't go up in marketshare unless others are losing %. I don't know how market share % is even debatable, it's always out of 100%.",Negative
AMD,By stagnating client side you mean majority of newly sold CPUs being AMD?,Negative
AMD,Plus we know the cost is extremely low for both Nvidia and Nintendo despite the switch and their low budget games selling for outrageous prices relative to cost.Â   The wet dream for both nv and Nintendo.,Neutral
AMD,"Just linked a cheaper laptop because mountain said it's the cheapest. I would pay the premium to get a better display as well, otherwise it would be a downgrade over what I have already.",Positive
AMD,"Youâ€™re right. I overlooked market share and was thinking about volume and growth.  AMD is probably still seeing growth as the sector continues to expand, just by keeping their current market share. They can be expanding but not gaining market share.  The term growth was used earlier, so in that context, itâ€™s not fair to focus on market share. They can be shipping more units and growing revenue, which is probably more important than market share (not that marketshare isnâ€™t relevant, itâ€™s more a popularity thing).",Neutral
AMD,"Not at all, it just means youâ€™re a delusional PCMR / ayyyymd type user who thinks the DIY desktop is somehow important when the laptop began to outsell the desktop 20 whole years ago.",Negative
AMD,Majority of newly sold CPUs? Got a source on that one?,Neutral
AMD,"To be fair even though it's a low cost device in terms of BOM, it punches above it's weight. The fact you can play AC Shadows and Cyberpunk on the go is a testament to how good NVIDIA can make silicon. Mind you it's on a pretty terrible node too. But you're right, Mario Kart and Mario games in general are cartoony simplistic graphics games, so generally easy to run.",Positive
AMD,Fundamentally different animal to that deal with Intel; the latter kind we know nVidia has historically fucked up every time.,Negative
AMD,[https://www.techspot.com/news/110677-amd-dominates-amazon-best-selling-cpu-chart-taking.html](https://www.techspot.com/news/110677-amd-dominates-amazon-best-selling-cpu-chart-taking.html)   [https://dropreference.com/en/blog/news/amd-dominates-intel](https://dropreference.com/en/blog/news/amd-dominates-intel)   [https://overclock3d.net/news/cpu\_mainboard/amd-hits-record-cpu-market-share-on-steam/](https://overclock3d.net/news/cpu_mainboard/amd-hits-record-cpu-market-share-on-steam/),Neutral
AMD,"The AAA games that run on the switch look like if you go into the config files to lower the settings to well below the minimum settings to run GTA V on circa 2009 Intel integrated graphics, however",Neutral
AMD,It will be fun to see what comes of it and how long it lasts,Positive
AMD,Thatâ€™s a statistic from a single German retailer. Way too small a sample size.   Doesnâ€™t factor in OEMs which are the majority of the market.,Negative
AMD,"Not always, sometimes they're legit good ports like AC Shadows.",Positive
AMD,"My expectation is that the coming design will ship, and we'll find out a few years after how the agreement broke down shortly before and precluded a second gen.",Neutral
AMD,"Huge improvements to latency vs ARL-H [(84.4ns vs 149.1ns)](https://forums.anandtech.com/attachments/1769440510043-png.137334/)  I'm looking forward to seeing some ISO-GPU gaming comparisons with the dGPU models in the next few days, to see what ARL could've been had it not had so many problems.",Positive
AMD,"He mentions that it's kind of a crutch to use 99 WHr batteries to get these battery life numbers â€¦. but I honestly applaud Lenovo and ASUS for doing that.  As we've seen in smartphones and even many laptops, batteries are ridiculously light per WHr. Just add more battery.   On my soapbox: every 15"" and larger laptop should have 99.9 WHr (max air travel size) batteries. All of them. I don't care what CPU: Intel, Apple, AMD, Qualcomm, etc.   There's no reason in 2026 that many bigger laptops are at 70 - 80 WHrâ€”except for cost and poor packaging.",Neutral
AMD,How does this compare to a Snapdragon CPU in terms of efficiency and longevity?,Neutral
AMD,"Impressed with content workflows with Blender and Handbrake performance on GPU and adobe PP. Davinci Resolve gets a nice uplift from LNL, but the M5's media engine is class leading. Still, probably nothing better on Windows laptops so that's nice. Photoshop and Lightroom are decent uplifts but ARM seems to be catching up in that regard with their ppt advantage. Performance on battery though, is pretty decent and is the turning point so far, HC saw \~10% loss on battery, though these were CPU workflows, would've liked to see Blender, but good stuff overall!",Positive
AMD,"Extremely impressive GPU. CPU is a very small improvement over Lunar Lake, overall chip efficiency still lags behind Apple but leaves AMD in the dust by a country mile",Positive
AMD,"Going by the XPS 16 with an Ultra 7 h is Â£2500, these Ultra X9's are gonna sting the wallet, even if they are very performant.",Negative
AMD,"For the first outing on 18A the CPU looks very impressive.   Seems to be ruffling some feathers, of course Intel were always far in the lead on mobile and AMD are no threat there but this further cements their lead.",Positive
AMD,New chips are looking good for mobile.,Positive
AMD,"min/Whr x9 388h lenovo has nearly the same efficiency as ultra 9 288v acer sift ai. Gpu is nice, cpu looks the same. Price/avaibility are going to be the deciding factor",Positive
AMD,"Honestly, don't know why you'd buy an AMD laptop these days.   * If you prefer OS X to Windows, get a Mac with Apple chips * If you want peak battery life on Windows, go with Snapdragon * If you want the multi-thread performance and integrated graphics, go with Intel     What does AMD do better than the competition? Strix Halo would have been an interesting product, if it showed up in more than 2 laptops.",Neutral
AMD,The single greatest thing I saw in this video was the X9 matching the M5 MacBook Pro in Blender and Premiere at similar power levels.  EDIT: Never mind. Just Joshâ€™s video shows it getting absolutely demolished. And Nvidia getting destroyed. Oh dear oh dear,Positive
AMD,It says a lot that most if the positive comments are about the GPU made by TSMC and not the CPU on 18A.,Neutral
AMD,$600 price difference between the 388H and 288H version,Neutral
AMD,It's the CPU I've been waiting for to upgrade my intel mac... I'm just too scared to see what 64gb ram and 4tb ssd cost this year..,Negative
AMD,"WHY ON EARTH do they have to start every video with ""So, [...]"" or ""Alright, so [...]"", it's driving me NUTS.",Negative
AMD,Looks like exagarated hype and marketing campaign. Let us wait half a year to see how this will do when machines hit market.,Neutral
AMD,Can somebody educate me how they achieving this with x86? I dont follow them regularly but last time they have some trouble and now boom their new cpu is battery king and not even arm chip?,Negative
AMD,I really wish this channel wouldn't mention USD pricing. It's not relevant considering they market themselves as Canadian.,Negative
AMD,"If this brings a boost to performance per watt, then that is good. That's what we need.",Positive
AMD,What a nice chip. The iGPU is just unexpectedly great. I'm glad to see something as exciting come out after a long streak of bad news.,Positive
AMD,Did they though intel is cutting back consumer product shipments to focus on shipping xeons so this could turn into a vaporware launch,Neutral
AMD,In a category I couldnâ€™t care less about,Negative
AMD,AMD there adding AI AI AI to every sku without actual performance gains.,Negative
AMD,Hardware for laptops.... so exciting....,Positive
AMD,It may well be that PTL-H + dGPU ends up being a better combo than ARL-HX + dGPU.,Positive
AMD,"Even AMDâ€™s flagship mobile poster boy since 2020, the Asus Zephyrus G14, switched to Panther for the high end model and limited Gorgon point to 5060. You know it will be good.",Positive
AMD,"[HotHardware's AIDA64 run shows similar improvements](https://hothardware.com/reviews/intel-core-ultra-x9-388h-panther-lake-review?page=2), though with its ARL-HX uses DDR5, so it was naturally better latency (107ns):  PTL-H: 82.9ns",Positive
AMD,"wow. Not as good as the old burning sun CPUs had, but getting close. And this was the biggest issue with ARL gaming performance.",Negative
AMD,"Crazy when you look at the teardown of a laptop in 2025/2026 and there's empty space...   Bruh, batteries are like $0.6/Wh retail, nevermind wholesale. Just up the price by $30 and make 99Wh standard.",Negative
AMD,"Yep. No reason not to include 99Wh, there's plenty of room in chassis of all laptops these days and makes a huge difference.  Even older gen, far less efficient laptops benefited hugely from it, have a Comet Lake machine that can do 12 hours of work thanks to 97Wh battery.  They should cram the maximum they can into every machine.",Positive
AMD,"My Zenbook S could easily last me 2 days with a 99Wh battery, the 78Wh is a cop out as there's space for more.",Neutral
AMD,"I fully agree, and on top that, I think that whole watt-hr limit for air travel is outdated, and we should be pushing the FAA to ditch that rule so we can get better laptop batteries. Edit: to expand on that, the current rules encourage people to bring multiple charging station batteries with them, often made by random companies that are going to have a lot less quality control than Lenovo, HP, or Apple.  Having devices with bigger batteries would probably end up being safer overall.",Negative
AMD,I wish I could replace the battery in my laptop. It has a 70Whr battery but I couldnt find a replacement online with 90+Whr capacity,Negative
AMD,"When just josh equalized for battery capacity, the zenbook duo was at 12h while the m5 (or m4 pro?) macbook was at 13h. Without equalizing, the former was at 17h. Pretty outstanding if you ask me.",Positive
AMD,My legion pro 7i from Lenovo has a 99.9 wh battery but with an i9 14900hx and rtx 4080 so I only get about 5 hours at best lol.,Neutral
AMD,99WHr is pretty much the standard battery size for any big laptop that isnt apple.,Neutral
AMD,"X1 was better than LL in CPU efficiency (at least high single digits % in SPEC, even higher in other benchmarks).  PTL is at best par with LL in that.  X2 is supposed to be bring ~30-40% improvement over X1.  You do the maths.",Positive
AMD,"Battery life and performance on par with Snapdragon X1, and a significantly better GPU.",Positive
AMD,"CPU ISO power efficiency is worse, but itâ€™s expected as itâ€™s just LNL but bigger",Negative
AMD,Lunar Lake had 4P + 4 LPE  Panther Lake is 4P + 8E + 4 LPE  That's a pretty significant increase.  EDIT: L3 cache is increased to 18MB from 12MB as well.,Positive
AMD,Is the ram soldered down or not? For such insane perf I assume the ram is soldered. I have a strong hunch upgradable ram is gonna become a thing of the past with these chips which I hope am wrong.,Negative
AMD,"Tbf, that is mostly cuz it is a XPS. Models from other brands and lower lineup will be cheaper, but probably not below $1000.",Neutral
AMD,"There is an MSI Prestige that looked good for $1300 with the 358H, I think.  I'm not sure they'll get much cheaper than that - with the fast RAM requirements - but that seems about right, laptops in the Â£2000+ range have always been a thing.  I looked at the chart and could find no reason to go for the X9, the only difference being +100MHz clock speed.",Positive
AMD,"That's an XPS problem, not an Intel problem. The line has never exactly been budget.",Negative
AMD,"> For the first outing on 18A the CPU looks very impressive.  The impressive part is the N3E GPU. The CPU is lackluster, though of course benefits from the inherited LNL changes.",Positive
AMD,"While the CPU performance is in the same ballpark vs Arrow Lake, efficiency at full load is much improved. Panther Lake hits the same numbers at 30w vs 43w for Arrow Lake. Thatâ€™s significant.",Positive
AMD,"on ther quarterly earnings call intel said that PTL margins were below corporate average (which is now \~35%) . . . So . . . You know yields, pricing, and availability are quite bad. Because at sub 35% GMs, intel is literally selling them at a loss right now. They did note that it should get better in the coming quarters (obviously).",Negative
AMD,"AMD is still pretty big in in the lower end laptop space. A large of people I know (including us) have AMD Ryzen laptops for their home laptops, due to their high power efficiency and battery life, while being cheap, something crucial in a price sensitive country like I'm in (India). Similarly, they also seem to be quite big in the mid range gaming laptop space - 1 in every 2 students I know with a gaming laptop uses Ryzen.  If we focus on business applications, creators, thin & light gaming, handhelds, or even many student oriented laptops though, Intel seems to have a VERY strong argument with Panther Lake this time.",Positive
AMD,">What does AMD do better than the competition?   You mentioned battery life and performance. You forgot a pretty significant factor: Price.  The Intel laptop they reviewed retails for $2300, while the AMD laptop they reviewed retails for $1350.  It's also a bit of a simplistic analysis to look only at the extremes and not consider that there may be places in the middle where AMD is the better option.  Also including OSX as a qualifier seems a bit pointless since AMD has no way to compete there (unless hackintoshes are a thing again).",Neutral
AMD,There's zero reason to buy a Snapdragon laptop when Intel chips are matching Mac's battery life.   https://i.imgur.com/VmSnR38.png,Negative
AMD,"I recently bought a gaming laptop (an Acer with a Ryzen 240 + an RTX 5050, for $600) using an AMD processor; it was better than the Intel options at the same price range (all like older Raptor lake based chips).  My main use cases for it are gaming and light office work; even that RTX 5050 will walk all over the iGPU in the high Intel CPUs for games, and for other stuff I do that Ryzen chip is plenty powerful while getting adequate battery life.    Honestly, I have a hard time getting excited about the ""good"" iGPUs for laptops; if you care about gaming, then laptops with discrete GPUs are cheaper and faster than the laptops with the fast versions of the iGPU.  If you don't care about gaming, then you probably don't need that iGPU performance, outside of some professional niches (and those people may want discrete cards anyways).",Positive
AMD,Linux support.,Neutral
AMD,Where does it show them beating it at similar power levels? I donâ€™t see that anywhere in the linked video.   And this other video goes against your claim https://youtu.be/Xjkzb-j6nKI?si=Skp4RPXvMZYzNB6R,Negative
AMD,"This chip has a much higher power envelope, especially when using the GPU. Where are you seeing iso-power comparisons?",Neutral
AMD,"Side grade node, tick uarch. CPU was never going to be too interesting.",Negative
AMD,Is it? In fact the architecture is same. So that means that Intel 18A is on par with TSMC. So that is a good thing no?,Positive
AMD,"Itâ€™s the same architecture with some minor adjustments, nothing special was going to happen",Neutral
AMD,Even a good node can only do so much to cover for a mediocre CPU architecture.,Negative
AMD,"For a lot of programs these days, GPU is more important, as almost everything can use the GPU for compute tasks.",Positive
AMD,launch price comparison?,Neutral
AMD,"Improved SOC design, which ARM chip companies already had to focus on due to their chips being used in phones.     Intel and AMD never had to focus on this area because laptops and desktops had humongous power stores to draw from until their battery life got left in the dust by Apple and Qualcomm.     Intel proceeded to focus on fixing that with LNL, which PTL expands upon by adding more cores.",Neutral
AMD,the ISA has absolutely nothing to do with battery consumption.,Negative
AMD,"Xeon isnâ€™t on 18A, how would it be competing with PTL for node space?",Neutral
AMD,"What does that have to do with the laptops that are absolutely not remotely cancelled and until it's completely doubling down on?  The reason the desktop stuff has been discontinued is because gamers basically shot themselves in the foot by sewering and tells desktop reputation. But in laptop, it's undeniable, Intel is superior and every single way. Why would they pull out of that?",Negative
AMD,This is also relevant for handheld gaming consoles.,Neutral
AMD,"I think so too - between latency improvements, and also the lower power draw allowing more power to go towards the dGPU at the same power draw.",Neutral
AMD,"The fact that PTL-H has much better latency than even ARL-HX bodes very well for PTL-H dGPU gaming performance, and potentially NVL gaming performance as well. ARL is strong, but severely let down by latency.",Positive
AMD,"I kinda want Intel to pull out all the stops for NVL. If they released an N2, bLLC chip out of the gate, the gen to gen gains would set the internet on fire. Doubly so if they managed it before Zen 6, though I think that's quite unlikely. Late '26/early '27 might feature the fiercest desktop CPU competition the market has seen in two decades.",Neutral
AMD,it would be nice. Battery life becomes a real thing when you can go for entire days without it running out.,Positive
AMD,I guarantee there has been pushes against it for at least a decade now. But that's how fast the government moves lol. You have to wait until something breaks before you get change.,Negative
AMD,I wonder if solid state batteries will have the same 100Wh limitation.,Neutral
AMD,"It was 13h 54m for M5. We need more normal laptops for Panther lake, maybe in a couple of days.",Neutral
AMD,"Is this with Duo screen off or on? If both screens are on, thatâ€™s even more impressive",Positive
AMD,"FWIW, some non-H Panther Lake CPUs will be a closer comparison vs LNL. These are ""H"" CPUs which are fed much higher power & have more cores. That is, we'd expect a 16C CPU to beat a 8C CPU.  The smaller non-H PTL CPUs:  U5 3**22**, U5 3**32**: 2P + 4LPE  U5 3**25**, U5 3**35**: 4P + 4LPE â€” same config as Lunar Lake.",Neutral
AMD,"They support LPCAMM, at least. Though at lower max speeds.",Neutral
AMD,What's lacklustre about it?,Negative
AMD,The CPU is essentially rebranded LNC and SKT on 18A. Considering that we're seeing 10-15% gains in MT in the perf/power curve is impressive enough for 18A.,Positive
AMD,They compared to lunar not arrow,Neutral
AMD,Wired tested MSI Prestige 14 with Ultra X7 358H and they showed it listed for $1299,Neutral
AMD,"for 2300 (388H) you can buy an AI Max 395 laptop (Asus ROG Flow Z13), that will absolutely mop the floor with the new Intel chip both in CPU and iGPU performance  the power efficiency is still pretty impressive though",Positive
AMD,"Unfortunately Just Josh did not test this on Panther Lake, but if Qualcomm continues their tradition of not significantly gimping ST perf for good battery life, it seems like there is still reason to buy Snapdragon laptops.   Hothardware did test PTL on the Lenovo Ideapad Pro 5 and on battery single thread perf in speedometer 3.1 is almost half of what it is plugged in.",Neutral
AMD,That's comparing to an older gen Qualcomm chip and in a device with a *much* smaller batter.,Neutral
AMD,The laptop at the top also had the largest battery size. Most conventional laptops are 70wh or less,Neutral
AMD,"People seem to not understand that while Intel may be able to match the battery life of Mac or Snapdragon, they significantly throttle the performance to compensate. This is often misunderstood.  So there is absolutely still reason to buy Snapdragon - if you want good battery life while maintaining decent performance. Though with the recent leaks on NVIDIAâ€™s N1X then Snapdragon may be in for some healthy WOA competition.",Neutral
AMD,"There are no battery capacity over 70 for Snapdragon laptops. Notebookcheck tested the X388H and Snapdragon X Elite is still 6th and Xplus is 3rd in Performance per watt. Snapdragon laptops are lighter, more portable and generate less heat. So there is still a reason to buy them.",Positive
AMD,A laptop with a high end igpu trashes your laptop in quality of life features. It's disingenous to compare prices based on performance alone when there's so much else that contributes to the cost of a laptop,Negative
AMD,Thatâ€™s not better either.,Negative
AMD,"Unless itâ€™s for gaming, thereâ€™s not much difference",Neutral
AMD,"That's assuming Nvidia N1X machines are anywhere close price wise to Strix Halo ones; I mean one of those DGX Sparks machine is what, nearly twice the price of a Strix Halo box with the same amount of RAM?",Neutral
AMD,"Yes, I watched this video after that one and after commenting. The gap in that case is big.   What is especially interesting to me about this one is the gap to Nvidia. Apple is cooking the 5050 in Blender using a chip that will go in a fanless laptop soon. Nvidia should be very concerned",Neutral
AMD,On par with TSMC's previous generation node. TSMC N2 already in volume production so Intel still a full node behind.,Neutral
AMD,"> In fact the architecture is same  It's a tick, but there should be some changes. Hell, even Raptor Cove was a tick. Though have historically been where Intel delivers frequency bumps.  So if core to core, PTL is merely *on par*, that would imply a regression at the node level vs N3B. At best, looks like more or less a draw.",Neutral
AMD,"18A is on par with TSMC's worst N3 class node when 18A was supposed to be better than TSMC's *best* N3-class node.  The process seems to have under-delivered.  It's basically the same as lunar lake plus a couple percent on architecture tweak - there's no uplift from the process, and N3 is from 2022!  It puts Intel's fabs 2+ years behind.  18AP is likely to improve to get to maybe the best of N3, but 18AP was supposed to originally compete with N2 and that isn't going to happen.  Now the hope is that 14A competes with N2, but N2 is coming this year and 14A isn't coming until early 2028.  That keeps Intel at nearly 2y behind TSMC, despite their plans to regain node leadership.  It's good that 18A is now a process that's 'ok', but I'm sure Intel hoped for more and so did the market.  14A may be more exciting and rumours are that progress is smooth, performance is pretty good, clients are taking a serious look and so on but still, ideally it'd be launching this year or early 2027.",Negative
AMD,Some people thought that 18A was actually an N2 class node.,Neutral
AMD,"What are you talking about? The GPU is only relevant for gaming, machine learning and certain professional tasks. The CPU does literally everything else, including coordonating those tasks, it's literally its name ""Central Processing Unit""",Neutral
AMD,"> For a lot of programs these days  For professional stuff, maybe. But not for most of client.",Neutral
AMD,Price to price comparison. I'm just referencing their own pricing they listed in the video,Neutral
AMD,They arenâ€™t? I thought that xeons hadnâ€™t left 18a yet,Neutral
AMD,"It would appear they stop producing the 2025 models if a 2026 model exists. Panther lake variant is also up to 5080, btw, at higher TGP.",Neutral
AMD,"I tihnk Intel is going to focus on own fabs where they can, especiall now that they have little external customers and need to keep the fabs running.",Neutral
AMD,"Stuff is breaking though, and still no changes.  Carry-on fires caused by dodgy temu power banks are not a rare occurrence anymore, but I guess we'll have to wait for one to actually cause a disaster to see progress.",Negative
AMD,They didn't say,Neutral
AMD,"The 325/335 vs 236V comparison is one I'm excited to see.   Even if it just matches LNL in everything, that's still a big win, because PTL-U is gonna be lower cost and higher volume than LNL",Positive
AMD,"Power is a very dynamic thing, and depends on the OEM design, nothing really stops manufacturers to use H chip at LNL power - maybe it won't scale to the extreme low end but it could roughly match previous LNL laptop power design.",Neutral
AMD,I dont mind some perf loss for upgradable ram because it allows the laptop to be used longer. Added 16gb ram to my retired 2020 legion laptop which got super slow with windows 11 and I still use it as a streaming device for my tv.,Positive
AMD,"ST perf has basically been flat for a while now, and even Apple's tablet chips are like 50% ahead. nT perf is in the same ballpark of Strix/Gorgon Point, despite being on a node that's ostensibly 1-2 full gens better. And the cores themselves are basically just minor tweaks of the ARL cores.  So if you basically took the same cores on the same node and made an ARL compute die out of it, it would barely budge the needle, if at all. What makes PTL look good are the SoC level changes it mostly inherits from LNL, and the GPU. The CPU cores are the weakest part of the whole.",Neutral
AMD,"[https://youtu.be/Ke3Kgwg7bV0?t=763](https://youtu.be/Ke3Kgwg7bV0?t=763)  its just incremental progress. keep in mind AMD is only TSMC 4nm. Being that 18a is supposed to be competitive with TSMC 2nm . . . Intel is an entire 2 nodes ahead. and achieving . . . performance wise the user experience from an AMD HX 370, a 288V, and a 388H are going to be identical . . . You will need to get your stop watch out to be able to tell a difference. And Being that they are at similar power levels, it means Intels 388H is matching the power efficiency of AMDs 4nm HX370 under load . . . that is . . . not . . . great . . . so the CPU portion of the chip is . . . lackluster.  the IGPU is great though. that thing is a beast and if intel builds future products with better GPUs like that one? They could have something special.  AMD's medusa point comes later this year on TSMCs N2. this is going to have to hold its ground against that when it hits sometime later this year. So . . . we will see . . . AMD is moving to a new INFO packaging technology. They are going skipping from 4nm to 2nm. and they have a big architectural upgrade happening. Any one of those things would probably be good enough to place AMD measurably ahead of intel on the CPU front.  Intel may still have battery life performance over zen6 though. As battery life is about way more than just CPU efficiency. And will be very interesting to see where the GPU lands performance wise.",Neutral
AMD,"> The CPU is essentially rebranded LNC and SKT on 18A  They're derivatives, but typically that means a few percent IPC, and some significant focus on power reduction and clock speed improvement. Also, they changed the core config (4+12 better for MT than 6+8) and the SoC is way better. So if anything, I think this is a very bad look for 18A. Pretty much everything that makes PTL look good was already done in LNL, or is the new GPU.",Neutral
AMD,"Then â€˜CPU looks the sameâ€™ makes absolutely zero sense. Itâ€™s 2-2,5x faster multi-threaded.",Negative
AMD,"Are you referring to [this article](https://www.wired.com/story/intel-panther-lake-core-ultra-series-3-review/), titled ""Intelâ€™s Panther Lake Chip Is Its Biggest Win in Years""?  If so, Wired appears to have [removed all mention](https://www.diffchecker.com/SyKjKaRG/) of the 358H/Prestige review from the live version as compared to [the archive article](https://web.archive.org/web/20260126110440/https://www.wired.com/story/intel-panther-lake-core-ultra-series-3-review/).  I'm not sure if that was due to poor quality of the review or a business decision (split it into another article), but either way I would wait for it to be live before giving it any weight.   Regardless, my point still stands: people generally shop by price first (is it within my budget?) and then specs. If my budget is $1500, I don't care that a $2500 Intel laptop is better than a $1500 AMD laptop. If the $1500 AMD laptop is better than a $1500 Intel laptop, I'm going with the AMD one.",Neutral
AMD,You can also buy a 1300 dollar laptop with full PTL config too,Neutral
AMD,>Hothardware did test PTL on the Lenovo Ideapad Pro 5 and on battery single thread perf in speedometer 3.1 is almost half of what it is plugged in.  You're not kidding. That is a huge regression: is Speedometer even that intensive? I wonder why they throttle so muchâ€¦  [Intel Core Ultra X9 388H Review: Panther Lake Tests Strong - Page 3 | HotHardware](https://hothardware.com/reviews/intel-core-ultra-x9-388h-panther-lake-review?page=3),Negative
AMD,Hardware Canucks did a similar test here and it wasn't as bad. Wonder why.,Neutral
AMD,And in best battery mode.,Positive
AMD,My Intel laptop with a ultra 9 185H is unusable on battery. They lower the clocks so much it takes 3 times as long to open the browser. I don't really trust the new chips till someone tests the performance on battery only. Then test the battery life with the same mode. I don't care about great battery life if the computer is unusable.,Negative
AMD,"Most people buying Snapdragon are just looking for snappy day to day performance but don't want to leave windows. If they're looking for more performance, they'd just get a mac. Those looking for more performance on windows are also likely going to be using apps that will have compatibility issues with arm. So for now, there's very little reason to go Snapdragon",Neutral
AMD,"All the ""quality of life"" features  are pointless if the performance is inadequate for what I want the device for.  I bought the laptop for gaming and tossing some spreadsheets around; it does those tasks well enough.  What exact ""quality of life"" features do you think I am missing that would justify paying hundreds of dollars more only to be worse at one of my main use cases?",Negative
AMD,"Apple has one of the best chip design teams in the world, despite not being a chip company first and foremost.",Positive
AMD,Hmm. Agreed. But atleast this means they are in the same ballpark now. This is still a huge huge improvement for Intel. This means even if they can't compete with the latest and greatest they can at least compete with TSMC core products. N3 is still a core product of TSMC.,Positive
AMD,N2 hasnt released products yet. Also being merely 1 node behind the industry leader is not a bad place to be.,Neutral
AMD,Half-nodes and full-nodes are yesteryear terminology. Those are no longer applicable in denoting PPA improvements between nodes.  It is meaningless to compare different nodes without having the same product made for each of them.,Negative
AMD,It isn't on par though. Its certainly better here? By around 10%? Thata N3P class.,Neutral
AMD,more like they thought it was N3 class node while you went around telling everyone they are idiots and it wont even come close.,Negative
AMD,"Web browser engines use the gpu for rendering, it contains the media encoders and decoders, Office and even the desktop is Gpu accelerated.",Neutral
AMD,"This is nonsense. GPU is useful even for menial office tasks, for example teams meetings can use GPU for video processing.",Neutral
AMD,"So last year's model (that's ending production), on discount, is cheaper than the brand-new model that launches tomorrow? That's the analysis?",Neutral
AMD,"Intel's DC product group has issues and are behind Client, they're still manufacturing Granite Rapids, which is on Intel 3.     Diamond Rapids apparently will be on Intel 18A, but that's going to be the tail end of this year.",Neutral
AMD,"They also need to keep their products competitive, and there's nothing that can compensate for a weaker CPU in premium desktop. So for NVL (and RZL), that means N2, whether they like it or not. If they manage to close the node gap to more like 5% perf, gain a significant uarch advantage, or have some other tech like X3D that boosts perf beyond 1:1 with AMD, *then* they can bring it back in-house. But too much margin is tied up in leadership otherwise.",Neutral
AMD,"and yet that powerbank had smaller capacity than those laptop batteries, so the rule clearly did nothing to protect the plane.",Negative
AMD,"> Carry-on fires caused by dodgy temu power banks are not a rare occurrence anymore, but I guess we'll have to wait for one to actually cause a disaster to see progress.  If anything, that would make the regulations even stricter.",Negative
AMD,"The GPU will probably be a sore point. Hopefully doesn't drag down the rest. Personally, more excited for WCL, as that market has been neglected for way too long. Imagine going from RPL-U or Mendocino to WCL. Will be night and day.",Positive
AMD,"Yeah, a lot of them ended up running LNL at 20W+ TDPs anyway. 10W, yeah, might have a problem.",Negative
AMD,"Unlike SO-DIMM, LPCAMM\\LPCAMM2 is not very supported(yet). You might have hard time finding machines with LPCAMM\\LPCAMM2.",Negative
AMD,"Iâ€™m not so sure. Panther Lake is 30-40% more efficient than Arrow Lake under load, I donâ€™t think thatâ€™s all down to SoC improvements and minor core tweaks.",Neutral
AMD,The E cores have a 700 mhz clock regression compared to ARL. A much bigger regression than what the P cores had so a 6+8 would've been better.,Neutral
AMD,Probably comparing single thread performance.,Neutral
AMD,"Oh I HATE this so much. My Omen Transcend 14 does this. Eco mode will get you 10 hours on my laptop with the RTX 4060 disabled, but the only things it is useful for are video playback and typing. It feels horrendous to use. Gets ~50 points in CB 2024.   Switch it over to Balanced and change nothing. Suddenly the single core score doubles to 110 ish and the laptop feels nice to use. But the battery life drops to 6 hours.  It is so stupid they do this and even stupider that so many reviewers miss this. Do they not actually use the laptops?",Negative
AMD,Battery life benchmaxing in the dumbest way possible?,Negative
AMD,Same. The issue gets worse because they also drop the refresh rate to 60Hz. My Omen Transcend 14 actually drops to 48. Itâ€™s infuriating. The reviewed battery life for my laptop was 9-10 hours. I get 5-6 with usable performance and 120Hz,Negative
AMD,What OEM does this? My Galaxy Book4 Pro 360 barely sheds 10% of single core performance when in Windows balanced mode.,Negative
AMD,"Battery life, overall weight, and noise. The first one alone would get me to pick a big igpu over a low end discrete gpu.",Neutral
AMD,">All the ""quality of life"" features  are pointless if the performance is inadequate for what I want the device for.   Except there's nothing inadequate about the performance of panther lake. But nice strawman there. Btw $600 is never the msrp for that laptop. So another flaw in your argument.  Quality of life features.  A nicer sharper screen Better battery life Better build quality Better speakers Better keyboard and touchpad Touchscreen  If you don't care about any of those. Thats fine. But a lot of people do. And you cannot establish a solid argument against just based on your preference",Negative
AMD,I meant moreso to specify the length of time their behind.,Neutral
AMD,"In terms of ST performance relative to LNL it's explained entirely by the higher wattage and the architecture tweak.  There doesn't seem to be a performance difference process-wise versus N3B.  If you assume 18AP is 8% better, then that's roughly at the best of N3, we'll how that works out",Neutral
AMD,"Lmao, now you're rewriting history. It's literally showing just as I said it would be, *maybe* N3 class, and certainly not N2 class like you and some others were insisting.",Negative
AMD,"But those tasks can be accomplished by any GPU made in the last 15 years, I was specifically referring to GPU intensive tasks",Neutral
AMD,"Yes, and any GPU manufactured in the last 15 years will provide a satisfactory experience, while a CPU from 15 years ago will not be adequate today.",Neutral
AMD,Just go watch the analysis at 17:36. I don't know what the hell you are trying to get at,Negative
AMD,"As has been discussed to death, it is still relevant. Why bother if you pay 600$ more, for example. So people stay on older hardware and see no point in upgrade",Negative
AMD,"Thereâ€™s also Clearwater Forest on 18A, but I have no idea wether thatâ€™s â€œshipping nowâ€ or â€œwill ship at some future dateâ€.",Neutral
AMD,"Their products will remain competetive, even if they are stuck on N3 equivalent node.   Isnt intel once again experimenting with larger caches?",Neutral
AMD,"> I fully agree, and on top that, I think that whole watt-hr limit for air travel is outdated, and we should be pushing the FAA to ditch that rule so we can get better laptop batteries. Edit: to expand on that, the current rules encourage people to bring multiple charging station batteries with them, often made by random companies that are going to have a lot less quality control than Lenovo, HP, or Apple.  Having devices with bigger batteries would probably end up being safer overall.  Just scroll a bit further up mate",Negative
AMD,> Panther Lake is 30-40% more efficient than Arrow Lake under load  Which numbers are you looking at?,Neutral
AMD,> so a 6+8 would've been better  There's zero chance 2 P-cores would have been better in MT than 4 E-cores. Though the observation of the minimum clock speed is interesting.,Neutral
AMD,"Meanwhile, i would love such a model for my work laptop as i often have to sit there in a 8 hour long conference typing notes. 10 hour battery for typing sounds great.",Positive
AMD,"Noise?  I don't care about fan noise, if I am doing something intensive then I am wearing headphones anyways.  Weight?  The laptop I purchased weighs 5.38 lbs; it looks like the Ideapad Pro with the same size screen is 3.77 lbs; how limp-wristed are you that an extra 1.5 lbs in your bag matters?  Battery life?  Yes, if I had a job that required me to be constantly using a laptop away from any sort of power outlet then it might be important, but I don't; if I am using the laptop for more than an hour or three then I am probably next to an outlet.    Better performance and being much cheaper were much more important to me than any of those factors.",Neutral
AMD,"Battery life? Odd. My Amd gaming laptops (7940hs) last about 8 hours with the discrete Gpu (4070) disabled on battery. If I wanted to do gaming, I just plug it in.   I don't think battery life has been a majorÂ  problem for daily task alone sans gaming for these big laptops for some time already.",Neutral
AMD,"Everything you said plus build and overall component quality. Cheap gaming laptops are exactly that. Cheap. Like old American muscle cars. Theyâ€™ll get you the power without much sophistication. The keyboard decks of most lower end laptops not called Lenovo LOQ are floppy, the trackpads tend to be bad, screens are IPS with sRGB coverage and speakers exist for the sake of existing",Negative
AMD,TSMC is behind in terms of shipping products made on a GAAFET node. They are also behind in delivering BSPD.,Negative
AMD,Why LNL? PTL-H is the successor to ARL-H. Which it does beat by a significant margin in P/W. LNL should be compared with PTL-U.,Neutral
AMD,"No, you are the one rewritting history, we had this discussion before. I said its will be between N2 and N3. So did most others. Turns out thats been true. While your ""worse than N3 in every way"" turned out to be false, again.",Negative
AMD,"No, they cannot. You have no clue how heavy web browser media engines are. older iGPUs completely choke an die.",Negative
AMD,"What I'm getting at is ""you can get last years model at a discount vs the brand new model"" isn't a revelation. This is true for nearly every market, from cars, to laptops, to TVs, to phones - every year.  It's really only a meaningful point in the few weeks of overlap where both old and new models are available together - but old model inventory will be rapidly depleted over the next few weeks and it's not a deal that every intended buyer can take advantage of.",Neutral
AMD,"It's not irrelevant, because these models will also see discounts in the coming months. And not to mention all laptops across the board are seeing price increases from the memory shortage.  You're basically comparing laptop A at the most expensive it'll ever be, to laptop B as it's getting discounted and discontinued.  Yes, you can take advantage of getting last years model at a lower price than this years model: that's always been true and is irrelevant to the assessment of the current launch, and is useless for trying to determine if the new chips themselves are actually more expensive",Neutral
AMD,"except the 2026 Zenbook Duo isn't just a CPU change, Asus completely reworked the chassis compared to the old version (the old version only got a single 75Wh battery, the 2026 one has *two* batteries that total 99.9Wh)",Neutral
AMD,"> Their products will remain competetive, even if they are stuck on N3 equivalent node.  Let me illustrate. A full node gap is something like 10-15% perf. In other words, similar to the advantage X3D gives in gaming, but in almost every workload instead of just a subset. By adding something like 60mm^(2) of 7nm silicon, AMD's able to bump the retail price by ~$100. That's fantastic ROI. And then on top of that you have the exceptional marketing value of the halo effect.  Intel's looking at the same fundamentals. N2 is expensive, but the silicon cost is dwarfed by the premium it gets you in the market. So the only thing that would allow them to stomach an N-1 node is if they had some other advantage(s) that would still let them maintain clear leadership *despite* the node. Right now, they don't have anything.   > Isnt intel once again experimenting with larger caches?  Yes, and bLLC *could* even have an edge vs AMD's V-cache. But ultimately these are more or less tit for tat. If they don't have node parity, then they would need something that AMD doesn't have a direct answer for.",Neutral
AMD,"At 12:53 in the video, thereâ€™s a graph comparing Cinebench nT results. Panther Lake scores the same at 30w as Arrow Lake at 43w. Of course this is just one specific example.",Neutral
AMD,"What? Its 2P cores replaced by 2E cores right? Not 2P replaced by 4E. 285H is 6+8+2, 385H is 4+8+4. Granted the remaining two are Crestmont, but Darkmont is clocked like 700Mhz lower as well. I'm waiting on David Huang's chart to put to bed this conendrum.",Neutral
AMD,"Oh, of course. It is also great for watching downloaded movies while travelling. But these laptops should be able to do it without having to throttle down so much. MacBooks can do it. These cost the same. So they should also be able to do it.   And reviews should have two numbers. One for max endurance for typing/travelling/emergencies, and one where the computer is actually a computer",Positive
AMD,everyone is. Nodes just take a lot more time now.,Neutral
AMD,> Which it does beat by a significant margin in P/W  At a core level or SoC? Quite a difference.,Neutral
AMD,">  I said its will be between N2 and N3  And that's absolutely not what we're seeing. What're you on about? Have you skipped all the reviews?  > While your ""worse than N3 in every way"" turned out to be false, again.  Once again, outright lying. I said that about N2.",Negative
AMD,"You are still missing the point.   Both prices need to be compared. Not just launch to launch. Because otherwise you will live in your stupid bubble, not understanding the reality.   I have a choice between 2 laptops. One is 1500$ and other is 2200$ but 10% efficient (performance/wattage). Why the hell would I bother in this case? Yes, first laptop was 2200$ at launch too, but it's not ""at launch"" right now",Negative
AMD,"Iso-perf results naturally give a far bigger delta than iso-power, because power scales roughly cubicly with clock speed. So e.g. a mere 5% perf increase at iso-power (*well* within bounds of a tick uarch) translates to a ~15% power decrease at iso-perf.  On top of the tick cores and SoC changes, PTL also has a different core config. We'll get a better sense if/when someone's able to isolate a single core/cluster.",Neutral
AMD,"> Granted the remaining two are Crestmont  They're not just Crestmont, but a neutered implementation of it. So yes, technically do need to factor those in as well, but I suspect it wouldn't meaningfully change the conclusion.",Neutral
AMD,"Notebookcheck will have these numbers, as they measure both",Neutral
AMD,We're using Cinebench 1T for P/W comparisions right? Which did not show any regression or negative reprucussions due to 285H's old SoC design over Lunar Lake. Its definitely core level or process level.   5% performance improvement in 1T could be explained by the new SoC/updated core. The subsequent 10% power reduction has to be process node. We'll see once Huang or someone eles makes a proper 1 to 1 SPEC comparision perf/power chart.,Neutral
AMD,">And that's absolutely not what we're seeing  Yes, it is.  >Once again, outright lying. I said that about N2.  No, you said worse than N3, back in the thread where initial gains leaked.",Negative
AMD,">I have a choice between 2 laptops. One is 1500$ and other is 2200$  The point you are missing is that this price comparisons is a temporary one that is only applicable if you buy within the next few weeks, and a choice that not everyone can make because inventory of last year's model is limited. A few years ago I bought the prior year's Samsung S80 TV for half off by getting a floor model. No new TV could match the price to performance of the deal I got...but the deal I got is not scalable to the wider consumer market. Just like deals on last years outgoing laptop model are not scalable to the wider consumer. Those laptops will be out of stock soon. This PTL laptop will see price drops  Regarding efficiency, PTL-H at 45W is matching ARL-H at 75W in MT. It's also, in light load tests, getting nearly **double** the battery life. And also I haven't seen *any* dGPU test comparisons either.  A new laptop launch will never be able to match the deals you can get from buying last year's model on discount.",Neutral
AMD,"Youâ€™re right, when comparing both at 30w the difference drops down to 20-25% in the same graph. Another day, another thing learned.",Neutral
AMD,"> Which did not show any regression or negative reprucussions due to 285H's old SoC design over Lunar Lake.  Depends. Perf wasn't affected by the memory latency, but if we're talking about SoC power (vs core power), then LNL made significant strides in power budget available to compute. That's one of the biggest factors at lower TDPs (and light loads), actually, because SoC power doesn't scale down as well.   > 5% performance improvement in 1T could be explained by the new SoC/updated core. The subsequent 10% power reduction has to be process node  Could you link the data you're using to compare here? Because +5% perf *or* -10% power iso-process would be very consistent with a tick, even modest by historical standards. For reference, their past ticks were WLC (SNC tick), RPC, and RWC (both GLC ticks). Obviously, very difficult to tease out the process contributions, but you'd think after fairly big reworks with both LNC and SKT, they'd have some room for refinement. Also given that the PTL IP should have benefitted heavily from the cancelled ARL-20A work, given the similarities in both the cores and node.",Neutral
AMD,"> Yes, it is.  Again, you're not seeing the same reviews.   > No, you said worse than N3  It does look indeed worse than the modern N3 variants in both PnP and PPA, though the specific ""worse in every way"" quote was a very recent one about N2. Don't twist my words.   It's genuinely baffling you think this is a still a good look for Intel's supposedly ""unquestioned leadership"" node. Even with a tick uarch they can't beat N3B clocks. And the funny thing is in doing so, you completely ignore where Intel's demonstrated actual improvement.",Negative
AMD,"I never made any claims to unquestioned leadership. What i did claim, repeatedly, that being only slightly worse than the very expensive industry leader isnt a terrible position to be in.",Negative
AMD,a 5600x or a 5800xt are really the only options you can reliably get new at the moment at about $160/$200 respectively. Even though they aren't X3D chips they would still be a MASSIVE upgrade over your 2700x.  Short of going to a AM5 DDR5 system this is probably the most impact you could do without spending $400+ on a 3 generation old 5800x3d/5700x3d CPU.,Positive
AMD,"9800X3D will not work on your current mobo, it's AM5, your mobo can only use AM4 socket CPUs.  5700X3D could work, but it's also hard to find and overpriced. Definitely not worth the same cost as a 9800X3D, imo.   Depending on your budget, a 5800XT or similar could work and would still  be a big upgrade from your current CPU.",Negative
AMD,"5800XT is the obvious choice at this point as others have said. Either that, or buy a used and overpriced 5800X3D/5700X3D *or* a full rebuild with an AM5 motherboard and something like a 9800X3D.",Neutral
AMD,You could also wait to see what AM4 cpus have revived production. Nothing concrete yet but prices could drop in the very near future  https://www.tomshardware.com/pc-components/cpus/amd-ryzen-chief-teases-return-of-older-zen-3-chips-to-fight-soaring-ram-prices-thats-something-were-actively-working-on-right-now,Neutral
AMD,"If that's what you feel is wisest then go for it, personally I'd advise against passing up on a good used deal if you see it. Especially on eBay since it has damn near bullet proof buyer protections these days. My PC is mostly used and parts bin and is pretty much bulletproof so far. Built and booted first time without issue and cost me not much over a third what I would pay now for it in this economy.",Positive
AMD,"for 9800x3d you will need a new motherboard and ddr5 ram which at the moment is vary expensive so it is hard to recommend.   Buying used 5800x3d is not a bad idea if you can get it for fairly cheap. The are the parts that are among the hardest to destroy, so if you can get it from a ""trusted"" seller, you are good to go.  You said that it is similar price to 9800x3d... for 5800x3d I wouldnt pay more than 250$.   Good alternative is 5700x3d which is a bit slower than 5800x3d but are selling for quite cheaper. Both 5800x3d and 5700x3d are the best gaming cpus you can get without changing board or ram.       The third option is 5700x. It is an amazing value cpu since they are selling for around 90-130$. It is quite a bit slower than both 5700x3d and 5800x3d chips but it is miles ahead of what you currently have.       Any of these three options would be a good choice for reducing or eliminating the bottleneck you are seeing in some games...",Neutral
AMD,Make sure you update bios before switching as old boards might not work with new cpus using old bios.,Neutral
AMD,"Went from 5600x to 5700X3D last year, good upgrade for gaming. Anything from 3-5 series is better than your old CPU and is a good upgrade. Make sure your mobo can support it via bios update before switching.",Positive
AMD,"I know cost is a factor, but there is a good chance a used 5800x3d wont be terrible for you if you can overcome it. If it lasts 3 to 5 more years, is it really that concerning?  But otherwise refer to the other cpu recommendations.",Neutral
AMD,5700x3D or else the usual 5700x/5800xt. Don't the 5700/G.  Any non x3D is still a significant upgrade vs the 2700x,Neutral
AMD,"I would look for an R7 5700x. Slightly cooler, should be cheaper and still available easily enough. The 5800x/xt are also options. You could get an R5 for similar performance for a bit cheaper, but if it were me I would look to a full 8-core (single CCD) Zen3 which will basically max-out your AM4 system (until your next full-build) for an average consumer/productivity on a budget.",Positive
AMD,If you could sell your platform and keep the ddr4 you could go lga1700 like the 14th gen 14600k and it's faster than ryzen 5000 and still affordable compared to moving to am5,Positive
AMD,"5700X3Dâ€™s on ebay have dipped under Â£300, and you have buyer protection. Even if you donâ€™t want to buy used, i think thatâ€™s how you maximise your money.",Neutral
AMD,5800xt is what iâ€™d get no point of paying for  a  used and overpriced am4 x3d chips people are mental wanting these chips at the same or more of the cost of a 9800x3dâ€¦.,Negative
AMD,"If 5700x3d and 9800x3d have the same price. Itâ€™s no brainer to jump to 9800x3d , but make sure you have the budget for ddr5 ram , and new motherboard.",Neutral
AMD,"Thank you, I'll look into them and do some benchmark comparisons and whatnot.",Positive
AMD,"Okay, thanks. I'm sticking with the AM4 at the moment because I just don't have the money to a full overhaul like that, especially with RAM prices being what they are at the moment. Until that gets fixed, I'm just going to try to squeeze all the juice I can out of this. I found a 5800XT for about 200 quid which is within my budget so I'll probably just pull the trigger on that then. Cheers.",Neutral
AMD,"Oh that would be huge, and a massive relief, probably cant wait that long but if they drop enough in price might be worth upgrading to a 5800x3d if they do restart prod. Thanks for sharing!",Positive
AMD,"Even with the RAM apocalypse, there's not much reason to consider the 5800X3D at >$400, or the 5700X3D at >$350. Just not a smart purchase imo.  I would rather pay $180-200 for a 5800XT and save the rest for a platform upgrade in the future.",Negative
AMD,"I do not unfortunately, and I don't think I have enough spare organs to sell either to fund it.",Negative
AMD,"Moving to 4K will put more load on the GPU, but will also result in lower frames per second.  Did you use something to determine that your 2700x is indeed holding you back?  (Do NOT rely on internet bottleneck calculators).  Did you use HWMonitor or AMD Adrenaline to determine that CPU was at full utilization during gaming?  According to [PCPartPicker.com](http://PCPartPicker.com), the 5600XT is available for $155 and the 5800XT is available for $200.  Single thread performance of the 5600XT is only 2-3% less than 5800XT.  Not enough to justify the $45 price increase for gaming.  If you were using Davinci Resolve, Adobe Premiere, or Blender, it would be worth it.  Then again, only you can decide how much it is worth it to you.  (A 5700G is in the middle price-wise, but is actually worse for gaming than either, since it sacrifices half it's cache to include the iGPU.)",Neutral
AMD,I went from 2700 to 5700x and it is a very noticeable upgrade. In hindsight absolutely kicking myself for not spending the 100 extra for the x3d but it is still holding up fine.,Positive
AMD,"Go get 5700x, its should be work just fine.  On average 1080p, it has 10-20% performance loss compared to its x3d counter part.  On higher resolution, the gap become closer.",Neutral
AMD,"I run OBS from time to time to record sometimes but thats about it. My budget is anything under Â£300, but obviously better value is better value. The games I play have ingame graphs showing various usage and my CPU sometimes spikes to triple digit numbers which has more or less confirmed to me its the CPU (ive also had the System Monitor open and it goes to the moon).  I have seen sources say that moving to a higher graphic output lile 4k or even 1440p would lessen the load by shifting it to my gpu but even then i feel like its probably worth it to upgrade the cpu anyway before they go the way of RAM (even more than they are).",Neutral
AMD,"Lessen the load, yes, but then the GPU becomes the bottleneck and you get lower framerates.  The reason the CPU utilization is lower is because you are generating fewer frames because the GPU can't output the same number of 4K frames/sec as 1080p frames/sec.  I mean if you have 100% CPU utilization and 15% GPU utilization, maybe you might still see the same number of frames., but if you have 100% CPU utilization and 50% GPU utilization, switch from 1080p to 4K results in 4x the work for the GPU.  While most people don't recommend bottleneck calculators, they can can show you RELATIVE performance.  While I wouldn't necessarily trust the actual frame rates and bottleneck percentages, they do show you want kind of shift you might experience going to a higher resolution.  The table below assumes a Ryzen 7 2700 and RX 6800 16GB playing Cyberpunk 2077 at medium settings.  As you can see, CPU becomes less of an issue, but FPS goes down as the GPU workload increases due to increased resolution.  |Resolution|Avg FPS|Min|Max|Playability|In-game Bottleneck| |:-|:-|:-|:-|:-|:-| |1920 Ã— 1080|**63**|54|72|Good|CPU Bottleneck (47%)| |2560 Ã— 1440|**57**|49|66|Okay|CPU Bottleneck (36%)| |3840 Ã— 2160|**43**|37|50|Average|CPU Bottleneck (16%)|",Neutral
AMD,5070 one is the no brainer.   extra storage is very easy to add later and the CPU can be upgraded to anything on the AM5 platform. The 14700f is more or less the best of the best for that socket. Give me expansion and upgradability any day.,Positive
AMD,8700f is a pretty garabage cpu but you have an upgrade path and the 5070 is easily worth 50 over the 5060 ti,Positive
AMD,5070,Neutral
AMD,"In a gaming system, the GPU is much more important than the CPU.",Neutral
AMD,I donâ€™t know about computers,Neutral
AMD,yes he should spend a little more.,Neutral
AMD,amd but look into upgrading that cpu,Neutral
AMD,does it have to be a 8700f ? it's garbage,Negative
AMD,go for amd,Neutral
AMD,Why do you want 20 cores for Gaming?,Neutral
AMD,I didnâ€™t say I did. I was just trying to give more information on the chip incase someone were to ask.,Neutral
AMD,"It was a rhetoric question, you don't need 20 cores for Gaming.",Neutral
AMD,All depends on your budget and performance goals.,Neutral
AMD,9060xt 16gb,Neutral
AMD,What is the resolution and refresh rate of your monitor? What is your budget?,Neutral
AMD,Whats your current build? All hardware included,Neutral
AMD,"With a 650w psu, the best you can do is the 9060xt 16gb or 5060ti 16gb and that's really just a side grade to the 6700xt. You'll want the 5070 or 9070 to upgrade the gpu but you'll need to upgrade the psu as well.",Neutral
AMD,rx 9060 xt 16gb will be in budget   rx 9070 will get you 1440p at close to your goals frame,Neutral
AMD,"ah forgot to put those sorry, max budget is around $500 and performance is enough to run most games at 165fps",Neutral
AMD,Lol this is just totally wrong a 650w could totally handle a 5070 without issue. I ran my 5080 on a 750w without any issue. Also the 5070 only uses 30 more watts than the 6700xt lolol.,Negative
AMD,so should i just keep what i got now?,Neutral
AMD,"What resolution?  Either way, I'd look at the RTX 5070.",Neutral
AMD,"5070 is the best, although I think it went up a bit on Price closer to 600â‚¬... Check 5060TI 16GB, should be below 500â‚¬ still or even the 9070.",Positive
AMD,it would probably handle it at 100% load with a 650w. he's already pulling 460w and to have headroom he would need up to 690w. I have my 5070 OC along with my cpu OC and had a 850w PSU that would BSOD while gaming. I now have a 1000w PSU that has no issues but could have gone with an A-tier psu and possibly be fine but I wanted to make sure. just with the spikes from my CPU and GPU were hitting 500w combined. I wouldn't recommend a 650w with a 5070 unless you are not going to do any OC at all.,Neutral
AMD,You only get the newer tech of fsr4 or dlss4.5 and better RT out of both cards. You won't get much more fps in 1440p,Neutral
AMD,is the upgrade worth it?,Neutral
AMD,"So the spikes from your cpu and gpu were hitting 500w... sounds like a lot less than 650w. Your bsod could've simply been a bad psu, or maybe just a bad connection. Either that or you've got the most power hungry 5070 on the market and are cramming as much power into your cpu as possible. Like I said. 7800x3d + a manually oc'd 5080 on a 9 year old 750w psu never skipped a beat once (not entirely true, the newest nvidia drivers DID crash my pc once or twice until I stepped down the driver version).",Negative
AMD,Yes if 1440p is your intent.,Neutral
AMD,"I just saw a few videos comparing the 6700XT to the 5070, you would get close to x2 Performance... and that without taking into account all the AI Techs that Nvidia provide...  If you upgraded to the 5060TI 16GB, there would be still a difference, but not as big, between 10-30 fps, so around 20% more, but this is also without taking into account the AI Techs...",Neutral
AMD,CPU was spiking to 220w and the 5070 was spike at 270 with a c tier 850w atx3.0 psu. This was using Msi afterburner while gaming. Plus I have 10 case fans. My whole build comes out to about 600w on partpicker. If you take that and multiply by 1.5 (headroom) that comes out to 900w to soak up for spikes and since my OC are set high but within reason I opted for a 1000w because it was an A tier psu that was the same price as many 750 or 850 psu,Neutral
AMD,should i just wait for a sale on the 5070?,Neutral
AMD,"Just because a psu is only rated for 650w doesnt mean that's all it can handle. Thats just what it can handle sustained. Psu's are able to handle spikes multiple times their rated wattage, however the amount of headroom depends on quality of psu.",Neutral
AMD,"""Sale"" and the name of any current gen GPU in the same sentence lol",Neutral
AMD,"I would, 9070 is not a bad option if you can get it much cheaper, like 150â‚¬ cheaper, but I doubt this could happen.",Neutral
AMD,I don't think there is going to be a discount on GDDR7 based GPUs any time soon instead they are only going to go higher in price! So get it now or else get the 5060 Ti 16gb if you can find one! Even with the 5060 Ti you can get decent fps at 1440p using DLSS!,Negative
AMD,we're just gonna have to hope,Neutral
AMD,ok im just gonna wait for a sale on the 5070 then,Neutral
AMD,"Well you missed them. There were plenty of sales and discounts with good supply last year but all GPUs will be experiencing price increases throughout this year so any ""sales"" that may end up happening would only put them at the prices that they currently are right now lol",Neutral
AMD,"When I overclock my RX 6650 XT too far it crashes with a green screen.  It sounds like an OC profile configuration error like perhaps you saved an aggressive overclock through AMD Arenalin.  First thing I would try is a 100Mhz underclock on the GPU and see if it happens.  If you aren't getting the speed promised by an RX 7600 then I would consider an RMA.  The green screen is a very big tell that its an overclock crash, in my opinion.  Anyone with an AMD thats stress tested it in Heaven could tell you that.  Also Heaven is a good benchmark to run in a loop and play with the GPU frequency sliders to check for stability and artifacts.  Mine typically makes zero artifacts and just crashes.  It can't even tolerate even a mild overclock like 2703 core -> 2725 core is about the best it can do.  Mine has 2300mhz ram chips (Its an RX 6650 XT so very similar) so I actually run mine at 2499core/2300 ram and I get like 95% of the performance for 75% of the power.  So it typically draws like 125watts in that configuration and I'm happy with that.  My default never crashes though (2703Mhz), I would be suspicious and potentially RMA the card if that were the case.  You can \*maybe\* try reseating the GPU as maybe it has power delivery issues through the slot or cable.  I'm 100% certain though that green screen crashes are AMD GPU errors, like what you would see from too aggressive of an overclock.  The good thing is its definitely fixable with an underclock.  The bad thing is you might need to RMA the card if its not stable at defaults.",Negative
AMD,"Ignore bottleneck calculators, they are nonsense. 32GB is perfect for gaming.",Negative
AMD,"just get a dual channel 16 gb, more than enough for sims4 and chrome",Positive
AMD,"32 GB. For DDR5, always 32 GB if you can afford it (unless its a workstation)",Neutral
AMD,"Don't use bottleneck calculators, they're snake oil and bullshit  https://www.techspot.com/articles-info/2852/bench/2024-06-19-image-p.webp  https://www.techspot.com/review/2852-how-much-ram/",Negative
AMD,"get at least 16Gb. it's the minimum these days given how much RAM is needed to run Windows. if you can, 32Gb is better. not strictly required if you are not running anything heavy, which seems your case, but better for future proofing. you don't need 64Gb.",Neutral
AMD,For Windows 11 you typically want 16gb of system memory as a minimum with 32gb being considered the sweet spot for general gaming.  This is regardless of any CPU or GPU you may have.,Neutral
AMD,"The only way to know is to do whatever it is you're going to do on the PC and look at the ram usage.  If you get 32gb and your games/work + any open software and stuff never get past 15gb, then the extra 16gb stick is literally doing nothing and was a waste of money.  (keep in mind browsers allocate more ram than they use, so don't count those as they allocate it, but give it up when something else requests it, and they put hold on tabs that are not in focus releasing that from ram if idle long enough, etc..).  Just assume ""browser"" is going to use like 5gb MAX unless you have open browsers on like 3 displays all playing videos and HTML5/js games at the same time.   I doubt minecraft or sims 4 needs more than 16, and probably leaves plenty of headroom to do other things at the same time within reason.   Buy a 16gb kit, install it, play your games and look at ram usage, if you're maxing it out or identify a bottleneck, return it (so buy somewhere u can return), and get 32gb kit.",Negative
AMD,32gb in my opinion. It's more than enough.,Positive
AMD,I put as much as I can but you do you boo.,Neutral
AMD,"okay, thanks so much!!",Positive
AMD,does that mean getting two 16 gb ones?,Neutral
AMD,"okay, thank you so much!",Positive
AMD,16 gb is also good for now I know it's not enough but 32gb is needed only for 4k or 2k,Neutral
AMD,okay thanks so much!,Positive
AMD,okay thank gosh haha!,Positive
AMD,"alright, thank you a ton!",Positive
AMD,okay thanks a ton!,Positive
AMD,"i understand that and i lowkey wish i could, but iâ€™m still having to save up lolol and i dunno if i quite like my kidney haha!",Negative
AMD,"16GB (2x8GB) is plenty to run the games you mention Iâ€™m running both of these games with a 10 year old Acer laptop with an Intel i5 processor 8GB ddr4 (maybe ddr3?) RAM and an ancient AMD Radeon processor with 500MB VRAM and they work perfectly, so Iâ€™d suggest save some money now as RAM is very pricey currently and upgrade to 32 when you need to, which from your post is likely to be a good few years yet.",Positive
AMD,"no no ! 16gb dual channel means two sticks of 8gb, if you get single channel i.e one stick of 16gb it will be slower so avoid the single channel setup (one 16gb stick) i could have advised 32gb but you are not a workstation user plus there are some games recently who are using 11-12gbs of ram but you are not gonna play those as you said so 16gb js fine",Negative
AMD,"They should be included together. 9 times out of 10, if you buy 32GB at a time it should be 2 16s",Neutral
AMD,DDR5 doesn't have an 8gb stick i think.,Neutral
AMD,alright thank you! iâ€™ll keep that in mind!,Positive
AMD,alright! thank you so much!,Positive
AMD,"Hold off. Your CPU isn't terrible, and the platforms you are considering are already end-of-life. Better to wait a year for Intel Nova Lake or a year and a half for Zen 6.. and by that time, hopefully DDR5 RAM prices will be more sane, as well.",Neutral
AMD,"Can you detail your whole setup? And did you check what bottlenecked your current build?  Also, can you define a maximum budget?",Neutral
AMD,"https://www.tomshardware.com/reviews/cpu-hierarchy,4312.html  I'd go to eBay and look at the used intel CPUs for the LGA 1200 socket. Buy from a reputable seller with history and you'll be fine.  The move to a 14400 or Ryzen means new board etc. Oh and a i5-14400 isn't that much netter than the one you have now. More cores are better.",Neutral
AMD,Thank you ðŸ™‚,Positive
AMD,Sorry for that. I'll update the post too.  My budget is around 240$  PC Setup:  CPU: I5 14400f  GPU: RX 6600 Challenger D RAM: 32GB RAM Hyperx Fury Cl16 3200Mhz PSU: 650W Seasonic,Neutral
AMD,Thanks,Positive
AMD,"5700x/5800x/5800xt. Not gonna really make a huge difference. Sure I'd pay maybe $10-20 more for a 5800xt over 5700x, but not like $50.",Negative
AMD,"5600X vs 5800XT, the later is going to be maybe 2% faster. The 5700X is going to split the difference between them. Tarkov is almost entirely single thread limited, so the additional cores of the Ryzen 7 CPUs over the Ryzen 5 doesn't make a big difference. That said, the 5700X, 5800X, and 5800XT are sometimes sold for basically the same price as the 5600X. So if they're the same price or only very slightly more, go for it.  Otherwise, they're all about 25\~30% faster than the Ryzen 5 3600. You'd need a 5700X3D to see another 25% over the 5600X (or roughly 60% faster than the 3600).",Neutral
AMD,5800XT is fairly cheap on Amazon offers all the time and  is enough to power nearly all GPUs.. love mine,Positive
AMD,"Hi!! I had the same CPU as you and I upgraded to an R7 5800XT because it was cheaper than the R75800X (R7 5700X wasn't even available to buy). I'm happy with my purchase. I did upgrade my GPU as well to a 9060XT 16gb and I'm playing all my games on 1440p with a 3440x 1440p monitor (most of my games I'm hitting between 60-100FPS on high/ultra setting) this of course is because of my monitor being ultrawide. If I was using the regular 27'' flat panel then I would be 100+.   Some people will tell you to get a 5600X but some newer games are demanding more and more CPU cores, so I go with 8 cores (Current consoles all run on 8core CPU) However going with a 5800XT you will def need a aftermarket cooler (Pearless assasins is a great budget alternative, I have a deepcool AK620-SE, and my CPU runs normal browsing and video at around 45\*, playing games is running around 51-60\*.",Positive
AMD,I just did a 3600 to 5800XT last week. Made a huge difference at 1440p for CPU bound stuff like BF6.    I'm still on a B350 board from 2017. Stretching it a little further. Went from 1600 to 3600 to 5800XT all on the same AM4 chipset. Nearly a decade lol. Hopefully AM5 lasts as long.,Positive
AMD,"Whichever is cheaper. Same silicon, 5800X and 5800XT just have higher stock power limits and boost clock.  If you are only gaming the 5600/5600X will deliver the same results.",Neutral
AMD,Iâ€™d get the 5800xt since you can buy it new and used prices on the other considerations (5600-5800x) are not that much lower.,Neutral
AMD,"5700x or 5800xt is the best value. X3d is overpriced, the 12 and 16 core 5900x and 5950xt are for productive work.",Neutral
AMD,"I am in the same situation, if ordered a 5700x on alixpress, I thought it was the most reasonable upgrade for the money.",Neutral
AMD,Iâ€™ve had a 5700x since 2022 and have had no issues playing any modern games with it (although Iâ€™ve not played Tarkov specifically).,Positive
AMD,"About to make the same move from a 3600x, most likely will go for a 5800x but depends on prices, not in a rush either way as it's not limiting me (more that I want to ensure I don't miss the chance to upgrade within AM4 if I'm going to stick with it a few more yrs) and would like to upgrade my board from a B450. If I see a decent offer on DDR5 though I might make that jump instead.",Neutral
AMD,I upgraded from a 3600 to a 5800x when they were $128 and it was definitely the right decision.,Positive
AMD,"I did a 3600 to a 5500x3d for like 170 usd, along other parts, now I am all set for at least 5 years",Neutral
AMD,"I went from the 3600 to a 5700x and the difference was enormous, from experience the 5700x is a quality-price option.",Positive
AMD,"I second this, this is the advice I would give",Positive
AMD,">Otherwise, they're all about 25\~30% faster than the Ryzen 5 3600. You'd need a 5700X3D to see another 25% over the 5600X (or roughly 60% faster than the 3600).  In 1080p with an 4090 maybe. You only get those numbers if you want to highlite CPU differences. The average/typical user will see a much smaller difference between these CPUs.",Neutral
AMD,"I made the same upgrades recently but went with a be quiet! 280mm AIO for not that much. Also have an additional 2x8gb of ram on the way. 5800xt is the way to go, especially with it being lower price than the 5800x and the same price as a 5700x on Amazon.",Positive
AMD,Are you me?!? I did almost the same Sequence of processors. Hoping my AM4 will last through all this NAND business so I can have a nice cold pint and wait for all this to blow over.,Positive
AMD,"Tarkov can be quite CPU heavy, and very spiking in terms of framerate. Even with low end GPUs you can actually see much higher FPS with an AM4 X3D CPU vs the rest of the Ryzen 5000 CPUs.  7800X3D / 9800X3D is definitely diminishing returns though unless you have a beastly GPU.",Neutral
AMD,"AM4 has been the best deal to adopt early than any other platform recently!   I also went GTX 1080, 3060 Ti, 6800XT and now 3070 all on the same mobo. Might get a 5070 or something to squeeze a little extra out.    I was going to pull the trigger on a DDR5 build but I knew I'd kick myself eventually for spending so much. I'm waiting for the Winchester too lol.",Positive
AMD,I went from 1660 to 2080 and just this past month got a 5070ti thatâ€™s waiting to be installed. Got a lucky near retail purchase from Best Buy.,Positive
AMD,"For 650$ you could get a 5700x + rx 9060 xt 16GB.  Your PSU isn't great, but the 9060 XT should be around the same level as a 2070 S in terms of power consumption, while the 5700x is really power efficiÃ«nt.",Neutral
AMD,Yeah you don't need a new power supply for a 5700x + 9060xt (16gb!). 550 watt is enough.,Neutral
AMD,"Budget might be a little rough especially with having to buy a new psu if you want to game at 1440p but it also depends on your standards, look at getting a 5700x or 5800x and at least a 7700xt or 9060xt (I would buy used for the gpu) I would also try to sell your old parts and include them in the budget",Neutral
AMD,Ryzen 5 5600(x) or 5700x/5800x(t) and a 9060xt 16gb should be within the budget and very good upgrades do you.,Positive
AMD,5700x + 9060xt ðŸ’ª,Neutral
AMD,"your pc will run basically all games well for the indefinite future especially now that the next console generation will likely be very delayed. id just save up for whatever the future holds and continue enjoying your current PC. You can upgrade to something noticeabley better now, but in real world scenarios youl basically just be playing all the things your currently playing just with higher framerates or settings, and once next gen comes around youl have to upgrade again regardless of what you get now",Positive
AMD,5600X and 9060XT 16Gb.,Neutral
AMD,"You could get a 9060XT GPU and 5800XT CPU for $650.  The problem is that your PSU barely meets the power requirements for those.  So you might want to up the budget to $700ish to get a CX750 as well.  If $650 is the absolute max then I'd get the 9060XT, a CX750 and a 5600XT.",Neutral
AMD,"Get these parts, find the 3080 used on Facebook Marketplace or something similar for $300 or less. Iâ€™ve seen plenty listed at that price recently.   [PCPartPicker Part List](https://pcpartpicker.com/list/7bFNLc)  Type|Item|Price :----|:----|:---- **CPU** | [AMD Ryzen 5 5600XT 3.7 GHz 6-Core Processor](https://pcpartpicker.com/product/GY6NnQ/amd-ryzen-5-5600xt-37-ghz-6-core-processor-100-100001585box) | $150.00 @ Best Buy  **Storage** | [Silicon Power UD90 1 TB M.2-2280 PCIe 4.0 X4 NVME Solid State Drive](https://pcpartpicker.com/product/4kpzK8/silicon-power-ud90-1-tb-m2-2280-pcie-40-x4-nvme-solid-state-drive-sp01kgbp44ud9005) | $119.97 @ Silicon Power  **Video Card** | [NVIDIA Founders Edition GeForce RTX 3080 10GB 10 GB Video Card](https://pcpartpicker.com/product/RnDkcf/nvidia-geforce-rtx-3080-10-gb-founders-edition-video-card-9001g1332530000) | $300.00  **Power Supply** | [Montech CENTURY II 850 W 80+ Gold Certified Fully Modular ATX Power Supply](https://pcpartpicker.com/product/sqbypg/montech-century-ii-850-w-80-gold-certified-fully-modular-atx-power-supply-century-ii-850w) | $89.90 @ Amazon   | *Prices include shipping, taxes, rebates, and discounts* |  | **Total** | **$659.87**  | Generated by [PCPartPicker](https://pcpartpicker.com) 2026-01-28 10:17 EST-0500 |",Neutral
AMD,There is no reason to buy the X CPUs anymore.  They are pretty expensive compared to the XTs that just just came out.  The XTs are better anyway because they have a slightly higher boost clock.,Negative
AMD,I've found a few RM750x for under $100USD and would upgrade to that before getting a new GPU & CPU from outside the set budget,Neutral
AMD,"Fully depends on your local prices, if you can grab the XT for a similar price, why not, but for gaming these CPU's are within margins of each other, other than the 5700x3d.",Neutral
AMD,I don't know much about usd pricing or anything but for most games a 5700x will be good enough maybe a 5800x and I think you'd at least want a 7700xt or 9060xt but if you can push it to something slightly better I would,Neutral
AMD,"Yeah, if you are buying locally that could change things.  I assume most people will be buying online and online prices tend to be higher for the X than the XT.  Yeah, I'm glad a snagged a 5800X3D when I did.  Aside from the X3D stuff anything from a 5600 and up performs really close in games.",Neutral
AMD,From my understanding you are definitely on the right track.,Positive
AMD,"Oh yeah for sure, the 9060xt 16gb is a great card that offers a ton of new features along with a nice jump in performance and pretty good drivers.",Positive
AMD,"Yeah 9060xt (the more vram the better though) would be a great starting point. If you can find one used or at a good discount, Iâ€™d recommend the next tier up and go with the 9070xt. Nothing wrong with the 9060xt though, itâ€™ll still kill at 1080p and keep up well at 1440p.  Unless you want to jump to AM5, just upgrade to a 5600 series cpu or something like that thatâ€™ll fit your budget",Positive
AMD,"9060 XT 16GB and 5060 Ti 16GB (if you can find it below 500) are both decent upgrades if you want to go for it, roughly 70 or 80% faster respectively. Also the FSR4 upscaling is quite a bit better, so you can draw a bit more extra performance there, or if you were already using FSR3 then the quality of FSR4 is a noticeable improvement.",Positive
AMD,"9060XT, but make sure it's the 16Gb version. Great card for the price, though it doesn't look like it's $350 these days.",Positive
AMD,I upgraded to a used 6700xt and love it. Sell your 5700 and youâ€™re already half way there price wise,Positive
AMD,9060XT 16gb brand new is around $400 so theyâ€™re not too bad. If they can snag a used 9070XT for $500 that would be perfect,Positive
AMD,"A 750w PSU is the recommended minimum for a 9070 xt. OP only has a 550w PSU, so they should stick to the 9060 xt.",Neutral
AMD,"I'm thinking I need to upgrade my CPU as well, it's a Ryzen 5 3600. Do you have a good recommendation for a sub-$120 cpu upgrade, specifically with gaming in mind?",Neutral
AMD,I just bought a steel legend 9060 XT 16gb last week for $400 brand new on Newegg,Positive
AMD,Correct. I only suggested it because they had been considering a PSU upgrade. The 9060xt is the winner for sure if they stick with their plan to keep the current psu.,Positive
AMD,"Not sure if any are under $120, but your options to consider are 5600/5600X/5600XT/5700X/5800X/5800XT. There are some cheaper 5000 series models (5500, 5700, 5600G, etc), but all are of a different design that make them not really any better than a 3600.  You also probably need to update your motherboard BIOS before installing any of those 5000 series CPUs.",Neutral
AMD,"My suggestion would be to get the new GPU and crank up the eye candy and enjoy that for a couple years to save up for a big CPU/MB/RAM upgrade. Where you will maybe dial down some of the eye candy for fps.  A perfectly balanced system is over-rated. Alternate, which way the system is unbalanced over time.",Neutral
AMD,"just get a 5700X, DDR5 is way too expensive to recommended an AM5 upgrade",Negative
AMD,If you can find a used 5600x thatâ€™s a great cpu for that GPU,Positive
AMD,"I got mine a few weeks back already, but found an open box Hellhound for $285 at MC.",Neutral
AMD,Would the Ryzen 5 3600 not be seriously bottlenecking the 9060?,Neutral
AMD,Sadly I donâ€™t have a microcenter near me so my only option is Newegg unless I wanna pay Best Buyâ€™s outrageous prices,Negative
AMD,"Hard to say. Your monitor might be the bottleneck. 4K/60fps the CPU will not be the bottleneck. 1080P/240fps the CPU is a bottleneck, but by bottleneck that is maybe 120fps which is still pretty good, and you can max out the eye candy. At 1440P, it is probably pretty close to balanced.  Then, in a couple of years, you get a Zen 6 X3D and keep your 9060XT, and your 9060XT is the bottleneck. But, you are maxing out it's frame rate. Enjoy that for a couple of years, then buy a 11060XT and flip the bottleneck again, maybe, it might take a couple generations to max out a Zen 6 X3D without a flagship GPU.  I like avoiding the full upgrade CPU/MB/RAM/GPU. So, I want unbalanced, so when I upgrade the GPU, I get an improvement, and then a couple uears later, I upgrade the CPU and get an improvement. If my system is balanced, I can't upgrade just one or the other and get a benefit.  Is it worth keeping an eye out for a really good deal on a 5700X3D or other AM4 5000 series X3D CPU? Yes. Is it prerequisite to getting a 9060XT (or even 9070XT) and seeing a difference you can enjoy? No.  And, per my hint above, a monitor upgrade to go with the GPU, might be a better quality of life upgrade than a CPU. I don't know how good your monitor is.",Neutral
AMD,It's [this one](https://www.amazon.com/AOC-CQ27G1-DisplayPort-adjustable-Zero-Bright/dp/B07V39QHMY) if it helps,Positive
AMD,"My guess after skimming some benchmarks, with eye candy cranked, a 9060XT will still be the bottleneck at 1440p. Dialing down some settings, I would guess a 3600 may not get to 144fps in every game, but will probably exceed 100fps pretty consistently.  Like I said, I would do the GPU upgrade and just keep an eye out for a good deal on an AM4 X3D CPU. If you find one great, if you don't, I think you will still be happy.",Neutral
AMD,Title is the wrong way around ðŸ˜”  I was really worried that you were going in the wrong direction there for a second (jk),Negative
AMD,That's fine,Positive
AMD,You messed up your title. I thought you were devolving,Negative
AMD,"You messed up the title.   I think most modern Prime boards are kinda crap. The B850's VRMs got really hot in Hardware Unboxed review: [https://www.youtube.com/watch?v=CFqd7lnXlIk](https://www.youtube.com/watch?v=CFqd7lnXlIk)  You're overlooking that the RAM price can stay stupidly expensive for more than month or two, but noone really knows.",Negative
AMD,"If you have access to a microcenter, just get whatever 9850x3d bundle they have, maybe pay for the upgraded motherboard if it's nicer.",Neutral
AMD,What are you worried about overlooking? AMD does the job perfectly fine and will save you money.,Positive
AMD,Yeah I read through the whole post then changed the title and whatâ€™d ya know that one thing I didnâ€™t check was the mistake ðŸ˜‚. Iâ€™ve been wanting to switch to AMD for a while. Just seems to be the best idea for gaming in my opinion.,Neutral
AMD,"Yeah thanks I just noticed. Yeah. I might just go with the AORUS Elite then. I know that RAM prices will stay mostly the same but can always hope, I donâ€™t need to upgrade right now anyways so I figure just waiting a bit wouldnâ€™t hurt.",Positive
AMD,"Sadly Iâ€™m based in the UK and we donâ€™t have a MicroCenter, wish there was.",Negative
AMD,"Making sure I wouldnâ€™t make a mistake Iâ€™d regret, like someone else mentioned I probably wouldnâ€™t want to get a Prime board. Good to hear the parts make sense at least. Thanks.",Neutral
AMD,"Understandable. Itâ€™s always the most obvious bits that are overlooked.Â   Unfortunately, I canâ€™t really contribute in any meaningful way to the discussion. Anecdotally however I switched to AMD in 2024 and have never been happier with my rig. All the best with your new build :)",Negative
AMD,"Yeah I havenâ€™t really heard any bad things from people switching to AMD. Thanks for your anecdote nonetheless, still helped.",Neutral
AMD,"I'm biased towards air cooling; I'd stick with the NH-D15.  When you're using the PC, you're not generally gawking at it's internals",Neutral
AMD,"nh d15 is so fucking overpriced for no good reason, a peerless assasian is around 4-5x cheaper and is barely worse. anyone who tells you to buy one is a D1 shill, idiotic or stuck in the past and shouldnt be giving advice   https://gamersnexus.net/megacharts/cpu-coolers#200W-normalized-100",Negative
AMD,"D15 is just wasting money, only buy it if you're a die hard Noctua Fanboy/girl.  Thermalright Peerless Assassin / Phantom Spirit offer similar cooling performance for a fraction of the price.",Negative
AMD,"I am using a Noctua NH-U12A with a 9800x3d.  Good ram clearance, cool, quiet.  No regrets, I would recommend this over an AIO for reliability and maintenance.",Positive
AMD,Noctua has never done me wrong,Positive
AMD,Phantom Spirit 120 and call it a day. Noctua if you care about looks/silence,Neutral
AMD,">NH-D15  You can spend 1/4th up to 1/2 of the money of a Noctua cooler by getting something like a Thermalright Peerless Assassin/Phantom Spirit... or Frost Commander 140. Total height matters, you'll have to check the specs on the case on max height.    >However, I won't have clearance for my RAM  Most coolers have cutouts for taller RAM, and you can always reposition the front fan a little higher to accommodate.",Neutral
AMD,"oh, i thought you had a D15 already, didnt realise you're weighing up options.  What are you using now, and have you considered undervolting?  Even setting the proc on eco mode will bring down temps significantly.",Neutral
AMD,Scythe Fuma 3 is a decent air cooler that lets you see your RGB RAM  If you don't care about seeing your RAM then get a Thermalright Phantom Spirit,Positive
AMD,Depends on price of said aio. Noctua air coolers are insanely overpriced. Peerless assassin 120 is same performance but only 30 bucks,Negative
AMD,"Go with the aio, air coolers are loud and an eyesore.",Negative
AMD,Prepare to be downvoted by people who justify 100$ for 2015 technology,Negative
AMD,Do you know what kind of temps you get with it?,Neutral
AMD,https://gamersnexus.net/megacharts/cpu-coolers#200W-normalized-100  noctua is barely better in noise normalised test. fucking embarassing for how much they charge,Negative
AMD,The AIO Iâ€™ve seen are cheaper than the Noctua,Neutral
AMD,I'm away for a few days before I could get any more data points.  Playing BF6 it runs at 63C at indicated 32% cpu utilization from the steam overlay.  I don't think I have seen it over 70C but would need to benchmark it again.,Neutral
AMD,"If aesthetics are important, go aio. Never buy noctua. The 30 dolla versions perform the same",Negative
AMD,"If youâ€™re going to stay on AM4 Iâ€™d save up for a 5600, you donâ€™t need a new motherboard.",Neutral
AMD,Do not buy a new AM4 motherboard. That defeats the whole purpose.,Negative
AMD,Don't buy a new motherboard or ram if you're gonna get a 3600 or 5600x     What motherboard exactly do you have?,Neutral
AMD,"Don't spend money on mother and ram, put that money into the CPU, don't forget to update the bios.  Changing the motherboard is not going to give you any improvement, and going from 2400mhz to 3200mhz does not give a significant performance change, what will do is the cpu, 5600, 5500x3d or 5700x  Add a 1TB HDD to relieve the SSD, so you can put your files and install programs and light games, so that the SSD is left for heavy games.",Neutral
AMD,"The difference between a 1700X and a 3600, in games, is pretty significant. I'd just get the 3600 first; you have enough RAM (though it is a little slow) and your motherboard is perfectly fine. Upgrade the RAM later, if you need more capacity or if you find a real good deal on DDR4-3200/3600 stuff.",Positive
AMD,"If you can get a 3600, or really any 3/5000 chip that isn't an APU or cut APU, for reasonable money I'd say do it.   The ""good"" part of AM4 is being able to do that; buying another AM4 motherboard would be a bit silly, and the only benefit you'd really have from a motherboard upgrade would be to add a second M.2 and/or gain PCIe Gen 4, but neither of those make meaningful impacts on a 3060.   I'd also look at the 3700X if available for a modest cost difference vs the 3600, just because it lets you keep your core count and guarantees a system that's better everywhere than current, rather than better-or-the-same as a 3600 would be.",Neutral
AMD,I'd be going 5600 at a minimum,Neutral
AMD,I did buy a 3600X for my 1700 replacement just to make it work with Windows 11.,Neutral
AMD,You can find 5800x 8 core for 140â‚¬$ ... Don't buy 6 core CPU,Neutral
AMD,"I'd really try to aim for a 5600, but if not, a 3600/5500 would be a solid upgrade.",Positive
AMD,"As someone with a current R5 3600 I would buy something newer, and prioritize an AM5 platform.  Im trying to hold out one more year for an upgrade, we will see if that comes to fruition.  Its starting to show some signs of aging.",Neutral
AMD,"Yes, it is a great processor. Try to find one on Facebook Marketplace or AliExpress for a good deal if you can. Are you sure you also need to upgrade your MoBo?",Positive
AMD,Probably get a 5600 and keep your current motherboard and ram   Yes Ryzen is memory sensitive and will be faster with faster ram. But the uplift from 3000 series to 5000 is larger than that ram upgrade and probably cheaper just update your bios,Positive
AMD,The 5600x shouldn't be much more expensive and definitely worth it.,Positive
AMD,"at least get one of those if you are gonna upgrade 5600,5600x,5700x,5800x,5800xt those are better than 3600 and are a diminishing return in the am4 platform you could get the 5800x3d thou but the price is expensive for them so just get one of the cpus i listed below",Neutral
AMD,"Cause everybody is going after 5000 series, the 3600 is really affordable.  It's an upgrade so go for it.  I wouldn't bother upgrading your motherboard, put the money towards a better CPU and/or the 3200 memory.",Positive
AMD,A brand new 5600 non-X is like $170. Probably around $100 on the used market. Would be a massive upgrade to your 1700X even without any other upgrades. Although getting a kit of RAM in the 3200 or 3600 speed would also help with performance some. (EDIT: but not a HUGE deal if you dont upgrade your ram)  Your motherboard would just need a bios update and you can plop that sucker in. You'd have to check your motherboards support page tho - as some early boards remove support for 1st gen Ryzen CPUs after a bios update to support newer CPUs. But IDK which chipset that was on.,Neutral
AMD,"Thereâ€™s quite a bit of improvements from 3 series to 5, so try for 5600 if you can.   You can pretty much reuse everything you have just make sure to update your bios to a version that supports 5 series.  Most x370 and b350 boards should have them.",Positive
AMD,"Look used as well, but a 5600 would be better. The 3600 is not bad though. Both are definitely a good upgrade over first gen ryzen.",Positive
AMD,"Look used as well, but a 5600 would be better. The 3600 is not bad though. Both are definitely a good upgrade over first gen ryzen.",Positive
AMD,"with a coupon you can get a 5600x for 80 pounds on aliexpress, much faster than a 3600 which costs around 50 pounds on ebay",Positive
AMD,"In order I would get a 5600, then upgrade your ram to a faster speed, then upgrade your GPU. Those x370 boards are really nice and will be great for a new CPU.",Positive
AMD,"Get a 3600, or a 5600, plus a ram upgrade if you really want.   Do not buy a motherboard. Your motherboard will support either option with a bios update.",Neutral
AMD,"I had a 3600x, it started showing it's age. Playing games with discord on the background was starting to stutter.  Today I would not get a CPU worse than a 5600. Check 2nd hand market, the price difference might not be that big VS a 3600.",Negative
AMD,"I'd get the ryzen 5 7600x plus the peerless assassin heatsink   2nd hand cost is less than Â£200  I've just upgraded from that myself, and it had no issues playing Battlefield 6",Positive
AMD,Says right there X370 slr plus.,Neutral
AMD,Yeah agree with this comment just going to provide a list of the chips to avoid  These are the zen3 Apu chips.  https://www.techpowerup.com/cpu-specs/?f=codename_=Cezanne  The Ryzen 5 5500 this is a 5600g without the igpu in some games if loses to a 3600 due to low cache  The 5700 non X it's a 5700g without the igpu   Anything with a g or gt E.G 5600g 5600gt 5700g  These are the regular zen 3 chips and would all be pretty respectable upgrades  https://www.techpowerup.com/cpu-specs/?f=codename_=Vermeer,Neutral
AMD,not in my country. i just checked the 5600 is 145 in euro,Neutral
AMD,where to find this price? thank u,Neutral
AMD,6 core is plenty heck HUB just did a review of the 5600 and it holds up well in the majority of games. A few exceptions but the GPU will also limit performance.,Positive
AMD,"Not really, its still running strong. it was only as most of the cpus are part of the upgrade kit",Positive
AMD,how do i get a coupon,Neutral
AMD,"> 2nd hand cost is less than Â£200  Plus the cost of a motherboard and DDR5 RAM, compared to like $50 for a Ryzen 5 3600 though. It's better, but whether it's worth it is pretty subjective.",Neutral
AMD,The issue with that is you're making the jump to am5 and ddr5 which is definitely gonna cost more than a 5600x,Negative
AMD,If it's the MSI board then it supports all the at up to the 5800x3d on latest bios so no need to grab a 3600 when you can get anything from the 5000 gen,Neutral
AMD,aliexpress,Neutral
AMD,theres like a 15 pounds off above 99 voucher where i am from. should be on the love delivers event main page. or maybe you could use a welcome offer if you have one.,Neutral
AMD,DDR 5 ram is going to be an issue with the skyrocketing prices,Negative
AMD,Ok I had no idea.  I donâ€™t suppose my Auros B450 in my second rig supports anything above my 2600.,Negative
AMD,You'd be good with a 5000-series CPU as long as you update your BIOS.,Positive
AMD,"Thanks, I realized I was being lazy and looked up the CPU support for it, curious why the 5000 x3d is not listed. I can look this up as well but thought it was strange.  Also, correction that Iâ€™m running a 3600 in this machine now, too many PCs in the family lol. Iâ€™m curious what others thoughts are on 3600 with my 5070 for 1080p gaming (240fps targets) and video editing. Would 3600-5000 be a significant uplift?",Neutral
AMD,"You'll need to check benchmarks for the games and programs you're interested in. If I remember correctly, there's roughly a 40% uplift from a 3600 to a 5600, but whether or not that's meaningful depends on what you're doing.",Neutral
AMD,"The best would be a 5x00x3d CPU hands down, but they're expensive. A 5700x for example is a good upgrade over the 5500 as it has 2 extra cores, a better architecture and more cache. Expect an uplift in performance of about 20-30%.   The ram should be matched for better performance but it is also very expensive.",Positive
AMD,"PCIe 3.0 doesn't make much of a difference, don't worry about that.   If they still have X3D chips at prices close to MSRP, those might be worth it. Otherwise get the 5800x or 5800XT.   Also, you'll want to upgrade that 4GB stick to another 16GB one to have 32GB of RAM.",Neutral
AMD,"Depends what is a reasonable price to you. What platform you choose depends on your expectations and budget. On am4 for gaming, I would only consider the 5600, or the 5700x3d if you can find one for a good price.",Neutral
AMD,"5700x.  Yeah the 16+4gb ram isn't ideal and will probably hold bad performance to an extent.  Motherboard might not be good enough to stably support the 5700x but PCIe 3.0 shouldn't a big problem as it is a x16 slot. (If you were getting a 5050, 5060, it 5060ti 8/16gb it would be a different stor6)",Negative
AMD,The only real bottleneck here is the ram Just run 16gb You can get a 5600 if you want to but the best for am4 is 5700/5800x3d I'd honestly just run 16gb and call it a day,Neutral
AMD,Bro. Donâ€™t use mixed  RAM in a gaming pc,Negative
AMD,7600x3d combo from microcenter,Neutral
AMD,"5800x3d, 5800xt. Or grab a microcenter bundle of amd 9600x/9700x/7800x3d.",Neutral
AMD,"At 1440p with your RX 9070 XT, the GPU is still the main driver for performance, but your current Ryzen 5 5500 can start to bottleneck in CPU-heavy games, especially ones with high frame rates or simulation workloads. Moving up to a Ryzen 7 5700X or 5900X will give you more cores and threads, which is helpful for multitasking and modern gaming, but the difference at 1440p is not as dramatic as at 1080p, because the GPU is doing most of the work. The memory configuration you have (16+4 GB) is not ideal. Mismatched DIMMs can impact performance, particularly on AMD platforms where dual-channel operation is crucial. Even if you upgrade the CPU, that memory setup could hold you back slightly. Ideally, a matched 32 GB dual-channel kit would squeeze the most performance out of a 5900X or X3D CPU. As for the X3D chips, they excel in gaming due to the large L3 cache, but at 1440p and with your PCIe 3.0 board, the real-world benefit may be modest. They are expensive and hard to source, so unless you find a deal, the value proposition isnâ€™t great compared to a standard 5900X or even a 5700X. Jumping to AM5 now would solve the memory limitation and future-proof you for PCIe 4.0/5.0 and DDR5, but it comes with significant cost due to new motherboard and RAM prices. If youâ€™re price-sensitive and the goal is mainly to get a modest CPU improvement at 1440p, staying on AM4 with a 5700X or 5900X is reasonable. Youâ€™ll reduce bottlenecks for CPU-heavy titles and keep most of your investment intact. So in short: for 1440p gaming, upgrading to a 5700X or 5900X gives you a tangible benefit without the high costs of AM5/X3D. Donâ€™t stress too much about PCIe 3.0 or DDR4; your GPU will still be the main factor for FPS. Reserve AM5 for when youâ€™re ready for a full platform overhaul.",Neutral
AMD,"5800X, 5800 XT or 5900X, whichever you can get a good deal on. But 5700X would also be a good upgrade.  The AM4 X3D CPUs sell for ridiculously high prices and aren't worth it. At least last time I checked prices were craaaaaazy and supply limited.",Positive
AMD,"You can get a 5800x3d as x3d chips are good for gaming, if AM5 is too expensive due to RAN prices",Neutral
AMD,What's your budget,Neutral
AMD,Best one that you can actually buy for a reasonable price - 5800XT or 5700X.,Positive
AMD,"Was in similar dilemma as you last month before, bottleneck is too much and im playing 1440p .. ended up upgrading all, just happen finding a bundle deal for motherboard cpu and ram so went for that upsetting the ram crazy markup prices . Went for 9600x has lower voltage consumption keeping it cooler than other options as was contemplating x3d and more than I need for just gaming at 1440p. And never gone past 60 degrees playing ghost of tsushima for cpu and gpu temp  and compliments well with my gpu, utilizing 100% of gpu and 40-60% cpu",Neutral
AMD,5700x3d or 5800x3d,Neutral
AMD,"This is the way, OP",Neutral
AMD,"I'll definitely do that, thank you. I just ordered another 16GB 3600MHz CL18 RAM module, I managed to find a good deal for a little less than $100. I hope this will help improve the situation.   The only thing is that my old 16 GB stick is from 2017, 2133MHz CL15.  Although I recently managed to achieve stable operation of my current ""kit"" (16+4GB) at 3200MHz with timings of 16/17/17/21.",Positive
AMD,Up to $400 on CPU + potential RAM upgrade,Neutral
AMD,Goodluck with the new kitðŸ˜…,Positive
AMD,Defo keep the RAM at the current state of the market if it's 20GB already  Cop a Ryzen 7 7800X3D from AliExpress it's like 350 bucks  It doesnt come in the box but lots of people bought it and said it works well for them so youll be ok,Positive
AMD,Or heck if you can find it in new condition for a bit more in amazon newegg etc go for it,Positive
AMD,5800X,Neutral
AMD,5800x,Neutral
AMD,"If you are doing video editing and 3D, the extra cores for the 3900 would be worth it imo.",Positive
AMD,5800x if you're going more for gaming. 3900x if you're going more for the video editing and 3d design.,Neutral
AMD,"The question is why you need to upgrade. The 5800X is the better choice, but neither will give you earth shattering performance improvements except the 3900X and only where AVX2 isn't heavily relied on but many cores are needed. At least the 5800X won't be a downgrade in gaming.",Neutral
AMD,"Have you had troubles with your 5600X? A lot of people tend to assume that you need a lot of cores for productivity work, but realistically it rarely makes a big difference.  If you must upgrade, the 5800X is still the better choice. The only time the 3900X comes out on top is when you are utilizing all the cores which is very rare. For the rest of the time, the 5800X will be faster (although the 5600X should be nearly the same way).",Neutral
AMD,I would save more for a bigger upgrade. Both of these wouldnâ€™t give too much of a performance increase,Neutral
AMD,"how much of your income does come from productive, professional 3d design and video editing ? Can you wait some additional seconds if your buildchain for your programming is not scaling over 12 but only 8 faster cores ?  Personal bet is, get the 5800x and call it a day",Neutral
AMD,5800x has~30% faster single core perf vs the 3900x. The 3900x has 50% more cores but they clock down a bit when running at full tilt.   Both are performance peers for mt but the 5800 is a bit ahead on ST.,Neutral
AMD,5800X has much faster single core performance and will still be reasonably close to 3900X in multicore. 5800X also has a much better AVX2 implementation where 3900X will show its age. 3900X will also be a significant downgrade from the 5600X in gaming.,Positive
AMD,"depending on the resolution you're already there with a 3070. A better GPU will give more fps, but not as much as you would get with a far superior CPU.  Basically 9850x3d + 3070 to 9850x3d+5070 would probably be a 55% improvement at 1440p, but with your CPU you maybe would only see like a 40% improvement going 3700x+3070 to 3700x+5070. Maybe less, maybe more, Depends on game and I doubt anyone could tell you exactly. Your 3700x just already is holding you back in some games unless maybe playing at 4K.  Edit: [https://www.techpowerup.com/review/amd-ryzen-5-7600x/19.html](https://www.techpowerup.com/review/amd-ryzen-5-7600x/19.html) just to give a sense of how your CPU stacks up with just an RTX 3080, and the 7800/9800X3D CPUs aren't even on there.  I wouldn't go over an RTX 5070 or RX 9070, and a Ryzen 5600/5600x/5700x/5800x are probably worth looking into no matter what GPU. RTX 3080 is the weakest I'd consider, or 4070.",Neutral
AMD,"You would be better off upgrading the CPU first. the 3070 is already probably near the top if not the best GPU for what you have before you start bottlenecking from newer hardware. If you're on a budget, the 5600X is a good upgrade (5700X if you dont mind spending a bit more.",Neutral
AMD,">what GPU would be the best to use without running into bottleneck territory?  In what games? What resolution?  Some games can be bottlenecked by the GPU, some by the CPU, so it depends on the games you are trying to run at higher settings.",Neutral
AMD,"For a ryzen 7 3700X, you want GPUs that wonâ€™t hold it back too much. An RTX 3080 or a 6800 XT are good upgrades   Theyâ€™ll boost your performance without stressing the CPU too much. If you wanna see some benchmarks and prices, gputifulâ€™s a good site for checking out the best graphics cards at the moment.",Positive
AMD,"Thats assuming they want to build a whole new setup tho, which by what they said doesnt look like they are looking to do so.",Neutral
AMD,"Definitely not looking to upgrade into a 5000 series card unless I were buying an entire new system. I noticed the 4000 series cards are running less than I expected ($600ish...I haven't been keeping track lately) and that's what prompted it. The monitor is a Samsung curved 27"" 256mhz, running 1440 normally.",Negative
AMD,"Running some fairly graphic-heavy games at 1440 (256mhz 27"" curved Samsung monitor). Star Citizen, MSFS 2024 are probably the biggest hits and where the FPS drops going from medium to high settings are the most noticeable.  I brought the whole thing up because I noticed 4000-series cards are running $500-600 and wondered how much improvement we'd get. If I have to replace the GPU, I might just end up getting a whole new build and make this computer a backup or alternate. Seems like a waste when it still does so well in *most* games.",Neutral
AMD,"Excellent, thanks.",Positive
AMD,"Well ya. I'm just trying to explain that it's not like there's some magical limit for his CPU where a more powerful GPU won't give him more fps on average.  5800x3d/5700x3d would be a huge  improvement, they're just absurdly expensive because everyone is buying them since DDR5 ram costs way too much and many people had B450/B550 boards.  A 3700x is bottlenecking already and given GPUs are now over MSRP and we have no idea on the guys value of more fps, it's not easy to say what a good GPU is. Maybe an RTX 5070 or RX 9070 at best I suppose, still gonna be some big bottlenecking even at 1440p potentially.",Neutral
AMD,"I would rather not. If I have to change the CPU/mobo, I'm inclined to just built a whole new system :)",Neutral
AMD,"Also just saw this, if you're trying to run star citizen of all games, you need a new setup in general. Any upgrades to either side isnt gonna see a noticable improvement in any of those 2 games you mentioned cuz you're gonna be affected by lack of fps one way or the other",Negative
AMD,right so you just need to upgrade to the 5000 series. 5700X3d/5800X3D(if you have the money for it) Oh just saw your comment about the CPU. My point is that it makes more sense upgrading the CPU instead of the GPU in order to get more FPS. The 3070 is a fine card in itself for 1080p- medium 1440p  as long as you temper your expectations,Neutral
AMD,"Oh boy, here we go again.   There's a reason I out right refuse to recommend Asrock boards on AM5.",Negative
AMD,"I have an AsRock B650 board with my 7800x3D, no issues.   It's Zen 5 that's affected, Zen 4 is fine.",Neutral
AMD,Yeah my 9700x died from a B850 pro rs after a couple weeks.  I went back to a gigabyte board and have had no issues except for laughably weak m.2 screws.  Real.  Just look at those screws wrong and they snap in half.  Iâ€™m surprised the tension from the angle of the pcb hasnâ€™t sheared it off sending it through my side panelâ€¦ /s,Negative
AMD,"This is literally not news. A) its not a secret. B) Following the flood of 9800X3D reports, as one might suspect, others reported that more CPUs were effected. Its like if your car has a recall for a bad transmission, they find that the clutch was damaged.  Is the clutch torched because the trans, or did it just happen to fall in line with what would be normal failure rate.  The reason we don't see more bad clutches... I mean CPUs with other brands is because they are not being dug into, not to the degree that Asrock has been. The Mods over on r/ASRock have done a down right divine service tracking reports.  Now, while I like Asrock products, I will not pretend you should buy any 9000 series with any 800 series board, until fixes are concrete. But anyone pretending that they should be avoided until the end of time, is a fool because every brand has issues. ASrock isn't even the first to nuke X3D CPUs.",Negative
AMD,Also since 3.40 bios memory compability got worse. And you have to enable ln2 to boot system everytime otherwise ig T might not boot.   I am like very dissapointed. Still my 9800x3d is alive after over a year. So i cant compline much.,Negative
AMD,How new are these reports?,Neutral
AMD,Can someone on a asrock board confirm what auto expo voltage is for VSOC? I really highly doubt this is vsoc voltage relatedâ€¦,Negative
AMD,Is it only limited to ASRock motherboards or any brand overall? I'm kind of worried because I recently built a PC with a 9600X and an MSI B850-S motherboard.,Negative
AMD,Its not a X3D so its got to be a Zen 5 Issue.,Neutral
AMD,How do 7700x look in this regard? Was looking at a 9600x or 7800x3d but 7700x looks more appealing now,Neutral
AMD,I noticed that the AGESA 1.2.0.F is causing the issue for AM4 CPUs. I thought my Ryzen 7 5800X3D died because I am having my CPU debug led lit up in the motherboard. But when I downgraded my BIOS to 1.2.0.E it came back to life and never had the issue. There is something in the latest AGESA update that is causing the issue. Looks like it does not only affect AM5 but also AM4.,Negative
AMD,thank goodness i didn't buy asrock when building my AMD system last year. if this would have happened to my 7600X i would lose my mind.,Negative
AMD,many so many new org and people on reddit are experts in engineering and software for this subject.  oh wait they are not.,Neutral
AMD,this happened to me with the 9950x3D.,Neutral
AMD,I traded my 9800x3d to a dude I know for his 7800x3d and 100 bucks.,Neutral
AMD,ASRock went from one of the best brands to something you avoid. They need to fix this ASAP,Negative
AMD,Common. Denominator.,Neutral
AMD,Still AsCrap problem?  There should be a PSA not to use any Asrock AM5 boards for any reason.,Negative
AMD,"Have we had any such reports for 7000 series chips on ASRock boards?   Also Asus boards have started killing 9800x3ds too, I hear",Negative
AMD,Even if it's only am5 this will damage their reputation for years  I was going to get the ASRock nova board with my 9809x3d and then all the dead CPU reports come out ..I waited to see if it was fixed ... Then just went a different brand.  And now I'll never go ASRock in the future,Negative
AMD,"Same, had some issues with being able to boot computer  everytime I updated my 4090 but eventually fixed that and itâ€™s been smooth sailing",Neutral
AMD,How goes the Gigabyte control center? for me it caused blue screen crashes.      Yes that brand and some ausus boards the screws are a joke i like the rare times you just get a screwless m.2 slot.,Negative
AMD,So 600 boards are fine?  Iâ€™m rocking a rig strix b650e-f and was going to upgrade from a 7600 to either a 7800x3D or a 9800x3D.,Neutral
AMD,">This is literally not news  In other subs one can still see random claims that the dead CPU issue was ""fixed"" through BIOS updates, it's therefore good that we are made aware (and reminded) how reality is. Even if just to help others make a sensible purchasing decision for their next motherboard.",Negative
AMD,"https://preview.redd.it/14dshck8srgg1.png?width=1265&format=png&auto=webp&s=9973f8bee920f5dbc128b3667de6f0e6f5c413cf  9600x has been implicated for some time, from the ASrock megathread:",Neutral
AMD,You can see in the article then go to the reddit as recent as 4 days ago.,Neutral
AMD,Asus recently joined them   https://preview.redd.it/qmmo4zg1izgg1.png?width=1220&format=png&auto=webp&s=024c350a1d650eb75431c27aea40fce32f501def    So for now i have not heard of MSI issues but its a waiting game,Neutral
AMD,"All of them have this problem: MSI, Gigabyte and Asus. Most likely it's an problem with CPU rather than a motherboard.",Negative
AMD,You can look at the mega thread on /r/AsRock   It's a Zen 5 issue. More 9700x and 9600x CPUs dead than 7800x3Ds or any other Zen 4 CPU. Mostly dead 9800x3D.,Negative
AMD,Biggest thing with Gigabyte Control Center is donâ€™t let it install Norton.  Fuck that shit! Mine works fine for changing my rgb.  Thatâ€™s all I use it for.  Iâ€™ve got a 9070xt red devil and fixed blue light speakers so Iâ€™m stuck with the Spider-Man color scheme until further notice (Iâ€™m not complaining).  I could plug in a cable to change the color of the gpu but why bother.  Blue ram and speakers and red case fans and gpu.,Negative
AMD,"A ROG board? Not asrock...   I mean, ironically with a 7000X3D CPU its a worse combo (asus was the other company that recently was nuking such CPUs when they launched). But, that's by and large old news. As the other comment noted, across the baord 9000X3D CPUs have a higher rate of failure. How high, we do not know, AMD is being tight lipped about that.  Personally, I am rocking a 7800x3d in a X870e Asrock mobo. As the failures of 7000 series seems to be ""normal"" ie of no special concern(and that asrock board had features that would have cost 1.5x to 2x easy with other brands). I am also plugging a 7600X3D into an Asus B650e-I mobo for another build.",Negative
AMD,Get the 7800x3d. The failure rate is pretty low on that one and is pretty stable. I would say avoid the 9800x3d for now as it seems like the combination of the cpu and motherboard is causing these failures.,Negative
AMD,I got an asrock taichi lite b650e with 7800x3d for 2 years. Absolutely zero problems with it. Amazing gaming performance.,Positive
AMD,"Not as bad as I suspected.Â    Still a problem, but nowhere close to enough to keep me off AM5 in the future.   Definitely avoid asrock AM5 boards though. It's not just the dying cpus, there are other issues I've seen as well.",Negative
AMD,"Nope. You can see from literally other subs their motherboard is just fine with zen 5 cpus, its just Asrock kept having this problem.  Tom's Hardware said its due to Asrock incompatible PBO config. I don't know to much about that but I'm hoping for the best for my Gigabyte b650",Neutral
AMD,I never messed with power color for awhile but you can check the sides of the pcb for a rgb switch some of those brands have them my asrock does. Or you can get tweezers look for the rgb cable you can get lucky and see it on the side of the card wiggle it out. Its all up to in the end just though i pass on some info.      I had rainbow puke ram could not get colors to set so glad before the crazy price hike i got new non rgb ram.,Neutral
AMD,I un-installed gigabyte control center and all my issues went away. I use signal rgb now.,Positive
AMD,I kept seeing Asus was in second place behind asrock and that ROG is still Asus but their â€œgamerâ€ line or something like that.  Wasnâ€™t sure if people just lumped rog in with Asus stats at that point.,Neutral
AMD,"There's a lot of bias in those numbers to be fair, we don't know the relative market share of each brand nor the total number of cpus out there.   While it does appear ASRock is more likely to be involved, it's still a tiny % and very hard to draw any solid conclusions.   A single retailer said they sold 8700 9800x3ds in a single day, back in Jan '25.   There are probably tens of thousands of ASRock AM5 systems out there by now.   Fwiw my B850 steel legend/9800x3d has been running great for over a year, but that said it's perfectly reasonable to want to use another brand.",Neutral
AMD,"Sorry, what I'm trying to say is that it's an AsRock issue specifically with Zen 5, Zen 4 it seems based on the number of cases is not affected.",Neutral
AMD,The gpu has a header for the rgb.  I just canâ€™t be bothered after my last build bit the dust and I spent countless hours trying to diagnose the problem (asrock mobo and zen5) during my busy season at work.  I was working 10-12 hours a day 6 days a week at a tire shop here in Alaska.  Then spending my off time trying to get it to work.  My case can change the fan rgb with a button push (montech air 903 max).  I have 32gb cl30 Corsair vengeance and havenâ€™t had problems setting the color.,Negative
AMD,"No.   There is a company that holds stock, or owns both Asus and ASRock(I forget). That's why people say they are the same brand nowadays.   ROG is just a ""model"" of ASUS. Like how RAM is Dodge. That's why it is Asus ROG -product-.",Neutral
AMD,It does appear to be a small percentage and mine has been running fine for about a year on an Asrock board. But had I known at the time of purchase I would've picked another brand.  I've tried to stay on top of the bios updates at least,Neutral
AMD,I did take this into account. It makes AM5 a much better platform than lga1700 in that way. This to say that I don't like intel bros claiming AM5 is more unstable than LGA 1851/1700.,Neutral
AMD,I had a old old drr4 kit still works just rgb puke can't complain.      Montech nice never new about the rgb button they got now.      All you had to say alaska tire shop the amount of tire changes would be exhausting on its own no doubt. Put on those hours fuck man hows the body?,Positive
AMD,"Bodyâ€™s banging, brain ainâ€™t so tough.  I tent to take it year by year.  I do what I can.",Positive
AMD,People really suck.,Negative
AMD,Oh i did the customer side fixing pcs fucking hated talking to many.      You take care out there maybe i will see you on gold rush? :),Negative
AMD,This just shows what tests from other reviewers have also shown.   For gaming the extra Cache of AMDs X3D CPUs can almost completely negate the bottleneck that comes from slower memory.,Neutral
AMD,Dumb question because I donâ€™t really know anything about PCâ€™s: are there motherboards out there for AM5 that actually support DDR4? I thought you were essentially locked to DDR5 on AM5 mobos?,Neutral
AMD,"No, AM5 CPUs themselves inherently do not support DDR4.",Neutral
AMD,"Iâ€™m so stupid, I read DDR5-4800 as DDR4 lmao",Negative
AMD,I read it like that as well,Neutral
AMD,It's probably because before the RAMocalypse you never heard of DDR5-4800. It was always at least 5000-something MT/s.,Neutral
AMD,Iâ€™d stick with what you have,Neutral
AMD,The 5080 one would be 600 more for about 15 percent more performance so have to ask yourself if it's worth it.  And just noticed its not a X3D so would lose a little cpu performance in more CPU bound games.,Neutral
AMD,"stick with what you have.  though if you *do* end up getting a prebuilt, make sure to reinstall the OS.  Prebuilds come with a whole slew of bloatware installed.",Negative
AMD,Thanks! Do you see any issues with the glass case not having good heat circulation ?,Neutral
AMD,I'm currently looking into buying a pre-built computer from Costco the one posted here is currently 300 dollars off would you recommend this one or do you have any suggestions from their store?     Edit: Wait nevermind its sold out in my zipcode.,Neutral
AMD,I grabbed the 9800x3d bundle last January along with 16x2 6000 ram and some asus mid range mobo for 500 bucks when I was visiting the states.   You american folks don't know how lucky you guys are,Positive
AMD,https://preview.redd.it/c7e66qtivkgg1.png?width=805&format=png&auto=webp&s=d11ac6cfa128159ffedf9c0f0385fc263a65bf21,Neutral
AMD,I grabbed the 7800x3d bundle today. Got them to swap the motherboard out for an open-box aorus b850 board too. $200 for the RAM kit (in today's market) feels like a steal lol.,Neutral
AMD,"What I'd love to know is if the 9850X3D has had some changes made to it to make it less likely to self-destruct, or if it really is just a higher-binned 9800X3D.",Neutral
AMD,I picked up the 7800X3D combo for $599 and just hit my 30 days today. Feels like this might have been with the upgrade for better CPU and mobo for only $100 more.,Positive
AMD,Can we just get a 9800 price drop vs paying more for the overvolted version lol,Neutral
AMD,Iâ€™d rather have healthcare I think,Neutral
AMD,https://preview.redd.it/mxyjgmkj8kgg1.png?width=398&format=png&auto=webp&s=92b3c0daae3a4e7dd4886c116342d67bc78313ff  the cpu ram and the mobo was the bundle.,Neutral
AMD,The vast majority of Americans don't live near a Microcenter so it's not something most people can take advantage of.  This is more a case of you being lucky that you get to travel.  Most Americans don't get any paid days off or vacation days.,Neutral
AMD,They were ok swapping out mobo? What microcenter did you go to?,Neutral
AMD,American here. I have a 9800x3d and healthcare.,Neutral
AMD,good for you.,Positive
AMD,"It's not about having micro center near your place, it's more of the abundance of goods you get access too.",Neutral
AMD,"One of the ones here in Atlanta. And it seemed like the sales guy and manager were cool with it, but the checkout guys oddly seemed to act like it was a hassle.",Neutral
AMD,I also have a 9800x3d And my healthcare is great.,Positive
AMD,youre such a goober bro lmao,Negative
AMD,Anyone paying attention to tarrifs or COVID knows that simply isn't true anymore.,Negative
AMD,Wish I can swap it for a itx or even a matx board. Hate that they took away that option. I just want a smaller case for my travels,Negative
AMD,"Careful, youâ€™re gonna upset 5 redditors",Negative
AMD,"Really? I always feel like if I want something I can get it at a good price and easily accessible. You must live in California or something, I know they jack the prices up on everything out west.",Neutral
AMD,First of all almost the whole world uses a different currency when it comes to trading and guess what it's American dollars.  A gpu that's 1000 bucks isn't 1000bucks in the other parts of the world. More like 1200-1300.,Neutral
AMD,"tariffs are not state dependent.  I paid over $1,000 in tariffs last year alone.",Neutral
AMD,"What does this comment have to do with accessibility to goods?  You are off on a tangent about paying more that Microcenter when not even most Americans get those prices.  FYI a $1,000 GPU ain't $1,000 in the US anymore anyways thanks to tariffs and shortages.    You certainly have a privileged picture of the US being able to come here on a vacation that most Americans don't get to take advantage of the low prices and then just assume all Americans can do the same.  Must be nice.",Negative
AMD,Last year that makes sense.. I don't feel I'm feeling the tariffs near as bad if at all this year comparitevly.,Neutral
AMD,I have a privileged picture of the United States because I've been fortunate enough to travel to more countries than there are States in the USA.   It's not about the prices even but the abundance of choices you have even.,Positive
AMD,Most people don't because they aren't direct importers.  The effects will ripple down the chain and increases prices for customers.,Negative
AMD,"Point out to me the abundance of choice Americans have and I'll demonstrate to you how that's either not true, an illusion, or prohibitively expensive.  Let's start with price.  Upfront price in the US doesn't include tax and the actual effective tax rate in the United States (the percentage of total income paid in taxes) is comparable or higher than many EU countries (without the benefit of strong social services).  That's before adding in the whole tariff nonsense, which is a regressive tax on the middle and lower classes.  You complain about prices in places outside the US but everyone living in the states is geting nipped elsewhere in the pocketbook in order to have those lower prices (and the US doesn't even have lower prices than the EU anymore after tariffs so it's a double whammy).",Negative
AMD,That's what I'm saying. I am that customer and compared to last year that is not trickling down to me. I agree last year it did but in comparison I don't feel any of it right now so I'm not sure your original point about covid and tariffs applies right now.,Negative
AMD,again the issue is not the money. its the abundance of goods you have access to the united states. not everyone has money i know that. its the same everywhere else.  but nobody on this planet has the same access to goods like Americans. since this is the pc subreddit. how many FE cards are available in the united states and the rest of the world? just compare? or how many FE cards make it to the American market and let say any eastern European nation?   id advise you to visit any part of the world and than compare the states.,Neutral
AMD,"Avoid 8gb gpus, specially if you wanna play AAA games.   From the rest? 9060xt 16gb or 5060ti 16gb is best option, Acess to DLSS4.5 on nvidia and FSR4 on 9060xt. The rest? Rx6800 is best by far and its capable 1440p and perfect 1080p card no worries",Positive
AMD,Budget? Arc b580. Mid tier? 9060xt 16Gb or 5060ti 16Gb high end? 9070xt or 5070ti,Neutral
AMD,For 350 I think 4060 ti 16gb or 6800xt,Neutral
AMD,ryzen 4070,Neutral
AMD,"If they are considering the 5060ti 16gb, they rather aswell go for a 5070, as previously they have been the same price of 400  9060xt 16gb has increased from 300 to 350 for me  Other option would be the b580",Neutral
AMD,"Forgot on intel completly, thansk for adding it up.   Depends, in my case 5060ti 16gb still runs arounD 500â‚¬ while 5070 below 650â‚¬ mark is too hard to get.",Neutral
AMD,How did they get my cell phone specs? ðŸ˜†,Neutral
AMD,anything is a gaming pc if you like doom.,Positive
AMD,Was,Positive
AMD,Komputer,Neutral
AMD,Device name says it all !,Neutral
AMD,JESUS! Only 4GB of RAM?! I couldn't run Windows on that! Gaming? On what? Solitaire?,Negative
AMD,"The GPU carries everything, used to have a gtx 970 2y ago, played cyberpunk 2077 on it everyday, not the best but werks fine, the ram ain't that bad ngl, with today prices the ones that budgeted for 16 are turning back to 8 and well... The ones on 8 turn to 4",Positive
AMD,"Ah see it's a gaming motherboard, so it must be a gaming computer.  https://preview.redd.it/4jxxi50vuygg1.png?width=800&format=png&auto=webp&s=a69896641054ada020a20855c11e5ee53f9f7808",Positive
AMD,Toaster specs,Neutral
AMD,Microsoft pinball works Fine,Positive
AMD,Yeah for Tetris.,Positive
AMD,"![gif](giphy|07OBA9P4yDaV3OgOB7)  Parents be like, ""I saw him in your street fighting game once so it must be true.""",Neutral
AMD,I'm sure he knows what he got.,Neutral
AMD,"Yah fr, my 5 year old Galaxy S21 has more RAM",Positive
AMD,Source port and old console emulator rig.,Neutral
AMD,People in my country say kompjuuter,Neutral
AMD,grammur,Neutral
AMD,"Probably had more. Maybe it was 8GB and one stick died, or it was even more than that and they replaced the memory with a single stick that was cheap so the PC would power on for resale.",Neutral
AMD,"Yah fr, even the cheap Celeron Laptops are starting to go towards 8GB",Neutral
AMD,"Exactly, like putting a GTI badge on your 1.6TDI Golf, it automatically doubles your horsepower or framerate",Neutral
AMD,"Yeah mabye at low settings, 4GB of ram ain't much",Neutral
AMD,And the seller was probably too dumb to realize,Negative
AMD,"I've owned red cars, and this checks out.",Neutral
AMD,That 5060 Ti is solid for 1080p and light 1440p gaming if you don't crank ray tracing. Got the Ventus last month and it runs quiet with good temps in my mid build. Skip if you want futureproofing though,Positive
AMD,"You probably already considered this, but if you can get the 9060XT GB for around the same price or for a bit more but within your budget the doubled VRAM is probably a better idea.Maybe by getting a used 5700X? That still may be just outside your budget, though--you'd have to find a MSRP or near-MSRP 9060XT.   It's within spitting distance of the *16GB* 5060TI and in modern games the 8GB 5060TI may struggle due to VRAM limitations.",Neutral
AMD,Call that an absolute win,Positive
AMD,wpuld be funny if they just slapped on the IHS of the 5600 on it lmao. reverse of the reverse scam,Negative
AMD,You got reverse scammed,Negative
AMD,lucky. with my luck it would be i bought a ryzen 5 5600 and got a core 2 duo e6600,Positive
AMD,Don't be too happy yet. Verify with CPU-Z.,Neutral
AMD,"""This is not the Ryzen 7 I ordered! This is a trashy Ryzen 5!!!""  Nice bro, that's absolutely insane. Bet the seller didn't remember what CPU they had.",Negative
AMD,https://i.redd.it/3dgys2ofuzgg1.gif,Neutral
AMD,Lucky bastard you are,Negative
AMD,Meanwhile the other guy is wondering why his newly upgraded PC doesn't perform any better than before.,Negative
AMD,imagine whoever sold this forgot to upgrade their 1700 to what you recieved ðŸ˜…ðŸ˜…,Negative
AMD,Nicely done if it's genuine  https://preview.redd.it/cu5u84a4xzgg1.png?width=2856&format=png&auto=webp&s=46329d900c4e9c255a96e1d062cab0bb79279edb,Positive
AMD,https://preview.redd.it/nr6t4hax70hg1.png?width=1080&format=png&auto=webp&s=6e954ad7824865a88dc7079005bf6ebdd26fbee6,Neutral
AMD,Hopefully you donâ€™t need to update the BIOS on that board to use it!,Neutral
AMD,"Thats a great cpu there, what a deal! I got my 5600X on sale for like $95 3 or 4 years ago and it still kicks ass",Positive
AMD,my steak too juicy,Positive
AMD,![gif](giphy|w2ldbBLfoB37AcqVem|downsized),Neutral
AMD,Oh no how awful hope it happens to you again with a gpu,Negative
AMD,Now that R5 is a beast!! Congrats! Iâ€™m pushing a 4080 no problem with one like that,Positive
AMD,"And I thought I was getting a somewhat decent deal when I paid AUD$20 for what the ad said was a 1600X and it turned out to be a 1600AF, heh.",Negative
AMD,hah! lucky you!,Positive
AMD,https://preview.redd.it/jffabnqpw0hg1.jpeg?width=474&format=pjpg&auto=webp&s=18ed509fff0dd8cd51ff3704d412a6650e5eae0e,Neutral
AMD,a reverse scam?,Negative
AMD,https://preview.redd.it/mwfww6hza2hg1.jpeg?width=234&format=pjpg&auto=webp&s=471e93b0e1c88272d5c87a5ac57c3a02b72260b4,Neutral
AMD,"someone, somewhere is mad about a 5600 they bought being a 1700x",Negative
AMD,R7 is always better than R5 right?  Edit: /s for the r/woosh,Positive
AMD,"If you bought from an individual seller, you should 100% contact the seller and let them know and ask what they want to be done about it offering to send it back if they cover s/h. If it was a company, ehhh I'd just keep it.",Neutral
AMD,WW bro,Neutral
AMD,Win brooo,Positive
AMD,I have my 5600 trimmed down to the limits of its silicon. Barely mosquito bites the aio cooler I have on it while giving me better than 5600x performance. Very efficient chip. Grats,Positive
AMD,5600 still a good CPU and for $10 dam,Positive
AMD,Stonks,Neutral
AMD,GG,Neutral
AMD,Absolute steal if it works,Positive
AMD,Those scammers can't keep getting away with it! Good for you tho ;),Negative
AMD,"Quick, go and buy a lottery ticket!",Neutral
AMD,"Either way it would be a crazy deal, getting a 1700x for $10 AUD is pretty nuts",Neutral
AMD,"Even the seller faked the information of the cpu, but itâ€™s a steal. itâ€™s cheap and you should keep it",Negative
AMD,Sucks to be the person who was waiting for the 5600 ðŸ˜‰,Negative
AMD,"Nice, can't go wrong with that",Positive
AMD,I'm using it. amazing processor,Positive
AMD,![gif](giphy|cLYAs7gtaEunQqRt1G|downsized),Neutral
AMD,I never get this lucky,Positive
AMD,I call that a win in my book,Positive
AMD,"Iâ€™ve a question : why did you buy a R7 1700x ? Itâ€™s an old design and not that powerful with todayâ€™s standard, is it sufficient for newer games ?",Negative
AMD,Itâ€™s good and decent CPU.,Positive
AMD,Thatâ€™s a huge win!,Positive
AMD,"Some people are so lucky, it's usually the other way around ðŸ™ƒ",Positive
AMD,u got it for free,Neutral
AMD,you got a ryzen 5 when you bought ryzen 7,Neutral
AMD,Perfect,Positive
AMD,major upgrade for cheap! thats like finding gold under all that paste lol,Positive
AMD,If it will work.,Neutral
AMD,"I've had that happen before, ordered a bunch of 256gb SSD for tricking out older gaming consoles on amazon. Got sent a bunch of 1tb ones with a 256gb sticker, I presume there is 256gb ones out there somewhere with a 1tb sticker on them",Neutral
AMD,ðŸ¤£ðŸ¤£ðŸ¤£,Neutral
AMD,Would be even funnier if it turns out to be a ryzen 9950X3D when plugged in,Neutral
AMD,Rare to see that nowadays,Neutral
AMD,"The number's bigger, it's clearly better.",Positive
AMD,"m8 no one is faking a 5600x, if they were they'd at least fake a 5800x3d or something",Negative
AMD,That's an upward downgrade ðŸ˜‚,Negative
AMD,Someone always posts this image lol,Neutral
AMD,https://preview.redd.it/o56t8bjyi6hg1.jpeg?width=1170&format=pjpg&auto=webp&s=f127bfe1dc3162724477a676b195e864439ec5cf,Neutral
AMD,Knew this would be here without fail,Negative
AMD,This said a lot about the Threadripper PRO 9995WX,Neutral
AMD,Also dont use user benchmark simce it is rigged.,Negative
AMD,"Its more of a quite mild tempered mule. Mine has been dutifully trodding along for some 6 years now and doing a fantastic job doing whatever it is doing most of the time. Math, I assume. That thing has outlived a graphics card, motherboard, ram upgrade, SSD failure, the PSU still lives too but thats the heart of my PC of Theseus.",Positive
AMD,"Yeah not to rain on your parade but a 5600 is not pushing your 4080, its quite literally the opposite. Its HARDCORE bottlenecking a 4080 in anything baring 4K.   Source: my 10900K (better than 5600) is already bottlenecking my (worse than yours) 3080 at times. Your combination is even more susceptible to that.",Negative
AMD,Nice enough win.  Better than you thought is a good deal.,Positive
AMD,"A Ryzen 9 3900X will get demolished by a Ryzen 5 7500F. It all comes down to generations.   Edit: In gaming ofc, R9 has more cores so some workloads it can beat",Neutral
AMD,"No, this isn't the exact ... but basically, a r5 9000 would be as good or equal to an r7 8000 and an r9 7000 series. So, no, but I thought that for a bit myself.",Neutral
AMD,It could have been a mistake to ðŸ¤£,Neutral
AMD,"yeah a newer processor for a older one, canâ€™t really see any downsides ngl",Neutral
AMD,"Ordered a Hikvision 1TB from supplier that had them on sale.  Guess they ran out of stock and shipped Samsung EVO instead, 1TB, and faster.  Bought another one to be sure, got Samsung again. ðŸ˜",Neutral
AMD,You would have to buy 256gb drives and receive 256gb drives labelled 1tb for that to have happened to you. You just got regular reverse scammed,Negative
AMD,wouldnt work on an am4 motherboard,Negative
AMD,Ryzen 5950x or 5800X3D would be the top processors this could be swapped with.,Neutral
AMD,"Also E means ""Enhanced""",Neutral
AMD,https://preview.redd.it/stiqsk5wg3hg1.png?width=1272&format=png&auto=webp&s=983d55ca79b5e6ae58a7be603c8f0353a20db0f2,Neutral
AMD,"Not even a 5600X lol, a base 5600.",Neutral
AMD,"There's always someone who feels it. Not all of us have high end rigs. I had a R3 2200g and a 1060 3gb for 5 years. Only got a 3060 and a 5700x3d about 2 years ago. Been here way longer, lol",Neutral
AMD,https://preview.redd.it/qtgfxz7357hg1.jpeg?width=1170&format=pjpg&auto=webp&s=dd93f10d978640c3da5db7d2440c66fdd99893be,Neutral
AMD,It's a multicore benchmark. Check out some of the xeons in there...,Neutral
AMD,This ain't UBM dawg,Negative
AMD,">   6 years  A CPU that has not even been available for 4 years has been ""trodding along for some 6 years now""? You might be confusing CPUs here.",Neutral
AMD,Clearly people missed the /s,Negative
AMD,I know I am being facetious. Someone may have swapped that for the r7 thinking the r7 was better because 7 > 5,Neutral
AMD,"It was a joke obviously, 4 generations newer is better",Neutral
AMD,I had something like that happen ages ago. Ordered a new in box g5 imac for my brother from a school surplus sale. Received a Core Duo iMac instead. They must've run out of G5s! It was a good deal for a G5 but a fantastic deal for a core duo model lol.,Positive
AMD,and it turns out the motherboard is secretly an LGA 1151,Neutral
AMD,uhhh,Neutral
AMD,I have a r3 3200g and a 1060 3gb right now... Coincidence?,Neutral
AMD,Threadrippers are better than xeons buddy,Positive
AMD,i saw before the edit oopsies,Neutral
AMD,I lawld,Neutral
AMD,"Tis a blessing. The universe is aligning a way for you to upgrade. Lol, wouldn't that be wild",Positive
AMD,I know. Saying look at the xeons. They score a funny amount of points.   It told me a 32Â core xeon silverÂ  was better than the latest ryzen 5/i5.   That's when I realized it was not a standard benchmark for gaming performance.,Negative
AMD,All good,Positive
AMD,"Not only that they also rig amd cpus to rank lower, it was confirmed.  Sad it is still used as a benchmark...",Negative
AMD,Good Reddit comments ending (which is rare)ðŸ«‚,Positive
AMD,"user benchmark? hell yeah itâ€™s rigged af. look at the product review of a bunch of amd products, some are funny as hell man",Negative
AMD,"AMD CPU review: Its decent at best and its only hyped by the paid trolls to promote it also it kicked me in the balls and took my wallet.  Intel CPU review: This is Gods gift to the world this is the only CPU nay the only thing you need in life, we are not worthy.",Negative
AMD,"Fucking nice. I have the 9060 XT reaper and love it, was considering the 9070 XT but due to ITX, cost, and a few other things I went with the 9060 XT.  May it severe you well!",Positive
AMD,My stock 5080 hits 8800+,Positive
AMD,"Honestly I'm looking at switching to an itx build at some point (mobo and PSU) are holding me back. Oh and price aha. I did have a Lian Li A3 which is the smallest I've run which was great. I'm just having a REALLY hadd time wanting to give up my Thermaltake Tower 300 though.   As for the Reaper, even in 4K. I've rarely had to sacrifice in any game since I'm not aiming for obscene frame rates.",Neutral
AMD,A 5080 and a 2x8pin 9070XT are entirely two different levels of performance so yeah...nice,Positive
AMD,"Same here but 5080 is a different tier of product despite what people will try and say on reddit, so not really a fair comparison.  On average in raster 5080 is 15-20% faster, so a sizeable gap in benchmarks isn't surprising.",Negative
AMD,And someone else's stock 5090 hits 14k+. What's your point?,Negative
AMD,"Cost is definitely a big factor - I made the switch within the last few weeks and honestly I have wondered repeatedly why I didnâ€™t do it sooner.  Iâ€™m about to move to a much smaller apartment, so weâ€™re trying to get a lot more space efficient, ultimately meaning  no M-ATX tower for me.  Iâ€™m currently using a Densium 4+ which is 5.5L, and can fit up to a 220mm GPU (which why ultimately I couldnâ€™t get the 9070 XT Reaper, as itâ€™s 3 fan opposed to the 9060 XT Reaper 2 fan.   I posted a review (if you look at my profile) with some of the pros / cons, since the review I changed GPU (my 6600 XT pictured in the review died lol) but the core of it still applies.  Itâ€™s not for everyone but Iâ€™ve never really had a â€œbigâ€ GPU before, usually the things I buy or one or two fans, so Iâ€™m still puzzled as to why I didnâ€™t do it sooner!",Neutral
AMD,"To be fair... 2x8 or 3x8 (independent cable of course) also doesn't really matter. 9070xt, with out modding, doesn't exceed what 2x8pcie can provide. Hell it barely surpasses 1 cable.",Neutral
AMD,You're also on a 5700x3d,Neutral
AMD,Idk everyone Iâ€™ve heard says the 5080 isnâ€™t worth it and the 9070XT is better.,Negative
AMD,Exactly my point.,Neutral
AMD,Nice! I think I'm sold on a Corsair 2000D if I can make the switch. I've always loved the style and dimensions overall since space isn't really a factor overall when it comes to my desk but I was actually shocked at how the Repair sized up overall. It ended up being the same size as my 2 fan Sapphire Pulse 7700XT somehow.   I would like a smaller overall build but I'm reluctant on the itx tax lol.,Positive
AMD,"Again it's reddit which tends to be an AMD echo chamber. Comparing the cards at current prices doesn't even make sense, can't find either for anywhere near MSRP atm.   But back when it was $600 vs $1000 I agreed with most people that 9070 XT was the better buy at $600. But for me $400 more gets better performance across the board in raster and especially RT/PT, along with the entire Nvidia feature stack, so it was worth it. Really just comes down to how much people value features like RT, DLSS, and frame gen.",Negative
AMD,And they're right. They'd be wrong if they said the 9070xt was faster. But nobody's saying that,Neutral
AMD,"its now 700-750 vs 1200-1300 here in germany, so its not just another performance tier but another 2 price tiers first and foremost",Neutral
AMD,Like I said it doesn't make sense to compare prices anymore with how messed up the market is. $600 vs $1000 was the pricing up until a couple months ago.,Negative
AMD,I don't think it's supposed to do that,Neutral
AMD,with a 'puter that fast you'd think can take a proper screenshot,Neutral
AMD,That was actually very funny,Positive
AMD,Gg cya next universe,Neutral
AMD,"Nah, happens to the best of us",Neutral
AMD,latest win11 update bricked that function,Neutral
AMD,Not winnkey plus shift and s,Negative
AMD,Bet Agnes is running cooler than my ex's attitude during an argument!,Neutral
AMD,ðŸ«£,Neutral
AMD,Fortnite competition temps are remarkably cool. Averaging about 70. Even during heavy end games she seldom tops 80.,Positive
AMD,"This post has been flaired as a rumor.   Rumors may end up being true, completely false or somewhere in the middle.  Please take all rumors and any information not from AMD or their partners with a grain of salt and degree of skepticism.",Negative
AMD,"Really stretching here. 9950X3Dv2 != 9950X3D2; 9950X3D version 2 can be anything, like improved frequency and cache CCDs, not unlike 9850X3D. It can still be a hybrid chip. Creating one 9950X3D2 will cost two 9850X3Ds in practice because really good CCDs don't just magically appear. There's a limited supply of very good bins.  Even if 9950X3D2 (the dual V-Cache one) exists, it's not for gamers. It'd be for parallel workloads that require cache and execution consistency. That'd be better under a Pro variant that offers enterprise security features for workstations or even under EPYC 4000-series that can combine higher frequencies and cache use in database operations that are hitting system RAM a bit harder than usual.  Gamers can't have everything.",Neutral
AMD,"It says ""v2"". Pretty sure that's revision 2 of the folder under it. Maybe they screwed up v1 or v2 shows better numbers than v1.",Negative
AMD,How is this a rumor when thereâ€™s a video of it. wtf?,Negative
AMD,If i worked at one of these places i would name folders like this  just to cause confusion,Negative
AMD,multiplier 65x... damn,Negative
AMD,I also have a folder on my desktop. I just created it. It is called: AMD Ryzen 9 9990X3D with a whopping 4 cache CCD's. Absolute monster of a CPU. Created custom silicon and took 4 9800X3D CCD's and put them on 1. Benchmarks are off the charts.,Positive
AMD,That's cool.   What about 6Ghz 9990X3D?,Positive
AMD,Iâ€™m more interested in what happened to R5 9600X3D to be honest.,Neutral
AMD,Link to video please,Neutral
AMD,"why would u want that... it is a two chiplet design, and for gaming it would have issues like all the other dual ccd cpus where u loose perf when a core access a level 3 cache on the other ccd.",Negative
AMD,Ehh AMD. I use it but I also am team blue,Neutral
AMD,It's the v2 version which doesn't catch fire on the asus and asrock boards.,Neutral
AMD,"There were rumors about 32GB VRAM 9070 XT, they denied it, 6 months later we got the AI PRO 9700.   I think there has been too many independent rumors about the 9950X3D2 as dual V-Cache. Whether it will end up as a real, purchasable product or not, might be a different story. But at this point, I'm fully convinced the dual V-Cache CPU exists.",Neutral
AMD,Yeah and why would they call it 9950x3d2? Thatâ€™s such a clumsy name compared to e.g. 9990x3d,Negative
AMD,Or the Ryzen 9 Pro 9965X3D,Neutral
AMD,"We don't even know what is in that folder. Maybe it is a draft for a presentation they have to give on the 9950X3D, and that folder is the second draft of the presentation.",Neutral
AMD,"We do not know that the folder refers to model number. Note that they have 9950X3D and 9950X3Dv2 folders right next to each other. These could simply be v1 and v2 of something to do with that existing chip. We also don't know if the 9950X3D2 or whatever it gets called (please be XT3D) will be released. It could be, but AMD could also opt not to, finding it unprofitable or just unnecessary.",Neutral
AMD,Because you can name a folder anything. I create content for Enterprise IT customers and partners and regularly slip in little easter eggs. None of them are based on anything real.,Neutral
AMD,video of what? a fucking folder?,Negative
AMD,You mean the second time they ran the test?,Neutral
AMD,Frequency go brrr,Neutral
AMD,"They will release 9999X3D with 6.9 GHz, instead.",Neutral
AMD,9950x6d,Neutral
AMD,"But the title is literally a folder name on desktop, yeah It can be fake, but it's no way rumor, the folder with that name is there",Negative
AMD,I'll allow it.,Neutral
AMD,"Its missing ""MAX AI"" or some other bullshit marketing suffix",Negative
AMD,Yes but the implication of a leak IS a rumour,Neutral
AMD,"Your comment has been removed, likely because it contains trollish, political, rude or uncivil language, such as insults, racist or other derogatory remarks.  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",Negative
AMD,how can it be a better binned 9800x3d when the layers are above or under which made them run cooler?,Neutral
AMD,So I need help here is the 9850x3d safer to use than 9800x3d ?  By that I mean it won't get fucked as easily! Because I seen a lot of people talking about the 9800x3d getting burned or not working and so on  So is it better quality?,Negative
AMD,The 9800X3D is exactly the same. This is not new for the 9850X3D.,Neutral
AMD,"Doubtful but who knows at this point, itâ€™s just a better binned 9800x3d so in theory it should still have the same issues unless AMD tweaked something from the original",Negative
AMD,I think it would be better. Later batches of CPUs should be more reliable.,Positive
AMD,Where do you hear about 9800x3ds getting burned?  Those are only with ASROCK motherboards killing them.,Negative
AMD,I see because in my country it's 50$ more expensive than 9800x3d  So it makes 0 sense to get the new one if it's just a overclocked version lol,Negative
AMD,"its not just asrock, there are reports from msi, asus, gigabyte. asus put out a statement not too long ago. seems to be something wrong with the 800 series motherboards",Negative
AMD,"Oh I didn't know about that, why not use the b650/ x670s then?",Neutral
AMD,"yeah those are the safer bets right now. 800 series is better if you need USB4, otherwise they're effectively similar",Neutral
AMD,"Have any of the reviewers addressed if the IMC is better with heavier overclocks? Most of them seem to have gone the other way to test the claim that the 3d cache makes binned memory less important.  I just wanna know if this one is better at heavy memory OC, because memory OC is fun!",Neutral
AMD,its just a KS from AMD instead of intel.,Neutral
AMD,tldr: itâ€™s not worth the premium.  edit: I am a hypocrite I just bought it for my new system.,Negative
AMD,"The best reviews are those from Hardware Canucks and Der8auer, slamming the CPU for being power inefficient and running hot for just a bunch of additional frames... on a 5090.",Positive
AMD,cool so basically â€œdonâ€™t botherâ€,Neutral
AMD,"Manufacturer makes a newer model clearly based on last years model. Calls it the same, but with a 50 in the end instead, which is widely understood as â€žrefresh at bestâ€œ in the field. People are livid because it is just marginally better than last years model.  but_why.gif  If anything, the 9950x (and the other 16C parts) are the odd man out here, they shouldâ€™ve been called 3999 and so on imho.   Donâ€™t get me wrong, Iâ€™d very much rather see a new 10000 series roll out right now, which would suck in many games like 9000 did before the x3D variants released.   I am just saying they did not, in fact, call this here chip 10800x3D.",Negative
AMD,Was it released in UD today ? I canâ€™t find any listings .,Neutral
AMD,"Nice up-bin, but it is still the same chip, so a bit of a nothingburger. If you were still planning on upgrading (with today's RAM and SSD prices, lul) and targeting 9800X3D, this is a fair improvement to buy instead if you not tight on money, but otherwise this does not matter in the slightest.  The actual upgrades are about an year away. Non-X3Ds maybe bit earlier, but Zen 6 X3Ds, actual improvements over what already exists, maybe an year from now. And Intel may have something useful again by then as well.",Neutral
AMD,Asking the real questions here. Also curious if these chips are more consistent in their memory OC across multiple chips. It seems hit or miss with the IMC on regular 9800X3Dâ€™s,Neutral
AMD,I wouldn't really expect that kind of content for day one reviews. That's more of a few-weeks-after-launch type of content. It also has the propensity to be silicon-lottery dependent so you can't really go by a single sample anyway.,Negative
AMD,"you are so brave, with how expensive ram right now, i don't think i want to take that risk",Negative
AMD,Exactly my question itâ€™s the weakest part of my 9800x3d by far and Iâ€™m just hoping they made it better for the 9950x3d2 Iâ€™m eventually going to waste my money on lol,Negative
AMD,"At least it's at a reasonable price point, instead of the way overpriced KS strategy of Intel.",Neutral
AMD,it is if you plug your 5090 to a calculator screen,Neutral
AMD,Intel says hi,Positive
AMD,Eh okay. I'll keep my 7800X3D then.,Neutral
AMD,Itâ€™s not a bunch though compared to the 9800,Neutral
AMD,Techpowerup also noted the increased power consumption and temperatures. The small gain in performance is not free lol,Neutral
AMD,â¤ï¸,Neutral
AMD,"> refresh at best  I don't mind refreshes to be honest, as long as the price is roughly the same.",Neutral
AMD,Tomorrow.,Neutral
AMD,Would it be worth $20 more assuming you're upgrading anyways?,Neutral
AMD,Why would you be looking at a refresh part for gaming at 4k??  Makes zero sense you don't need to upgrade your cpu until Zen 6 X3D is out.,Negative
AMD,"I can tell you that the 9950x3d appears to have a slightly better IMC, and I've seen others say the same. If the 9850x3d is similar then it serves a niche which ironically is the opposite of the marketing push for ""it's okay to use cheaper RAM.""",Neutral
AMD,"Yeah, maybe we could get der8auer to do some follow-up content like that.",Neutral
AMD,RAM is hard to break. Like really hard.  The system will crash 99.99% of the time before you get even close to doing damage.,Negative
AMD,"I typically pick a conservative voltage which allows me to get a decent OC, but isn't breaking any world records. I don't think I've ever killed RAM that way.",Negative
AMD,Wait for Zen 6 X3D 12 core that will be a better use of your money fight the FOMO.,Positive
AMD,"Yeah, then again the 9800X3D isn't sold at its MSRP right now, so more AMD trying to 'reset' the price a bit for each sold.",Neutral
AMD,"your 1000$ oled calculator screen that runs at 720hz. lol.  But yeah, it's a waste of money for a cpu that won't even be the fastest for a year when zen 6 comes out.",Negative
AMD,Prescott anyone?,Neutral
AMD,"to which 9800? 9800X3D PBO + 200 ? 9800X3D eco mode ? 9800X3D 720p ? 9800X3D 1440p ? 9800X3D 5070 Ti ? 5090 ? Medium settings? Ultra settings? 4% average in best case scenario 5090 and medium settings at 1080p, 4 or 5 frames on top of 100, 105 vs 100, a bunch (never a lot).  look at this: [https://i.imgur.com/SD3LxBc.png](https://i.imgur.com/SD3LxBc.png)  That is a 5090 running at 1440p, 2 fps difference between the 9850X3D and 9800X3D, the very moment you swap that 5090 for a 5080 or a 5070 Ti level GPU (far more realistic scenario) the difference between both CPUs will become null and void, except for the power draw difference, which is nasty in the case of the 9850X3D, 108 watts vs 75 watts just for two extra frames no one is going to notice, shame.  There's also a +10c delta hurting the 9850X3D compared to the much cooler and power efficient 9800X3D. It would be silly to buy the new part if you're going to play on something else than a 5090 or at 1440p ultra. Use those 20 bucks to buy a game on Steam.",Neutral
AMD,"Many who buy 9800X3D or 9850X3D are just going for the fastest gaming CPU. At that point the price does not matter.  If you are price sensitive, 9800X3D is better value, since the difference is tiny.",Neutral
AMD,"You should probably mention that its hard to kill ram with clocks, or timings. But voltage, ya its easy to fry with too much voltage.",Negative
AMD,"tell that to my B450 Carbon that overvolted my RAM by 0.07v after a BIOS update - 1.54v, all 4 sticks instantly dead - thankfully Patriot honored my limited lifetime warranty with no receipt or packaging",Negative
AMD,"I think they're just milking all those enthusiasts suffering from FOMO, and they're a lot. They will buy this overclocked 9800X3D, then they will get the 9950X3D-2 but at the same time they will be keeping an eye on Zen 6 pre-orders.",Neutral
AMD,"I'll look at the reviews eventually, but I'm wondering if there's an analysis available 1:1 with 9800X3D - if there's any efficiency gains at the same clockspeeds and voltages (etc.).  Cause it looks like they just pushed the envelope a bit with better silicon in terms of stability but they haven't gained any efficiency.",Neutral
AMD,">the very moment you swap that 5090 for a 5080 or a 5070 Ti level GPU (far more realistic scenario) the difference between both CPUs will become null and void  This is CPU review, not GPU.",Neutral
AMD,"Wow, doing a CPU test in a GPU limited scenario...what a revelation that the CPU doesn't really matter.  The entire goal of a cpu test should be to differentiate the cpu. That means min settings at 720p (thank god for that new oled) or 1080p resolutions in esport games with uncapped fps.   We know what the result will be like in GPU limited scenarios already. It's a waste of a test.",Negative
AMD,Even that. It's not impossible - really depends on the dies used and quality - but *most* RAM will just keep on trucking while crashing the system.,Negative
AMD,How does that kill RAM? I've run 1.55 volts to my DDR4 for 5-7 years. Others daily at 1.65v.  I would understand if it was 1.8-2.2 volts.,Negative
AMD,bro personally attacked me,Negative
AMD,"It's not better silicon, at least not premium silicon, if it was then they wouldn't have needed to bump the stock core voltage to 1.3v, they might have done some basic binning but at the end of the day it's the same 14 month old CPU but factory overclocked, you can manually overclock your 9800X3D, it's unlocked.",Negative
AMD,"Yeah if you want to actually check the performance increase of an overclocked 9800X3D you should run a 720p test or lower, but the thing is the vast majority of 9850X3D buyers are running their games at 1440p or higher on a 4080/90 5070 Ti/80/90 or AMD 7900 XTX / 9070 XT.",Neutral
AMD,You also had active cooling on that ram.,Neutral
AMD,"those are DDR3 voltages, nobody other than people with watercooling daily 1.5+v",Neutral
AMD,"sorry, I also replied to this other comment you just made, if you're happy with it then just keep it, even if doesn't make any sense for anything 5080 and below.",Neutral
AMD,"> if it was then they wouldn't have needed to bump the stock core voltage to 1.3v  The spec VID range for all zen 5 CPU's, vcache or not, goes up to 1.42 VID. There is no voltage range change on the 9850x3d.",Neutral
AMD,"I mean I agree - I have no idea if my 9800X3D can handle the higher speeds as I'm content with it stock (still under the cheapest TR dual-tower I could find at MicroCenter, haven't gotten my custom loop built yet).  I think it's more just that these CPUs can reliably handle the speeds, whereas not all 9800X3D CPUs could.  Also still wondering about the memory controller, but I understand that that's an insensitive thing to ask about these days lol",Negative
AMD,"And the result will be obvious: almost zero difference in performance.  If you have a speed limit of 60 mph on the highway, don't be surprised when the ferrari drives at the same speed as a toyota.",Negative
AMD,"Mm. I started out with 1.5v. Ran that for a short while. Then 1.55v and a 120mm fan, hanging from the case with zipties. If voltage would have killed RAM instantly, it would have killed it with or without fan/cooling.",Neutral
AMD,"BS. Very few watercool their RAM. All you need is ANY kind of fan blowing on the RAM when going past 1.5v. And that is not to keep them alive, it is to keep them stable. RAM will spit out bit-errors way before they die. Normal DDR4 is rated for 85 C. Generally, it is best to keep them under 50-55 C if you overclock them.    DDR3 default is 1.65v, yes. What do people that OC ram on DDR5 run? Is it 1.4-1.5v? And default is 1.1-1.2v. Of course, XMP profiles for even DDR5 often runs at 1.4v. Have you heard of millions of RAM sticks dying?",Neutral
AMD,While running medium/ light loads (gaming) the core voltage now jumps to 1.3v+ while the 9800X3D stays around 1.1v,Neutral
AMD,"The memory controller is also the same, they're not developing a new IMC or upgrading the current one just for a factory overclocked 9800X3D, they're doing that for Zen 6. We've had 9850X3D users here stating that their CPU can't handle certain RAM configurations that they could achieve with a 9800X3D. It's just a silicon lottery. You might swap your 9800X3D for this factory overclocked CPU and get a worse IMC compared to what you had.  If the memory controller was any better AMD would have marketed the fact non-stop while charging extra money for it.",Negative
AMD,"DDR5 is irrelevant here, I'm talking about DDR4 voltages - and honestly I'm barely acquainted with DDR5 OC. DDR4 EXPO/XMP generally doesn't go over 1.4v and I don't know where you get the idea that many people daily 1.55-1.65v.",Negative
AMD,"Especially DDR 5 and crazy so dual rank DDR 5 is next level sensitive to temperature for single errors (classic 10k Karhu single errors)  So you're dead on, at least on AM5, no one in their right mind would daily sticks voltage high enough to kill them.",Negative
AMD,"The CPU's won't use more VID than they need to hit the maximum frequency that is on their boost table, even if it's safe and available.  For the 9800x3d out of the box, that means that whatever voltage that it takes to hit ~5225mhz is the maximum that you'll see. You may have had a 9800x3d which would be happy at 5500mhz with normal gaming voltage, but since 5225 was an arbitrary limit, the CPU would sit at 5225. It will then use the voltage that it thinks that it needs for 5225mhz, rather than using the full voltage.  Removing fmax and other limits so that you only hit the voltage/reliability limiters exposes the actual voltage range.  Likewise, applying an fmax limit to another CPU like the 9850x3d or the 9950x3d's vcache CCD brings behavior in line with 9800x3d (just deleting all of the frequency options near the top of the curve).  If you're riding the safety limiter at 1x scalar, then about 1.34 VID on zen5 (x3d or standard) is typical in games.",Neutral
AMD,"Ah, cool. I wasn't sure if they improved over a stepping or whatever else (been known to happen).  Yeah I'm aware that they're redoing it for Zen 6, which will be perfect timing-wise. Zen 5 can't really make use of faster memory outside of niche cases.",Positive
AMD,"[https://pcpartpicker.com/products/memory/#ff=ddr4&b=ddr4&B=1550000000,4250000000](https://pcpartpicker.com/products/memory/#ff=ddr4&b=ddr4&B=1550000000,4250000000)  What does that look like? You can get DDR 4, running 1.55v, straight  from the shop and a wide selection. Have you even looked?  Where do I get the idea? Watching RAM OC content like Buildzoid, being on the Overclocking subreddit, [overclockers.co.uk](http://overclockers.co.uk) etc for the past 10-15 years.  DDR5 at 1.4v, OOTB: [https://pcpartpicker.com/products/memory/#b=ddr5&B=1400000000,4250000000&ff=ddr5](https://pcpartpicker.com/products/memory/#b=ddr5&B=1400000000,4250000000&ff=ddr5)  Another popular voltage for DDR5 is 1.45v. Expo/XMP.",Neutral
AMD,advanced users that tweak and run active cooling on ram sometimes forget the average casual users don't run fans on their ram and what they are doing applies to a very small percentage of people.,Neutral
AMD,I'm doing scalar x1 and never seen anything beyond 1.15v,Neutral
AMD,"I didn't know they made DDR4-4800/5333 sticks, do people actually run these in ""regular"" builds?   Browsing OC-centered sites won't give you a realistic image of the general population, most people don't OC much and run at <1.5v (they're also afraid of the numbers turning red in the BIOS).Â    >Where do I get the idea? Watching RAM OC content like Buildzoid, being on the Overclocking subreddit,Â overclockers.co.ukÂ etc for the past 10-15 years.   Cool, I've been on the internet for a little while too :\^)",Neutral
AMD,"If that is the case, then your CPU is restricted in software to a maximum boost frequency which is well below its capabilities, and it just never botheres to use a medium-high voltage because it's always running at a frequency which is stable with a low voltage. The scalar will allow for ~1.34 VID and there is hundreds of mhz of stable clock gain between 1.15v and 1.34v.  The 9800x3d can buy +200mhz via the PBO controls, but otherwise you need async eclk to fully bypass AMD's frequency lockouts.",Neutral
AMD,"I grabbed one in a Micro Center bundle.  The pricing works that way (though is comparatively the same).  I didnâ€™t need it and know it doesnâ€™t matter, but I needed a bundle anyways and we have 3x AM5 systems in the family, soon to be 4.  Everybody gets a bump.",Neutral
AMD,Opinions on 9850x3d? Even for people who dont own a 9800x3d this refresh chip takes a pretty huge hit in efficiency for its minor performance uplifts.  I was planning on upgrading to this but considering I build in SFF is might just be better to pick the 9800x3d instead (especially with the price drops)  Id say this itteration is mid. Luckily it doesnt cost much more but thats about it,Negative
AMD,"I'm jealous of these bundles with CPU, RAM, and mobo you can get in US here in UK there is nothing like that.",Negative
AMD,.44,Neutral
AMD,"Yeah, IMO the margin doesn't justify the gains, just like most modern TDP-boosted chips. It certainly has its place, though, and I imagine it does better than the 9800X3D when given the 9800X3D's power budget.",Neutral
AMD,waiting for zen 6 still rocking a 7500f,Neutral
AMD,If the 9800X3D didnâ€™t exist Iâ€™d imagine no one would be really talking about the power draw of the 9850X3D for the level of performance delivered.  What will be interesting to see is how well it undervolts. Itâ€™s such a highly binned version of this chip I would not be surprised if it can be made to run cooler than a 9800X3D if set close to 9800X3D performance.,Neutral
AMD,"MSRP vs MSRP it's fine ($20 more). With the 9800X3D at $449 though, that's a much better value. I think with how the prices change, the value of each other will fluctuate. At most I'd pay 10% more for up to 5% performance bump. For comparison a 5090 is 3x to 4x the price of a 5080 at 50% higher performance. A 10% price increase for a halo product is nice, but not essential.   Hidden value king from this though is definitely the 7800X3D. Can sometimes be found even cheaper than a 5800X3D.",Positive
AMD,I wouldn't pay more for it than the 9800x3d,Neutral
AMD,In Canada we have similar bundles but the pricing is insane on all parts right now.  Its a major turn off.,Negative
AMD,"I just built a 9800x3d over the weekend 449 at microcenter. Coming from intel the 9800 power usage is amazing. I could return and get the new 50 but Iâ€™m not worried about it.  If it was already out sure I probably would have gone 9850 but Iâ€™ll take my power draw win and enjoy it for a long time. Iâ€™m so used to seeing high temps and fighting throttles, this cpu is awesome.",Positive
AMD,Amazing dedication. Im not so patient apparently even though I have a 7700x haha,Positive
AMD,"Hmmm. True, I'll wait and see if there anything that comes out with more testing. But frankly stock for stock, Id pick the cheaper one right now. After a point, a better cpu doesnt net huge gains, speaking for myself at the very least",Neutral
AMD,"don't do it unless you're playing on a 5090 at 1080 high settings, wasted power efficiency and thermals for barely any gains at 1440 high/ultra.",Negative
AMD,Nah I donâ€™t plan to. Iâ€™m on 3440x1440 with 7900xtx and quite happy. Looking forward to running the 9800x3d for at least 4 years.,Positive
AMD,Should I return my 9850X3D and get the 9800X3D? It was a tiny price difference.,Neutral
AMD,Linus said the trade off isn't that bad at all,Neutral
AMD,"Yep, and if you didn't get a lemon then you can always manually overclock it if you wanna have a 9850X3D for free, I've sometimes set my 9800X3D to 5700 MHz at 1.25v and it's rock solid stable with the same power draw and thermals than the factory overclocked 9850X3D, but I'm playing on a 4080 at 1440p ultra settings so the difference was laughable, I reverted back to PBO+100 and scalar x1, incredibly power efficient with per-core curve optimizer and gaming at 41-47c.",Positive
AMD,"if you don't care about the increased power draw and thermals then no, it's not the end of the world and will just hurt it in the summer time if your cooler is mediocre, but I wonder why you decided to go with that CPU to pair with a 6950XT.",Negative
AMD,Looks like you bought it lol,Neutral
AMD,"This is a good read: [https://www.tomshardware.com/pc-components/cpus/amd-ryzen-7-9850x3d-review/5](https://www.tomshardware.com/pc-components/cpus/amd-ryzen-7-9850x3d-review/5)  ""The Ryzen 7 9850X3D was never set up for success. From the moment it was announced and AMD revealed its internal benchmarks, it was clear that we were dealing with a CPU that offered marginal, single-digit performance increases over the Ryzen 7 9800X3D. Even when being charitable to the Ryzen 7 9850X3D, it fails to meet muster.  Itâ€™s a worse value than the Ryzen 7 9800X3D, consumes more power, and just barely claims a new top slot in our gaming rankings. The extra juice isnâ€™t worth the squeeze here. Thatâ€™s even more true when you factor in PBO, which itself can bring up the clock speed of the Ryzen 7 9800X3D by 200MHz and likely close the performance gap"" /Quote",Positive
AMD,Well that depends if your cooling is overkill enough to not matter. Otherwise its 10cÂ° or more in heat,Neutral
AMD,I haven't changed my flair yet. I upgraded my GPU too a couple of days ago to 9070XT. My CPU cooler is the Peerless Assassin.,Neutral
AMD,Hahaha yes I couldn't resist. It's a freaking monster.,Negative
AMD,"you won't see any difference compared to a 9800X3D, but who knows, maybe you will get a 5090 or 6090 at some point, but if you have deep pockets for a 5090 or 6090 then you should have bought / waited for a 9950X3D-2 instead.",Neutral
AMD,The 5090 is on a league of its own. It costs 4000 euros minimum here compared to the 9070XT which cost me 799. I have the money for the 5090 but I really cannot justify it in any way shape or form considering I mostly play CPU bound games.,Negative
AMD,"just enjoy your new CPU, it should be a noticeable difference compared to the 7700X playing those CPU-bound games at 1080p high, or 1440p with DLSS. More playing, less Reddit doom-scrolling.",Positive
AMD,"3% faster than 9800x3D on avg at 1080p medium settings, DDR5 4800 CL40 vs DDR5 6000 CL30 around 1%-2% performance hit on avg",Neutral
AMD,AMD steals the gaming crown from AMD yet again!,Positive
AMD,Thereâ€™s gotta be zero different at 4k lmao,Negative
AMD,Where is my 7800x3d successor after almost 3 years?,Negative
AMD,"it's fine, just fine",Positive
AMD,Maube it scales better with tuning? Like UV etc?,Neutral
AMD,I'm more curious for when the dual v-cache comes out how much better will it perform compared to it's normal counter part,Positive
AMD,"It runs 10-20w more and it also runs 5-10 degrees hotter than the 9800X3D for 3% gains?? It even? Yeah, no thank you. Iâ€™ll stick to 9800X3D until zen 6 comes out",Negative
AMD,"Well, I'm considering upgrading from 7700X so performance difference would be great!",Positive
AMD,I upgraded into AM5 with this processor coming from a 5800x3D. Big difference for me all around but I agree probably not worth it coming from a 9800 or maybe even a 7800 chip,Negative
AMD,"1080p testing has its place, you kinda want to know how it performs when not gpu bottlenecked and you can be more sure of future performance viability in realistic situations.   However showing higher resolutions equally has its place, because real performance is important too and if you're acting in good will towards your audience, you wouldn't want them to run and purchase something that they don't really need.   It's like you'd be testing a car, put it on a dyno and claim it's the only relevant metric, and completely disregard real track testing.     Both are equally important",Neutral
AMD,Way better reviews out there.,Positive
AMD,How come der8auer and other media outlets manage to test this cpu (and show essentially the same outcomes) at meaningful resolutions/settings (example: 1440p ultra with raytracing) while amdunboxed show these idiotic 1080p medium settings scenarios? Completely unnecessary.,Negative
AMD,Soo pointless,Negative
AMD,"It's 6% faster in counterstrike, and 7% faster in battelfield 6  Using averages includes cherry picking semi gpu bound games. Averages are a damn lie.",Negative
AMD,Is the performance hit also 2-3% on the 9800x3d and 7800x3d?,Neutral
AMD,I mean I upgraded from a 10 year old cpu to 9800x3d and there's practically zero difference at 4k even then so.... yea,Neutral
AMD,Just check benchmarks with the 9800x3D and +3-5% lol,Neutral
AMD,It runs hotter and uses 20% more energy for maybe a 5% gain in fps if even,Neutral
AMD,"Their reaction is meant to be like ""what's the purpose of this release really? Only 3% improvement at 1080p, why does this even exist when the 9800x3d already exist.""",Negative
AMD,You must be a very fragile person if a tech review hurt your feelings...,Negative
AMD,"By that line of reasoning every GPU test should also be done with a 7500F and slow RAM, but somehow I never see people argue for real world scenarios there. These real world scenarios people want are at best separate videos, which they have done a few times at least. It doesn't belong into a component test. It's a waste of time and effort to show you a bar graph where every bar is the same length.  It's also very easy to get the numbers you want from a GPU review of the GPU you have. These are your real world results for 4K. It's the GPU limit 99% of the time.",Negative
AMD,I like 1080p testing because it reflects the internal res i play at (960p from 1440P+DLSSQ),Positive
AMD,The fact that people still do not understand cpu testing in 2026 is wild to me. You use 1080p resolution because it is a CPU test not a gpu test. Higher resolutions tests tell you nothing about the cpu.,Negative
AMD,"Well, 1080p is the ideal resolution for CPU tests as it drastically reduces GPU bottlenecks and benchmarks the CPU, providing variable control.",Positive
AMD,"If a RTX 5090 takes 8 millisecond to render a frame at ultra settings, but the CPU only takes up 7.3 milliseconds, then ultimately the fps will be based on the ""slowest"" performing part which is the 5090 in this case.Â   I recalled in games of the idTech engine, you could see separate CPU & GPU render time, showing which component is the main bottleneck.",Neutral
AMD,Because they want to test the cpu and not the gpu. You need to remove the bottleneck as well as you can.,Neutral
AMD,"I mean this is to show performance delta when cpu performance does matter. If you want native results for gpu bound scenarios at high resolutions, you'll find you can pair a 7500f with a 5090 and be happy enough. Plus having extra cpu headroom certainly helps once you upgrade gpu in the future and real world results would use upscaling which makes it more cpu bound again.  TLDR; this benchmark isn't to show what the end user experiences but the difference in raw gaming potential that each of these cpu's can achieve.",Neutral
AMD,"Pointless to upgrade from other AM5 x3d chip, ok if you're buying into AM5, because premium over 9800x3D is small.",Neutral
AMD,More supply of something faster is always welcomed,Positive
AMD,It's 30$ more for 6% faster in counterstrike and 7% faster in battlefield 6  whats the problem?,Neutral
AMD,"A population of people on here will snap it up to upgrade their 9800x3d ""because I like it""  rinse and repeat ad nauseum. Happens with each and every upgrade.  Same deal will happen with the 9950x3d2 or whatever bullshit 1% improvement that gets.  35% extra power usage it looks like from 9800x3d -> 9850x3d, so probably thermal throttles much easier.",Negative
AMD,"Averages are data, but you should really look at the game you play and see what the real world benefit is. 7% faster is worth the 50 to 100 bucks i lose by selling my 9800.",Neutral
AMD,9800X3D Super,Positive
AMD,It exists to hold them over till Zen 6 releases because nova lake comes out at the end of this year,Neutral
AMD,They absolutely do. 1440p or 4k dlss performance with crazy raytracing is still insanely cpu intensive and not as braindead as 1080p medium which shows nothing.,Negative
AMD,Might as well do 720p low then. No reason to do medium 1080p. Itâ€™s just arbitrary hardware unboxed incompetence as usual.,Negative
AMD,"The 9800X3D is way below MSRP now so premium is actually pretty big, at least where I live.",Positive
AMD,"Don't worry, with these ram prices there will be plenty of supplies.",Positive
AMD,"I personally have to see around ~150-200% performance boost for me to upgrade. If im upgrading, im upgrading everything. The monitors/whole pc/mouse/desk/chair etc. I like to have things that feel worth for the money. I right now ride the 9070xt/7800x3d/240hz oled ultrawide. I came from 2080ti/i9700k/1080p/144Hz/ lcd. Companies hate my 1 trick lol. 35% is nice if you dont have any cpu near 2 yrs ago. Just not worth the price imo. But I guess more power to them.",Positive
AMD,"My point is the new cpu is actually legit 6 to 7% faster   But the problem is that the 9800x3d is already gpu bottle necking many games   And thats a major problem with averages, they don't show how fast the cpu actually is, it shows how gpu dependent games are.   If new more cpu heavy games come out in the future, or you get a faster gpu in the future, the faster cpu will have more longevity than the slower one   For you, and many new buyers, its worth it, but averages don't tell you that   15 game averages just don't work to show how fast a cpu actually is",Neutral
AMD,U have no idea what u are talking about,Negative
AMD,Actually 720p can decrease performance nowadays.  Edit: also 1080p is still the most used resolution. 720p is outdated. 1080p is more than enough to test cpu performance without gou bottleneck. In many cases you could even test on 1440p with minimal gpu bottleneck.,Negative
AMD,Win - win to me :),Positive
AMD,"This is true, although am5 has been around long enough where there are plenty of people in the market for a cpu upgrade, but dont necessarily have to upgrade their ram.",Neutral
AMD,"thats kind of just a given with benchmarking in general.  CPUs and GPUs are not these single order pieces of machinery that spit widgets per second.  some will handle some things better, even within the same very game!  if you really truly care about your $500 purchase, find a benchmark using the game you play or software you use.  its just, thats not practical for every single game.  i personally play at 4k and 5k, and as you can imagine benchmarks at those settings are incredibly rare.  most times it doesnt matter!  but in my performance bracket, 5% upgrades are rare, and I jump on them. PC gaming is what I spend 14 hours a day doing, it matters to me. :D",Neutral
AMD,Except he makes more sense than the 1080p low defenders. Useless numbers vs real world usecase numbers.,Negative
AMD,One thing a lot of people don't realize is 4k dlss performance is actually 1080p,Neutral
AMD,"Basically every pro / competitive player in relevant games like CS, Valorant, Fortnite, Cod / Warzone , R6 siege, PUBG, Rocket league, Apex & League plays on 1080p low or even 4/3 & 16/10 resolutions like 1440x1080, 1280x9060 & 1680x1050.   That's a significant part of the market for high end cpus. The hard to swallow pill is that 1080p low isn't even low enough quality testing for the people who actually get real value from cpus like the x3ds and 14900k.",Neutral
AMD,"Funny how I never see you people complain about GPU testing with the fastest CPU and RAM available. Where are all the real world considerations then? These are component tests, not real world demonstrations.",Negative
AMD,And dlss itself has a lot of overhead,Neutral
AMD,The most interesting part of this review is the inclusion of DDR5-4800 which proved almost as fast as their regular test setup in most of the gaming tests.,Positive
AMD,Pretty sure I read the review embargo is going to be lifted tomorrow 1/29 lol,Neutral
AMD,"I don't get the constant mentions of the 9800x3d, as if this was ever going to be an upgrade for 9800x3d owners.  ""It's just 4%!"", ok, but to the target demographic, people who are finally coming into AM5, this is a good cpu for the extra 30$.",Negative
AMD,This uses more power for tiny performance increase. Pass.  So when is zen6 coming out?,Neutral
AMD,In my country the 9850X3D costs 100â‚¬ more. So i don't think it's worth it. I'll get the 9800X3D instead,Negative
AMD,Test the memory controller! We want 6600 1:1!!,Neutral
AMD,How much better is it compared to the 7800x3d?   Worth upgrading or am I fine,Positive
AMD,Was it released today ? Canâ€™t find any listings,Neutral
AMD,At least it'd still let me retire my 2700x.,Neutral
AMD,And yet Intels KS cpus got a better reception for half the uplift. Its not an upgrade for 9800 owners its an upgrade for eveyone else. Of course some of them will buy it but thats what people with more money than brains do. I've been one of those.   Its a great cpu at a tiny premuim over its brother. Meanwhile Intel charged a much larger premuim and was praised more for it. I dont get it.,Positive
AMD,Oh no Steve is getting old!,Negative
AMD,"Still gonna roll the dice and see if I get a better IMC, my 9800X3D has no problem doing 5.75 with a 106 eCLK and +200 PBO but the IMC will not do 6400 1:1 under any circumstances.  Upgrading is not worth 500 dollars of course, but to me it's worth the 150ish it'll cost me after I resell my 9800X3D.",Neutral
AMD,most games dont care about the ram speed!,Negative
AMD,**Tech Judas**,Neutral
AMD,Would that mean even the 9800X3D and 7800X3D performs almost the same with 4800MHz ram?,Neutral
AMD,I thought it was pretty well known that ram speed is irrelevant for gaming. I think for certain production tasks it can matter a lot though.,Neutral
AMD,Review embargo lifted 1/28. Becomes available in stores 1/29,Neutral
AMD,"You mean ""is going to be lifted""?",Neutral
AMD,Yeah 30 bucks extra to have the best of the best isn't bad,Positive
AMD,"Yeah, if it was available in November for small premium over 9800X3D I would have gone with it. Like hell I'm going to upgrade from 9800X3D...",Positive
AMD,"exactly. if this was an option a month ago when i built my pc, i of course would have gotten this instead of a 9800x3d... but iâ€™m not going to upgrade to this now.",Negative
AMD,"I don't think the intent is to show it as a poor upgrade from the 9800X3D (though, it is true).  >people who are finally coming into AM5, this is a good cpu for the extra 30$.  Or even from people upgrading within AM5. The 7600/7600x to the 9850X3D is a pretty notable jump in CPU performance.",Neutral
AMD,"It is kinda insane seeing people think this is not worth it. The target audience pair this up with at least the 5080.   Paying $30 more to get 4% more out of something that costs 1k+ is basically a **no-brainer**. If looking strictly at MSRP, practically no one with a brain will buy the 9800X3D over the 9850X3D.   The only question becomes how much discount you can get with a 9800X3D.",Negative
AMD,"Imagine we upgrade to this instead of 9800x3d.  Won't there be a higher risk of cpu failure, given it's probably under higher stress?  I'm still not confident about the 9800x3d failure reports...",Negative
AMD,"Depending if the newcomers are pairing their CPU with a 5090 or not, the very moment you use the 9850X3D with a 5080 or a 5070 Ti level GPU at 1440p high settings the difference between the 9800X3D and the factory overclocked part becomes null.   However, the factory overclocked part will still be much more power hungry and will run hotter regardless of the performance. In that case buy a 9800X3D and use those 30 bucks to buy a game on Steam.  I know most of you can't help yourselves and will still buy a 9850 to pair with a 4070 Ti or a 9070 XT just to say ""I have the latest"", even if it's just a 14 month old CPU which has been overclocked back at the factory.",Neutral
AMD,"all other things equal, i agree.   ~~since 9850x3d isnt bundled currently whereas others are, you can get more than $30 savings moving to AM5. at least a new mobo and especially if you require DDR5 the difference grows.~~ Microcenter has already dropped bundles, nvm",Positive
AMD,People gotta bitch.,Negative
AMD,Maybe it doesnâ€™t go pop,Neutral
AMD,"For $30 more it is completely worth it.  Zen 6 isnt until very end of this year, or possibly 2027.",Positive
AMD,You mean Zen6%. Just wwit for Nova Lake its going to destroy Zen6 while AMD is busy with RDNA3.5 and shooting themselves in the foot,Negative
AMD,Do that already with a 9800x3D. Just gotta get lucky,Positive
AMD,"Youâ€™re absolutely fine. 7800X3D is still a powerhouse, itâ€™s extremely energy efficient and most importantly isnâ€™t plagued by the sudden death issue.",Positive
AMD,"15% faster at best, while it uses double the power... yeah don't bother upgrading especially if you care about power efficiency because the 7800X3D is still the most efficient CPU out of the box for any of this.",Neutral
AMD,"are you playing at 1440p high/ultra settings or higher ? Then you don't ""need"" anything until AM6 arrives. The very moment you pair the 9850X3D with a 5080 or a 5070 Ti instead of a 5090 the performance difference vanishes, especially when you're not doing 1080p medium settings which is completely unrealistic.",Neutral
AMD,"Overall around 13% more performance, but costs 170â‚¬ more.  And let's not even talk about power draw. The 7800x3d is quite efficient, the 9800x3d is already a good chunk worse while the 9850x3d fails in terms of efficiency.  Neep the 7800x3d for a couple more years. Only upgrade when there is a true performance increase.",Negative
AMD,Tomorrow.,Neutral
AMD,Please do let us know! I also just like having the very best in my system and trickle down the replacements to other PCS I use. But it almost sounds like there isn't necessarily any more performance to be gained here if you're constrained on thermals or anything else.,Positive
AMD,"350 for some used and abused (overclocked) 9800X3D that cannot do 6400 1:1, hopefully you make it clear that the CPU you're selling is not exactly a silicon lottery winner.",Negative
AMD,Any cpu bound game will. We got plenty of tests out there showing a 10 to 20% increase depending on ram speed. X3d chips reduce the value of fast ram due to the larger cache and less need of moving data from the ram to the cpu constantly.,Neutral
AMD,Judas betrayed jesus so I'm not sure you wanted to say that...,Negative
AMD,"Someone should convince hardware unboxed to do a more extensive testing of this, sounds like the content Steve might make a video on.",Neutral
AMD,That statement only applies to X3D chips. Non-X3D suffer with slower RAM  https://www.techspot.com/review/2866-ddr5-ram-stock-vs-xmp-expo/,Neutral
AMD,"The less CPU cache you have, the more it matters.",Neutral
AMD,"It can matter if you are CPU limited, but 3d vcache chips specifically don't take much of a hit because of their larger cache (duh).",Neutral
AMD,That's not even remotely true.,Negative
AMD,"It matters a lot depending on the platform. For AM4 it absolutely matters. [Here is a Dawid Does Tech Stuff](https://www.youtube.com/watch?v=_SapA20lCFU) video comparing memory speed and single channel vs duel channel ram for a Ryzen 7 3700X. DDR4-2400 vs DDR4-3200 was a 20% performance difference in game. Single channel vs duel channel was an additional 20% performance difference on top of that. Now imagine the difference DDR-2133 vs DDR-3600 would have on an AM4 CPU. Other tests have shown that X3D chips care a lot less about memory speed, because they use memory a lot less for time sensitive stuff than non-X3D chips do.",Neutral
AMD,"In the big 2026 and someone is still spreading this garbage. Its not 2016 anymore, both Intel and AMD benefit from faster RAM in CPU-bound gaming scenarios.",Negative
AMD,Yeah.  Noticed it isnt listed at Mircocenter yet for some reason.,Neutral
AMD,"Yes, thank you.  Will correct.",Positive
AMD,"not even worth upgrading over the 7800X3D in my opinion, im looking forward to zen 6 or zen 7",Positive
AMD,No one knows that except for AMD. There have been reports on more than just the 9800X3D failing (seen 9600 and 9700 as well).   If the reason for the failure is related to what is required to get higher clock speeds then maybe; alternatively the failures could be something totally different like a manufacturing defect that impacts a certain percentage of chips. Alternatively maybe itâ€™s just an Asus / Asrock thing.   Maybe the 9850X3D will be more reliable since it is a binned 9800X3D so best of the best silicon.,Negative
AMD,I think that's the whole purpose of 9850X3D - to fix the issue 9800X3D has. They just didn't want to admit it's their fault.,Negative
AMD,"> Depending if the newcomers are pairing their CPU with a 5090 or not, the very moment you use the 9850X3D with a 5080 or a 5070 Ti level GPU at 1440p high settings the difference between the 9800X3D and the factory overclocked part becomes null.  You say that as if most people aren't running their games using DLSS or FSR, at either Quality or Balanced these days (especially DLSS 4 or DLSS 4.5 in the case you don't use RT, it's almost a no brainer to run Balanced instead of quality).  Meaning those benchmarks at 1440p native are meaningless.  You have to look at 1080p benchmarks to know what kind of benefits your CPU will give you when your GPU is running lower internal resolution.  That's not to mention every game is different and some are just CPU hungry, while others are much more GPU limited.  So yes, even for a gamer at 1440p high settings, there will be benefits.  It's 30$, the power and heat differences are negligeable.  It's still not worth upgrading from the 9800x3D if you already have it, of course, but for a new buyer looking at that CPU, it's not a wasted 30$ at all.",Neutral
AMD,Couldnâ€™t agree more.,Positive
AMD,"Itâ€™s only worth it if you donâ€™t already have the 98X3D though, I think that point needs to be driven home",Neutral
AMD,Userbenchmark is that you?,Neutral
AMD,Thank you,Positive
AMD,Unless you play something specifically very CPU intensive like factory/simulation/RTS/4X  Youâ€™ll see a difference no matter your resolution because the GPU is barely doing anything in those games,Neutral
AMD,Thank you!,Positive
AMD,What about a 9070XT ?,Neutral
AMD,Thatâ€™s what I thought but they said released today :-),Positive
AMD,"The IMC is better, at least in my sample of 1. I was able to go to 6400CL26 and even go to nitro 1/2/1 with the 9850X3D when I had to do 6200CL26 and nitro set to auto with the 9800X3D.  I haven't done comprehensive stability testing yet but in my case the IMC is absolutely an improvement.",Positive
AMD,I did a Newegg trade in on it for 320 and had a 33 dollar store credit. It'd probably do 6400 1:1 with a single rank kit but I'm running dual rank which is a lot more hit or miss at 6400. Not too sure what your problem is.,Neutral
AMD,"Yes, that's exactly what I meant.",Neutral
AMD,He already has.  https://www.youtube.com/watch?v=aD-4ScpDSo8  https://www.youtube.com/watch?v=Fr7Bfr-wPYw,Neutral
AMD,"Im a bit sad cuz only GN tests FF14. And before anyone says you dont need much hardware for it, I can only get 80FPS at 1440p in crowded Limsa with 7800X3D+5070Ti",Negative
AMD,Didn't he?,Neutral
AMD,"All chips suffer with slower RAM, just not as much as people imply. X3D hits that problem less frequently because of the cache but that doesn't mean it will never do so. Some of the tests in this very post (and yours) even show that.  If you care about performance don't get RAM with garbage latency. Having an X3D doesn't save you from that statement.     Edit: Techspot's examples are even a rather extreme 50% worse latency with a flagship GPU. You're going to notice smaller gaps on the kinds of systems that might have non-X3D chips in them, especially if they aren't running base jedec speeds even if the memory is still below 6000 (or 8000).",Negative
AMD,On Amzon it's about $50 more than the 9800x3d,Neutral
AMD,"in my limited experience with CPUs, I find it best to upgrade every 3-5 generations.  I have Zen 2 and am considering this chip for my next computer (though with RAM prices that may not happen until Zen 7).  my R5 3600 works fine, but is aging.  I can't imagine upgrading from the 7800x3D, which is still an amazing chip.",Positive
AMD,"Nah, a new product is released to increase profit, not to fix issues they don't want to admit that exist with design flaws.  This product is most likely aimed at increasing prices, by setting a new higher profit margin, at nearly the same cost to produce.",Negative
AMD,"Yes, but it still depends on your GPU, 1440p ultra settings DLSS Quality on a 5070 Ti and you won't see any difference between the 9800X3D and the factory overclocked version they sell at a premium. No matter if you're playing space marine 2 or cyberpunk with path tracing.   You need to understand that the 5090 is orders of magnitude faster than anything else in the market and Hardware Unboxed found a 4% difference on average at 1080p medium settings on that beast of a GPU. Just turn PBO+200 on a 9800X3D and that difference will be down to 1 or 2%. Now imagine you have anything else than a 5090, it's hilarious that some people expect double digit performance improvements on a 5070 - 5080 running DLSS.   The only thing you can expect is that the factory overclocked 9800X3D they're selling with a fancy new name will run hotter and will draw more power. It should be such an easy purchase decision but nowadays FOMO rules everything and you make excuses and false expectations out of thin air just to get the newest... even when the newest is actually a 14 month old factory overclocked CPU. Go watch Hardware Canucks and der8auer reviews.",Neutral
AMD,"I agree.  But for new builders like myself that isnt already on AM5, totally worth it.",Positive
AMD,"As a counterexample, I'm moving from 7600x to x3d and was waiting for the reviews before pulling the trigger.  I decided to go for the 9800 in the end, we're talking about some 10 celsius difference in gaming with a 360 aio for 4% performance in 1080p, which is not worth for me.",Neutral
AMD,I am not even sure if the 9800x3d is worth it over the 7800x3d. 120â‚¬ for 10â‚¬ performance. The 7800x3d is a pretty good deal atm. Now another 50â‚¬ for 3 to 4%... nah...,Negative
AMD,Yeah the 7800x3d is still a great cpu.  I've been running one for the last couple years and I'll be set for the rest of AM5 imo.  The only thing that could tempt me to upgrade to another AM5 cpu would be if they release a 16 core x3d chip that has the extra cache on both ccd's.,Positive
AMD,"That is true, even if the difference won't be exactly groundbreaking, barely noticeable I would say... you want an actual upgrade then wait for Zen 6. This is, if you have to buy right now, you might want to assess whether you prefer an ever so slightly faster CPU for those games or maybe a cheaper, much cooler and efficient processor.",Neutral
AMD,"Are you playing your games at 720p on your 9070 XT at medium settings? Then congrats, you can get 5 additional frames if you get a 9850X3D instead of a 9800X3D, but it will run hotter while drawing more power.  On the other hand, you can get a much cooler and efficient 9800X3D and use the 30 bucks to buy a game.  A lot of users are completely ignoring the fact that most reviewers are using a 5090 at 1080p to review the factory overclocked 14 month old CPU. Are you buying a 5090 and playing at 1080p ?",Neutral
AMD,"None, just that for a bit more you can get a fully new CPU that might very well have a better memory controller, so in good faith you should be open about the capabilities of the used part you're selling (not just the IMC, but also that it was overclocked for X amount of time.",Neutral
AMD,"I watch GN for the Stellaris benchmarks, one of the games where you'd also notice the extra CPU performance.",Neutral
AMD,"Any mmo will need a beefy cpu for handling large crowds. Just the natur of the beast.   But I agree, it's nice to see some mmo hardware testing as they can run on a potato, but usually still require gold hardware for a seamless experience.",Neutral
AMD,"Well, it's 5070... ðŸ˜",Positive
AMD,It is up now. $50 more,Positive
AMD,I agree. I went from a 4820k to a 9700k.  I finally got a 9800x3d the other day. It didn't feel like a good enough reason to upgrade for me until the 7800x3d came out and even then I dragged my feet.  I want to see a noticeable difference when I change platforms and CPUs personally.,Neutral
AMD,"i went from a 1600 to a 3600 to this 7800X3D, and i feel like the 7800X3D will have alot more longevity than the 3600 did (and its still a fine chip, i kept it in my ITX travel PC)",Positive
AMD,"I've hopped from 5950x. It was nice upgrade for most of my use cases, but sometimes I miss those extra few cores. If Zen6 is going to have single CCD 12-core X3D chip, I may jump (I have two kids hungry for hand me downs, so I'm tempted to upgrade a bit more often).",Positive
AMD,"yes i agree a release like this is to increase pricing/profit and sell a new ""best"" thing and all that but could also be to fix an issue without admitting to the issue.   look at what the PSU/GPU market is looking like right now for higher end cards. no company is admitting or stating there is an issue with their adapter/cable/GPU in terms of burn cables and place it on user error, but at the same time more and more companies are releasing either new connectors or safeguard PSUs. yet nobody is actually admitting to the problem, but at the same time are trying to solve a problem.",Neutral
AMD,> You need to understand that the 5090 is orders of magnitude faster than anything else in the market  You need to understand what orders of magnitude are.,Neutral
AMD,"> Yes, but it still depends on your GPU, 1440p ultra settings DLSS Quality on a 5070 Ti and you won't see any difference between the 9800X3D and the factory overclocked version they sell at a premium.   That's just not true.  The 5070 Ti is quite powerful enough to where it can get bottlenecked by the CPU, especially once you start pushing DLSS usage.  It's highly dependent on the game.  Not all games are Cyberpunk 2077 with full Path Tracing.  People already gave you CPU bottlenecked examples of games, and that's before we even factor people using DLSS 4.5 at Balanced or even performance because DLSS 4.5 without RT is just really that good.  > You need to understand that the 5090 is orders of magnitude faster  I think you need to calm down and understand that the 5090 is not the only thing bottlenecked by CPUs.  The problem with HUB, GN, Jayz and others is that they completely ignore DLSS and FSR as a thing when benchmarking and have made people unable to understand how upscaling can in fact increase CPU usage through higher framerate and thus more frame preparation.  > The only thing you can expect is that the factory overclocked 9800X3D they're selling with a fancy new name will run hotter and will draw more power.  You're free to not buy it.  You're not entitled to make sweeping remarks about how it's only worth it with a 5090 though.",Neutral
AMD,"i am coming from am4, so need a motherboard and RAM too. to me, it still seems better value to grab a 7800x3d bundle including one or both - until 9850x3d bundles come around",Neutral
AMD,"If sometimes tech savvy itâ€™s not worth it at all, itâ€™s just a higher clocked 9800X3D, any other one can achieve exactly the same, itâ€™s just up to the user",Negative
AMD,"Firstly, it's Newegg, secondly it's performing perfectly within spec 6400 is not guaranteed at all and most 9800X3Ds hit a wall at 6200. Have you even bothered tuning your memory or do you just enjoy being contrarian?",Negative
AMD,"I'm experiencing the same thing.  Games like Arc Raiders are choppy, but still technically running.  Total War Warhammer 3 runs, but does take forever to load anything and big battles get really choppy.  I might have to just spend the money to buy.  It seems foolish to spend $300 for me to stay on AM4 just to avoid high RAM prices.",Negative
AMD,It can be both though. Usually these new chips increase the stepping and probably the engineering departments feel confident that a overlook model might present lower than expected failures of the vcache and such they want to milk the market. I disagree with them milking us thought its the same product with on a stable node and platform which is why Nova Lake is sorely needed to put AMD in its place.,Neutral
AMD,Clearly an order of magnitude is about yea big. Also 5090-5080 = 10. Boom checkmate,Neutral
AMD,"Believe what you want. By all means enjoy the hotter and inefficient ""new"" CPU then, such an elegant engineering masterpiece (bump core voltage, charge more money and call it a day, lol). Guess der8uer is lying on his review and findings. Go open a thread about it, what a mean guy.  That you think I'm not entitled to my opinion on the matter is a bit crazy, as crazy as believing you're going to get a 4% performance bump in your average game on a 5070 Ti at 1440p DLSS Q ultra settings.",Negative
AMD,"those bundles are already available at Microcenter.  Its about $50 more and you get a ""better"" motherboard with it that you probably don't need.",Neutral
AMD,Would you like a second mortgage for that RAM?,Neutral
AMD,"Yeah I tuned mine to 6400 CL30 1:1 aiming for 100% stability even if it meant loosening some timings a little bit, PBO+100 scalar x1, it runs cool, efficient and quite fast, thanks for asking.  Here you have my tune settings and some benchmarks:  [https://i.imgur.com/UTA1CHL.png](https://i.imgur.com/UTA1CHL.png)  [https://i.imgur.com/NpF7ikg.png](https://i.imgur.com/NpF7ikg.png)  [https://i.imgur.com/kAUmokG.png](https://i.imgur.com/kAUmokG.png)  [https://i.imgur.com/SyYHdrD.png](https://i.imgur.com/SyYHdrD.png)  I mean it's just empathy, for sure if you were in the market for some 2nd hand 9800X3D you'd definitely want to know the capabilities of the CPU they're offering to you. Don't just say ""nahhhh 6400 ?? ? That's ultra-rare, and it's not even worth it, just pay me 350 for my abused CPU"" when you're selling just to try and get a CPU capable of 6400 1:1. Be honest, that's all.",Positive
AMD,"I bit the bullet and did something I'm not proud of. I bought a pre built that I think was a good price (considering the market).   It has a 9800x3d, 32gb 6400mhz, 2tb nvme, 5070 TI(I plan on selling to offset the cost of the system).  The only thing I'm going to do is carry my current GPU over and replace the power supply immediately.  I parted it out and the math wasn't on my side to buy it all individually even without a GPU",Negative
AMD,But to your point I'm bottlenecked with the 9700k pretty hard in any CPU intensive newer games. When I first got it it smoothed out all my games at the time and I fully expect the same thing here.   Just much better frame times and lows with 9800x3d and it can let my card stretch it's legs in a lot more games.,Positive
AMD,100% agree it could be both. at the end of the day we may never know. All we could do is throw our thoughts out on it and time will tell if we see CPU/Motherboard issues in the coming weeks once the 9850x3d fully launches tomorrow. I hope there wont be any issues but who knows. The PC building realm needs some positivity cause lately its been rough with all the issues out there.,Negative
AMD,Canâ€™t argue with that math!  But thatâ€™s still just one order of magnitude.,Neutral
AMD,5090 - 5070 Ti = 5090 - 507084105 (in ASCII) = -507079015 = 5070 OSI. Therefore 5070 Ti > 5090.,Neutral
AMD,"> Believe what you want. By all means enjoy the hotter and inefficient ""new"" CPU then,  Now you're just being aggressive and dismissive as soon as you can't really address points anymore.  > That you think I'm not entitled to my opinion on the matter  You're entitled to your opinion, not to making up facts either.  > as crazy as believing you're going to get a 4% performance bump in your average game on a 5070 Ti at 1440p DLSS Q ultra settings.  1440p DLSS Q is 1080p internal.  Make of that information what you will.  I also will now stop engaging with you as you're just being irrationally angry for some reason.",Negative
AMD,Yea I was too quick on the draw. The bundles came quickly,Neutral
AMD,Used market isn't AS bad - or a bundle lol,Positive
AMD,That is a single rank kit. How difficult is this for you to understand? Tuning single rank and dual rank is not the same. Dual rank is harder on the IMC.  [https://imgur.com/a/aisYFBA](https://imgur.com/a/aisYFBA),Negative
AMD,"Im probably gonna do a microcenter bundles.  $750 for the 9800x3D or $800 for the 9850x3D.  I'll be replacing my case since I need a bigger one but my PSU and my 6950xt should be able to be carried over.  The pricing isnt bad, though certainly not the deal it once was.",Neutral
AMD,Its not about us its about them for us to go to this level.about positivity shows how incompetent companies are in not owning up or addressing the the issues and also how they can get away with these efforts easily.,Negative
AMD,Listen that's a pretty solid deal considering that the exact kit in my new PC costs 450 if you buy it alone.  My PSU is amazing but alas it is over 10 years old (EVGA) so I got an atx 3.1 that was graded very highly on the PSU hierarchy chart.,Positive
AMD,"My PSU is 3 years old so still good and solid.  The 6950xt is holding up just fine, even if it sucks at RT.  I think i can get a couple of years out of it until I need to upgrade or can wait for a deal.",Positive
AMD,"Good thing the 9850x3d just came out, surely that wont push the limits further right?",Neutral
AMD,"At this point, I think thereâ€™s something wrong with the 9800x3d, not necessarily the motherboards",Negative
AMD,It is specifically the 9800x3d that's the problem. Any other AM5 chip should be fine.,Negative
AMD,are 9950x3d in danger as well?,Negative
AMD,"First off we don't even know if there is a real problem here.   It is completely possible there is nothing wrong with ASUS, motherboards and we are just seeing mass panic from the online world.  At least ASUS is taking on this issue with a positive investigative approach.  As for BIOS upgrades I either never touch a BIOS or upgrade whenever a new one comes out.   When working with new technology BIOS upgrades can be very valuable, on a stable system that has been running for years, I'd be reluctant to upgrade the BIOS.",Negative
AMD,should an undervolt help prevent this?,Negative
AMD,"I had a X870E-E for a little more than year and I'm on bios 1003 which is a year old and I have no issues so far, I don't think I'm gonna update",Positive
AMD,"At least they took responsibility somwhat. When I7 and I9 died, Intel did not. My personal opinion, the cpu got overvolt. I have a budget friendly build. Busy replacing everything as my brother got this pc as I am a web dev and was using an I5 3340. When I got this pc. It had PBO enabled and was pushing volts sometimes over 1.4v. I am old shool and PBO ran hella unstable (may be this crap msi budget board) So I disabled PBO, Manually set the cpu to 4.2ghz and undrvolt it to 1.2v. Been running it for a couple issues with no problems yet.",Neutral
AMD,I undervolted my 9800x3d CPU by -15 on all curves temps fell dramatically rarely see it get above 86c before it was getting into the 96c,Negative
AMD,"It likely is the board partners just pushing way to much voltages into the CPU, the moment people enable XMP/EXPO.   Its a bit similar to the Intel problems, where they were the ones pushing way to much power into the cpus, and Intel being the one not enforcing stricter rules.  It could be coincidental that AMD itself proclaimed 4800 DDR5 only being slightly slower, but thats the opposite  everything AMD used to do when DDR5 wasn't as expensive, even sending 8000 Kits with the boards because that would give you 1% more performance in that single usecase instead of using a good 6000 kit.  I mean 4800 kits aren't that much cheaper than most 56/6000 kits, and the usability if you change your system would be worse for that 4800 kit.  The thing that people won't do when using 4800 kits, is enabling xmp/expo.  There also have been multiple tests by outlets, which have shown how the power consumption goes up, sometimes a lot, just enabling xmp/expo, which makes sense if the voltages are way higher.  Everyone just assumed the voltages set by the boards were safe, now it seems the were on the edge the whole time, and when the process nodes are shrinking, higher voltages get more problematic.",Negative
AMD,isnt asrock a shoot off of asus anyway? seems that is what i recall and it would make sense if they share bios code.,Neutral
AMD,"This issue is likely manifesting in strange ways across pretty much all 9000 series CPUs. Think I/O and stability issues that people are blaming on other peripherals, SSDs, chipsets, GPUs, anything. This needs to be addressed ASAP",Negative
AMD,â€œWe are now checking if our AMD boards are actually compatible with AMDâ€,Neutral
AMD,i am the only one who think cpu should carry lifetime warranty for hardware failure? since overlocking is now a base fature for both manufacturers they cant blame the user for this anymore,Negative
AMD,"I just dont touch mine at all ... BIOS is default, RAM is manually set to whatever its spec is and thats that. No undervolting, no optimization, no ram tuning, nothing. So far runs excellent on my b850.",Positive
AMD,Asus b850-a. Im on the original bios that game with the board. Should i be updating as well? ðŸ¥²,Neutral
AMD,"And yet when my 7900x was murdered it was a back and forth with AMD and ASUS blaming each other and not doing my damn RMA  I don't think you can do anything it might happen or it might not, in my case because it didn't burn the CPU and it still botted technically it was unknown to either company what was defective the CPU or mobo  If you can purchase and extended warranty that might be worth it but just save up for a new mobo and CPU or put aside the advanced RMA fee so you can get it quickly replaced and don't worry about it that much",Negative
AMD,Is this an issue with 9000 series or the 800 chipset? Because Iâ€™ve noticed some random spikes in usage/temps on my 7800X3D + B850G,Neutral
AMD,"I've got an early batch 9800x3d on a asrock taichi lite built just over a year ago.  Pretty much just turned on expo for the ram and thats it, and haven't really updated bios at all (3.1 on agesa 1.2.0.2.  Running an AIO, it idles at 50 exact or so, up to 60/70 normal gaming, but can get very toasty under full load (like up to 90).  It generally doesn't get that loaded, and always thought it was an issue with the paste and cooler.  Should I be concerned?  Should I update bios, repaste or look into pre-emptive rma with amd or something?",Neutral
AMD,"Who updates their Asus Mobo bios after discovering this? I have had my Asus Mobo since 03 last year, I updated to the newest bios at that time. I even got an undervolt and a overclock on my CPU I don't remember the numbers anymore but my CPU rarely goes past 60Â°.",Neutral
AMD,honestly the general rule with BIOS updates is if your system is stable and working fine then there's not much reason to rush into an update. what i've learned over the years is that BIOS updates are more for fixing specific issues or adding compatibility for new hardware rather than preventive maintenance. from what i've seen the issue seems primarily tied to the 9800X3D and specific board configurations but ASUS hasn't been super clear about the full scope. if you're running a non-X3D chip and everything is stable i'd probably wait until there's more clarity or unless you actually need features from the new BIOS. the rollback restriction is concerning so i'd only update if you're experiencing actual problems or ASUS specifically recommends it for your exact setup.,Neutral
AMD,"I have been using 9800x3D with b650m Tomahawk for a few months now, no issues. Idles at 37 - 42 and peaks at around 70 at 4K in games like Battlefield",Positive
AMD,"Most likely happened to my 9800X3D with Asus B850i . Currently in rma process. Died all of a sudden , confirmed it was not a psu issue or ram . Gonna be a very expensive paperweight of a motherboard and not gonna put the rma cpu in it. Knowing ASUS they probably won't even rma the board itself in real life.",Negative
AMD,"I own a highend x3d cpu, if you check the temps it can soar suddenly before the fan can pick up and dissipate the heat  so if you have bad motherboard capacitors, a bad psu, insufficient cooling and bad silicon luck I can completely see how the cpu can pull too much juice to boost or overclock and slowly kill itself  it's made even worse for the two cccd cpu's they pull more power and the sandwiched chips retain more heat, undervolting doesn't help because the chip ramps up higher seeing it has more headroom  most users don't want to run it in eco mode to limit the amount of power it can pull, I would say the bios defaults for these boards is overly agressive on the pbo/auto overclocking, the sudden ramp in voltage and watts causes a spike in temp that physically damages the chip if high enough, repeat it enough times and the chip and/or motherboard fries itself and fails the POST check  some motherboards claim it's great for overclocking, but when you look at the physical number of vram chips and capacitors, and calculate the power, current and resistance you quickly see if it were actually to pull the amount of power a high end cpu can boost too, the heat would overwhelm the system",Negative
AMD,"Better advise for now  Vsoc 1.2v or lower. Run 6000 on ram for now and try 1.15v.   Pbo, manual limits. Or eco mode 105w for easy. No frequency override, no scalar, pbo highest - value.   Vddg voltages 0.95v  Other guy taking about soc voltage and fclk is wrong.",Neutral
AMD,Reddit acted like the 13900k and 14900k degradation was the end of the world (and still do) but these posts don't even get close to the same amount of traction.,Negative
AMD,"I knew this wasn't an ASRock issue entirely, yet the slander continues each passing day.",Negative
AMD,"Would this also apply to asrock motherboards since theyre under ASUS? Kinda concerned, as I recommended a friend of mine to get an asrock motherboard and a 9800x3d after my good experience with the b850 riptide wifi and 9600x",Neutral
AMD,"My Gigabyte X870 AORUS ELITE WIFI7 board (latest BIOS, F9 from December 12th) seems to be handling my 9800X3D (and Gigabyte RT 9070 XT) build quite well with a Thermalright Peerless Assassin.  Been running it since March when I built it and it works like a charm.  Is this problem only with ASUS boards?",Positive
AMD,"""ASUS-voiding warranties since 1886""",Negative
AMD,It is 100% cpu issue and not motherboard issues with w/e vendor,Neutral
AMD,Should I worried about my rog b850-I + 7800x3d? Or this is ryzen 9 problem only?,Negative
AMD,They launched that one so everyone needing a new CPU after the last one burnt up will get a slight upgrade when they replace it.  Imagine if they made a CPU that didn't have a builtin self destruct. They'd only be selling a new CPU every time the consumer felt like buying one instead.,Neutral
AMD,Or AMD fixed the problem.,Neutral
AMD,"if it's VSoC as speculated that's causing the chips to do then i don't see how it can be unique to that chip, every AM5 chiplet CPU uses that same i/o die",Negative
AMD,Yeah it's been borking on multiple brands of motherboards. Something is iffy about the 9800x3d which makes the 9850x3d kinda worrying. Either they secretly fixed it or that CPU is going to see the same issues,Negative
AMD,This is the last thing I want to hear after just recently putting together a 9800x3d build. I am on a Gigabyte board though and not seeing their board pop up in this mess.,Negative
AMD,Correct. Cropped up first on ASRock boards but now the issue is spreading across brands. Earlier CPU batches seem to be most affected.,Negative
AMD,"The 9800x3d is more sensitive, but this is the second time, and the common denominator is Asus/Asrock",Neutral
AMD,Mine blew a resistor in my x870 E-E wifi gaming board. Got the board back repaired and still no response from the 9800. If that helps narrow it down a little.,Negative
AMD,"I had a 9700X go out the exact same way people have described 9800X3Ds failing ... just immediately dead during a reboot, even stuck it in a different board since we were all assuming it was an ASRock problem at the time.",Negative
AMD,"Incorrect   2x asus b850e rog strix, 2x 9700x, updated bios in may, both started getting over volted well past safe limits for the 9700x both chips killed.  Swapped to a msi x870e edge ti and zero problems, voltage never goes past amds stated safe limit.  Thatâ€™s what has been killing the CPUâ€™s, in virtually ever instance itâ€™s been noted to be overvolting.",Negative
AMD,"You do know that Asrock is a sub brand of Asus, right?",Neutral
AMD,"9950x3d been frying, 9700's, its pretty much the entire 9xxx line. Though 9800x3d's have the majority",Neutral
AMD,"I'm sure some have died, just as the 9800X3D. My 9950X3D has been sitting tight since I bought it at launch, and I haven't had any issues with it so far. I'm hoping it stays that way.",Neutral
AMD,"whatâ€™s the AGESA version of that Bios? Version numbering is different for every board, but it should be the same Bios if the AGESA version is the same",Neutral
AMD,The 9800x3d has been sitting at 97c for my friend.,Neutral
AMD,What?! Iâ€™ve never seen more than 75 on mine in stress test. Never more than 65-70 when gaming. Are people not using aios?,Negative
AMD,i have a steady -40 all cores on my 9800x3d,Neutral
AMD,"What voltages should we be manually checking to make sure they're within spec, and what even is the spec? I have EXPO enabled, but I've never even thought that could be a problem...",Neutral
AMD,It's not the voltage.,Negative
AMD,haha would be funny if the socket and pcb footprint/pin layout would be compatible with intel's and someone loaded the wrong batch of pcbs,Neutral
AMD,Undervolting doesn't hurt and is an extra protection without affecting performance,Neutral
AMD,No one knows yet for certain.,Neutral
AMD,"Updated BIOS + undervolt would be all that I would suggest. You can YouTube for the undervolt stuff, itâ€™s very easy.",Neutral
AMD,Upgrade you bios and that's it. Undervolting wouldn't do much.,Neutral
AMD,"Do you remember which BIOS you had. Also did you have undervolt, PBO etc?",Neutral
AMD,"Jesus Christ, after years of wanting one finaly got my first gaming rig, before hearing of all this controversy... same.cpu  on a Asus B850 E. Only comforting thought was the slight hope that maybe outdated drivers were responsible ðŸ˜®â€ðŸ’¨",Negative
AMD,The voltage spike thing is also why I got a beefier PSU than required.  I think a lot of people here use 850W with maybe a 5070Ti. The spikes would probably cause the PSU to hit above limit after other components are accounted for when running a 9800x3d. I upgraded mine to 1200w after my 850w one melted (not cpu related) and seems like itâ€™s handling my EPYC 4585px well enough. A power spike on an under capacity PSU could kill chips.   Iâ€™d suggest at least 1000w for 9800x3d/9850x3d and at least 1200w for 9950x3d. If you use a 5090 nothing short of 1300w would work.,Neutral
AMD,I thought that Vcore was the issue...,Neutral
AMD,Yeah because it's not even close to being the same kind of issue nor is it equally widespread.,Negative
AMD,Because youre not allowed to say bad things about the X3D chips as it goes against the narrative.,Negative
AMD,"ASRock is not under Asus, they share a parent company.",Neutral
AMD,"Asrock is the worst for this particular issue with the 9800x3d, it was the first manufacturer that people reported these issues on, and still seems to have the highest proportion of failures with that cpu.",Negative
AMD,"Have the same mobo and same cpu, I hope it will last forever.",Positive
AMD,Imagine needing to do all this just to use a pc safely :/ this is full circle(jerk) to when amd was partially successful and then a few generations of chips under 1% adoptionâ€¦ NOTHING should require what you just wrote just to function as expected. Thanks for the info tho it might keep someone safeðŸ˜ ,Negative
AMD,"1.1V isn't gonna work for everyone if you're running 64+ gigs of RAM, it puts more strain on the IO die. If you're running non standard fclk in general - don't. Not worth the effort.",Negative
AMD,Fclk scales negatively with soc. Also this is gonna cause people systems to unstable.,Negative
AMD,"ikr? Honestly, everyone should be working with PSU manufacturers. Make PSU last 1-2 years and randomly die and take out all of the components with it. Imagine the sales HW manufacturers would have!",Negative
AMD,I've manually been on 1.15v VSOC since purchase and my 9800X3D still died after 8 months. I don't think is VSOC unless there is some unknown issue where it spikes higher than it should.,Negative
AMD,"V-Cache seems to make it more fragile due to the copper pillars (TSVs) that need to stay in alignment. CCDs also use SoC when communicating to IOD via GMI. VDDG CCD and IOD should also not exceed SoC voltage. I run my 5800X3D at 1.050V SoC and VDDGs are 1.025v. But, 5800X3D only has a voltage tolerance of 1.2V, with 1.1V being nominal during actual running. Hynix DDR4 kits always required higher VSoC to work properly. I hated that and switched to B-Die before getting my 5800X3D. The 9800X3D allegedly has a VSoC tolerance of up to 1.3V.  There is still the possibility of these being slightly defective and bonding process created a slight misalignment that wasn't caught in QA. Seems to cover any production fab and date (based on reports), so not sure if that's it.   Something is causing these failures and I'd center on poor voltage AND current controls (or overly aggressive when EXPO is enabled) on the motherboard. A millisecond voltage spike probably won't kill anything, but a current spike in conjunction with that extra voltage? Yikes!",Negative
AMD,"2x asus b850e rog strix, 2x 9700x both chips dead after bios updates back in April/may. Both begin way overvolting after bios updates.  Msi x870e edge ti + 9700x and no problems.",Negative
AMD,Hoping I'm clear of any potential issues as well having just done a 9800x3D build for myself and someone else. Both Gigabyte boards so fingers crossed.,Positive
AMD,"Same, I ordered a gigabyte for my build, I hope it works",Positive
AMD,"""now issue is spreading to other brands""...     no... the issue has ALWAYS appeared on other brands, in fact the initial issues originated on an asus board to begin with. It's just that due to copious amount of bias and willfully blindness, almost everyone INSISTS that asrock was the only manufacturer, apparently the posts prior.. during and after the claim was made that asrock was predominantly the the one and only...  ""but the stats show asrock has...."" even the creator of that stat collection admits and clearly states that due to the individual posts being recorded that numerous, tons of posts were put under the ""asrock"" counter even though it was shown NOT to be an asrock board, to the point of putting the disclaimer that it's bias against asrock.  Honestly people need to get this out of their head that somehow this was an asrock problem, it never was, it was a universal problem. As far as what the problem is, even gamersnexus's own board they received that supposedly claimed 2 separate 9800x3D's life, having been put through their ringer, showed actually exceptional results of doing precisely what it was supposed to do and very well, and they've had that for what, 3 months now with ZERO problems reported which further suggests that the rule holds most likely true, user error being the primary likely cause.",Negative
AMD,Then why are we only hearing about issues with Asus (Pegatron)?,Negative
AMD,Asus and Asrock arenâ€™t the same company anymore,Neutral
AMD,"Nope, voltage does not kill CPUs, stop spreading lies.",Negative
AMD,"Not really, ASRock was started by ASUS but later split off, making them 2 distinct companies owned by Pegatron",Neutral
AMD,"That's not true. You have statistics on r/ASRock to prove it. X3D on 800 chipset is the problem, not everything from 9000.  And it's not proven that the CPU's are the problem either, but let's just keep saying it based on... feelings?",Negative
AMD,Because itâ€™s most popular 9 series chip,Positive
AMD,Motherboard &bios version??,Neutral
AMD,1.2.0.3a Patch A,Neutral
AMD,"my tdie regularly pushes 95 under stress test or shader complication, but cores always stay in the 60-mid 80 range",Neutral
AMD,Pretty sure most people use air coolers,Neutral
AMD,"depends on the room temperature as well, I have a liquid freezer 3 420 and it can definitely reach 90Â° on a stress test or during shaders compilation in some games but it's not too hot while gaming",Neutral
AMD,Air cooled and I've never seen it go above 74 while gaming.  MSI motherboard.,Neutral
AMD,But AIOS are generally not that much different in long sessions anyway. IM using AK 620 (air) on mine 9800x3d and i dont break 80c when doing cinebench and never had 70 when gaming.   The whole 'u need aio' for any consumer cpu is so stupid.,Negative
AMD,"No need for aios. Also, nowadays it's also about bios options. PBO on auto vs. enabled, pbo multiplier and so on... But mostly these 2 I guess.",Neutral
AMD,Most prefer superior in every way tech called â€œair coolersâ€,Positive
AMD,Would that even work to begin with?,Negative
AMD,it does affect performance... in a positive way!,Positive
AMD,"The latest one , 1402 I think. And no overclock or undervolt. I do have a suspicion the latest bios messed something up cause it started having sudden crashes for two three days and died randomly. Didn't have any problems before that.",Negative
AMD,"The latest one , 1402 I think. And no overclock or undervolt. I do have a suspicion the latest bios messed something up cause it started having sudden crashes for two three days and died randomly. Didn't have any problems before that.",Negative
AMD,False. PSU has nothing to do it. You can run 9800x3d and 5070ti on 700w PSU no problem.,Neutral
AMD,"Using curve optimizer along with NOT using the frequency override is the best. Frequency override extends the vf curve up to 1.3v or higher. If you don't use that, you typically won't see more than 1.25v before undervolting",Neutral
AMD,"13 and 14th gen had less issues than previous gens from both intel and AMD for system builders:   [https://www.guru3d.com/data/publish/223/5afc45269b598ee1df1d84ce6569ed253c9545/1722839835\_guru3d.webp](https://www.guru3d.com/data/publish/223/5afc45269b598ee1df1d84ce6569ed253c9545/1722839835_guru3d.webp)  But internet changed heavily, outrage feeds Youtube algorithm, Wendel presented some insane data from datacenters that noone else confirms (like 50%+ failure rate) even being close to the issue etc. Over the years i had 4 5000 series AMD RMAd beteween me and my fiancee. Constant issues, stability, performance, USB drop outs fueling me with rage every day at work. Intel 13th gen thats now home NAS, but spend 2 years with 600ghz overclock on pcores? Flawless. 9800x3d in my PC now? Flawless. 9700XT (apart from being atrocious in VR to this day) and 4080? Flawless. Previous AMD cards from Sapphire 3 times solder ball fatigue in last decade (2x R9 classic). It just shows how media can make people think that some things are bigger than they really are. Just like adapters are responsible for 99% of 12VHPWR issues.  The best joke is, AMD is as always behind with both burning connectors and exploding cpus, just like upscaling and other stuff /s.  Never miss opportunity to miss an opportunity.  Edit: Oh, its also probably short form content being people source of 'information' nowadays adding to the problem.",Neutral
AMD,"consider that this could just be survivor bias. Or something akin to the spanish flu, which wasn't spanish at all but it was one of the places to actually report the disease in full.",Negative
AMD,"Yeah I'm gonna run it for a while, next upgrade would probably be a GPU? But even that wouldn't be for years.",Neutral
AMD,"you don't need to do any of that, nobody knows what the cause of the issues are, and what's killing the chips, just that an ASUS and especially an Asrock board are more likely to kill a chip than MSI or Gigabyte.      We don't even know if it's actually VSoC, but it's strange that there's such a variation in VSoC settings between board makers.     With 6000 Expo on my Gigabyte board it's ay 1.195V, some on Asus have been reporting figures of 1.24 and sometimes above",Negative
AMD,"Yep I think they pushed these (especially X3D) chips too near to the limit.  I also think the IHS is too thick, so all my AM5 chips are delidded.",Negative
AMD,"I'm running 1.14v vsoc, 64gb ddr5 6000mhz manually tunned tight timings, 2133fclk, for more than a year. No issues.",Positive
AMD,I ran 1.1vSOC on my 7800X3D with 128GB.,Neutral
AMD,I think Nvidia is on that pilot program.,Neutral
AMD,Asrock?,Neutral
AMD,"It's not ever a voltage issue when it looks like that, it's  amps. So if you limit the voltage, you effectively allow it to draw more amps to get it's rated wattage. You need to limit the watt or current draw.",Neutral
AMD,"I think that was the problem with the 7800X3D, it spiked higher than it should.  Looks like it's a similar problem here.   My non specialist guess.     I find it strange that manufacturing defect would result in a CPU suddenly dying and that kind of bug would escape QC.",Negative
AMD,did you also turn off PBO ?,Neutral
AMD,"Cpu vddio can also play a role here. In my main motherboard, it sets vddio = dram vdd when you enable expo.  So vddio which should be at 1.15 to 1.20V is now set to 1.35V (msi x670e).",Neutral
AMD,"id wonder if its some kind of TSV degradation where power is going thru the shortest path until that just cascades as fewer and fewer low resistance TSVs remain. this generation was the first to put the cache below so power must traverse thru those TSVs while prior generations it was mostly just data.    i do have a 5700x3d that is rather abnormal, hard to explain but it was one i had to repair pins on so idk the history. but the thing takes forever to post in my msi b550 and the sensor data is wrong in the bios (2v dram 1v soc and 64c temps) in another board jginyue b550 the cache and dram latency was an order of magnitude higher than normal (stock 500ns mem 20ns l1 cache) stutters in benchmarks and uprof seemed to show it hanging in amdgpio. the jginyue board is hot garbage but doesnt explain the cache or memory latency (despite the board pcb being so shit it cant do pcie4 or tune much better than 180ns trfc). never worked out whats wrong with it, it works fine in the msi board aside from that quirk... only cpu ive ever seen that on. id maybe wonder if theres some kind of issue with the cache its able to train away on the msi board but its a blackbox.",Negative
AMD,"I 100% think it's current, and not voltage. I can't see voltage do anything but fry silicon, and that's not what's happening here. Voltage could make it jump wires, but that'd result in a short circuit protection tripping? And at 1,3v?",Negative
AMD,"When you enable EXPO, some motherboards automatically set VDDIO = Dram VDD, which is absurd.",Negative
AMD,I have a strix b850-f and 9800x3d ðŸ¥²,Neutral
AMD,only if youâ€™re the first purchaser of the cpu,Neutral
AMD,"There are issues with Gigabyte and MSI.   The way there subreddit are designed, technical support post don't appear everywhere, just like Nvidia's sub, it's limited to one megathread. That's why it seems like Nvidia never has any issues.",Negative
AMD,"GN on the initial reporting has said it has affected all vendors (they had a spread sheet tallying up user reports), but Asrock at the start was disproportionately affected, and the rest had numbers that was closer to standard deviation.",Negative
AMD,Because the internet is full of idiots that don't have the ability to think but great ability to jump on a bandwagon.,Negative
AMD,I assume this is sarcasm.,Neutral
AMD,"People, Asus owns pegatron. How does this misinfo keep getting spread? They are the same company. Even if what you said was true, they'd still be the same company. They make the same products.",Negative
AMD,"Wow I live in Taiwan and guys are teaching me what's the relationship between Asrock and Asus. Till this day we still call them big rock and small rock and trust me, there will always be some bounds as long as they are in the same industry. It is naive to think just because they are distinct in finance, their engineers won't share design or policy. And don't forget they both had questionable attempts shipping beyond stock default settings. Hell, Asus' default ""Multicore Enhancement"" was not even too long time ago.",Neutral
AMD,"https://www.reddit.com/r/ASRock/s/yRt1HFvGl4  https://www.reddit.com/r/ASRock/s/00vh3fDEAr  https://www.reddit.com/r/ASRock/s/k5QHlqWgxD  9700x, 9900x, 9600x, and the x3d's we've all heard about... and multiples of them... this was about 2 minutes of looking into it.  Its the entire lineup, with x3d being the majority. Funny... these are posted on r/ASRock...  But maybe my feelings have nothing to do with statistics?  Its also on multiple brands, the only commonality is the 9xxx series, whatever the mobo manufacturers are doing exasperates the issues with the cpu.",Neutral
AMD,"ROG STRIX X870-I GAMING WIFI. I've been updating my BIOS as they've been coming out. I'm currently on BIOS 1402, which is one behind the latest one available.",Neutral
AMD,"I hear thatâ€™s the one that runs very cool. My board doesnâ€™t have AGESA version that far back, but itâ€™s been working well since July",Positive
AMD,"IDK if I got a factory freak, but mine undervolts like crazy and runs really cool. I'm at -30, -25, -35, -15, -30, -30, -45, -50, and it stays in the 60s/70s in game. I only see temps in the 90s with prime95.",Positive
AMD,I can confirm I use an air cooler,Neutral
AMD,Gaming is usually not very hot except for shaders compilation or dragons dogma 2 lol. You are good,Positive
AMD,"yeah... superior in what way?  Worse temps, just as loud, huge and obstruct ram or cables... I had air coolers for 30 years. Finally got 360 aio this year and it's SO MUCH cooler. And it was exactly the same price as dark rock pro be quiet cooler",Negative
AMD,"The one which was released in December? Good to know, since I have b850i.",Positive
AMD,Yeah there are some theories that anything over 1.2V on core degrades it quicker.,Negative
AMD,"Not this puget chart, cmon bro ðŸ˜­",Negative
AMD,"Yup, X870E Nova.",Neutral
AMD,How is it an amps issue? The CPU draws as much amps as it needs and lowering voltage lowers the wattage used. Meaning it's not increasing amps to maintain wattage.,Neutral
AMD,How?,Neutral
AMD,How is this done?,Neutral
AMD,"VDDIO was 1.23v. I didn't enable EXPO, I set the voltages and RAM timings manually.",Neutral
AMD,Its electron migration that is the issue.,Negative
AMD,"lol good luck  To be honest I only went with asus because they were the generally best option for main boards forever and what I had before. Msi was always a runner up brand/tech.  After my experience with asus the x870e was on sale for the same price as the b850e rog board and honestly I was very surprised and pleased with not only the build/features but also how the bios works.  One feature I donâ€™t think I can ever go back on is a pcie eject button thatâ€™s easily accessible even with my old xfx 6800xt merc or the new 9070xt red devil.  But yeah, it was extremely consistent. Everything worked fine with the absolute original bios, update and left hwmonitor logging. The 9700x isnâ€™t supposed to go past 1.3v and post bios update stayed at 1.36v boosting to 1.39. Both started failing to boot proper and black screening after a couple of days of updating.",Positive
AMD,"Same, we're cooked.Â    I give it 6 months tops before I have to RMA the CPU. I'll be throwing the board away when that happens.",Negative
AMD,Its hilarious how you get downvoted because redditors don't like the truth.,Negative
AMD,"So how does that prove that anything else than 9000 X3D's are dying outside of normal failure rate? You have statistics made by people who tracked the issue:  https://www.reddit.com/r/ASRock/comments/1mvgndh/9000series_cpu_failuresdeaths_megathread_2/  There is probably something more recent as well.  Multiple brands? Okay. Let me ask you this then: why did it start happening on ASUS 2-3 weeks ago while it was happening on ASRock a year ago? That makes no sense if it's CPU fault.  Stop saying something like it's absolutely true when we still don't know why it happens. I'm not saying it's not something on CPU side, I'm just asking to stop guessing.",Negative
AMD,"Its a ASRock motherboard problem, my 9700x works fine on my msi mag tomahawk motherboard.",Neutral
AMD,"yeah when im gaming and not stress testing im 60-70, tdie mid-high 80s, im also at stock",Neutral
AMD,"Naw those folks above have something wierd going on, I -20 all cores and get 50-65 under load, 85-90 on prime95",Negative
AMD,Yes that's the one. It's also irreversible or something. Better not update if you haven't already.,Negative
AMD,"I think that was more so on the previous gen chips, when cache was on top. I typically like to keep mine at 1.3v or below when using eclk",Neutral
AMD,"Puget has been most reliable system builder to provide failure data for all hardware for well over a decade. Like article from 2014:   [https://www.pugetsystems.com/labs/articles/video-card-failure-rates-by-generation-563/](https://www.pugetsystems.com/labs/articles/video-card-failure-rates-by-generation-563/)  I still got their 2006-2010 data on hard drive somewhere that i got back in the day but i dont own any sata cables at home.  Just because u dont like the data, dosent mean its bad.  But when wendel claims 50% failure rate without any data in datacenters that somehow still buy intel (obviously not everyone but if 50% failure rate was anywhere near true nobody would buy them period) no one bats an eye, wild.",Positive
AMD,Damn. Did you get a refund for both mobo and CPU? How was the situation handled?,Negative
AMD,"It lowers the wattage used.. At the same amps. It will see headroom (allowed watt) and draw more amps. Unless there is an amp limit we can't see. The amps will absolutely cook the tiny contacts wires and vias in the chip, way more than volts.",Neutral
AMD,"Wattage = voltage (v) x amperage (a). If you lower voltage, you have to increase amperage to achieve the same amount of wattage.",Neutral
AMD,"So, a ""slow"" short?",Neutral
AMD,"Kind of wonder if we will end up seeing a mobo crackdown similar to what the GPU market went through. People may lament the loss of crazy partner cards but Nvidia and AMD limiting partner designs more over the years has resulted in less cards that do insanely dumb shit or don't meet a certain baseline of quality.   Whereas the mobo market still plays fast and loose on voltages, on boosting, on default settings pushing chips beyond defaults.",Negative
AMD,"Whatever, just gotta get used to it.",Neutral
AMD,"You said x3d chips are the problem, i showed evidence thats its beyond x3d's. Funny... your link also stipulates 9000 series, not just x3d's  Asus was also killing them from the very beginning. This link below is from the original megathread 1 year ago... https://www.reddit.com/r/ASRock/s/L6UjH7Qclg <â€ original thread  https://www.reddit.com/r/ASRock/s/1MfEJsIuYI <- failures by manufacturer from original thread, gave up counting after 15+ asus, about 5 giabyte and msi together, as well as being on 800 and 600 series boards, evidence contrary to your claim of being on 800 only.  True fact, the only commonality is a 9000 series cpu, true fact there is something the boards are doing to exascerbate an issue(s) with these cpu's. These are absolutely true.  I never claimed to know the problem, i never said it even was a problem. Having a weakness isnt a problem till it becomes one. Superman is still superman until he encounters kryptonite.   We just dont know what the krypronite is yet. But feelings have nothing to do with facts, i havent guessed anything and supplied evidence.  Might want to watch your own feelings here. Might be getting the better of you",Negative
AMD,"Except its not, all major brands of motherboard have been recorded killing the 9xxx line cpus.  Asrock has ~85% of them, asus has ~10%(and rising), MSI and gigabyte combined make up the remaining, with gigabyte being slighty more. All 600 and 800 chipsets. A,B,X prefixes  Most of these failures revolve around it being fine for a long time, then suddenly failing.  The only commonality is a 9xxx cpu, we just dont know the kryptonite yet. Amd once stated memory incompatibility, asrock and asus have changed bios to handle power  Hell I have a 9800x3d and a 9070xt, i'm not against AMD. I'm just looking at the data, the really only shared bit is the cpu line",Negative
AMD,"Nah, it's AMD problem.",Neutral
AMD,"iâ€™m at stock thatâ€™s why, but also sure those are your cores, whatâ€™s ur ccd/tdie?",Neutral
AMD,Yep. I am still on BIOS from October.,Neutral
AMD,It is a bad data but not because I don't like it.,Negative
AMD,"For now I sent back only the CPU to the retailer two weeks ago and it's at their service center. I'm still waiting for an answer, they are taking their sweet time.",Negative
AMD,That's not what I see when stress testing. Voltage lowers wattage. Meaning amps stay the same.,Neutral
AMD,The wattage rating on a CPU isnâ€™t a fixed power draw.,Neutral
AMD,had a asus b650 tuf gaming plus  board since 2022 with a 7800x3d and upgraded recently to a 9800x3d.  electronics are funny stuff,Positive
AMD,"Soooo, failure rate is supposed to be 0% across the board and if it isn't there is some major fault somewhere?  I hope you understand that electronics are bound to die prematurely or arrive DOA from time to time. QA problems, unknown issues, shipping, bad handling, etc... ASUS failure rate from the links you sent was pretty normal considering the popularity of the brand and sales they achieve. It started getting out of hand recently.  Just because the megathread includes non-X3D as well doesn't mean that they get fried the same way as X3D does. They are literally including them because that's how statistics works. You won't just ignore things. Whole point of including the non-X3D is to prove that X3D is the problem. The link you sent includes 165 X3D failures and 16 non-X3D failures. You shouldn't have counted either, they summed up everything near the end of the post.  It's good that you like to use ""evidence"". Now all that's left is to add the context and you'll have the objective picture.  Also, I'm sorry that you took my feelings comment personally. I didn't mean that. That's why there is no need to take this further, good luck to you.",Negative
AMD,Damn. What about the mobo? Is that still working 100% normally or did that get fried too?,Negative
AMD,"Amps never stay the same. Wattage is voltage x amperage. In order for wattage to increase, amps must rise when voltage is static. If you undervolt, by definition, you must pull more amps.",Neutral
AMD,That is correct.,Neutral
AMD,"Like you said, its pretty normal for the amount of Asus boards, and overall, it still is with the amount of boards they sell.   The second megathread has 80 x3d to 51 non x3d failures. Seems the issues is becoming worse. It went from  <10% and increased to 64% of what we have recorded.  Which is why i brought it up, the statistics are relevant and point to something within the whole line of 9xxx cpus, potentially a board manufacturer, but again the only real commonality is the 9xxx line.  If you want to ignore data thats fine, but saying to add context when we dont know the problem is a problem.   Having context implies we have the whole story to make sense of the details, at the bare minimum, having context means we can make sense of the details on its own. We cant, there is no context.  Like i said, we just dont know what the kryptonite is yet, thats the major fault. I never said there wasnt one, as qell as never said theres a problem, only that something is going on.   Again the only one seeming to base things on feelings, is yourself. The only one guessing has been you, stating its only on x3d with 800 chipset. When we have evidence its not only x3d, and not only 800 chipset. You scoffed at multiple brands, i showed you its not. You claimed asus only started this 3 weeks ago, i showed you they didnt.  If you want to keep spreading misinformation, do so. Ill keep basing things on my ""feelings""",Negative
AMD,"Can't know for sure until I get a new CPU but it's seemengly fine. I can do BIOS flashback with an USB no problem, and all the fans, RAM, and GPU light up correctly.  There are zero burn marks on either CPU or Mobo.",Positive
AMD,I'm saying wattage decreases... This is the second time I have said this.,Neutral
AMD,"CPU's apparently actually work very differently and it's not as simple as VxA=W and lowering the voltage with no boost in frequency also lowers current. If undervolting increases frequency, it may keep the current the same or slightly higher. So we're both wrong.",Negative
AMD,Damn. How did you exactly pinpoint the issue to the CPU then?,Negative
AMD,CPUâ€™s donâ€™t change the laws of electricity. I would expect the amps to be higher if you lower the voltage. That would be correct. They only stay the same if wattage drops.,Neutral
AMD,"I don't know how reliable the SP metric is but my 9950X3D is higher ranked than the fastest one according to my mobo.  I feel like the benefits of overclocking with these chips is essentially useless though, for longevity and efficiency I think I'm just going to go back to stock clocks.",Negative
AMD,on my 9800X3D  SP 114,Neutral
AMD,Well my 9950x3d has an SP rating of 120,Neutral
AMD,Or maybe a nice lil undervolt. As a treat,Positive
AMD,"Same as mine, but CCD1 bumps the overall so rating. My CCD0 is 117.25.",Neutral
AMD,"Sir, Reddit is the last place to be, if that's your concern.",Negative
AMD,Huh? I find they always list the sources at the bottom.,Neutral
AMD,Nice,Positive
AMD,"Wait, what?   Since when Acer makes GPUs?",Neutral
AMD,Sooo late :(  Would've taken this if launched earlier.,Negative
AMD,https://i.redd.it/sd1oiv9xw5hg1.gif,Neutral
AMD,They have been making GPUs at least since 2023,Neutral
AMD,"Started with Intel's Alchemist GPUs, now they're entering AMD I guess (not sure if they had 7000-series).  Edit: seems like they have AMD 7000-series.",Neutral
AMD,Didn't know that. Interesting.,Positive
AMD,"This post has been flaired as a rumor.   Rumors may end up being true, completely false or somewhere in the middle.  Please take all rumors and any information not from AMD or their partners with a grain of salt and degree of skepticism.",Negative
AMD,"A bundle where the most expensive part is RAM, not CPU + CPU Cooler.",Neutral
AMD,The DDR5 modules look remarkable. ðŸ˜… Are they even real?,Positive
AMD,Just re-release the 5800x3d and make everyone happy,Positive
AMD,"Out of the those 3 components, is that Coolermaster CPU air cooler as good as Thermalright PA/PS/RP? Where does it stack up in the competition?",Neutral
AMD,Canâ€™t wait to see the cooler and cpu combo for sale on eBay from  folks who kept the ddr5 module ðŸ¤£,Positive
AMD,"Those bundles will just be bought up by AI data centers they hoping for a CPU shortage so they can also benefit from the memory shortage, while creating a CPU shortage.",Negative
AMD,For the low low price of 2000 bucks,Neutral
AMD,you wouldn't need to make these bundles if you didn't fuel the AI fire by mentioning AI \~300 times on CES  and not like these will be bought by AI startups to get whatever RAM they can get  zen 3d restart is inevitable AMD,Neutral
AMD,LOL  sign of the times,Neutral
AMD,https://v-color.net/collections/ddr5-oled-xfinity-gaming-memory/products/oled-ddr5-manta-xfinity-argb-gaming-memory-amd-expo  EDIT: Corrected link,Neutral
AMD,I would love to upgrade my 5800x to a 5800x3d but i cant find one anywhere for less than a new 9800x3d. I would get that but i need new ram and motherboard and ddr5 would be insane right now to buy.,Negative
AMD,"What are they going to do with them? Landfill? After all, they're not useful for data centers.",Negative
AMD,"No, the AI datacenters don't buy the RAM. They buy some other chips that are made on the same factory lines as the RAM. We have a shortage because noone produces enough ram anymore.",Negative
AMD,That's not how this work. What you're describing are scalpers and not data centers.,Negative
AMD,"Vultures: ""write it down! write it down!""",Neutral
AMD,">you wouldn't need to make these bundles if you didn't fuel the AI fire by mentioning AI \~300 times on CES  The RAM shortages happened far before CES. AMD is hopping on the AI bandwagon but acting like they're completely responsible for this or that the RAM shortage would have magically ended if they didn't do their bullshit at CES is stupid  >and not like these will be bought by AI startups to get whatever RAM they can get  The shortage is as a result of memory production being diverted to HBM2, which is what data centers actually use. DDR5 is virtually useless to them.",Negative
AMD,We're at the point AMD could have skipped CES entirely not peddling the generative slop and data farming market and it wouldn't have changed shit when every other big tech company is 100% all-aboard. AMD is a drop in the bucket.,Negative
AMD,I don't think the last CES had any influence on the situation the planet is in.,Negative
AMD,...Data centers don't use consumer RAM sticks. Holy shit why does no one get that.,Negative
AMD,"V-Color. Whose DRAM do they use? Because it's going to be pricey AF if it's micron, hynix or Samsung.",Neutral
AMD,Fair enough.  ![gif](giphy|8ymvg6pl1Lzy0)  I didn't expect someone could come up with that design.,Neutral
AMD,Not the same cooler. This is a new CPU cooler that CM hasn't released yet as far as I know. You are probably thinking of the 612 Apex that goes for 80$.,Neutral
AMD,You can rent servers with these cpus without problems. Most of the time they are marketed in the game server categories since they arent epyc 4004/4005.,Neutral
AMD,">The RAM shortages happened far before CES. AMD is hopping on the AI bandwagon but acting like they're completely responsible for this or that the RAM shortage would have magically ended if they didn't do their bullshit at CES is stupid  every bit of trying helps, especially on one of largest electronics shows in the world  >The shortage is as a result of memory production being diverted to HBM2, which is what data centers actually use. DDR5 is virtually useless to them.  these LLM's need RAM and cold storage to store data, HBM2 is not built for this hence why RAM and storage prices are going up",Negative
AMD,"problem with what you said is that for NVIDIA GPU's to work they need a platform to hook to  that platform is epyc because it can handle tons of I/0 and tons of memory  so AMD could have easily rigged their CPU's to just throttle down to 400mhz the moment it detects AI workloads and they chose not to  hell AMD could have easily made their consumer CPU's just crash the system the moment internal scheduler detects AI workload is being executed, and use this to deter cheaters in gaming industry  but yeah lets not do that, lets do the stupid bundles which will get bought by scalpers and AI bros instead of normal people",Negative
AMD,"True, but they are allocating most of the ram production in favor of ai data centers which means much much less consumer grade ram memory on market which raises the price...",Neutral
AMD,"Exactly, I'm no fan of the AI focused direction they've been taking but I'm seeing some absolute room temperature IQ takes in this thread lol",Negative
AMD,Almost every large manufacturer uses the big 3. Only in China is there any other options.,Neutral
AMD,"Says xfinity on them, I would assume its verizon dram",Neutral
AMD,"From what I can tell from some fast googling, they mainly seem to use chips from SK Hynix.",Neutral
AMD,"Guaranteed SK Hynix DR A-dies is what they put in description. I ended up buying their V-Color Manta Ray 32GB CL30 @ 1.25v and itâ€™s been running really, really well.",Positive
AMD,Says they all use hynix,Neutral
AMD,Exactly I couldn't find this particular cooler review anywhere on the internet that's bundled with ram and 9850X3d,Negative
AMD,"Ah oops, missed the Pro part. I still imagine it would be pretty decent given how good the non pro is.",Positive
AMD,"Are you aware that HBM is a kind of RAM? One that has a very wide bus that allows for a very high bandwidth, and a very high bandwidth is precisely what LLMs need.  AI datacenters use HBM, not DDR.",Neutral
AMD,"1 of the funniest shit i've read in a while, gotta save this comment.",Positive
AMD,And nvidia should throttle and crash their GPUs when they detect an AI workload.  /s,Negative
AMD,Nvidia designs their own CPUs for their AI server hardware.,Neutral
AMD,"Sure, but the statement I'm replying to is so far off reality that part isn't even related.  Wayyyy too many people on reddit think hardware from these AI centers is 1:1 with consumer parts. Consumer parts are worthless for those centers, and the parts from those centers will never work in consumer builds.",Negative
AMD,"Nah in Europe you can buy CXMT modules (I have seen Asgard and Kingston so far) but I guess they are import restricted in the US.  but they are all limited to 5600 MT/s so far, which is fine in today's times.",Neutral
AMD,Do i have to return my ram after my 3 years contract is over?,Neutral
AMD,![gif](giphy|29nDtEH1ViY8FcPeaV|downsized),Neutral
AMD,"Shame, that means this isnâ€™t going to be cheap.",Negative
AMD,It was seen at CES this year. From what I know it should be a pretty good cooler. It's a single tower with 2 30mm LCP fans.,Positive
AMD,Yea should be pretty solid with two 30mm LCP fans.,Positive
AMD,"HBM is also space inefficient and HBM is vulnreable to interposer failure  those things do matter in datacenter applications which is why advancements in HBM has been power efficiency + density and not the bandwidth because bandwidth requirement was already met with HBM1  and once again, DDR and NAND flash still matters because not all data fits on HBM",Neutral
AMD,"This is the kind of dumb shit you'd expect to read over at r/pcmasterrace or something. I thought this subreddit being slightly more niche would filter out the dumbasses, but I guess I was wrong.  The fact that what he said about scalpers and bundles (even though bundles are some of the most effective scalper deterrents) isn't even the stupidest statement in that comment is genuinely astounding.",Negative
AMD,Jerk of the century candidate,Neutral
AMD,and still needs AMD CPU's to feed the GPU's because we talk about enormeous data sizes where ARM CPU's choke on themselves,Negative
AMD,what about people doing homelab setups to do local LLM's who do buy DDR5? they apparently don't exist,Neutral
AMD,CXMTÂ will get better. The current environment will speed that only up probably.,Positive
AMD,"I run 5600 DDR5, it's totally fine. I would happily buy CXMT if it was cheaper.",Positive
AMD,"To be fair that's what AMD says to use. Any higher and you're overclocking, which is ""dangerous"".",Negative
AMD,Only if you didn't pay off the remaining balance or ended the contract early.,Neutral
AMD,"Oh it is typical for here, Nvidia sends its worst astroturfers imaginable.",Negative
AMD,There is a lot of overlap between all the computer hobby subs. So expect to see the same names and same unhinged theories across all of them.,Neutral
AMD,Nvidia's giant AI servers use like 36 custom ARM CPUs. You're literally making shit up as you go.,Negative
AMD,Are those people in the room with us right now? If you think a small number of people using stable diffusion at home unprofitably are snatching up all the hardware I have a bridge in Arizona to sell you along with beachfront property.,Neutral
AMD,"I don't even think this guy is an Nvidia astroturfer. I think he's genuinely just that stupid. I don't even see how saying that AMD should rig their CPUs to shut down whenever they detected an AI workload (lol) would benefit Nvidia in any way. This is just a completely uneducated person mindlessly frothing at the mouth to attack anything related to AI or ML.  Like, I have a lot of grievances with what AI is doing to our society and how it's been affecting the DIY PC market, but Jesus, he gives us a bad name.  Shit, maybe you're right and that's what he's being paid to do lmao. But that doesn't exactly hurt AMD either lol",Negative
AMD,"and that is still not enough because people and AI startups combine NVIDIA GPU's and AMD server CPU's  hell people started switching to AMD altogether because it is cheaper and performs better than NVIDIA due to open source nature of driver stack (having CUDA isn't enough once you leave windows infrastructure)  AMD deserves every bit of hate they get, they actively chose to compete in the AI bubble",Negative
AMD,"small amount of people you say? if thats the case than why does AMD sell so many 9950x's these days?  why did 7950x and 5950x prices go up the moment people started doing local LLM work?  just look at how prices of mini PC's and raspberry pi's have gone up by like 2-3x after AI bubble hit to the point that you have minisforum sell mini PC's with no RAM and storage included  but go ahead and assume they aren't in the room, be completely unaware of how people use local LLM's and/or chatGPT to cheat in their exams",Negative
AMD,">hell people started switching to AMD altogether because it is cheaper and performs better than NVIDIA due to open source nature of driver stack (having CUDA isn't enough once you leave windows infrastructure)  I too enjoy a good fairytale.   >AMD deserves every bit of hate they get, they actively chose to compete in the AI bubble  Sure, but we don't need to fabricate reality as we go. There's enough real things to be annoyed with big tech over.",Positive
AMD,">if thats the case than why does AMD sell so many 9950x's these days?  9950x are usable for a lot of things not just AI. They've been making expensive high end SKUs for longer than the AI bubble has been a thing for a reason.  Also it's like $40-50 more than a 9800x3D on Amazon. It's way below MSRP. So... if someone wants a lot of cores it's not that bad of price.   >why did 7950x and 5950x prices go up the moment people started doing local LLM work?  The 7950x is below MSRP too with the bare minimum of searching. The 5950x pricing varies more, but it's out of production and the last 16 core processor that can take DDR4 RAM.   >just look at how prices of mini PC's and raspberry pi's have gone up by like 2-3x after AI bubble hit to the point that you have minisforum sell mini PC's with no RAM and storage included  Everything that uses DRAM has had the costs go up. For a low price lower margin product that will inflate the price more. If it's harder to secure a stable supply of a component and the price of said component goes up a ton the economics of a $30-40 dollar SoC goes out the window.   Anything using DRAM or NAND will have the price increase or the margins worsen. That doesn't mean every phone or video game console is being used by ""AI data centers and home labs"" FYI.   >but go ahead and assume they aren't in the room, be completely unaware of how people use local LLM's and/or chatGPT to cheat in their exams  That doesn't require that much hardware, and most people doing that will be using the online GPT or Gemini or whatever. They aren't buying up stacks of RAM.",Neutral
AMD,If Gigabyte made an ITX version of the Aero Wood Version I'd lose my mind...,Neutral
AMD,The gigabyte aero x16 would be an interesting budget-ish thin gaming laptop but the 85w TGP (including dynamic boost! Itâ€™s really more like 70w) kills it.,Negative
AMD,"As a Gigabyte OLED owner, I can say that Freesync is utterly useless on it, and by extension probably on all QD-OLEDs (don't know about WOLED). Look up VRR flicker if you aren't familiar with it. Even having VRR on in Windows is driving me nuts. Every menu you open, or window you minimize, causes brightness flicker.  Luckily, the refresh rate on OLED is so high that you can disable Freesync and never see tearing, but using the term Freesync for OLED marketing is a bit weird to say the least.",Negative
AMD,Too Expensive.,Negative
AMD,Itx boards pretty please?,Neutral
AMD,I have an MSI QD-OLED and the VRR flicker only happens for me when my FPS drops below let's say 40 or 30 which is never since low FPS would be an unplayable problem for me anyway.  Basically the only reason why I know what the flicker looks like is because of loading screens.,Negative
AMD,"i have an Agon QD-OLED and yes indeed, Freesync is practically unusable for anything cause of the flicker which is particularly noticable in dark games, but luckily so far i havent exprienced issues with the Enhanced sync",Negative
AMD,Selection bias is a helluva drug. And all this because 2 years ago one goober installed their AM5 CPU with the system upright and it got reposted everywhere.,Negative
AMD,"Itâ€™s hard to say whether itâ€™s directly the boards fault or other issues.  Faulty PSU, maybe the user overclocked the living hell out of it. Maybe the cooler was incorrectly inserted resulting in improper cooling. A lot of factorsÂ   Edit: yes it could definitely be AMDâ€™s fault. Bad silicon does happen, but that isnâ€™t to say that all of these failures are AMDâ€™s nor the motherboards fault.",Negative
AMD,"the problem with these articles is even though they are reported as such doesn't mean that the motherboard is actually the cause.   Like i have a high suspicion that early 9800x3ds had some sort of defect or issue.  The 9600x i can't say.  Asrock, whether you like it or not, are more for budget conscious builds so there is going to be more of them in use.  Some of these issues can be user error.",Negative
AMD,"We certainly need some clarification on the ASRock CPU death issue. Even ASUS boards have been reported recently as a cause of AMD CPU deaths.  My personal experience, 9950X3D on a X870E Nova, no death yet after \~6 months. I see other commenters have mentioned power supplies, mine is a Corsair HX750, so on the upper end of PSUs. Not absolute top tier, but definitely mid range+.   If my 9950X3D is killed, I'll just RMA the CPU & board. Sell the board, buy an MSI/Gigabyte board. I just like the Nova because of 4/5 NVMes without lane sharing/etc. But I'm sure I can find an MSI board with this feature. Had I known, I would have avoided ASRock, but it was already in shipment when I found out about ASRock issues. Not worth the effort of returning.",Negative
AMD,"Great, my wife's got a 9600X on an ASRock B850I Lightning WiFi. It's been running since October last year with the latest BIOS.  Guess all we can do is keep our fingers crossed?",Positive
AMD,"Probably just another case of cheaply built board symptom, which because these motherboards use cheap vrms inevitably kills itself and the CPU. Can AMD start imposing stricter requirements on manufacturers already?",Negative
AMD,"this isn't news, it has been happening 24/7 for a year or so soon. just spamblog spam.",Negative
AMD,"Asus x670e tuf and day one 9800x3d, I hope nothing will happen. But it seems there are no reports of death with my combi",Negative
AMD,I recenly had a 9600x die in the Asus Tuf b650.,Neutral
AMD,"ASROCK, the gift that keeps on giving, something like Pandora of Greek myth.",Positive
AMD,"Question is, *why are the boards supposedly killing CPUs*?  And why are other boards doing it too, albeit to a lesser degree?  If it were something that ASrock can fix, they would fix it. They themselves seem to be at loss, while trying to figure it out by changing mobo settings via BIOS update. They should also be working close with AMD on this and yet it seems they're being left on their own.  The folks, that have no issues and yet claim they have it figured out, cannot actually be sure if their ""fix"" works, if they never really encountered the problem.  What i find concerning, is that AMD just replaces each of these CPUs without questions. Shouldn't they be more reluctant? It's almost as if they're afraid of someone investigating *them*, or leaking internal info.",Negative
AMD,"I have the asrock x870 steel legend with my 9600x, everything works fine. Had a minor hiccup 1 month after installation where pc would not boot (the red and orange lights on the motherboard were stuck on), thought i burned my cpu, i flashed my bios to a very old version then re updated my bios to the latest version, put the same settings as i had before but i also overclocked my cpu,gpu, ram. It's been months now and there are no issues.",Neutral
AMD,Why we are not killing ASRock boards with a hammer ? Ah ?,Negative
AMD,"buy budget, get budget results.",Neutral
AMD,"Meanwhile i'm hoping my 9800x3D will fail soon, paid inflated prices a year ago and since AMD only issues refunds, if i were to RMA i'd be able to buy a new one and still have $250 left lol",Negative
AMD,People still buy Asrock...,Neutral
AMD,Idk if it's entirely that because other motherboard brands had the whole 7800x3d fiasco but don't get post nearly as often as ASRock does these days. It could be that ASRock has a 0.6% failure rate over a 0.1% other brands have or etc where problems rarely occur but since their rate despite being low is worse than other brands it's just brought up more often.,Negative
AMD,I don't think so.  [https://www.reddit.com/r/ASRock/comments/1q3ff0t/9000series\_cpu\_failures\_deaths\_megathread\_4/](https://www.reddit.com/r/ASRock/comments/1q3ff0t/9000series_cpu_failures_deaths_megathread_4/),Negative
AMD,You forgot the possibility of bad silicon,Negative
AMD,No one ever thinks it could be AMD?,Neutral
AMD,My guess is user error or abuse. Easy to get Reddit sympathy because the internet will always take the side of the Redditor posting a sob story.,Negative
AMD,"Maybe their house has really dirty power, or infrequently has dirty power, and they have no UPS with PFC",Negative
AMD,"Asus boards killed 2 cpu im extreme testing and internet and GN goes wild. When ASrock kills 4 board everyday: ""It must be some other issues""",Negative
AMD,Or it just a normal thing to stop working for cpu after 3-7 months itâ€™s already old cpu. Hence why they released a new 9850x3d.,Neutral
AMD,"And in use with other budget equipment, like cheaper power supplies.",Neutral
AMD,"I could see it having been the processors fault if these deaths would have died down over a couple of months or if we had seen a proportional amount of deaths across all motherboard manufacturers. Fact is that we are over a year out and many batches of CPUâ€™s have been made. The deaths are mainly happening on ASROCK boards with the occasional death on other motherboards.  Edit: downvote all you want but provide an explanation to why this is mainly happening on ASROCK motherboards? Explain why it is not limited to just the 9800X3D (other processors have been killed). Instead of downvoting, provide some information on why my theory may be wrong.",Negative
AMD,my 9800x3d brought last year died about 6 months after install on an asrock board so definitely not an early one.,Negative
AMD,"There are speculations that X3D must be using copper bump connections, and there must be resistance imbalance due to microscopic misalignments and contact defects, with that much current spread across so many bumps to starting the classic heat->resistance drop->current concentrates->more heat->catastrophic failure loop like we saw with 12VHPWR/12V-2x6 GPU power plugs  zero proofs but it's one plausible theory among many",Negative
AMD,"> Asrock, whether you like it or not, are more for budget conscious builds so there is going to be more of them in use.  This keeps getting thrown around in the asrock sub but all evidence point to the contrary. Feel free to post any concrete data from any vendors that show asrock boards ahead of any of the other major manufacturers.",Neutral
AMD,"Sincerely doubt it's just an ASRock issue.  There's so many variables here, and i'm betting on early 9th gen Ryzen being defective.",Negative
AMD,"Given that the 9800x3d has a ~0.6% rma rate in germanyâ€™s biggest computer store, I think youâ€™re fine lol",Positive
AMD,"Nothing gonna happen, donâ€™t even think about it",Negative
AMD,"Zzz more selection bias again. How about RMAs at retailers, or system builders?",Negative
AMD,if it was amd it would happen on all boards,Neutral
AMD,It almost seems to be damn near impossible to get a bed CPU. But as they've gotten more complex and the notes of shrank and the chances have increased.,Negative
AMD,"GN bought multiple asrock killer mobos from users and were unable to recreate the issue or to find out why it happened, last I saw.",Negative
AMD,"Yeah, no... This is not what's happening. A lot of analysis (also by Gamersnexus) has gone into ASRock boards and nothing could be found until now. Also, Gamersnexus hasn't gone ""wild"". Where did you get that from?",Negative
AMD,Gamers Nexus literally bought the boards from Redditors one year ago and they didnâ€™t manage to fry a single CPU with the exact same Asrock boards despite the fact that theyâ€™re actively trying to do it.   But nobody wants to blame AMD for the bad silicon,Negative
AMD,Ragebait used to be believable,Neutral
AMD,"I've been thinking for a while that the problem is actually something like bad solder paste application where the socket is soldered to the board, like the mask was offset or too much was used or something and once enough current goes through the bad solder joint it creates it either melts and goes where it's supposed to or melts and goes where it shouldn't. It's the only thing left that makes sense to me after seeing some of these boards still work after the socket was replaced with no apparent defects that could be found... maybe there's no defect found because repairing the board to where it can even be tested wipes out the evidence of the issue. I don't think I've ever seen anyone do electrical continuity tests on all the pins in the burned socket to see if there are any pins bridged that shouldn't be beyond shared common VCC or ground. It would definitely be more widespread if it was an AMD production issue but it's pretty clearly limited almost completely to ASRock. It's simply logical to suspect that when all the boards still work when testing, the minimal repair to the burner area required to even test them is fixing what was wrong to begin with.",Neutral
AMD,"The higher number of cases could just be that Asrock boards are more popular. They do offer more features for a lower price compared to other boards. Without concrete numbers, we canâ€™t really say anything about this issue. Maybe Asrock boards are 10x more likely to kill CPUs than other motherboards, but that doesnâ€™t matter when this has a 1/1,000,000 chance of happening or something minuscule.",Neutral
AMD,"To me its really ASROCK as the majority culprit. If its not, why are they like 95% of the reported cases.",Negative
AMD,"And ASRock **used** to be primarily a manufacturer of budget boards before they were spun off from ASUS. I don't think any motherboard over $300 is ""budget."" These board prices have become so inflated with offerings like MSI's GODLIKE primarily to push profit margins. There's nothing really magical about them that would convince me to throw $1200 on a motherboard. That's just psychotic.",Negative
AMD,"It has happened on other boards, just nowhere near the same amount as on Asrock.",Neutral
AMD,Tell me a board vendor it doesn't happen on...,Neutral
AMD,"GN pretty much said that Asus burned boards like Asrock does now but with only 2 confirmed cases of extreme overclocking in their bag. Then instead of contacting Asus before releasing their piece they just release it over the weekend so Asus can't respond in 2 days so their piece can get traction which it got. Also tried to give Asus backlash for their beta bios disclaimer like it was something new when it wasn't.  Asus ""fixed"" it with their beta bios in a workday or two then a week later with a official one.  Love them or hate them. This is how GN works. They like controversies.",Neutral
AMD,"I still suspect that the houses they came from, or the psus that were attached, were feeding the systems dirty power, and it was the combination of dirty power and ASRock riz that caused the burnings.",Negative
AMD,AMD is the halo child on reddit. They do no wrong and its everyone else's fault.   Remember there the billion dollar underdog that everyone should feel sorry for.,Negative
AMD,Whatever GN has done. The fact are still there. ASrock boards still had major issues when other board brands doesn't. ASrock can't even fix this with a quick bios change like Asus did.,Negative
AMD,"It could be a design flaw that is inherent in the CPU, and that Asrock motherboards just make it more apparent. The fact that AM5 CPUs have died for all motherboard vendors does make me think that.",Negative
AMD,"They are popular but ASROCK is not selling more than MSI, Gigabyte or ASUS. The Taichi models were popular because they had provided very solid offerings for a good price the last few generations.   Even if they sold a lot, go to another sub and see how many reports of sudden processor failure that you find. Youâ€™re going to be hard pressed to find a mention of it on other subs because itâ€™s hardly ever happening with other brands. Even ASUS (who has come into the spotlight recently) didnâ€™t start having any issues until basically a year after the processor was released. That leads me to assume that they may have released a buggy update of some sort for their motherboards.",Neutral
AMD,"I barely see any CPU killed by MSI or Gigabytes this gen. Also, I don't believe Asrock sells more than those two. In most of countries Asrock aren't even an option.",Negative
AMD,">They do offer more features  I think this might be the cause. My asrock board has *way* more options than I've ever seen on a motherboard before. I've had it for a year and a half now and still don't know what a lot of them do. It makes me wonder if people are messing with options they don't understand, which is actually frying things.  my system: asrock x670e taichi, amd ryzen 9 7950xt, amd asrock rx 6950xt. it's been great so far, only a single issue having to do with resuming from sleep with a keyboard. I have not overclocked anything because i haven't needed to.",Neutral
AMD,"Yeah, I remember when ASRock was definitely the budget brand, but after a certain point I began noticing I liked the ASRock boards I was buying more than my Asus or Gigabyte boards.",Positive
AMD,"Yeah correct, but thats fine if its within the standard failure rate %, ASRock is like really standing out with failures.",Negative
AMD,"MSI and Gigabyte is absolutely negligible, especially considering each has a greater market share than ASRock. ASUS AMD CPU Deaths are also not proportional to their market share which is more than 40%. ASRock is evidently 95% of cases.",Negative
AMD,">AMD is the halo child on reddit. They do no wrong and its everyone else's fault.   You are just crying out loud. There have been multiple investigations, and no one could realize what really happened.",Negative
AMD,"Sure, show us the data to support your claim.",Neutral
AMD,"Only the Asrock subreddit has a dedicated mega thread for these failures, which could make the issue seem bigger than it is in reality. Ryzen CPUs have died on other motherboards vendors as well, so I think that this issue is AMDâ€™s fault.",Negative
AMD,We have no idea if this is standard failure rate that's literally where all the speculation comes from,Negative
AMD,Mate we have no idea how widespread it is we're on reddit reading articles about reddit posts,Neutral
AMD,It not my job to show you the facts that has been are right infront of you in this and other tech subs and articles for months.   But Im sure that if you google ASrock boards killing cpus then you can find what you're searching for.,Neutral
AMD,By other vendor you mean ASUS? They are basically the same.,Neutral
AMD,">It not my job to show you the facts that has been are right infront of you in this and other tech subs and articles for months.   So, is it as easy as this? You make a random claim, people ask for sources and you just tell people to search for you???",Negative
AMD,Go touch grass. Its not like im stating something from aoem obscure science paper in India. Even your saviour tech jesus GN made several pieces on the matter.,Neutral
AMD,>Go touch grass.  That is your argument now? LMAO.  >Its not like im stating something from aoem obscure science paper in India. Even your saviour tech jesus GN made several    pieces on the matter.  Tell me their conclusion.,Negative
AMD,Anyone tried gow 2018 to see if ahadows are fixed with 9000 series,Neutral
AMD,"Darktide still not listed as known issue , amd is even ghosting Fatshark ( dev of darktide / vermintide ) for 1 year....Â [https://forums.fatsharkgames.com/t/investigation-poor-performance-power-draw-issues-impacting-amd-radeon-6000-9000-series-gpus/107462](https://forums.fatsharkgames.com/t/investigation-poor-performance-power-draw-issues-impacting-amd-radeon-6000-9000-series-gpus/107462)",Negative
AMD,No clue whats up but my first crash after installing the drivers completely uninstalled Adrenlin software. First time seeing that happen.,Negative
AMD,Roadcraft - Crash   Factorio - Crash   Borderlands 4 - Crash  This driver is a gammon. How on earth has this made it through QA. I've rolled back to 25.12.1,Negative
AMD,Thank god its optional amirite,Positive
AMD,Roadcraft crash in 9070XT after 26.1.1,Neutral
AMD,Another AI Crap,Negative
AMD,So...what exactly should this thing be used for? Ask if the driver is working? Can't understand why it's there and what is the use for it.,Negative
AMD,Did adrenaline get really leggy for anyone else with this update?,Neutral
AMD,Anyone tried Starrail yet to see if the error pop up still comes up? Like for mine the game still runs fine but stutters for a few seconds on launch and crashes adrenaline.,Negative
AMD,destroyed my 6800,Negative
AMD,Does the ai bundle also for 7900xtx?,Neutral
AMD,Nueva versiÃ³n y aÃºn no arreglan el problema de crasheos en battlefield 6,Neutral
AMD,im on 25.9.2   it works fine there,Positive
AMD,"If shadows are wack for whatever reason, file a bug report and use DXVK GPLAsync in the meantime",Negative
AMD,No,Neutral
AMD,No,Neutral
AMD,"Cyberpunk crashes are also not fixed but we get AI, yay!",Positive
AMD,"It's unbelievable that the game is still broken and AMD just doesn't care one bit. I love the game but can't play it as it's a stuttering / low FPS mess. The worst part is my GPU only seems to use 50% or less.  I'm not sure what's wrong, but the AMD driver just doesn't seem to treat it like a game and allocate high power mode to the GPU.",Negative
AMD,It's optional and when you use it it's local running on your own GPU.,Neutral
AMD,Ai image/video gen with comfyUi etc. and local LLMs,Neutral
AMD,"I get random crashes, no lag though.",Neutral
AMD,For the time being it's optional.,Neutral
AMD,Its optional and not clicked by default. Its litterally only a benefit. If you accidentally click custom install then accidentally click each ai tool on you dud something wrong.,Neutral
AMD,How that?,Neutral
AMD,From what I've heard it's for 7000 and 9000 series. So yes.,Neutral
AMD,Cyberpunk just crashes at the logo for me. I hear like a second of sound and then back to the desktop.  Edit: Reverted back to 25.12.1 and it is working again.,Negative
AMD,yay  :),Positive
AMD,"On Steam or GoG? I have the GoG version and I rarely crash, even with mods. I mostly have problems with the launcher sometimes, but not in the actual game itself.  That said, it's odd and bad that Cyberpunk crashes aren't fixed given how big of a game it is. AMD really ought to do better.",Neutral
AMD,Atleast the the pink path tracing is fixed  How long roughly does it take to crash for you? I drove around the map for a good 10 mins to see if the path tracing was fixed and it didn't crash,Neutral
AMD,How do you actually generate images and stuff?,Neutral
AMD,I am having a blast with it so far.,Positive
AMD,You only see these if you click custom. And they are not including the files only options to dl them.,Negative
AMD,"While I agree I think TPU got it right when they speculated as to why AMD did this the way they did. Drivers are just more far reaching as compared to a web page. AMD clearly wants far more people working with ROCm and knowing that they're capable in AI development and this was the most wide spread way for them to do so.   Thankfully, it's optional so it shouldn't have much of an impact in day to day use.",Neutral
AMD,"when I go to install the new 26.1.1 I dont see the option, even though its for 7700 or newer, 7900xtx is a part of that so was wondering if anyone else knows whats happening?",Neutral
AMD,"If you have mods, delete your r6/cache folder + verify files via Steam. if you tried this already, then RIP.",Neutral
AMD,"1. Have you tried using the command ""  --launcher-skip "" in launch options?    2. Also might sound very basic, but have you also tried to run the game as administrator?    3. Do you have all the Visuall C++ files installed? (Like the Visual Redistributable 2015-2022?Even the newer ones)   4. Turning off all overlays.   5. Rolling back the drivers to... well, older ones, I always keep an install of older drivers just in case (Like 23.12.1, 24.4.1, 25.6.3, which I found very stable for me personally)   If any of these doesn't work, there's a guy with 17 mins of fixes on youtube, lel",Neutral
AMD,ComfyUi for more advanced stuff. Amuse for sinple beginner friendly stuff,Neutral
AMD,Really?  The collective Nickelback AI hate boner is so massively erect that we're now downvoting anyone who has the audacity to say on the internet that they're enjoying locally ran AI?  It's like the one mostly harmless use case for AI. Come on people.,Negative
AMD,Press custom install.,Neutral
AMD,I don't have any mods and I already tried verifying & restarting.  : /,Negative
AMD,"1. Just gets to back to the desktop quicker as I don't have to press play on the launcher 2. Same CTD 3. I'm pretty sure I have as the game ran fine just a few weeks ago. Installed the newest one 2017-2026 ones. Didn't help. 4. Disabled Steams overlay and closed RivaTuner, which I use to limit fps in GTA or The Witcher. Didn't help. 5. Never done this before but I guess it's worth a try now.  Btw tried it with disabled HDR and also didn't help.  **Ok reverted back to 25.12.1 and the game works again**. Wow.",Neutral
AMD,"Wasn't working, had to install driver, than there was an AI tab at the top of the software that let me get the bundle through there.",Negative
AMD,"Yeah, ugh damn. Very sorry to hear you're having issues. AMDpls :/",Negative
AMD,"Lovely to hear this, also this is why I keep a pair of older drivers, they just randomly work XD Have a blast, sir!",Positive
AMD,I'm going to try a reinstall tomorrow and see if that helps. I didn't have had anything like this before until now :<,Negative
AMD,Reinstall did not help. ;\_;,Negative
AMD,"There is an issue where you have to delete the newest auto save and then turn off auto save. Worked for a bunch of friends of mine.Â  Give it a try.Â  If it works, not an AMD issue.",Neutral
AMD,I deleted all AutoSave folders and it still crashes to desktop after the Cyberpunk 2077 splash screen animation. I see like less than a second of the CD Project Red logo and then it's gone.,Negative
AMD,Please do not burn my CPU while also causing CPU shortages in the near future thank you....,Negative
AMD,"But Asus has all its BIOS in beta, and that voids the warranty. ðŸ‘€",Neutral
AMD,i lowered my SOC to 1.22v and turned off precision boost overdrive for the meantime. better be safe than sorry,Neutral
AMD,"ASUS- ""voiding warranties since 1886""...",Negative
AMD,"I've long suspected that the ASRock 800-series motherboard issues had more to do with poor 9800x3D QC practices by AMD than the boards. The same issues being encountered with the same series of boards made by a *different* company is definitely lending some credibility to this theory. If true, this doesn't fully absolve ASRock or ASUS but it should certainly shift the spotlight towards AMD.",Neutral
AMD,"Didn't we already go through this with the 7800X3D & ASUS motherboards?  As Bush once said ""Fool me once, shame on you. Fool me...you can't get fooled again""",Negative
AMD,"Hey OP â€” /r/AMD is in manual approval mode, this means **all submissions are automatically removed and must first be approved before they are visible to others**. This is done to prevent spam, scams, excessive self-promotion and other rule-breaking posts.  Your post will be approved, provided it follows the subreddit [rules](https://www.reddit.com/r/Amd/about/rules/).  **Posts regarding purchase advice, PC build questions or technical support will not be approved.** If you are looking for purchasing advice, have a PC build question or technical support problem, please visit the [Q1 2026, PC Build Questions, Purchase Advice and Technical Support Megathread](https://www.reddit.com/r/Amd/comments/1q1efc5/pc_build_questions_purchase_advice_and_technical/).   *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Amd) if you have any questions or concerns.*",Neutral
AMD,"Absolutely NOT a fan of ASUS, given their behavior over recent years, but that statement IS completely false. They stopped doing that shit back in May of 2023. Of course, they did replace it with god awful customer service, and trying to actively scam people with their RMA service, but still, the point stands that all BIOS are now covered by warranty.",Negative
AMD,"ASUS- ""voiding warranties since 1886""...",Negative
AMD,This is false. [Both official and beta BIOS updates are covered under warranty](https://www.asus.com/us/news/ihctikmgahafyrib/).,Neutral
AMD,it was above that before?     Expo on my gigabyte X870 board has the SoC voltage at 1.195V out the box,Neutral
AMD,"They are both owned by pegatron and share practices. For all intents and purposes, Asus is Asrock in everything but name.",Neutral
AMD,That wasn't an ASUS issue,Neutral
AMD,"No, that was ASRock. Still is ASRock, too, as they seemingly haven't done anything to fix the issue.",Negative
AMD,"Only for AM5, not for the rest",Neutral
AMD,yeah my stock board + expo had a current reading of 1.238 soc on auto,Neutral
AMD,"Incorrect. ASRock started as an ASUS brand that was later placed under the Pegatron umbrella when ASUS spun it off into an independent company. ASUS is still Pegatron's controlling shareholder, but they've significantly divested from them over the years. They currently own 16% of Pegatron.   Pegatron started with legacy ASUS manufacturing assets but established independent processes not long after their split. They have their own in-house blend of plastics, metal tooling, thermal system design features, and RF validation labs. However, the two companies still have similar supply chain clustering.",Neutral
AMD,"it was, Asus boards were literally burning up 7800X3D chips",Negative
AMD,"No, it was Asus with the 7800X3D     [https://www.youtube.com/watch?v=cbGfc-JBxlY](https://www.youtube.com/watch?v=cbGfc-JBxlY)     [https://www.youtube.com/watch?v=kiTngvvD5dI](https://www.youtube.com/watch?v=kiTngvvD5dI)     Asrock has had no issues with 7000 series chips, it's the 9000 series chips, especially the X3D ones that they have been killing multiple per day for close to a year.",Neutral
AMD,That's not been a thing for nearly 3 years. May of 2023 they changed their warranty coverage so that Beta BIOS was covered in the same way as regular BIOS.,Neutral
AMD,"So when pegatron makes boards for both asrock and asus, sharing practices between them both.. you are stunned both have the same failures and suddenly its about semantics of who owns how much of what when they are making boards at the same factories?",Negative
AMD,"Nope, the issue came from another company that needed to fix their shit which also needed to wait on AMD's approval to get released",Negative
AMD,"You can't make objectively false statements and then expect to be taken seriously, mate.",Negative
AMD,"which ""other company"" was responsible for Asus overvolting VSoC when Expo was enabled with 7000X3D chips?  you can't just sit and lie, it's publicly known that Asus was the only one killing 7000X3D chips and the issue was wholly their fault to the point where AMD had to put a hard cap on VSoC after that to protect customers from board vender stupidity.",Negative
AMD,Don't remember the name. However this is a fact,Neutral
AMD,"it's not a fact, it was Asus, and if Asus is relying on an external company to configure their bios and set unsafe voltages then guess what, it's still Asus's fault, no other board vendor had this issue.",Negative
AMD,It also affected MSI and not just ASUS. It is a FACT,Neutral
AMD,"got any proof? every single 7800X3D burning report or result i've found has involved an Asus board      you're making empty claims blaming it on some ""unknown company"" with no source and saying MSI was also impacted, but again with no source.",Negative
AMD,"https://www.theverge.com/2023/4/27/23700688/amd-ryzen-7000-x3d-cpus-burnt-out-am5-motherboard-fix  Here it quite clearly says 'AMD has resolved the issue', not ASUS has resolved the issue  Do your research correctly next time",Negative
AMD,Whatâ€™s insane is the IPC of the Darkmont E cores in Pantherlake seems to be better than AMDâ€™s zen5 P cores.,Positive
AMD,"Now they just need to put this in a desktop package, slap some BLLC (Big Last Level Cache) on that mfer and we're talking. And by the time they've done that, Zen 6 is here. So we'll see. The end of the year will be interesting.",Neutral
AMD,"I'm very hopeful for Intel on this gen and Nova Lake I'm very excited about.Â    Intel in benchmarks though was always hit or miss due to cache issues and lack of avx 512. Canned benchmarks they did good on, but a lot of apps were starting to get avx512 optimized more and they would lose HARD there. Not only that but there were certain games where it was just catastrophic, and not due to windows e core issues.Â    Look at Homeworld 3 CPU benchmarks (I know it sucks).",Positive
AMD,Give me barlett lake for lga 1700. Its all I care about.,Neutral
AMD,"Great to see good competition, we need to wait for Zen 6 for more equal comparison (18A vs 2nm cores)",Positive
AMD,"AMD doesn't really have P cores  Great job Intel though, this is what we like to see",Positive
AMD,It's Mobile Zen 5 Cores that have lot less cache,Neutral
AMD,"Why? AMD still uses 5/4nm, that is a tech from 2020.  They can move to 3nm, and their performance will be in pair. They just did it to make as much profit as they can.",Neutral
AMD,Yeah. We gonna have a 28 core with bllc cache with novalake. They also making a 28 core with no bllc cache.,Neutral
AMD,"Intel has this golden opportunity to just rule the new DDR4 world while AMD plays pretend like people are still buying DDR5, but instead Intel wants to play pretend, too.  It's sad how stupid Intel's strategy people are.",Negative
AMD,"This. As a early adopter of the 12900K, all the shait we had to go through with Intel/W11 software just to make it work and not to mention 13/14th gen issues.. I mean sure, now 12900K is superb, but still. We deserve Bartlett Lake K.  Would love to OC that juicy chunk of a CPU.",Positive
AMD,still much bigger than darkmont E core,Positive
AMD,18mb vs 16mb so a pretty fair comparison.,Neutral
AMD,The e-cores have no micro-op cache.,Neutral
AMD,"Except it's not as easy as cramming more transistors into the same space... You can increase perf/W that way, but not really an IPC, that's all about architecture.",Negative
AMD,"> They can move to 3nm, and their performance will be in pair.   A pure node shrink doesn't give you any IPC benefits. IPC is dictated by the underlying architecture. It might help their boost clocks and energy efficiency, but it doesn't improve IPC.",Neutral
AMD,Except we are running out of ddr4 stockpile and the prices are starting to reach parity unfortunately.,Negative
AMD,"TF? AMD literally just released 5900XT which is basically a renamed 5950X not too long ago and still selling. Also, don't bet on DDR4 as those prices are hiking too now.",Negative
AMD,He's saying mobile zen 5 has less ipc than desktop zen 5,Neutral
AMD,Panther Lake is also Mobile. So itâ€™s a fair comparison.,Neutral
AMD,Yes I agree but does ipc differ between intle mobile and desktop with the same core?,Neutral
AMD,Spec is dependent on Cache size and Memory Latency outside the core IPC,Neutral
AMD,Yep,Positive
AMD,"Let's just wait for products to hit, maybe Intel is going to hit it out of the park, but they have a long way to go before I will trust their marketing slides.   AMD is no better in that regard, I'm not just shitting on Intel.   In all honesty, I'm pretty happy Intel is doing better on the iGPU side, cause it was so bad for so very long.   My laptop is currently an i7-1185g7, not their best showing, but was a step in the right direction on the iGPU side.   Not anything I would have bought brand new, but being a refurbisher in my spare time has perks.   My laptop is always 3-6 years old.",Positive
AMD,Intel's been down this road before. It's not worth it. 14900HX is the only reminder you need. How fast does it need to be before we start talking about just putting a GPU in? If I'm getting a laptop why would I get a power hog collapsing star? It's called mITX.,Negative
AMD,Spinning a delay of building a competitor into this? Good try,Negative
AMD,"To completely compete with Strix Halo (really just the graphics side) would require intel to increase the die size just like AMD did. In practice, even in gaming, it isn't worth it. Yes, you get between 20-30% more performance with Strix Halo up to 65W, and then pushing 80w+ Strix Halo opens up further to closer to 40-50% better performance. Thing is, it just doesn't make sense to create a large APU with those power requirements for full performance in today's market... especially at the prices of Strix Halo products. You can just get a solution with a dGPU at those prices.  I just wish Intel would push for Linux compatibility. Panther Lake is being held back by the suck that is current Windows 11 imo.",Negative
AMD,"Hmm, that's a shame.  I really like Strix Halo.  They're niche, no doubt, but with NVIDIA having DGX Spark, and AMD releasing a ""competitor"" later this year, kind of surprised Intel is going to ignore the compact AI development market.",Negative
AMD,"From what I've seen today on reviews, they really trade blows at different TDP ranges. I'm yet to see benchmarks that come out with the 70 something percent gains Intel claimed.",Neutral
AMD,"LPDDR tends to be more power efficient than GDDR, especially when shared with the CPU. Not to mention you lose less power to communication. In other words, an iGPU will always be more power efficient than a dGPU.",Positive
AMD,It still might not be a competitor because it's going to be expensive as hell. If one wants the bleeding edge chip they have to fork it out.,Negative
AMD,The 70% claim is against Strix Point which is the similarly sized offering from AMD. It only trades blows with Strix Halo because that's a far larger (and expensive to manufacture) chip whose gpu portion is as large as a desktop RX 7700. More cores at lower clocks means better efficiency.,Neutral
AMD,iGPU?,Neutral
AMD,"Itâ€™ll use less power, and itâ€™ll do less work per watt too.",Neutral
AMD,"By ""this"" I meant the quote. As much as Pantherlake is great, I don't believe they were able to pull an AX launch off in time but simply didn't",Negative
AMD,It only trades blows at low power. Once you get higher wattages in it does not. But efficiency wise I think id trade my strip halo for an extra hour or battery gaming even with the lesser performance as I won't feel it much in the type of games I play. Panther Lake is a strategy gamers dream chip. Thin and light that can play the games at 1080p for 3 hours on battery.,Neutral
AMD,This is more based on die size than work per watt.,Neutral
AMD,Nah,Positive
AMD,"I intended to say its large size was what allowed Strix Halo to also be competitive at certain low power ranges, at higher ones it completely dominates, you are absolutely right.",Positive
AMD,"Die size is going to limit channels more than anything though, right?",Negative
AMD,Only 6yrs later than the M1 launch and about 9.5yrs after Intel learned that Apple was developing their old SoC independently.,Neutral
AMD,"dear god pls give me a zenbook with an OLED screen and all day battery life ðŸ™ðŸ™ I don't need m5 performance, I just need to be able to have my terminal and browser open all day without needing to plug it in twice a day.",Positive
AMD,Nice! They will be sweet to run Linux. 30h battery life?,Positive
AMD,"If only Windows could catch up with Apple MacOS  Panther Lake development was chaotic and last year, they were not sure if 18A was going to be ready, but was worth the risk  I am more excited about Nova Lake ( wont be on Intel node)",Positive
AMD,"Panther Lake is very impressive, but this title is clickbait. Apple still is the leader overall, in both performance and efficiency.",Positive
AMD,And itâ€™s deleted before i read ðŸ¤£,Negative
AMD,I get a 404 error clicking that link. Is it pay-walled? Iâ€™ve searched for it on the main page and it doesnâ€™t come up.,Negative
AMD,QCOM and their pipe dream of Windows on ARM are done for. There's literally no reason to buy a Snapdragon X chip,Negative
AMD,"No it wonâ€™t. At least until the manufacturers get their shits together. I was looking for a mobile and somewhat capable, second laptop and every single brand has some serious shit. Especially related to usb-c ports and mainboards.",Negative
AMD,"They have to, otherwise they will be out of business bc arm",Negative
AMD,Iâ€™m more curious about ultra low power CPUs and how theyâ€™ll perform. I really want a low power truly fanless laptop for light tasks.,Positive
AMD,"So a high-end 16 core Intel chip beats out Apples lowest end chip with 10 cores in multitasking, is that really an answer? Apples chip is 50% faster in single core, and they have two tiers of chips above their low end.   Intel is very far from where Apple is, if these metrics are a good example of where they stand.",Neutral
AMD,"lol, its way behind even m4 and under desktop can't beat ryzens. I do wish them good luck though, getting bored with AMD(slacking a lot) becoming intel..",Negative
AMD,"No, it's not. ðŸ¤”",Neutral
AMD,My laptop is slow as hell and has a hard drive 8gb ram Intel i5 8th gen and a integrated graphics card how I make my laptop fast,Negative
AMD,"I honestly can't recall the last processor(s) I was anticipating as much as this, except perhaps Lunar Lake and the Snapdragon X Elites. Those were primarily focused on battery life and Panther Lake and The X2 Elites are the processors we really wanted the prior gen to be. I believe this will be the year of lightweight, long battery, performant notebooks with incredible screens, that you can game on. It's quite awesome. I expect this to go down as probably tbe biggest jump in compact performance ever.",Positive
AMD,"lol this is like the 3rd time Iâ€™ve seen headlines calling something the windows answer to apple silicon. First it was the latest windows ARM, then it was AMD Strix Halo, and how its intel Panther lake. Donâ€™t get me wrong, Iâ€™m stoked for Panther Lake, but it is diminished by their reliance on Windows for the operating system.",Neutral
AMD,I very doubt,Negative
AMD,Eh as per the article the only thing that stands out is the iGPU and that's it. The rest is on par with a mid-range Ryzen AI 7 350. And you pair that with a 5050 and boom: Double the FPS of the Intel.,Neutral
AMD,Better late than never. It's a very solid response. I do hope they keep pushing as we really need CPU and GPU competition.,Positive
AMD,"Move slowly, but surely",Neutral
AMD,Apple switched because of Intel node issues and now they are considering using Intel fabs for their own chips. Could have just stayed on Intel,Neutral
AMD,Oled screens tend to burn battery faster.,Neutral
AMD,"It already exists. The Lunar Lake will still have better battery life than Panther Lake, UNLESS you get the 4-core GPU which will result in worse performance for the GPU than the current lunar lake in the zenbook",Negative
AMD,This is all I want/wanted I caved and got a macbook air a few months ago. Damnit. Some of these machines look incredible,Positive
AMD,"Exactly! Windows 11 is horrible, Apple Silicon/ARM's Linux compatibility is not good. Linux + Intel = YES",Negative
AMD,>If only Windows could catch up with Apple MacOS  I have 3 wishes.    Mac: better emulation layer for games like with steam OS using proton. A more seamless experience.    Windows: better ARM support.   Linux: easier emulation of other applications like adobe suite/teams/(insert windows program not on linux),Positive
AMD,Do we really have any confirmation on Nova Lake node at this point in time?,Neutral
AMD,Windows doesn't need to catch up so much as stop ruining itself.,Negative
AMD,"Same if it has AVX10.2 it will likely be the best desktop CPU, and make most HEDT irrelevant",Positive
AMD,TBH i like windows over Mac. only think i like about apple is their M series chips. Never interested when they had intel chips,Positive
AMD,And Mac OS for those who swing that way ... mostly good on the outside (not loving the latest design tho) and Unix is just a terminal session away. I use Mac OS and Windows about 50/50 but vastly prefer Mac OS.,Positive
AMD,Same for me.,Neutral
AMD,"Seems like it got deleted, don't know why.",Negative
AMD,"Unless you want better battery life, reliable wake from sleep, better cpu and multi-core perf.   Apple proved you don't have to be gaming first to be successful. Intel only wins in gaming, nothing else, and only against a almost 2 year old Snapdragon SKU. Lets compare to X2 when it comes out.  This is like saying Intel just destroyed AMD, maybe in some ways, until AMD introduces their next gen, that's the way it works.",Neutral
AMD,You already own a laptop with a Panther Lake chip? ðŸ˜‚,Neutral
AMD,"Itâ€™s way ahead of midrange Ryzen, itâ€™s basically on par with high end Strix Point while delivering better battery life.",Positive
AMD,Don't forgrt the amazing battery life.,Positive
AMD,What do we possibly need cpu performance for or gpu?  All software is bloat. Its debloating we need.,Negative
AMD,Not really true. Apple switched so they could use ARM and control the design and vertical integration and intel wasnâ€™t a foundry.,Neutral
AMD,"oh definitely, it's just that after having it I can't go back. the thing is I don't even do any heavy compute on my laptop so I don't think I'm asking for anything unreasonable. most of my day is spent in an ssh session to my home server and a browser, discord, spotify. I just need like 8 hrs screen on time and I'd be happy. I get like 3-4 right now on my zenbook 14X and that's just laughably bad.",Negative
AMD,"If you gonna look at something all day, better make it good. Same thing with your bed, you spend so much time on that thing, might as well be good.",Positive
AMD,"Panther lake is more efficient at all power bands, why would lunar lake have a longer battery life?",Neutral
AMD,Proton is translation layer for windows directx api to vulcun  in Linux.  The translation layer for x86 to arm is way more difficult than what proton does,Negative
AMD,> Do we really have any confirmation on Nova Lake node at this point in time?  Intel's publicly confirmed they're also using TSMC for compute. Only one thing makes sense.,Neutral
AMD,"18A is not in the same league of N2.   Even 18AP is not on par with N2   14A is not ready  So unless they want inferior product to AMD (Zen6) which will be on N2, NovaLake will be on TSMC N2  14A is when Intel expects to match or surpass TSMC nodes",Negative
AMD,"Tell me you haven't watched the reviews without telling me. Lol ""better battery life"" has been QCOMs only argument vs Intel/AMD and now with Panther Lake's superior battery life, QCOM has nothing more going for it. The X2's efficiency is not going to be that much of any more than the X.",Negative
AMD,"Snapdragon has no advantages. It is not cheaper, it is not faster and it does not have better battery life at equal performance. Add the ARM performance translation tax for x86 apps and they are donezo.  Qualcomm needs to heavily discount and increase performance at the same time to have any chance to win.",Negative
AMD,Keep on dreaming. Numbers speak for themselves.,Positive
AMD,"I've mostly been picking up AMD as of late, but this is a great win Intel's needed for years. About the only potential downfall is pricing, but given that AMD has nearly zero design wins for Strix Halo on laptop, Intel has a pretty wide open field to work in.",Positive
AMD,The Ryzen will be better. Always been,Positive
AMD,In theory you are correct in practice that isn't happening so...,Neutral
AMD,"You can easily disable 90% of the bloat. It's especially easy if you have Windows pro. Removing bloat freed up over a GB of RAM on startup for me. But yes, the bloatware is ridiculously atrocious",Positive
AMD,No thatâ€™s the spin. Apple was mad about battery life and performance on laptops.,Negative
AMD,Actually having a mostly back background is good for OLED as it can actually save battery. So console or terminal is good.,Positive
AMD,"Actually for just text rendering, IPS is still better. But for colors and media and gaming, OLED wins.",Positive
AMD,The 17W Panther Lake has a worse GPU than Lunar Lake (17W) is what I'm saying. If you want the good GPU then it will have worse battery life because that's 25W+,Negative
AMD,Argh! My mistake!,Negative
AMD,Does it really that matter? I mean intel 12th and 13th  gen was on par or even better than zen3 and zen4 .  Both intel 12th ans 13th gen were on intel 7 or 10nm while zen  3 was 7nm and zen 4 at 5nm.  If anything I don't get how intel dropped ball so hard with arrow lake . Going from 10nm(intel 7) in 14th gen to 3nm of tsmc in arrow lake should produce both efficiency and performance gain like how nvidia got going from samsung 8nm to tsmc 4nm in 30xx to 40xx.,Neutral
AMD,"X2 is already rated 45% more efficient than X1, I've watched the reviews, but more than that I've had my hands on real hardware. Try actually informing yourself before responding. I'll just leave you with that, obviously on an Intel reddit people are going to be super defensive about their ""team"".",Neutral
AMD,"Yes, the numbers speak for themself on NotebookCheckâ€™s review of PTL, which places it ahead of Strix Pointâ€™s multi core and single core, and way ahead in efficiency.",Positive
AMD,Nothing indicates that,Neutral
AMD,Is this a troll? It's the X7 and X9 are going to be quite a bit better than a 350 are you joking? Do you read benchmarks or reviews at all? The ultra 5 with b 370 is probably gonna be at or above a 350-360.,Neutral
AMD,AMD Glazer spotted ðŸ¤¡,Neutral
AMD,Well we have to buy new devices just cause some company is too lazy to make a native app and use a web wrapper like whatsapp,Negative
AMD,Apple was also mad about margins. It cheaper for them to make their own than beholden to Intelâ€™s pricing.,Neutral
AMD,"Where did you see that? Iâ€™m not aware of any regressions vs Lunar Lake, and Intel is specifically releasing a handheld sku to deal with the super low power : high gpu performance regime. Â   SKU differences aside, take a 388H and throttle it to 17W and it greatly outperforms lunar lake.",Neutral
AMD,"The node helps, obviously, but you still need to design a product that works. The choice of node is not a magical solution.  Arrow Lake had flaws that showed themselves in certain workloads due to design. They \*did\* still get an overall efficiency boost but thats not a high bar given what they were coming from.",Neutral
AMD,"Intel 7 was competitive in peak performance, but lacked efficiency. Also note that arrowlake utilized N3b which was notorious for poor yield and over complexity and quickly replaced with N3e in Apples line of products. Arrowlake also followed the 13th/14th gen debacle and Intel reduced ring bus clocks significantly to play it safe.  Most notably, going from a monolithic design to chiplets leads to increased latency which reduces gaming performance and makes it harder to hold higher clock speeds. Monolothic designs will always be faster in a 1:1 comparison but chiplets make up for it by being modular and cheaper to scale, something intel hasnt been able to really take advantage of until Pantherlake.",Negative
AMD,"They were experimenting with tiles and itâ€™s an early iteration. Not to mention they have more experience with their own fab.   Arrow lake smokes 14th gen in compiler workloads. Those faster e cores help a lot!   Outside of gaming workloads, itâ€™s fine. Even with gaming workloads it does ok, just not a real jump from 14th gen. It was never going to beat x3d",Positive
AMD,It hardly does. Mid range chips from seven or eight years ago can still do everything that modern chips can. All you have is a bunch of tech consumers who convinced themselves that they need the latest tech.,Negative
AMD,"> Does it really that matter?  Yes, you're looking at something like 15% perf for a full node. That's very significant. A node shrink alone could constitute an entirely new gen in perf.   > If anything I don't get how intel dropped ball so hard with arrow lake  They redesigned the SoC fabric, and it's shit.",Neutral
AMD,No way! You've had your hands on real Panther Lake hardware already?? But it hasn't even been released yet! You must be a special redditor. Give me a break.,Negative
AMD,I'm talking about Krackan,Neutral
AMD,This test does: https://www.computerbase.de/artikel/prozessoren/intel-core-ultra-x9-388h-test.95776/seite-5  It looses quite strongly against the 288v (which is not anymore that efficient and far less so than the Ryzen 7 350),Negative
AMD,Any spec sheet will show you it will have only 4 cores for the GPU. Lunar lake has 8. Panther Lake cores would have to be twice as powerful as lunar lake which we know they aren't.,Neutral
AMD,Thanks for explaining,Positive
AMD,They still lose handily in efficiency and their multi core isnâ€™t better than Strix Point,Negative
AMD,Not really. It loses against the 288v in the first test and wins against in the second test.  There is no direct comparison against the Ryzen 7 350 and I don't know how you even reached the conclusion that the Ryzen 7 350 is more efficient than lunar lake?  [Notebookcheck](https://www.notebookcheck.net/Intel-Panther-Lake-Core-Ultra-X9-388H-performance-analysis-Outpaces-Arrow-Lake-and-exceeds-Zen-5-in-efficiency.1212583.0.html) conducted fairly good efficiency tests that compare the single and multicore CPU perf/W. The Ryzen 7 350 is actually included in their list and ranks dead last in the multicore comparison so there's that and in the single core comparison Lunar Lake generally performs better than both but once again the Ryzen 7 350 is beaten by panther lake.  They even include a nice graph for different PL which also happens to include the Ryzen 7 PRO 350.,Neutral
AMD,"You are discussing SKUs. The reason lower stack PTL has fewer Xe cores is because they are nearly 2x efficiency.Â   However, should you take a higher SKU and configure TDP to 20W (or even 15W to account for external memory) it will be more efficient than Lunar. Lunar Lake is great, but PTL is much better.",Neutral
AMD,You'll see but not even in your wettest dreams the Ryzen will be beaten. Intel remains Intel after all.,Neutral
AMD,"It needs to be at least 2x as efficient to be as powerful because it has HALF as many cores. It isn't, therefore the GPU will be weaker. You can do that same TDP configuration on Lunar Lake. Not sure why that matters.  ""Nearly 2x more efficient"" translates to ""nearly as powerful"". But not quite.",Neutral
AMD,It is 70% faster. Youâ€™re comparing different SKUs. Compare top Lunar Lake to top Panther. How the TDP is configured is up to the OEM,Neutral
AMD,"We don't know how efficient those 28W Panther Lake chips run at 17W. Just because you can run it at such low power does not mean it will work well. It will certainly be much less efficient if it were to be run that way otherwise Intel would be gloating at how powerful and efficient their Panther Lake GPU is at 17W. The fact that they don't means it is well below their sweet spot of efficiency. You are basically starving it, similar to stalling an engine.",Negative
AMD,"The fact that it can even compare to AMDs halo product, which the avg consumer canâ€™t afford is a win for Intel. Intel has plenty on leg room to expand the GPU too.",Positive
AMD,This suffers from bandwidth bottleneck. Strix halo is Quad channel while panther lake is dual. An igpu would benifit greatly with a quad channel,Negative
AMD,"This thing is absolutely nuts  AMD BTFO unironically, I'm floored. I never, ever would have considered an Intel chip before 2025, now this is the most obvious laptop part ever. AMD is surely sorely regretting recycling the same 780M and 890M chips for another entire gen, betting that Intel would continue stagnating.  This thing is gonna be a monster in handhelds.  I really, really wanted a Strix Halo laptop, but the lack of SKUs, price and the inflexibility with RAM kind of make it unappealing to say the least, not to mention the power draw compared to Panther Lake is unwelcome. These laptops are gonna be probably the best x86 in mobile has eaten in a very long time.  On top of that, it's almost making the 5050 look like a stupid part in a laptop. Why bother when you have a vastly more power efficient iGPU that will handle every desktop workload on top of being viable for gaming?",Negative
AMD,"â€œTakes on strict haloâ€ at about half the performance (:  Title aside, this looks pretty great.",Positive
AMD,"Amd hasnâ€™t even reached 30% market share mobile yet (oscillating between 20% and 26% since 2020) and are about to be almost wiped from existence again save some low end designs using Ryzen â€œAI 7â€ 445 (6 core, 2+4, 4CU iGP).",Negative
AMD,"The performance looks fantastic for high end $1k handhelds.    But the ""80% faster than AMD's 890M"" claim is absolute bullshit.  They tested against the HX370 with LPDDR5 5600.  That said, against an 890M that *hasn't* been crippled, it should still be 40-50% faster which is great.",Positive
AMD,"Will intel make it affordable for consumers though, or price it like LNL (2000+ USD laptops and up)",Neutral
AMD,"""compare"", it is half the performance. Still good for what it is, assuming it is priced right",Positive
AMD,"Well it's not just memory bandwidth. It's got about as much bandwidth as it needs to feed the Xe3 cores.   Panther Lake's GPU tile size is only 54mm^2 while Strix Halo's GPU is 308mm^2. For Panther Lake to compete with Strix Halo it would need 2-4Â times as many Xe3 cores probably. That'd be expensive. There's a reason Strix Halo is so expensive and kind of low volume, bigger CPU more RAM and more expensive motherboard aside.",Neutral
AMD,DDR6 can't come too soon for igpus too. But in reality memory bandwidth will stay an issue for a long time. Of course cramping enough compute power in such a format is an issue too,Negative
AMD,Framework desktop motherboard?  https://frame.work/products/framework-desktop-mainboard-amd-ryzen-ai-max-300-series?v=FRAFMK0004,Neutral
AMD,"Half the performance, half the power, (more than) half the price.",Neutral
AMD,I preordered X7 358H laptop for 1300,Neutral
AMD,Bro nothing's going to be affordable in computer hardware at this rate,Negative
AMD,There are plenty of LNL laptops around 1000 what you on about,Neutral
AMD,Lunar lake is in sub 800$ laptops now and 12xe cpus are available for sale 1300$ despite the ram and cpu shortage.   The comparison is good even before likely price hikes for strix halo,Positive
AMD,"Weâ€™re talking mobile chipsets here, strix halo is what happens when you throw efficiency out the window, with Power (TDP) range, typically from 55W up to 120W. The ultra H 300 has default TDP of 25W, with Maximum Turbo Power (MTP) going up to 65W-80W. Intel has a better design, if they threw 40 XeSS3 cores on it, it would prolly run circles around Strix.",Neutral
AMD,"Strix Halo is double the die size, this should be compared to Strix Point.  But price will tell everything.",Neutral
AMD,"> It's got about as much bandwidth as it needs to feed the Xe3 cores.  GPU's will take all the bandwidth you can feed them. It won't help EVERY benchmark, but it will help many.  I'd rather see 256-bit bus on something like this. maybe 192 since you can do that with LPDDR5X etc.",Neutral
AMD,">Panther Lake's GPU tile size is only 54mm^(2)  is this confirmed for the bigger tile?  edit: also, Halo has all the IO, en-/decoders, etc. in the ""GPU"" tile, so the comparison isn't quite valid",Neutral
AMD,And about four orders of magnitude more availability.,Neutral
AMD,"> (more than) half the price  Have we seen pricing? Not doubting it, I just haven't seen anything personally but probably missed it.  Strix Halo does seem to be a pretty mythical chip due to its price.",Neutral
AMD,Keep in mind that each Xe3 core is about as wide as an AMD WGP. We're looking at 1536 vs 2560 shaders. The B390 is 60% as wide as the 8060S. 20 Xe3 cores would match the 8060S in width. 40x Xe3 is as wide as the 7900GRE.,Neutral
AMD,"Bingo  Strix is also limited by being RDNA 3.5 and no FSR4, so it's rather dependent on raw throughput, and it can't possibly fit in a comfortable handheld that would last for more than an hour and a half under load.  I really, really appreciate what AMD has done historically in the APU space, but it is genuinely time for vendors to start considering Intel. The strides here are absolutely immense. They went from an iGPU being a thing that can do basic graphics and 2D gaming to something that competes against lower end NVIDIA parts at less power draw and can actually legitimately game. It's bonkers. In mobile it's a no brainer.  Of course, it's going to be interesting seeing AMD's next UDNA architecture and what they can pull off, but competition never hurt nobody, and it was sad seeing AMD stagnate in the APU space of all things, their bread and butter that gave them pretty much the entire console market plus the Steamdeck. The entire Windows and Linux handheld market has been nothing but AMD for years. This is even better than Lunar Lake.  We're getting to the point where Intel could legitimately compete in the home console space and make a really great product, but realistically they can't undermine AMD's relationship with vendors at this stage. I hope they keep it up, it would really be cool to see an AMD vs Intel APU console war generation.",Neutral
AMD,It's about 50% bigger die with 1 CCD (which seems comparable CPU performance),Neutral
AMD,https://youtu.be/X9eYQTkzxqU?si=Uzdz-E3QJzzVM42N  Not the only one comparing. Intel actually outperforms at lower wattage.,Neutral
AMD,">GPU's will take all the bandwidth you can feed them.Â   Didn't deny that. But 12 Xe cores is presumably considered the sweet spot, that's all I'm saying. And Strix Halo only has twice as much bandwidth to feed a GPU die 6 times the size of Panther. I'm sure it has more cache, but still. I think Intel would consider triple or quad channel memory not worth the costs. It would require new i/o, new pins, new motherboard, more RAM, and all, for what's essentially the lowest volume product.  Besides, Intel already has Nova Lake AX in the backlog, or whatever it's going to be called. Practically intel's strix halo. It'll have Xe3P cores, more powerful than Xe3, thus deemed more worthy of the halo treatment.",Neutral
AMD,"This is a big of exaggeration, as you can see with Nvidia moving to gddr7. While bandwidth has increased substantially, performance is clearly limited by lack of compute power",Negative
AMD,"No official confirmation yet, but JayKihn leaked the tile size for the 12Xe SKU last year. Another user somewhere else said the 4Xe GPU is 33mm2.Â Â  https://x.com/jaykihn0/status/1812898063502938260   And even without the PHYs and NPU, from what I see, Halo's GPU tile is still like almost 3 times as big. So yeah, it's on another class, that's my whole point.",Neutral
AMD,Yep,Positive
AMD,"I have a pre-order in for an MSI 14"" at B&H for $1300. 358H, 32GB LPDDR5X-9600, 2TB, 1200p OLED. I've seen some lower-end PTL laptops rumored around the $900-$1k starting range, but those are likely the 4Xe chips. Wildcat lake with its tiny 2Xe GPU is probably going directly into the budget sector.",Neutral
AMD,Good catch.,Positive
AMD,AMD is dormant on the APU space since it had basically the monopoly for x86 because Intel was just bad.  They are taking one of the old Intel's book by releasing rebrands and reashes,Negative
AMD,"> But 12 Xe cores is presumably considered the sweet spot  By what? much larger Xe3 GPU's exist.  We have nothing to compare against in Intel-iGPU-land that has 256bit memory.  Strix Halo die size isn't the metric you want either. It's only 2x the fps (and who knows, panther lake could be 2x its own fps with doubled memory bus, but we'll never know, because Intel won't release a strix halo competitor)",Neutral
AMD,"Halo's die is still quite a bit bigger, but from the Intel side, you need to include IO, GPU and about half of the compute die which has the MCs, encoders / decoders, etc. to match the ""GPU"" die of Halo, so it is more like 200mmÂ² to 300mmÂ² when compared",Neutral
AMD,AMD is paying more attention to NVIDIA for sure. ESP on the data center side.,Neutral
AMD,">much larger Xe3 GPU's exist.  The biggest one for the moment is on Panther Lake X CPUs. I wouldn't know if there's something bigger tbh.  >Strix Halo die size isn't the metric you want either.\\  Sure you can't compare two different architectures. But all I need to know is it's faaar bigger.  >panther lake could be 2x its own fps with doubled memory bus  That would be within Strix Halo territory. I highly doubt it. A GPU with bigger bandwidth will access things and perform raster operations faster, but it won't get much faster at actually processing vectors and other calculations. Gotta need more cores for that.",Neutral
AMD,"Well Panther uses mixed processes, and hybrid tiles are bound to be a bit less space efficient than putting everything on a single die. And to be fair, Halo GPU uses N4P process while Panther GPU uses N3E So, still not directly comparable.   Gotta say though, Arc's PPA has improved a lot since Alchemist and Battlemage.",Neutral
AMD,"> That would be within Strix Halo territory. I highly doubt it. A GPU with bigger bandwidth will access things and perform raster operations faster, but it won't get much faster at actually processing vectors and other calculations. Gotta need more cores for that.  Yeah, it doesn't matter how much memory bandwidth you have if the GPU doesn't have the raster performance to keep up with the flow of data. Case and point, AMD's R9 Fury X. Released with 4096bit bus HBM. Had a total memory bandwidth of 512GB/s. Yet the GTX 980 Ti released with a 384bit bus and 336GB/s memory bandwidth and it out performed the Fury X in pretty much everything.   That said, I have no idea how close the iGPU is to being bandwidth bottlenecked at 1080p. But I very much doubt doubling it would also double the frame rate.",Negative
AMD,"Yeah, I think Intel has done a great job with the improvements, I just don't want to overhype things.",Positive
AMD,"Hopefully they deliver. Amd needs a shake up in the APU market, mostly the GPU side of it.",Positive
AMD,That article claims it on par with the 4050 laptop. Jesus christ,Negative
AMD,this is nice but the handheld market could use less ultra 9 and 7s and more ultra 3s.  the closer they can get to the nintendo 2DS XL in size while being under $400 the better.,Positive
AMD,I am definitely looking to get a gaming handheld PC with PTL in it. Gonna cost a fortune probably but it's my first and intend to stick with it for a long time  The only thing that would stop me is if they skimp on ram... Which might be a very real problem,Positive
AMD,77% faster while using 80% more power.  I rather see power matched benchmarks.,Neutral
AMD,"happy about more handheld focus, genuinely have put in more hours on my steam deck than my pc setup this year. i have my eyes on ARM going forward as well",Positive
AMD,fun to see them tout XeSS MFG on mobile gpus while the B580 still doesnt have it....,Neutral
AMD,Really excited to see these chips on handhelds.,Positive
AMD,"Iâ€™ll always want a really good handheld besides my PC. Currently own a Legion Go S and the Switch 2 so this is good for everyone. AMD stays on their toes and if intel is good and gives us a SteamOS native device, Iâ€™ll definitely try them next upgrade. The",Positive
AMD,"I'm looking forward to this, especially for a gaming handheld/mini pc device, having a gpu that is nearly capable of a RTX 4050 with that power profile could be game changing.  Plus all the existing Intel XESS features are icing on the cake, although support for that scaler is flakey. I'm just hopeful that more games will support XESS.",Positive
AMD,"Can anyone say real life performance diff, and how much increase in battery life in real laptops, Because I feel many times those ppt numbers don't nearly match real usage (especially when ppt numbers are huge).   Can I get Mac like battery(or atleast 7hrs with no performance drop) and how much does it compare to Mac m1/a18 air performance with them on a $600 laptop.(Assuming fedora/mint as OS)",Neutral
AMD,"I don't understand, we need to see the price of this thing, because otherwise we have to compare it to the AMD 8060s which will be more powerful, but even the cheapest machine with that costs â‚¬1500/â‚¬2000. We just need to see what price point this chip will be offered at.",Neutral
AMD,"On just 2 channel / 128 bit RAM, well done Intel!",Positive
AMD,An ancient Chinese proverb (roughly) states: *'Talk...* does not make rice...' ðŸ¤”,Neutral
AMD,Steam deck 2??? Take my money gaben.,Negative
AMD,It does look like an amazing performer. I hope the Linux drivers are up to the taskâ€¦ Windows based handhelds have been pretty bad because of Windows.,Positive
AMD,Waiting for this since AMD 890M was disappointing,Negative
AMD,"Who cares, gives cheaper powerful GPUs for 2k, 4k gaming",Neutral
AMD,"Yeah, RDNA 3.5 lasted way too long. Admittedly, RDNA4 was a special case where they gave up on a mobile version in favour of getting UDNA ready but that's their own fault. Hopefully, this pushes them to make UDNA a mobile focused architecture as well and perhaps push more cores in igpus to take back the integrated graphics crown. Competition is very good for the consumer.",Negative
AMD,agreed. these rehashed mobile chips with bad upscaling are well beyond their lifespan.,Negative
AMD,"I looked at the benchmark scores they put out and it looks pretty promising, apparently the 12XE core variant can score somewhere around 6300 on Time Spy graphics (https://www.notebookcheck.net/Early-Intel-Panther-Lake-iGPU-benchmark-impresses-with-50-faster-performance-vs-Lunar-Lake.1138923.0.html).  Intel is comparing a 4050 with low wattage (60W system TDP IIRC) so it's not as good as the full powered 4050 which scores around 8000 on Time Spy. On low powered 4050s though like the one in the XPS and other thin and lights it will compare pretty evenly. It also outscores basically any 3050 on the market since the highest powered ones get around 4500-5000 on Time Spy (which was already matched pretty decently by the old 8XE core GPUs)",Positive
AMD,"It will depend on game to game basis. Some perform well on iGPUs, some tank hard due to memory bandwidth or whatever issue they have with it.",Neutral
AMD,"A quick Google says 9 TFLOPS or the equivalent to an RTX 1080, 2070, 3060, 4050 give or take.",Neutral
AMD,They did against the 285h and it's a similar margin. Lunar lake has a power burst max wattage below panther lakes max sustain power here so they can't compare 1:1 properly,Neutral
AMD,>77% faster while using 80% more power.  Are you following CES at all?  The top feature of that architecture so far has been power reduction,Positive
AMD,82% faster than 890M with 30% more power draw with native resolutions,Positive
AMD,rdna? dude their vega lasted too long they got very complacent in their igpu department,Negative
AMD,"At this point, we'll be lucky if they even care about consumer cards at all.  It's AI all the way these days.",Negative
AMD,"And then UDNA has been nowhere to be found, probably coming next year. AMD completely blew their lead in the APU space.",Negative
AMD,Panther Lake with an iGPU being able to play the newest games on medium/high settings in a thin notebook is pretty crazy,Neutral
AMD,Mfg on or off? The article wasnâ€™t clear on that.,Neutral
AMD,their Zen 5 desktop iGPU still use RDNA2; a 5 yr old architecture let that sink in...,Neutral
AMD,"AMD didn't have money when they were using Vega iGPUs, and they were still the best iGPUs around",Positive
AMD,"Unlike Nvidia they actually can make a lot of money relative to what they do right now if they get consumer marketshare. Iirc, Nvidias gaming revenue still beats AMDs enterprise earnings.",Positive
AMD,"Eh, they will still have the best igpus on the market for a while. If they price the 388 well there is hope for them. But it's never going to sell the volumes Intel will.  UDNA is a major architecture overhaul on par with the the introduction of Ryzen and RDNA. A year is a long time but AMD only really needs a single gen to recover this gap if they so wish. But UDNA will need to be made with versatility and low power application in mind.",Neutral
AMD,"Low to medium , not high",Neutral
AMD,native rendering,Neutral
AMD,Those weren't good though.  They didn't get close to the 1050ish equivalent that's a decent min spec card until the steam deck.,Negative
AMD,"High with XESS maybe at â€˜okayâ€™ frame rates. Still, crazy.",Neutral
AMD,"While I agree their naming scheme is a mess, yours is far worse.",Negative
AMD,"TBH, as long as the Ultra 5 338H is actually called an Ultra X5, it'd make the entire thing a lot more consistent  as in now X always means ""the one with the good GPU""",Positive
AMD,"You have no understanding of Intel's business and thus are not qualified to advise them what to do   Intel doesn't sell these CPUs to the end consumer, they sell them to their customers - the PC manufacturers. And that is the reason why there is so much choice, because the PC manufacturers want it.   Also, you clearly have never heard of vPro.",Negative
AMD,"The SKU count is roughly doubled because you have each step with/without vPro - these get a 100MHz max turbo frequency bump, but the main benefit is you can run the corporate firmware with vPro support, so you get additional security and manageability features. Exception is the Ultra 9 where they just do it with vPro support as standard.  These have a higher cost because you are getting more features.  You could make it so you just have one CPU and then the manufacturer pays a license for corporate firmware per device, but that's more work to then ensure manufacturers are licensing machines correctly, and more confusing for end-users where now if you're buying a corporate device with vPro support you know you are looking at Core Ultra 236V and 268V for vPro support whilst 226V and 258V don't have it.",Neutral
AMD,"Because intelâ€™s customers work with thin margins and want the wide product stack with lots of performance and price steps. For them it matters if they get 4.4ghz for $300 or 4.6ghz for $350. You are not Intelâ€™s customer unless you ordered a pallet of 1000 CPUs, which I doubt.",Neutral
AMD,Apple really isn't better. They leave out lots of the important performance information. They just don't tell you at all.,Negative
AMD,I agree for those cpu that have no alphabet denomination at the back as that just looks like how desktop cpu is.  But for X7 and X9 is just even easier CPU differentiation,Neutral
AMD,I only agree with the title. Your naming scheme is much worse lol,Negative
AMD,"At this point even S3, S3 Pro and S3 Pro Max would be a great improvement.",Positive
AMD,"Totally donâ€™t get it, miss the 13900k 14600k type names.",Negative
AMD,"Brah I don't care about the naming conventions, it is what it is.  It is petty to argue about all of this.  I need the B770 and C880 to be released.  I need more Intel Arc Pro cards to be released, there is no hope for humanity otherwise.  I need Battlemage and Battlematrix everywhere but TSMC is the bottleneck.  Hopefully there is more for 2026 where Intel IFS shines.  God help us all!",Negative
AMD,Are you saying they are all locked???,Neutral
AMD,I only care about the top level sku so the names don't matter.,Neutral
AMD,Samaung Galaxy S3,Neutral
AMD,Intel to $100 guaranteed,Positive
AMD,Just Josh presses them hard on this issue at about 7:30 in this videoÂ https://youtu.be/AzGFbkKZE7A?si=yq1pmpRv7exQ-7i5,Neutral
AMD,"Check the Just Josh interview! Dude criticizes exactly that to an intel executive... For me, they should drop the ultra naming scheme altogether... it hasn't stuck yet... they should go back to de i3/i5/i7/i9...use the X for the B390... and an S for the 16 core variants...",Negative
AMD,Apple always nails the small stuff,Positive
AMD,"Just because it sounds similar to Apple does not make it ""bad"".  I chose ""S3"" because they literally market them as ""Series 3"" (sounds awfully similar to M-series ðŸ¤¨). Could fiddle with it but my idea stands:  Different core count = different name, Better gpu = add X",Neutral
AMD,"Nope, its the Ultra 5 338H: [https://www.intel.com/content/www/us/en/products/sku/245531/intel-core-ultra-5-processor-338h-18m-cache-up-to-4-70-ghz/specifications.html](https://www.intel.com/content/www/us/en/products/sku/245531/intel-core-ultra-5-processor-338h-18m-cache-up-to-4-70-ghz/specifications.html)  The Ultra X7 and X9 are listed as such on Ark: [https://www.intel.com/content/www/us/en/ark/products/series/245528/intel-core-ultra-series-3-processors.html](https://www.intel.com/content/www/us/en/ark/products/series/245528/intel-core-ultra-series-3-processors.html)",Neutral
AMD,"the 338H doesn't have ""the"" good GPU, it has a B370, with 10 cores",Negative
AMD,"Btw, OEMs love the fact that the Ultra 5 336H and 338H are vastly different products with hugely different performance when it comes to graphics. Why? Cause they can market the 338H to you, and then sell you the 336H at a fraction of the cost, and if you are not very tech-savvy, well, that's too bad for you.",Positive
AMD,"Yes because PC manufacturers want a ""choice"" to get a CPU with 100MHz higher clock speed as if that will make a difference in a mobile device at all.  If you think ""vPro"" is so important, processors with it should have entirely unique names. You and many others in the comments made an effort to point this out more than intel's own naming scheme does.",Neutral
AMD,"I see, that does complicate things.",Negative
AMD,Why are you getting downvoted ðŸ˜­  For consumer products it makes complete sense to go for more simplistic naming schemes,Negative
AMD,"It still should have the X IMO. They're still bothering to call it a B3xx chip rather than just ""Intel Graphics"" like the <=4 Xe chips. The handheld chips running downclocked GPUs get the B360 and B380 names as well. Those should all be Core Ultra X.  As of right now only the ending 8 differentiates the 338H from the small-GPU SKUs, which IMO is not clear enough. Also, if the X became the standard for all big-GPU chips, that ending digit can be used for something else, such as noting the actual GPU performance within the stack. Perhaps just using the 6-9 from B360-390 or something like that.",Neutral
AMD,"You are placing way more importance into the naming than any normal customer would.  The names that matter to normal customers are Core Ultra 5, Core Ultra 7, Core Ultra X7, which is what you will also find on the stickers that Intel has the PC manufacturers put on the device. The model numbers are just for the PC manufacturers and customers who want the exact SKU.  Seriously, your obsession with this is weird. Just accept that the naming is not meant for you and move on. Not everything has to be like Apple.  > If you think ""vPro"" is so important, processors with it should have entirely unique names. You and many others in the comments made an effort to point this out more than intel's own naming scheme does.  Yes, because vPro doesn't matter for normal consumers, but only for big enterprise customers.",Neutral
AMD,Itâ€™s too hard to be a smart consumer and Google the names of the processor(s) and compare?,Neutral
AMD,"""Obsession"" as if multiple YouTubers, some with millions of subscribers, haven't said the exact same thing I did",Neutral
AMD,If you're a smart consumer you aren't buying windows laptops.,Neutral
AMD,"Right, those guys are surely the ultimate authority on anything and not just engagement driven outrage machines /s",Neutral
AMD,That's some serious credentials you're bringing up,Neutral
AMD,Ah I should instead buy Apple laptops and/or Arm laptops that don't work with my programs. Genius!,Negative
AMD,Probs the same reason tire companies donâ€™t make their own cars. Itâ€™s a lot of work. Plus thereâ€™s plenty of competition  What youâ€™re missing is companies like intel have initiatives such as the ultrabook initiative to help manufacturers make better laptops.    Besides itâ€™s way more profitable for them to just make the cpu and not deal directly with consumers as much as possible.,Neutral
AMD,">Another common complaint I hear with non Apple laptops is battery life on suspend  This is still a problem, and it's because of windows. Microsoft claim to have fixed it ONLY for snapdragon laptops, but I have heard some still having the issue. Ever since apple made the M chips the blame has shifted to X86 processors being the problem when it was and still is windows the whole time. This whole thing makes x86 seem worse than it actually is.",Negative
AMD,"They did. Intel produced NUC desktop and laptops for quite a while, then they sold the business to Asus. The desktops are absolutely excellent.",Positive
AMD,Because then theyre essentially *competing* against their own customers. In a market that would require a lot of effort for small margins.   Their effort is better spent horizontally expanding rather than vertically at this point.,Negative
AMD,"As someone who owns the Intel nuc 12 enthusiast, the engineering on them is phenomenal, Intel would do an extremely good job resulting in low margins and financially it doesnâ€™t make sense to make laptops stick and perfect the chips is probably the best financial decision seeing as neither Qualcomm, amd, nvidia make laptops themselves. Even reference designed are outsourced. I worked on intels Arc program those Intel branded cards are expensive AF as they donâ€™t have the bargaining power of getting low cost components like Asus or Lenovo would.",Positive
AMD,"They used to, NUC was acquired by Asus.",Neutral
AMD,Making and selling CPUs is more profitable. Apple has a different business model.,Positive
AMD,I really like Intel NUC. Too bad they sold it to Asus,Positive
AMD,"Why don't tire companies make their own cars? Why don't window companies build their own houses or office buildings?  Why don't the semiconductor tooling companies like ASML, LAM, Applied Materials just build their own fabs and make their own chips? Hell why can't they just build their own laptops too??   Do you really think that Apple manufactures their own M series chips? Or really any of the components in their products? Because the truth might shock you.   I recommend you look up supply chains and maybe learn a lil something :)",Negative
AMD,"You are not Intelâ€™s or AMDâ€™s customer  Dell, Asus, Lenovo, MSI, etc are all customers of Intel and AMD in that they are the ones who actually buy chips  If Intel or AMD go into the laptop business then they are competing with their customers which tends to make their customers upset  The same problem exists with Microsoft and their Surface line which is one of the reasons the Surface line often seems to struggle - Microsoft has to be careful walking the line between demonstrating what they would like the hardware companies to do vs actually competing with them  As for differences in performance that can often come down to what price point the manufacturer is aiming for with the laptop. Higher price can often mean better quality components (which in a laptop can mean lower power consumption)",Neutral
AMD,A mid ground solution would be to make a reference laptop and mandate manufacturers to meet or exceed the criteria like battery life and thermals.  Intel did have an initiative called Ultrabook serving a similar purpose before.,Neutral
AMD,"They did, but got out of it  https://www.intel.com/content/www/us/en/ark/products/series/196845/intel-nuc-laptop-kits.html  They used to make mobos too, but got out of that",Neutral
AMD,"low margin, and competing with customers is no good",Negative
AMD,"Please, don't.  Once, a long time ago, when dial-up was a thing and used by business, I've purchased an Intel modem. 9600 bps connection speed. It was *the* *worst modem I've ever witnessed* \[despite the fact that it was expensive\], because the firmware was expected to be run in sterile laboratory conditions. The real world with unperfect landlines drove this child into confusion and madness, it was repeatedly entering renegotiation on every disturbance, often ending in just dropped connection.  I assume that Intel entrusted the design to talented engineers who had no idea about real-world operating conditions and did not bother to study them. Even in the US at that time, analog telephone lines did not always have negligible levels of interference.  \* 9600bps was the bleeding edge at the time; the old modem at the company where I worked had a speed of 2400 bps.",Negative
AMD,"\> Itâ€™s a lot of work.  Smaller companies like Framework are able to come up with new designs from scratch, though. Slimbook too I think?  \> Besides itâ€™s way more profitable for them to just make the cpu  That pretty much sums it up & answers my question.",Neutral
AMD,It's both.,Neutral
AMD,I have an Intel NUC 9 Extreme [LAPQC71A](https://www.intel.com/content/www/us/en/products/sku/196641/intel-nuc-9-extreme-laptop-kit-lapqc71a/specifications.html). Itâ€™s built like a tank (magnesium alloy chassis) and Iâ€™ve always been very happy with it. Itâ€™s still my main laptop.,Positive
AMD,It's not cause SDXE also suffers from this issue Intel CPU Didn't have the issue with MacOS,Negative
AMD,"There are issues, but SDXE still did better on battery life than comparable Intel chips, and that's with a number of its own issues. Only with LNL/PTL has Intel meaningfully started to close that gap, the first such push since HSW-ULT.",Neutral
AMD,Some software on windows will break it you are one update away from Things breaking in windows be it WoA or X86_64,Negative
AMD,The biggest issue was that it was crippled by the ported meteor lake memory controller dies its that simple,Negative
AMD,"Very good explanation, I own a 285k and I can say the stock experience is average, but the platform is great and coming from 14900k, the temps and power efficiency are impressive. Once fully tuned, 9000c38 A-die, 36 d2d and 34 ngu, gaming is on par with 14900k, but more efficient. I think nova lake will be amazing.",Positive
AMD,">if you judge Arrow Lake solely by the frame rate counter in Cyberpunk 2077 at 1080p  Am I allowed to take into account that Intel went all the way from ""7"" to ""3"" lithography which is more than 2x improvement to achieve almost nothing?",Negative
AMD,Itâ€™s not necessary for consumers to buy an inferior product from a multibillion dollar company now backed by the global superpowerâ€™s government.,Negative
AMD,">We need to stop looking at the Core Ultra 9 285K through the lens of a typical generational refresh  That's all what consumers care about. They don't care if ARL on paper or on theory is some great reset. Perf, power, and cost is what's important.   >he 285K is suffering from the acute growing pains of decoupling the compute complex from the uncore in a way that creates a distinct latency penalty that enthusiasts are mistaking for regression.  It's not being ""mistaken"" for a regression, it quite literally is one.   The problem is also that AMD also has disaggregated their compute from their IMC, and yet has *better* latency on *less advanced* packaging.   >The controversy here isn't that Intel failed to push frequency; it is that they deliberately chose to execute a hard pivot away from the monolithic brute force strategy of Raptor Lake to a disaggregated chiplet design that prioritizes area efficiency and performance-per-watt over raw, latency-sensitive throughput.  Nothing about ARL's current design prioritizes ppw or area efficiency over RPL's design from a chiplets vs monolithic perspective. ARL isn't enabling higher core counts from going chiplets, that seems to be left to NVL according to rumors. And chiplets carries an area penalty over monolithic designs anyway.   >The removal of Hyper-Threading from the Lion Cove P-cores is the most contentious yet logically sound decision engineers could have made given the thermal constraints of modern silicon.Â   This makes no sense   >By removing the simultaneous multithreading logic, specifically the duplication of architectural state and the complexity required in the reorder buffers and schedulers to handle two threads, Intel was able to physically widen the core and increase the L2 cache per core to 3MB without blowing up the die size  SMT costs Zen 5 less than 5% in area btw. Just throwing that out there.   >The result is a P-core with significantly higher IPC than Raptor Cove  It's not though. This has been a significantly worse ""tock"" in terms of IPC uplift compared to something like SNC or GLC.   >but this raw single-threaded throughput is being masked by the interconnect latency.  Maybe gaming or some benchmarks are, but for the large part, no.   You can see this two ways, LNC's structural gains (core width, ROB capacity, etc etc) have smaller gains, percentage wise, over their predecessor versus something you would see in GLC vs SNC, or SNC vs SKL.  And also LNL's uncore is dramatically improved over ARL, and yet you see the same unimpressive IPC gains over MTL/RWC (which is the basis for ARL's mid mem fabric).   >the architectural overhead of the Foveros packaging means that ring bus latency is higher.  No? The ring runs at a different frequency than the D2D?",Negative
AMD,"https://chipsandcheese.com/p/skymont-in-gaming-workloads  None of the youtubers mentioned about core-to-core latency, improvements on the schedulers and execution ports setup.  The e-cores are really great in a 4 group cluster.",Neutral
AMD,Designing a consumer product line around the niche of top of the line workstation is not a good decision for the average consumer.  I only once met a person with video production workstation that has more than an I7 or R7.  Previous gen I5 were amazing combo of multi core and single core . They rivaled amd r7 in preformance . Now a person wanting mid level cpu's would pay preformance tax due to it being made for the few people needing extreme amount of cores since those people would not buy dies that actually were designed for it like Xeon.,Negative
AMD,"this is a lot of words, being honest this writing feels like ai (but in good sense, right to point without a bunch of bs)   i would agree this architecture is very much limited by d2d and without 200s or just pushing d2d can be kinda underwhelming in performance but for sure as first gen product is very solid and makes me personally excited for nova lake as it seems they plan to fix and improve on their current architecture  also i believe clockspeed difference was merely responsible to 13/14th gen failures which were caused by excessive idle voltage.  i would say adding DLVR was kinda smart as well as it reduces your power consumption significantly at idle especially with proper tuning.  Edit: fixed typos, autocorrect being silly with me",Neutral
AMD,as a person who made an upgrade from lga1700 13950hx ES laptop mutant to 265kf this cpu feels soooo smooth in win 11 despite on a huge 75 NS the ram latency and not ability to reduce latency this new E core with 800 score at 5 ghz in cpuz single core make using the pc so nice and ofc in single core game like cs2 I've loose a lot of performance with 13950hx at 5.6ghz I've had 980fps in dust 2 fps benchmark and on 265kf only 800... BUT in a multi core load game I got fps improvement but any way this upgrade is worth it for ppl who is not a pc enthusiast and don't want to tune the lga1700 CPUs,Positive
AMD,That's one big wall of excuses,Negative
AMD,"It smells like slop in here. Shit post rather than a shitpost, congratulations.  I like my 265K. It performs well for my purposes and has reduced my personal power consumption considerably vs AM4. It is behind AM5 in my testing for broad term ""gaming"" when specifically chasing framerates, but compared to a 9700X or 9800X3D it is absolutely stellar at doing stuff while doing other stuff.",Negative
AMD,Yea with a z bord and the 200s boost and fast ram 15th gen is finally matching or supasing 14th gen,Positive
AMD,Wall of slop.  Make your points in a more concise manner.,Neutral
AMD,"AMD had a very similar experience with their first generation of Ryzen CPUs. One of the differences here is Intel had a competitive product prior to their architectural shakeup. Had Intel totally croaked for years and not been competitive in the CPU space the narrative would be completely different and everyone would be singing their praises.  Aside from that I think the biggest problem with this new architecture is simply there's little reason to buy in. It was only recently (if memory serves, I could be wrong on this) announced that the next generation of CPUs will share this platform and later ones will be on a new socket. When AM4 was announced we knew that it would persist for multiple generations and now with AM5 - why would you buy a board that will be obsolete when its time to upgrade when you could buy into a platform that will support your next 1-2 CPUs? Especially with the old intel socket performing just as well on a more mature platform, for most end users this first core ultra series just isn't worth investing.",Neutral
AMD,"""they deliberately chose to execute a hard pivot away from the monolithic brute force strategy of Raptor Lake to a disaggregated chiplet design that prioritizes area efficiency and performance-per-watt over raw, latency-sensitive throughput.""  That good for them, but we don't want that. I would take better latency over improvements that pretty much only save money to the companies.",Neutral
AMD,Love my 285K rig.,Positive
AMD,"IMO corrupt tech sites and tech YouTubers are behind ARLâ€™s failure for two reasons.   The first: AMD MCM processors without 3D cache are bad for gaming, and itâ€™s hard to find this information in 90% of charts to warn intel about the consequences of going down this path, even though they should have done their own tests and experiments.   The second: in my own tests, the 265K was 15% faster than the 9700X on launch BIOS. Through BIOS updates, that gap extended to 20%, making it only 7%-10% slower than the 14700K. Yet on some very questionable charts, the 265K is shown as slower than the 9700X.   For experienced users, RPL CPUsâ€™ temperatures can be lowered by 20Â°C by turning Hyper-Threading off and undervolting. For inexperienced users, ARL is better, as it runs 20Â°C cooler out of the box.   I believe that in 2026 we deserve raw, unedited video benchmarks that start from the desktop, show full system specs, then enter game-by-game benchmarkingâ€”no more charts with zero evidence to back them up.   When I tried to confront HUB with my benchmarks, I got blocked to cover up their lies and corruption. If they truly cared about which CPU is faster, they would share their in-game benchmark scores and discuss them in a scientific way, but thatâ€™s not their goal. The numbers go up and down for the highest bidders.   Lastly, I believe Nova Lake, with its expected 144 MB cache, will be faster than Zen 6 X3D by 10â€“20% as 9700x in real world is 20% slower than 265k and if both got the same IPC uplift NL will end up on top.   My own testsÂ    14700k vs 9700x 30% faster https://youtu.be/1f6W6nkDS4o?si=chFUAeBWzybQopaL   265k vs 9700x 23% faster https://youtu.be/PuB0Dg-Jvyk?si=SmGJUFtYj-OjjpQh   Tech sites got same results that clearly show RPL and ARL CPUs are only slower than 9800x3d and faster than everything else from AMDÂ    https://www.pcgameshardware.de/Ryzen-9-9950X3D-CPU-281025/Tests/Benchmark-Release-Preis-vs-9800X3D-1467485/2/     https://www.purepc.pl/amd-ryzen-9-9950x3d-test-recenzja-opinia-cena-wydajnosc-gry-programy?page=0,55",Negative
AMD,"For me.   I will go with Intel because of reliability (I know about chip degradation) but for me I bought 13900K from first day I undervolted using offset and but Max turbo frequency to 5.5Ghz . so my chip never tried to boost 5.9Ghz with crazy voltage.  Next is the most important is Everything just works. The boot is faster. wakes from sleep. its a more mature. I have another amd pc with r5 2600, where I found some stability issue.  Another one that is important to me. is idle power consumption. My 13900K can idle at 6 watts. Imagine 24 cores idling at 6 watts. where as 6 core zen idle at 15-20watts.(and that is low side many user reported 25+watt). its all because of chiplet.  I didn't test the new Arrow Lake as this uses tile. so i cant comment on idle power draw. if anybody has test, let me know.",Neutral
AMD,"Intel's latency problems have been around for a while now. Arrow Lake just threw gasoline on a fire that was already burning. [The 14900K had a latency of about 90ns for memory access, which is awful compared to the 10900K's 66ns and the 3950X's 73ns latency.](https://chipsandcheese.com/p/examining-intels-arrow-lake-at-the). The 285K sits at 106ns.  The 9900X sits at 82.43ns, so it seems like latency is going up across the board in general.",Negative
AMD,"This subreddit is in manual approval mode, which means that **all submissions are automatically removed and must first be approved before they are visible**. Your post will only be approved if it concerns news or reviews related to Intel Corporation and its products or is a high quality discussion thread. Posts regarding purchase advice, cooling problems, technical support, etc... will not be approved. **If you are looking for purchasing advice please visit /r/buildapc. If you are looking for technical support please visit /r/techsupport or see the pinned /r/Intel megathread where Intel representatives and other users can assist you.**  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/intel) if you have any questions or concerns.*",Neutral
AMD,I compare Arrow Lake to Zen 1 or the first iterations of Ryzen. It is quite the techinal hurdle but it allows for future generations to bake very well. Intel was just playing catchup from having 14NM^6 nodes lmao.,Positive
AMD,the problem for me the platform cost value over lga1700 isn't where it needs to be. namely I'm not interested in trading 32GB of DDR4 for just 8GB of DDR5.,Negative
AMD,"Since you are talking about latencies, best intel gaming cpu, so far, is 14700k. Excellent gaming performance and also great cpu for productivity.  Second best, is 14900k, same as 14700k, but cause of price it gets to second place.  Third place, you name it.  Period.  PS: I'm with intel since ..... Pentium 3 at 800MHz. Also have AMD cpu.",Positive
AMD,"End-user workloads at midsized businesses are almost entirely single-threaded. Even when the applications are multi-threaded, they often become single-threaded when they get shuffled through corporate antimalware. While AMD chases gamers and Apple chases artists, Intel is hitting a sweet spot here not perfectly served by any other single-user processor.",Neutral
AMD,"I've been saying similar in a couple of PCMR threads.  Arrow lakes problem is chiplet to chiplet latency. Which is understandable as this was a major departure from monolithic dies this generation. This explains both why games particularly suffer, and why very high speed memory can mitigate the issue somewhat.  Does this mean they aren't bad chips? No, they are (or at least for gaming performance they are). But it's quite exciting in the sense that it's a specific issue holding them back that can be solved. The rest of the architecture has a lot of potential.  I think of these chips as in a similar place to AMD Zen 1 technology wise. A huge shift, not actually delivering much performance boost yet, but with a whole lot of potential for updates to make big improvements.",Neutral
AMD,"Yes yes, I remember saying similar things about my FX-8350.",Neutral
AMD,"285K seems to have fantastic workstation performance, I didn't think much before selecting Intel over AMD parts for work to be honest, considering the efficiency gains. We landed on 265K, it benches very favorably compared to AM5 parts in nearly every workload except for gaming, and even then, that's mostly the X3D parts, and even then, that's when there is virtually no GPU bottleneck.   Most initial ""gaming"" reviews were done exclusively with 5090s, which is extremely unrealistic for most gamers and gave an extremely false impression that you would see a massive uplift by buying this part compared with the alternative CPU parts in gaming.   A lot of reviewers such as HUB have done a lot of work to correct this impression with a variety of testing scenarios and explaining their reasoning behind removing the GPU limiting factor as much as possible in benchmarks. Incidentally, these reviews typically showed that anything less than a 5080 sees virtually no benefit with a 9800X3D versus, say, a 9700X, and incidentally the two parts that saw no discernible benefits were the Radeon 9070XT and the 9070.  Obviously, if you have a 5090 and an unlimited budget with price being no factor, your best bet for top tier performance in all categories is a 9950X3D, but that just isn't what most people are looking at.  I myself bought into the future proofing mentality with my CPU and bought a 9800X3D, and ironically bought another AMD Radeon 9070XT to pair it with, a GPU that seems literally no performance gain compared to a 9700X, let alone a 285K. The same 285K that takes a dump all over the 9800X3D in nearly every other productivity benchmark.  I guess the good news is that when I upgrade my GPU in 2-4 years, at least I'll take advantage of the 9800X3D in games, lol. But considering it cost me over $900 for CPU, RAM, and motherboard, that's cold comfort. Ironically I probably would have made out a lot better buying a 5700X3D or a 5800X3D and the 9070XT and keeping my AM4 board and DDR4 RAM and saving $600.",Positive
AMD,Itâ€™s a stepping stone â€¦ the efficiency is super and performs the same as a 14900 drawing a lot less power. Impressive.,Positive
AMD,"You are correct that they needed to make a big architectural change as the 14th gen was clearly having issues and was being pushed too hard to make up for them, and ARL is the first step to that reset.  From their engineering perspective, it makes sense.  I wouldn't buy it though.  NVL... different story.",Neutral
AMD,"No 285k is not shaving off 80-100W from 14900k, Set 100W PL1=PL2 on both and then compare. 285k is not even that much better than 9950x in MT. No amount of words can explain ARL flop, it took intel 3 gens after rocket lake fiasco to catch up, just to waste all that effort on ARL. Show me any other silicon design with advantage of 2 nodes and a new architecture just to be slower than the predcessor.",Negative
AMD,"""If you are buying a 285K solely for (1080P) gaming, you are buying the wrong product for the wrong reason.Â ""  Fixed it for you. I game in 4K and I didn't buy a Ultra 9 285K to play games in 1080P to get high(er) framerate at the expense of stuttering. The ultras are outstanding CPUs.",Neutral
AMD,I guess.,Neutral
AMD,No one has time to read all that,Negative
AMD,This is a very long way of saying Intel has chose to prioritize competing with Appleâ€™s SoC and ignoring gamerâ€™s and PC enthusiastâ€™s wants/needs.,Negative
AMD,"Iâ€™m just waiting for Nova Lake and if it gets delayed into 2027 and if TSMC does the packaging for some chips there may be issues  with supply. TSMC does not like that Intel has IFS and they play dirty, real dirty.  Nova Lake flagship could be at or above $1000, I may go with Ultra 9 285K with the fastest pcie5 nvme and ram, by then hopefully ddr5 is accessible.",Negative
AMD,My same experience with both of my 265k systems. They have been extremely stable for me and very efficient. Never have to worry about temps and they perform well with a 5080 and 9070XT. Contrary to all the media rhetoric I enjoy gaming with them.,Positive
AMD,Basically the same or even less FPS than a 9800X3D consuming 80 watts,Neutral
AMD,"Hi I'm sorry to ask but what does this mean?     9000c38 A-die, 36 d2d and 34 ngu     is that an app or something?",Neutral
AMD,"Exactly, tuned 285k is just 2-3% away from max tuned 14900KS + DDR4 at 4300MHz CL16.  All Z890 boards are so cheap so I grabbed an APEX with a 265K. Only costed me $600",Neutral
AMD,"In gaming specifically, how smooth would you say the 285k is compared to the 149k? in the sense of frametimes and shader caching.",Neutral
AMD,"that is exactly the point, if it was just architecture we could live with it and consider it an scurve of innovation, but the process proves that this design is going nowhere",Negative
AMD,"New process nodes donâ€™t improve  performance on desktop processors when clock speeds and core counts stay the same. A 10nm monolithic ARL could have performed better and cost them less, although the newer process does improve power consumption which is essential for laptops.",Negative
AMD,Stopgap design and their first major foray into chiplet. I think they learned a lot of things on the way and Intel is famous for their processes getting better with age after a shrink. Compare Alder Lake to Raptor Lake. Compare Broadwell to Comet Lake.,Positive
AMD,"And nobody was saying you're required to. The entire point of the post was to say regardless of your thoughts and purchasing habits, ARL was deliberate, and even smart. Those who look for single metrics by which to judge ARL are missing the point.   Yes, if that single metric is all you care about, by all means go spend your money elsewhere, but ARL is a step sideways so future generations can take leaps forward.",Neutral
AMD,"This is way too true. I want a healthy Intel and AMD, but I'm also not going to act like Intel being now backed by the US Government and MAGA, as well as securing a well funded partnership with nVidia, doesn't make me feel a lot less like they need consumers to pity buy things from them to encourage innovation.",Neutral
AMD,">In highly parallelized rendering workloads like Blender or Cinebench, the 24-thread Arrow Lake design is often matching or beating the 32-thread Raptor Lake parts, which proves that the removal of Hyper-Threading was not a net loss for total throughput  So matching perf with a last gen part, after you hit a double node shrink **and** a massive E-core IPC gain and a P-core tock too is fine?   >The ""rent"" paid in silicon area for HT was no longer worth the ""yield"" in multithreaded performance,  This was a mistake according to LBT himself.   >This implies that Intelâ€™s next step must be an aggressive overhaul of the interconnect topology, perhaps moving towards a mesh or a more direct active interposer solution for desktop parts if they want to reclaim the gaming crown from AMDâ€™s X3D parts  Moving to a mesh wouldn't help much, and Intel's mesh's have a reputation for being insanely slow on their Xeon parts.   How much more advanced packaging does Intel have to use to match the latency of AMD using iFOP?   >Â But if you analyze the architecture, the Lion Cove P-core is a marvel of width and prediction capability that is simply being strangled by the packaging logistics  It's not. LNC is both not that all that wide, all the ARM cores beat it in that metric, and the prediction capabilities of LNC is bad- it's a literal regression vs RWC (last gen) in accuracy. It's worse than the E-cores branch prediction accuracy. And it's much worse than Zen 5's as well.   >and the floating-point performance is stellar.  This specifically is not the case. While in previous generations Intel was very competitive with AMD in spec 2017 FP, with ARL vs Zen 5 we see an almost 15% gap.   >The 285K is the cooler, more efficient, strictly professional grown-up in the room that unfortunately forgot how to play games because itâ€™s too busy trying to figure out how to talk to its own memory controller across a microscopic bridge.  Idk why you are trying to trivialize gaming when it pushes a huge percentage of the market, and is why Intel has been repeatedly telling investors they have lost the high end DT market.",Neutral
AMD,Yes because they do core to cores transfers via their shared l2 rather than the l3/ring. It's sick. Skymont in general is so underrated for how enormous of a performance gain it was. They literally fixed all the ecore issues it's the pcores that flopped,Positive
AMD,"As someone who â€œwrites like AIâ€ in part because of a learning disability that made it hard for me to write, I tend to organize my thoughts very deliberately. Using lots of punctuation, dashes, etc is now often interpreted as having used AI, although I have no idea whether OP did or didnâ€™t.",Neutral
AMD,">this is a lot of words, being honest this writing feels like ai (but in good sense, right to point without a bunch of bs)  It doesn't point out a bunch of BS, it introduces a bunch of new BS that is just straight up, factually wrong.   >i would agree this architecture is very much limited by d2d  Not single core performance like he is implying it is.   Just look at ARL-H vs MTL-H for example.",Negative
AMD,"Soon you will not be able to tell what is AI and what was before, where you were living in the Stone Age. Fooz better buckle their seat belts and get rekt, itâ€™s about to get a Bit-Funky.",Negative
AMD,"\> For experienced users, RPL CPUsâ€™ temperatures can be lowered by 20Â°C by turning Hyper-Threading off     \> 265k vs 9700x 23% faster   \> 5 games    You are cute.",Positive
AMD,at least you have proved that i did make the right choice on my 265k,Positive
AMD,AMD Unboxed are not serious and should be ignored at every opportunity. They have a long history of doing what you've said they've done to you. They get in childish arguments on twitter when they aren't blocking people who have data that disagrees with their clear bias.,Negative
AMD,I have one 13900k since day one... But like all enthusiastic guys I did some benchmarks and the voltages were a concern. So I tuned the bios after just a few hours of working.  3 years have passed and I have 0 problems. It's like a rocket ðŸš€ very fast and reliable,Positive
AMD,"Very nice, do you also use a contact frame?",Positive
AMD,> so my chip never tried to boost 5.9Ghz with crazy voltage.  You have no idea what cause degradation and undervolting does not save CPU.,Negative
AMD,For sure.  I still use 10900k which benefits massively from memory frequency. When running 4500 cl16 it sits in 33-36ns territory. Lowest latency cpu around was 2020.  Doesnt hold up vs today's cpus but the user experience is great.,Positive
AMD,"Really, 90ns on DDR5-3600, what else can go wrong here...",Negative
AMD,"Be civil and follow Reddiquette, uncivil language, slurs and insults will result in a ban.",Negative
AMD,"""Wait till games leverage multicore"".",Neutral
AMD,"Could also add 1440p into the mix, at max settings with ray tracing, the CPU is going to matter less and less.",Neutral
AMD,"Be civil and follow Reddiquette, uncivil language, slurs and insults will result in a ban.",Negative
AMD,"Are you using a B580, Iâ€™m wondering how it performs.  I have a 5070 OC and an army of Alchemist and Battlemage cards.  I may try to get a 9070 this year and OC / solder it to XT performance. There is a great deal of fake hype around the 9070 XT, Lisa and her army of gawkers really pulled out the hype train for the 9070 XT.  Many influencers (somebody who can post a video to snoozetube) received 9070 XTs for free so they could gimp primp them out to the masses. It has left a stale, rotting smell in my loins.",Neutral
AMD,"Did you used just ""stock"" profile ie NGU and D2D at auto and Intels default profile? Or Intel 200s boost?",Neutral
AMD,"Both 14900K and 285K won't get frametime spike when the L3 Cache is maxed and no random stutter/issue.  If I want a good gaming experience, I would go for the 14600k instead of the 9800X3D. Way cheaper and works way better.",Positive
AMD,"These are the bios overclocking settings, ram speed is 9000mhz, d2d die2die is 3600mhz, ngu chip fabric 3400mhz fully manually tuned",Neutral
AMD,"Honestly I don't feel any difference, both are max tuned and there's no stutter or dips, 285k is the one I prefer, lower power and temps for about the same performance. And probably 285k is the winner for stability also.",Positive
AMD,"> New process nodes donâ€™t improve desktop performance when clock speeds and core counts stay the same.  This is correct. The node shrink itself does not give IPC gains, what it gives is energy efficiency and area. The reason why people associate node shrinks with better performance is because when they switch a processor to a newer node they typically increase cache sizes and/or improve base/turbo clocks.",Neutral
AMD,> New process nodes donâ€™t improve desktop performance when clock speeds and core counts stay the same.  Netburst was awesome!,Positive
AMD,The problem is that MTL for all means and purposes should have been that test bed product. Or even lakefield tbh.,Negative
AMD,"Nothing smart about it.. they just couldn't do any better than release a half unfinished product because the company is corrupt as hell, fully relying on US gvt injecting  tons of money that ends up in a few top manager pockets instead of being used for restarting the core architecture from scratch.",Negative
AMD,"We were backed strongly by Biden admin too, the CHIPS act money was what Trump gave us, but demanded the stock in return instead.   Which I think is ultimately good for us American citizens. Too many times companies just got hand outs, even Bernie Sanders approved the Intel stock deal. https://www.reuters.com/world/us/us-senator-sanders-favors-trump-plan-take-stake-intel-other-chipmakers-2025-08-20/",Positive
AMD,Brotha everyone is tryina get a piece of that maga pie. Or vice versa. It would probably be unlawful to go against maga on fiduciary responsibility alone,Negative
AMD,This!,Positive
AMD,"On my 13600k I also see a shared L2 for each 4-core E-core cluster. Was there a regression between then and now that they've resolved? Or is there some hidden behavior where this shared L2 couldn't actually be used to core-to-core communication without going through the ring?  If you have a source with more info, I'd greatly appreciate it.",Neutral
AMD,"AI is the aggregation of all the rules and examples fed to it.  You write according to proper ""rules"" or clear organization (which is very much not ""vernacular"" level writing), then boom, you and AI aren't all that different.  It's bloody annoying to try organizing thoughts or points to be easily digested instead of a wall-of-text like you've been doing since Mavis Beacon taught you typing only to have people bitch about the style and ignore the content.",Negative
AMD,There are so many of us lol,Positive
AMD,5 CPU bound games enough.,Neutral
AMD,Do you use contact frame for the cpu?,Neutral
AMD,"yes, i do",Neutral
AMD,"Please, High life form, what causes degradation? enlighten us, mere mortal",Negative
AMD,I do have a B580 but haven't paired it with the 265k cpus yet. The B580 is currently in a i5-13600 system.,Neutral
AMD,I have a 265k and b580. Had it about 6 months. First desktop I've had in about 20 years. Works flawless for everything I need. Very stable. Very fast for my needs.. I pretty much only play warcraft though.,Positive
AMD,"Stock. One system uses a Z890 mb with 8200mhz cudimm and the other uses a B860 MB with 8000mhz cudimm. I tried 200S boost on the Z890 and it didn't benchmark much faster at all for the games I play, plus I had occasional lockups. It wasn't worth leaving it on for me so everything is at the Intel default profile.",Neutral
AMD,Lmao,Neutral
AMD,"Lol, Userbenchmark guy making things up.",Negative
AMD,thank you,Positive
AMD,any tips/resources to tune/troubleshoot? ive been chasing stutters from 2 different 14th gen systems and no luck lol,Negative
AMD,"Clock speeds havenâ€™t meaningfully improved since 32 nm Sandy Bridge. The 2500K and 2600K could overclock to around 5.0 GHz, and modern CPUs still run at roughly the same frequencies. Core counts are also similarâ€”Intelâ€™s 14 nm 7980XE had 18 Skylake cores. Cache increases are possible on older nodes as well, so newer process nodes mainly improve efficiency these days, which is contrary to what most expect of them.  A 10nm monolithic ARL could have performed better at least in gaming on desktop.",Neutral
AMD,Apart from straight up increasing frequency improved nodes also make improvements to CPU possible even at the same clock.,Positive
AMD,"I suspect they just didn't have enough time to change anything. MTL releasing in Dec 2023, internal testing I'm sure yielding some set of data, and external reviews giving other feedback, even by the release of MTL, ARL has probably been in the pipeline for years and probably locked into certain design choices regardless of the feedback and testing.  Additionally I suspect that on mobile chips/laptop gaming rigs there's less focus on each individual part because  a) few people hardcore game on laptops b) the latency can be blamed on other things since laptops are a prepackaged consortium of parts and it's harder to isolate, and  c) therefore laptops tend to be evaluated as a whole rather than the individual pieces that comprise them.   Therefore the ""latency issues"" only became a massive kerfuffle when the offending cpu could be isolated and tested alone, and reviewers needed something to complain about.   That's even if Intel was considering latency as the issue everyone made it out to be. Intel could have looked at it and considered the latency worth the cost to improve in other areas and serve as intels seminal desktop entry utilizing disaggregated silicon. Then gamers came and lost their shit that the newest Intel chip deprioritized something that impacted their precious fps- even though the impact was ""the new one is approximately the same to maybe a little worse as last gen in most games"".   Notwithstanding the fact that the 200 series chips retain healthy gen-to-gen perf uplift and a _massive efficiency improvement_ in productivity and general computing, and boosting the NGU and D2D clocks (which are _very_ low from the factory, and can be done with the app that Intel _has specifically designed for tuning their chips_ and is freely available (XTU)) brings the gaming performance to ""approximately the same to a little better in most games"". Contrary to what some people may think these chips are not solely or even majority used for gaming and there are other use cases Intel can to think about/chose to prioritize.   To be fair, gamers and tech enthusiasts are the ones who will care the most and therefore have a disproportionately large impact on the kind of publicity the chip will get. So, was this intels smartest PR decision? Maybe not. But I think it was still a sound engineering decision, regardless of whether or not they had feedback or data on the issue, even if it didn't go over very well with their loudest customer base.  And this is all overshadowed by the fact that if you stuck even the most hardcore of gamers on a blind trial and told them to identify what kind of chip they were gaming on, I have a hard time believing any of them would be able to tell with any certainty which is which.   Once you get to 60 fps, the vast majority of people stop caring. Whats five fps going to do to radically change your gaming experience so much that it's unplayable? Which brings me back to one of my original points: If you care _that much_, you can go spend your money _elsewhere_.",Neutral
AMD,"I'm aware of CHIPS.  Like I said, I want Intel to be competitive. I hope if their new layouts mature into something that can retake marketshare that the same care will be taken to preserve AMD. AFAIK, no one came to lend them money or sign large multifaceted partnerships at that time. This ""must save Intel,"" movement is something that is borne out of how big Intel is. They're too big to fail, it would have too many implications for the economy. It's not tit for tat, but as they are both American companies and AMD has significantly more invested in my country, I don't feel particularly motivated to help bail out Intel when they have the equivalent of the iron rice bowl rolled out for them at the moment. I'll buy what works best for my needs at the time I'm buying, as always, and if Intel can make a better gaming focused, with some imagery stitching on the side, processor than AMD can at the time I'm buying, that's the direction I'll go.  Ultimately the 200 series is what the Ryzen 1000 series was, but more stable as Intel has always had better support both internally and from vendors. I have no doubt Intel may catch AMD. My worry will be, what happens when they put their boots on AMDs throat, especially now that nVidia has more control over the situation than ever before?",Neutral
AMD,Pouring free gvt money into Intel is only making the company high managers less interested in restructuring and improving the company when instead they can just keep going at snails pace while cashing in. Gvt money is only supporting growth of corruption inside the company and stalling progress.,Negative
AMD,"It's so strange to me that we've hit a spot in consumer and enterprise computing where politics is now a factor. It's a different game when companies have to worry about that side, far too many consumers make decisions based on their politics when all that does is cause other issues. Obviously I won't go farther than that in a tech focused discussion lol, but I will say again that it's a different game and I don't think anyone wins if it becomes the norm.",Negative
AMD,I upped the tREFI of my memory in my MSI Vector with Intel Ultra 9 275HX and got some fps gains in Fortnite/Valorant/Hogwarts Legacy at 1200p,Positive
AMD,Yeah pre arrow lake it was particularly shit as it would instead go through BOTH l2 and then to l3 to communicate between cores like a shitty ISP route to a game server   That is obviously worse than normal but core to core communication being done through even shared l2 is very rare so even without that quirk it's not expected  Go to chips and cheese.com they have a ton of information about this stuff. Like their skymont article in this case it details all the huge upgrades,Negative
AMD,"Be civil and follow Reddiquette, uncivil language, slurs and insults will result in a ban.",Negative
AMD,Every respectable benchmark is CPU-bound (including HUB whom you try to diss) because every sane reviewer uses a fat 5090 and 1080p to show CPU differences.  Even if you did not cherry-pick the games the review with fast GPU and more games is much more indicative of CPU performance than your benchmarks.,Neutral
AMD,No I don't need it... You need a 360mm AIO that's all... After that it's all about bios settings.,Neutral
AMD,which brand do you use?,Neutral
AMD,"1. tvb working incorrectly 2. unlimited current set by motherboards which gets only higher when undervolted because same power limit at lower voltage necessarily means more current   Motherboards were undervolting CPUs with wrong LLC calibration intentionally   4. ~~motherboards having wrong LLC calibration~~ EDIT: Intel CPUs themselves requesting abnormal voltage in anticipation of frequency boost resulting in abnormal idle voltage (just remembered it correctly) 5. motherboards having wrong LLC calibration resulting in abnormal load voltage  Not a single smart ass on the planet could have predicted that all of the above can happen with ""stock"" settings and foresee all of this.  No frequency limit will save CPU when it dies in idle state.",Negative
AMD,"Thanks so in short:  You use only ""intel default profile"" and enabled XMP on your CUDIMM's right?   No further manual tweaks under NGU or D2D and RING values or any other critical tweaks pertaining to voltages no?",Neutral
AMD,"If you don't understand overclocking and don't see how a CPU with multiple millimeters physically between the IMC and cores can not possibly perform as well as the monolithic CPU I don't know what to tell you. Fully tuned 285K and 9800X3D benchmarks exist btw, check Blackbird PC Tech. 14900K is the best 1440p CPU and the 285K is the best 4K CPU.  Benchmark bar graphs of 10 games aren't the whole story anyway. There are far too many variables in various applications which will make the IMC island CPUs perform worse than the monolithic CPUs, sometimes substantially. It's enough for some of us to want to stay on monolithic just so that it always works. AMD knows this, next gen they won't put the IMC so far away and their die shots will look more like Arrow Lake.  For now, 50% more power consumption on 8 P core loads vs 9800X3D is a price I'm willing to pay. I don't want an 8+8 core CPU either so AMD doesn't really compete with the 24 core monolithic 14900K currently.",Neutral
AMD,"Sync all cores 55/57 depending on your cooler, undervolt also, ram oc is the most important for intel, frequency and tuned timings.",Neutral
AMD,"Bruh my 2600k couldn't hit 5ghz. I struggled to get to 4.4. same with my 5820k, which would do 4.2, both with voltage bumps and good cooling.   Modern processors definitely run faster. The 12900k in my media pc will happily sit at 5.2 on lightly threaded loads   Tho you are right about the core counts. High core numbers have been around for eons, they were just far too expensive for mainstream use",Negative
AMD,"It's because AMD doesn't manufacture chips, we do. That's what the funding was for, to revive manufacturing leadership in the US not to save failing architectures.  And yes as a consumer buy what works best for your needs and budget. That's the best thing about Ryzen and AMD's resurgence.  I don't get your ""boots on throat"" comment, but to think AMD hasn't done anything mischievous in the past is, well a lot has happened between the two companies in 40 years.",Positive
AMD,"A strong Intel IFS is a strong US. Many people get disillusioned and deceived through all the cognitive dissonance on social media, especially gamers. Unfortunately they are easy to manipulate.  Many people are buying INTC in the US to retire on, we will see this more and more as we approach 2030. INTEL IFS has to succeed otherwise the US will be doomed in this century. Even India is getting into the semiconductor industry now and Intel is working with them. We need IFS to be on top, cream of the crop, I need a taste.  You are defeating yourself by getting wrapped up with all the geopolitical propaganda, go take a walk in the woods and get away from it all.  Checks are in the mail.",Neutral
AMD,"What? The deal under Trump was for 10% of the stake in shares. The government can sell the shares at any time to get a return. Since the stock has doubled since, it looks like it was a great deal for tax payers.",Positive
AMD,Which way is up...?,Neutral
AMD,"Be civil and follow Reddiquette, uncivil language, slurs and insults will result in a ban.  Rule 5: AyyMD-style content & memes are not allowed.   Please visit /r/AyyMD, or it's Intel counterpart - /r/Intelmao - for memes. This includes comments like ""mUh gAeMiNg kInG""",Negative
AMD,"Here are few more games  [https://youtu.be/XZ6JJNdMW4g?si=mkuKutnT1tc7k9U\_](https://youtu.be/XZ6JJNdMW4g?si=mkuKutnT1tc7k9U_)  [https://youtu.be/Ah6izQnylsM?si=s2iqbkLFHc83jHgI](https://youtu.be/Ah6izQnylsM?si=s2iqbkLFHc83jHgI)  [https://youtu.be/mQ80rNg0k3c?si=sgXQJ\_kh0Nb22BIM](https://youtu.be/mQ80rNg0k3c?si=sgXQJ_kh0Nb22BIM)  [https://youtu.be/fDdwwx4vYrs?si=QzJ7jz5H6oFWHwuU](https://youtu.be/fDdwwx4vYrs?si=QzJ7jz5H6oFWHwuU)  Non 3ds are bad for gaming, thats a fact.  Here is my latest test for 7800x3d vs 14700k  [https://youtu.be/ZTNE0EWtA1Y?si=zoujDFCzvCSj-UE2](https://youtu.be/ZTNE0EWtA1Y?si=zoujDFCzvCSj-UE2)",Neutral
AMD,thermalright.   Any frame will do. get whatever is cheap,Neutral
AMD,"Let me explain why it will not degrade my CPU.  1. **TVB (Thermal Velocity Boost) is disabled when I set the turbo limit.** 2. **Current is not the issue.**Â First, even Intel chips were failing at idle. Second, you stated that ""the same power limit at lower voltage necessarily means more current."" That is incorrect, if it drew more current, then why does lowering voltage reduce power consumption? Have you missed basic physics? 3. **CPUs follow a voltage-frequency (V-F) curve.**Â The main issue was that either the CPU or the motherboard was supplying excessive voltage, or the CPU was requesting too much. Higher voltage is required for extreme single-core boosts, such as 5.9 GHz. This is why i3 and i5 CPUs were not affected. When I limit my boost and apply an undervolt, the CPU no longer requests high voltage. It might request slightly higher voltage for 5.5 GHz, but that is nowhere near the voltage required for a 5.9 GHz boost. 4. **The same principle applies.**  Its seems you are a failure of high life form.   Maybe read here more. it was already to high voltage   [https://community.intel.com/t5/Blogs/Tech-Innovation/Client/Intel-Core-13th-and-14th-Gen-Desktop-Instability-Root-Cause/post/1633239](https://community.intel.com/t5/Blogs/Tech-Innovation/Client/Intel-Core-13th-and-14th-Gen-Desktop-Instability-Root-Cause/post/1633239)  Maybe you havent read much. if you undervolted only using AC/DC loadline and didnt limit max frequency. Then your CPU could have degraded.   While I used offset and set the max turbo limit.  I know how silicon works. I tune every CPU and GPU I buy.",Neutral
AMD,"Yeah, I do use XMP to get 8000/8200hz but no tweaks and everything is Intel default.",Neutral
AMD,"Be civil and follow Reddiquette, uncivil language, slurs and insults will result in a ban.",Negative
AMD,"Probably just bad chips. In almost every review, 4.7â€“4.8 GHz was achievable on the 2600K, and 4.6â€“5.0 GHz on Haswell-E. 5.0ghz wasn't hard to do on 8700k-9900k-10900k. Also, ARL runs at lower clock speeds than RPL, so in some cases newer process nodes actually clock lower.   this happened many times before like 32nm SNB OC better than 22nm IVB and haswell or even 14nm 6000 series skylake, so no in most cases new process nodes don't improve clock speeds or at least not on desktop.",Negative
AMD,"Okay, so we've gone right off the rails of a logical discussion. I fail to see how we went from talking about a failing architecture, which I don't think of Intel's product line as, to the whole bailout discussion. Maybe because I said AMD didn't get bailed out? I think maybe you forget that AMD had to offload global foundries, I don't think anyone even blinked when that happened and it's likely because that was a different era.   My post had nothing to do with the bailout versus architecture (or saving it) , apart from mentioning that I don't believe as a consumer I should feel motivated to buy Intel over AMD, or any other American firm, at the moment.   To be very clear, as this is personal for you, I do own Intel equipment including an Arc graphics setup for one of my children. I'm not anti-Intel or anti-American at all.   I know the history between AMD and Intel fairly well. Oversimplifying, AMD as it is doesn't exist without Intel. AMD only grew because they were the most successful second source producer for Intel, and the most successful at riding the thin grey line between patient infringement and unique implementation of similar IP that kept them alive while everyone else in the X86 space either died or became irrelevant to the consumer or enterprise space. After Itanium, the story levels out with both companies becoming effectively unwilling AMD64 codependents, and I'm saying that humorously.   Intel would gladly own the X86 market outright. So would AMD. At the end of the day, we need the two driving innovation through competition. Even if the CHIPS Act, the government stock acquisition, and the nVidia partnership are solely aimed at bringing more, needed, chip manufacturing to the US, it could create a situation where that amount of leverage puts Intel into a hyper dominant position again in the near future. Honestly, I hope I'm wrong.",Negative
AMD,"Hey sorry to interject like that, can you ask around what ppl in the team think the safe VCCSA voltage for raptor lake is beyond standard spec? You can dm the answer if u want. I'm from Russia so it's not like I'll go run RMA'ing this stuff just because you told me that info",Neutral
AMD,"Did you even read my post, or are you a bot? Seriously asking. I didn't bring up geopolitics. I live in Canada my dude. AMD has their graphics office still right beside the TO airport, and that's only a side comment. AMD is American too. My concern isn't about anything you just said lol.",Negative
AMD,65535,Neutral
AMD,"\>then why does lowering voltage reduce power consumption?  I have no idea what is the workload you are using which is guaranteed to never hit the limits. Solitaire?   Undervolting does not guarantee lower power usage with modern boosting CPUs. It very obviously (to any sane person) depends on workload.  \>Maybe read here more.   \>Thomas\_Hannaford, Employee   â€Ž You are so cute.  \>Motherboard power delivery settings exceeding Intel power guidance.  Literally what I said in 2, 3, 4 but in stupid terms.  \>Microcode and BIOS code requesting elevated core voltages which can cause Vmin shift especially during periods of idle and/or light activity.  Literally what I said.  \>IntelÂ® reaffirms that both **IntelÂ® Coreâ„¢ 13th and 14th Gen mobile processors** and future client product families â€“ including the codename Lunar Lake and Arrow Lake families - are unaffected by the Vmin Shift Instability issue.  This is verifiably bullshit because nothing about mobile processors protects them from wrong voltage received because of wrong LLC settings.  \>CPUs follow a voltage-frequency (V-F) curve  If you do not know that Intel is requesting high voltage to avoid insufficient voltage before frequency boost you do not know jack shit. It is literally what happens under description ""**Microcode and BIOS code requesting elevated core voltages which can cause Vmin shift especially during periods of idle and/or light activity**"" and there is a video proof of that with an oscilloscope.  No settings which you mentioned are preventing irreversible damage.   Claiming that you use Intel for reliability after you did not wish to use your own Intel at stock settings is laughable.",Neutral
AMD,"You skipped the 8600K, it also did 5ghz",Neutral
AMD,"Anything over 4.7ghz on Haswell-E was NOT very common. I would say 4.4-4.5 on those chips was more realistic. 5 GHz we are talking golden godly chip.  I had a 5960X for 8 years, one of the better ones manufactured in Costa Rica and not Malaysia which was better for OC, and mine did 4.7 ghz.",Neutral
AMD,"My initial comments were on, ""I'm also not going to act like Intel being now backed by the US Government and MAGA"" and what the funding was for.  Edit: and my response was about who also backed the funding.",Neutral
AMD,"All I can recommend and say is follow whatever guidelines you're given officially and make sure your BIOS is updated. All those teams work to make sure it's delivered to the customer. Otherwise it's all random, some parts can handle higher voltage, some can't.  The term silicon lottery is real and just a nature of small scale manufacturing, EM and quantum effects these days.  I will say, with our new CEO a lot of these customer issues are now streamlined internally. Used to be layers between engineering and customer interaction, so I expect better responses and reliability than before.",Neutral
AMD,"Ah, so you mean *lower* the TREFI then, from what JEDEC or XMP specified?",Neutral
AMD,"I believe that refined process nodes (the â€œ+++â€ stages) are what really improve clock speeds, not the first generation of a new node, or at least this is the case for the last 15 years.   Here are some examples:   -Intelâ€™s 32nm Sandy Bridge came after the early 32nm CPUs (dual-core i3/i5 300/500 series and the 6-core 980X), and Sandy Bridge turned out to be an excellent overclocker.   -22nm Ivy Bridge and Haswell were mediocre in that regard, while Haswell-E (a more mature implementation) overclocked better. Broadwell-E and early Skylake also werenâ€™t great for OC.   -Once the node matured, things improved again. Coffee Lake (refined 14nm) made 5 GHz relatively easy. The same pattern repeats with 10nm: Alder Lake (12th gen) came after Tiger Lake and could already reach ~5 GHz, while Raptor Lake pushed clocks even higher, up to ~5.7 GHz.   Overall, higher clock speeds tend to come from node maturity and refinement, not from the first use of a new manufacturing process, and I believe 5.8ghz could have been possible if intel used its own 10nm process node on ARL considering its HyperThreadingless.",Positive
AMD,"On that side, it'll depend on what the US does with the stock it has. Canada bought GM stock during the 2008 crash, and then quietly sold it off as GM recovered. If the US does that, I don't really see an issue.  The MAGA part was a half hearted comment, made to follow the weirdness of the whole situation and comment I was replying on as well. As I said in a separate post:  ""It's so strange to me that we've hit a spot in consumer and enterprise computing where politics is now a factor (speaking about how decisions beyond national security are now driven by politics and trying to be on the right side at any moment when it matters). It's a different game when companies have to worry about that side, far too many consumers make decisions based on their politics when all that does is cause other issues. Obviously I won't go farther than that in a tech focused discussion lol, but I will say again that it's a different game and I don't think anyone wins if it becomes the norm.""  I'm going to add, light heartedly, I do hope we see AMD/nVidia/Qualcomm/etc manufactured and final packaged products coming out of Intel Foundries one day. I'm not sure how or if it will work, but the situation seems dead set not to allow significant further nodes beyond 2 nm or packaging to occur outside of North America. If the US wants viable national chip production, Intel is the better option, I hope it works out in a way that maintains design level competition while meeting national security goals.",Neutral
AMD,"I get that. But itâ€™d be nice to have a â€œthis voltage is safe for 99% of the cpus and this voltage is the LD50 for the cpuâ€. That would probably improve customer relations but your legal team might be very, very unhappy with that lol.   Anyway cheers for the response, with the way things are looking up for intel, i might be buying some stocks soon",Neutral
AMD,JEDEC 5600 cl 40 kingston fury sodimm 2x 16 gb,Neutral
AMD,"I mean, you can just figure that out yourself and buy new CPUs till you get one working :P",Neutral
AMD,"Yeah, but what was TREFI before you lowered it?",Neutral
AMD,10000 ish,Neutral
AMD,"Hi everyone if I'm upgrading my Dell vostro 3670 i5 8400 @32gb ram to an i7 9700, would I be able to upgrade the RAM it's still being ddr4? To 64 or 128?",Neutral
AMD,"Hi there I have an xps 15 9530 laptop with two gpus: one is an arc a370m and the other is an iris xe graphics and in the Intel system it says I can use rebar, but I've tried and searched everywhere in the BIOS and followed countless guides and can't seem to find the setting. Can someone help me with enabling it please. I've searched the bios and done everything and can't seem to find it",Neutral
AMD,"With the crazy RAM prices, I'm looking to move to a 13600K or 14600K to keep using the 64GB of DDR4 from my ancient 7700K build. Do we users generally consider Vmin Shift Instability to be fixed at this point through the series of BIOS and microcode updates?  Related: Should I expect something in the range of a 10% performance drop from any of the reputable reviews, due to the fixes? Also, are efficiency-cores pretty much working as intended at this point, or is thread scheduling still a concern on them where your high performance thread ends up on an e-core?  Thanks all!  Note: This question is not for Intel\_Support. The answer from your side would obviously be ""Yes!"". :)",Neutral
AMD,Is Tiber cloud gone forever?  https://console.cloud.intel.com/ just gives a DNS error now.,Negative
AMD,"I have installed new Intel Wi-Fi 6 AX210.NGWG.NV in my ASUS laptop, bcz the old one died and couldnt connect to bluetooth since, WIFI works perfectly fine tho, so i dont know if problem is with drivers or not. Also i would just instal them from Intel, but i live in russia and i dont know any trustworthy sites, so if anybody knows, i would be really gratefull",Neutral
AMD,"How do I know the legitimacy of an Intel wifi card, model AX210? I've been searching for it in Amazon and most are manufactured in Vietnam and China, with varying prices.",Neutral
AMD,"I keep seeing mentions of TPM in our system requirements and I'm honestly a bit lost on what it actually does for our security, so who is the best person in the org to chat with to get the full rundown?",Neutral
AMD,"i've got an i7-14700kf on an asus rog strix b760-a with a corsair h100i elite capellix xt (240mm aio) and when i run after effects my cpu temps shoot up to 90 degrees, it probably wouldve gotten higher but i closed it cause it felt too high for what i was doing, i'm looking to undervolt my cpu but i dont know anything about it. i just want something safe and simple (im not looking for an extreme undervolt, just one that would lower my temps & possibly keep the same performance)",Negative
AMD,"u/Chelostyles Thank you for your inquiry regarding the CPU and RAM upgrade for your Dell Vostro 3670. As much as I'd like to provide my technical insights on this upgrade path, I'm not in a position to provide specific suggestions since this involves hardware modifications to an OEM system.  For the best compatibility outcome and to ensure optimal system performance, I strongly recommend reaching out to your system manufacturer directly. They can provide definitive guidance on supported CPU upgrades (i5-8400 to i7-9700) and maximum RAM configurations for your specific model. We don't want to inadvertently bypass any warranty terms and conditions on your system by providing modification recommendations that might affect your coverage.  Your system manufacturer's technical support team will have access to the exact specifications, BIOS compatibility matrices, and supported hardware configurations for your Vostro 3670 model. They can confirm whether the motherboard supports the i7-9700, the maximum RAM capacity (64GB vs 128GB), and any potential limitations or requirements for these upgrades.  This approach ensures you get accurate, manufacturer-validated information while maintaining your system's warranty protection.",Neutral
AMD,"u/I_like_carsyay  XPS 15 9530 hardware does support Resizable BAR, which is why Intel's system detection shows it as available for both your Arc A370M and Iris Xe graphics. However, the system manufacturer has designed their BIOS interface to prioritize stability and user-friendliness, often managing advanced PCIe features like ReBAR automatically in the background rather than exposing manual configuration options. This approach ensures optimal system performance while reducing complexity for users. I recommend checking for the latest BIOS updates from your OEM's support site and contacting their technical support team, as they would have the most current information about how ReBAR is implemented on your specific model and whether any additional configuration steps are needed to fully utilize this feature.     I've posted an article below in case you haven't yet come across it:  **Helpful Resources:**  *  [What Is Resizable BAR and How Do I Enable It?](https://www.intel.com/content/www/us/en/support/articles/000090831/graphics.html)",Neutral
AMD,"u/QunatumLeader Hi, thanks for your interest!Â  You can find and apply for all of our jobs online atÂ [http://](http://jobs.intel.com/)[j](http://jobs.intel.com/)[obs.intel.com](http://jobs.intel.com/). We donâ€™t currently accept submissions via social.Â  Good luck!",Positive
AMD,"Late to this, but I'm a 13900K owner. I have not had any issues with stability since applying the BIOS update and haven't noticed any performance loss, so I think this is fine. I did not thoroughly benchmark before and after though, partially because of how high peak temperatures were before the update. I am using a Noctua NH-D15 and a contact frame to reduce CPU temperatures.  Up until a few days ago I would have said that thread scheduling isn't an issue, but then I played the game Maneater and it's basically unplayable unless you use launch options to force the game to only P-cores. There's the Intel ""Application Optimizer (APO)"" utility but it seems abandoned and you can't add your own games if Intel hasn't added a profile. I was a big proponent of E-cores but honestly it seems like a half-baked technology that Intel never put the effort in to support properly. That said I guess I could just entirely disable them if I cared so much, but that's a non-trivial amount of performance to just give up.",Neutral
AMD,Hi u/ConspiracyPhD **Post**Â a question onÂ [IntelÂ® Tiber Developer Cloud Community](https://community.intel.com/t5/Intel-Developer-Cloud/bd-p/developer-cloud)Â forum for further investigation.,Neutral
AMD,"u/Far-Common2207 In this case, we suggest buying the wireless module from authorized Distributors to mitigate the legit concerns. Other than that, the OEM module warranty is not covered by Intel. For more details, you need to work with the Distributor or place of purchase for support to further verify if the wireless card is legitimate.  Check this article: [Where to find the Serial Number for IntelÂ® Wireless Cards](https://www.intel.com/content/www/us/en/support/articles/000092302/wireless.html)",Neutral
AMD,"[**Plenty-Solution-3692**](https://www.reddit.com/user/Plenty-Solution-3692/)**, TPM (Trusted Platform Module)** is builtâ€‘in security hardware that helps protect important data on your PC using encryption**. Intel PTT** is Intelâ€™s TPM that lives in the system firmware instead of being a separate chip, but it works the same way. Most PCs from the last few years already have TPM 2.0, sometimes it just needs to be turned on in the system settings. . If youâ€™re not sure how to do that, your motherboard or PC manufacturer should be able to help.  You can check this article for more information: [What Is Trusted Platform Model (TPM) and Its Relation to IntelÂ® Platform Trust Technology (IntelÂ® Pâ€¦](https://www.intel.com/content/www/us/en/support/articles/000094205/processors/intel-core-processors.html)",Neutral
AMD,"Individual\_War\_129, we do not provide typical temperature operating ranges for each processor or each core, as it can vary based on the system design and workload. Processors have internal protections to prevent against excessive temperatures. Operating ranges below the protection points are highly dependent on system configuration and workload.  In case you haven't come across it yet, you may check the articles below:  [Information about Temperature for IntelÂ® Processors](https://www.intel.com/content/www/us/en/support/articles/000005597/processors.html)  [What Is Undervolt Protection and How Does It Affect Overclocking in IntelÂ® Extreme Tuning Utility (â€¦](https://www.intel.com/content/www/us/en/support/articles/000094219/processors.html)  [Thermal Design Power (TDP) in IntelÂ® Processors](https://www.intel.com/content/www/us/en/support/articles/000055611/processors.html)",Neutral
AMD,Forum doesn't exist or access denied.  I guess Tiber is just gone now.,Negative
AMD,Do you know any authorized distributors here in the Philippines?,Neutral
AMD,"I see, all good thanks for your support!",Positive
AMD,u/ConspiracyPhD I just checked the forum and it looks like itâ€™s up and running. Could you try accessing it again using your Intel account?  [IntelÂ® Tiber Developer Cloud - Intel Community](https://community.intel.com/t5/Intel-Tiber-Developer-Cloud/bd-p/developer-cloud)  [](javascript:void(0);),Neutral
AMD,"u/Far-Common2207 According to the directory, these are the distributors in the Philippines. [Distributor Partners](https://www.intel.com/content/www/us/en/partner/showcase/partner-directory/distributor.html#sort=relevancy&f:@sfdisticountry_en=[Philippine,Philippines,Phillippines])",Neutral
AMD,"Nope.  https://imgur.com/a/tYRhYoV  Access denied and a nice ""This content is no longer available.""  Guess it's a completely dead project and should be removed from Intel's website.  http://console.cloud.intel.com/ is not accessible.",Negative
AMD,"u/ConspiracyPhD Please check your inbox, Iâ€™ve sent you a personal message. Iâ€™ve already coordinated your concern with the respective team, and as per their instructions, youâ€™ll need to email them directly.  [](javascript:void(0);)",Neutral
AMD,that is the most non-descript render of a laptop possible,Negative
AMD,So light it visibly doesn't have any ports?,Negative
AMD,"Does intel 10A still come out as scheduled in 2027? I googled it and found out intel said the 10A will come out in 2027, but this was old news in 2024.",Neutral
AMD,I wonder how intel and other companies are going to manage for next year? Prices for memory and SSDâ€™s are predicted to go even higher putting off many buyers from getting a new PC build or laptop.   This makes me concerned Nova Lake wonâ€™t sell as well because of this.,Negative
AMD,It's shameful to see LBT posing with 14A wafers when all the groundwork for this was setup by Pat Gelsinger. The entire Intel board should have been sacked instead of Pat.,Negative
AMD,"GFHK also has 14a for Razor and Coral Rapids in 2H 2027, so I'm taking what they are saying with very little credibility.   Plus, we had very similar rumors during 18A, and that went nowhere. Fool me once...",Negative
AMD,Unbelievable till official announcement,Positive
AMD,can't they use it to make more ram ?,Neutral
AMD,good news,Positive
AMD,They can't even sell 18A to NVDA what are they doing on 14A really ?,Negative
AMD,"Hm, we will see what happens with the stock price soon, but so far so good",Positive
AMD,"Lisa So Sue Me wants a taste of the Lip? Am I living in a different dimension? I callled out So Sue Me on X, is she jumping on Big Blueâ€™s Back?  Is anyone Dollar Cost Averaging INTC? It will still be awhile before IFS is firing on all cylinders. The Lip said he would stop high end chip production for external customers (If No One Took A Byte) in order to get $$$ to build out Ohio Fab.   Letâ€™s get it done. Iâ€™m driving distance from the Ohio Fab, any chance Intel will give me a tour?",Neutral
AMD,"If you are referring to an article like the one linked below, they later clarified that 10A was supposed to begin development in 2027, not production.  [https://www.tomshardware.com/pc-components/cpus/intel-puts-1nm-process-10a-on-the-roadmap-for-2027-aiming-for-fully-ai-automated-factories-with-cobots](https://www.tomshardware.com/pc-components/cpus/intel-puts-1nm-process-10a-on-the-roadmap-for-2027-aiming-for-fully-ai-automated-factories-with-cobots)  *""Intel's previously-unannounced Intel 10A (analogous to 1nm) will enter production/development in late 2027, marking the arrival of the company's first 1nm node, and its 14A (1.4nm) node will enter production in 2026.* Â ***\[Edit:Â to be clear, this means 10A is beginning development, not entering high volume manufacturing, in 2027\]*** *The company is also working to create fully autonomous AI-powered fabs in the future.""*",Neutral
AMD,"14A probably won't be ready for 2027, much less 10A.",Negative
AMD,10A & 7A are in R&D phase,Neutral
AMD,It's gonna be 2026 soon and 18A is launching at the very start of 2026. A double node shrink in like 2 years doesn't exactly sound very possible.,Neutral
AMD,"Remember, these are just names/nicknames. 10A? The difference between 14A and 10A is probably equivalent to the difference between 14nm and 14nm+",Neutral
AMD,And yet here you are.,Negative
AMD,"Brother, don't hint at your place of employment when you have your full face in your profile as well as you commenting in NSFW subs.",Neutral
AMD,There will probably still be another of layoffs next month ðŸ˜‚,Negative
AMD,"Yes, perhaps itâ€™s better if you post it on the r/intelstock subreddit instead ðŸ¤ª",Neutral
AMD,"Ram should be at a more reasonable price in 2027 according to Moores Law is Dead. Maybe not $100 for 32GBs, but maybe below $200 ðŸ¤ž",Neutral
AMD,They have contract.,Neutral
AMD,"TBH I feel LBT is doing a good job. I was hesitant at first, but he's making a lot more sense than Pat's crazy descent into spending crazy amount of cash with no business in sight.  Speaking as a shareholder.",Positive
AMD,"The entire Intel board probably should have been sacked, but Gelsinger as well. He failed at his main mission and drove the company into a crisis. That kind of thing should have consequences.",Negative
AMD,Who was it that decided to exit the SSD business.  They sold off a cash cow for pennies on the dollar.,Negative
AMD,Nvidia is at least some what believable. AMD though?,Neutral
AMD,"I thought that too. At least they'd have some money coming in. But apparently it takes years to rejig the plants to churn out RAM instead of CPUs. And they're heavily invested in getting the next gen CPU fabs working.   Pivoting to RAM just doesn't make sense, unless they magic'd up a new type of RAM that's cheap to make and has super low latency - which is one thing I've always thought they ought to do.   Imagine if external RAM ran with super low latencies like CL1 or CL2 or something. You wouldn't even need branch prediction and prefetch and massive caches in the CPUs.",Neutral
AMD,"""news"" needs a lot of quotes around it...",Neutral
AMD,This isn't wallstreetbets. We don't talk like that here.,Negative
AMD,">If you are referring to an article like the one linked below, they later clarified that 10A was supposed to begin development in 2027, not production.  Yup, and to make it even more obvious, the same graph also has Intel 14A showing up early 2026, and 20/18A showing up at the start of 2023*,* so clearly it's not the date of when the node is going to come out (or even start HVM).",Neutral
AMD,"Dunno why this is being downvoted, the CEO of Intel himself said that 14A is a 28-29 node in the Q2 2025 earnings call.",Neutral
AMD,enough info about how intel names products exists to know. if it didn't increase in transistor density per mm it would not be called 10A.,Neutral
AMD,"I think everyone knows there will be continued Q1 and possibly Q2 layoffs.   Return to office didn't lead to enough voluntary attrition. Leadership wants to hit a magic number which sounds good for financial reports, not what is actually viable to run things.",Negative
AMD,That crazy amount of cash being spent by Pat is what enabled 18A and 14A. They HAD to buy multuple $250M Litho machines from ASML in order to make that possible. Pat was playing catch up after years of under-investment by Swan and Krzanich. It was necessary and LBT is getting the credit. You don't appear to understand the lead times required in the semi industry. Pat understood that. The mistakes Pat made were trying to build a fab in Ohio and not cutting headcount and getting rid of dead weight sooner.,Neutral
AMD,The thing intel is doing rn is literally pat's groundwork isn't it?,Neutral
AMD,Still a tall order imo unless it's some defense chip for RAMP-C,Neutral
AMD,"If they're following industry standards I'd say it depends on how good AMD's next gen is. Intel doesn't need direct access to AMD designs to etch chips for them, and designers make way more than per wafer than foundries do.  If AMD has superior designs to intel again they could finally ship out some damn chips for laptop OEMs. It would hurt intel more than the revenue would benefit them imo since client has really been carrying intel for the last six years and demand for AMD chips has been high despite the drip feed of strix chips. honestly I'm considering an AIO/NUC/whatever the new name is with strix halo and unified LPDDR5 to upscale old footage without having to use my daily desktop. imagine if it was available at scale.",Neutral
AMD,"they don't have to make faster ram, just make it, right now, some ppl don't really care about speed",Negative
AMD,"So, risk production in late 27/early 28 and HVM in 2029 I suppose?",Neutral
AMD,YEs it is. He did make mistakes. He was hiring like crazy at the beginning of his term. And he should have started cutting sooner. But he doubled down on EUV lithography and tried to get orders in for the most advanced litho machines ASML made before TSMC started buying those machines. This is why 18A and 14A even exist at Intel.,Negative
AMD,"Nothing they're doing *right now* is a success story. Remember that they don't actually have customers, and that is first and foremost what got Gelsinger fired. As things stand, the foundry as a whole is a failure. If things turn around, that will have to be under Lip Bu.",Negative
AMD,I wasnâ€™t aware 14A is part of the RAMP-C initiative. I thought it was only Intel 16 & 18A that are currently covered by RAMP-C?,Neutral
AMD,I think so. Maybe optimistically we see a 14A product in late 28'.,Neutral
AMD,"> But he doubled down on EUV lithography and tried to get orders in for the most advanced litho machines ASML made before TSMC started buying those machines. This is why 18A and 14A even exist at Intel.  No, that was just more wasted money. 18A doesn't even use the high-NA machines Intel bragged so much about. It seems they tried blaming their struggles in foundry on the equipment instead of the broader org culture and talent.",Negative
AMD,"As much as I hate to say it, Intel arc was also a mistake.",Negative
AMD,get out of here with your sensable comments. we only circle jerk on this sub,Negative
AMD,It can expand in future ? My point is how can we believe such stuff at face value without actual proof.,Neutral
AMD,14A does use the High-NA machines. They didn't buy them with no plan to use them That would be stupid.,Negative
AMD,"no it wasnt. GPU's are surpassing cpu's eventually if not now.  a major part of amds success  was buying radeon all those years ago. when intel realized how utterly shortsighted they had been, they pushed arc heavy even though it wasnt going to succeed that well.  this was the right choice, as otherwise they would look like a dinosaur.",Neutral
AMD,"It can expand in the future but this is a trial, itâ€™s not yet a long term commitment until the outcome of the project is known (final evaluation wonâ€™t be until 2026/2027). 14A is not part of RAMP-C, itâ€™s still in phase III trial with 18A. Thereâ€™s been no additional RAMP-C design calls via NSTXL that Iâ€™m aware of",Neutral
AMD,"> 14A does use the High-NA machines. They didn't buy them with no plan to use them  They bought the very first high-NA machines, claiming it was for 18A. Now they won't be used until a node that hits volume in '28/'29, by which point TSMC will have (or rather, already has) much better machines. So what exactly was the point?  > That would be stupid.  Is that not a perfectly apt description for Intel's foundry strategy in recent years? It sounds like they really drunk the coolaid with their attempts to blame the 10nm failures on the lack of EUV.",Negative
AMD,Yeah. The real mistake was LBT and the other Intel board members nerfing the r&d budget.,Negative
AMD,14A will have volume production in 2027.,Neutral
AMD,Didn't Intel say in a presentation that 2027 is risk production for 14A? https://www.techspot.com/news/107736-intel-doubles-down-foundry-ambitions-unveils-18a-14a.html  https://www.youtube.com/watch?v=5Jbj4RQBXbo&t=818s,Neutral
AMD,"Lip Bu himself is saying '28-'29. At this point, there isn't a chance in hell it's ready for volume in '27.",Negative
AMD,I just wanted arc to succeed ðŸ˜”,Negative
AMD,did you buy one? I have owned two. A A750 and now a B580. They are great cards for the price paid. I'd like to upgrade to a B60 PRO. 24GB VRAM sounds amazing especially for $600. but I can't find one in stock anywhere.,Positive
AMD,"The fact 890M is that much faster than 140V shows this benchmark is terrible anyway. In real gaming performance, 140V performs very close to 890M and does so at usually superior efficiency.",Negative
AMD,Is panther lake on the intel process considered better perf than lunar lake on tsmc process? Or is it lateral,Neutral
AMD,I hope it comes to desktop CPUs,Positive
AMD,Almost 7600m performance ie stream machine. From a igpu . Hoping a handheld with this igpu under 1000usd,Positive
AMD,"yeah it says   ""We should also make it clear that these benchmarks seem to undermine the performance of Intel's Xe2 architecture. The Arc 140V is shown much slower than the Radeon 890M, but in reality, it ends up close to or faster in actual games. So it looks like this benchmark suite is not optimized for older Arc GPUs, but the new Arc Xe3 architecture is doing well, and we can see further improvement once the finalized drivers roll out.""",Negative
AMD,Yeah this headline doesn't add up based on my own testing,Negative
AMD,Yeah that's a strange result. Makes me think the 16% will be for PL improvement over LL.,Negative
AMD,"So imagine how much faster it is in actual practice.  These iGPUs Intel are putting out are great, it's a good time for lower-power handhelds!  And insane power handhelds too, with Strix Halo getting in them, the Ryzen 388 (8c16t with 40CU iGPU) allegedly coming, and I'm sure Intel is working on an answer to Strix Halo which if it uses this kind of uArch, will probably be deadly.  Good friggin times.",Positive
AMD,concur  some benchmarks are biased,Negative
AMD,lateral,Neutral
AMD,If itâ€™s just â€œ16% faster than 890mâ€ itâ€™s nowhere close to 7600m. You have to be over twice as fast as the 890m.,Negative
AMD,"Isn't 140T also faster than 140V in benchmarks, despite being Xe+?",Neutral
AMD,"Yeah the 388 makes a lot of sense, a worthy sacrifice of a cpu tile for cheaper more efficient gaming cpu.",Positive
AMD,Answer to strix halo was the partnership with nvidia,Neutral
AMD,Did is you see the link? Passmark graphics score? 10999 for 7600m and 9500 for b390.,Neutral
AMD,"since the 140T has 20 watts for the GPU itself, how can it be otherwise?",Neutral
AMD,"I feel like the partnership was an answer to a much broader question concerning both companies, none of it really being an implicit answer to Strix Halo beyond a vague promise to develop custom chips with Intel cores and RTX cores fuse together using nvlink.     I mean, if they actually launch something, cool. But as of now, we don't really have any information that directly points to a competing product.Â      In fact, I might be crazy but I feel like it is more likely that the actual answer to Strix Halo will be all Intel silicon, because Nvidia is very horny for all things ai and all things datacenter.",Neutral
AMD,"I mean no offense, but Passmark is irrelevant.Â  Even comparing the 890m to the 7600m (non-xt), the 7600m is usually twice as fast, with dips down to ~60% faster, and lifts up to ~170% faster.     NoteBookCheck has an extremely robust dataset of benchmarks in games for both the 890m and the 7600m (non-xt) at various resolutions, and they show not only a clear winner, but a very large difference in the performance of these devices.      Now I'm not trashing what the B390 will be, because we need an iGPU fight here.Â  But thinking that the 7600m (non-xt) is only ~15.7% faster than the B390 ((new-old)/old gives percent change) because of Passmark is erroneous.",Neutral
AMD,">I feel like the partnership was an answer to a much broader question concerning both companies, none of it really being an implicit answer to Strix Halo beyond a vague promise to develop custom chips with Intel cores and RTX cores fuse together using nvlink.  They explicitly talk about a client product that will have Intel cores and Nvidia iGPU tiles. It's not especially vague.   >In fact, I might be crazy but I feel like it is more likely that the actual answer to Strix Halo will be all Intel silicon, because Nvidia is very horny for all things ai and all things datacenter.  Despite that, Nvidia has already provided a custom iGPU tile for their Mediatek + Nvidia iGPU solution.   They have both the resources and financial incentive to do this. Plus, this should be better than any all intel silicon solution anyway.",Neutral
AMD,Yup and Jensen himself said the high powered SOCs is a $30 billion untapped market,Neutral
AMD,"I guess we'll see more when we get actual info about the potential devices.Â  Right now, I haven't read about a device coming to market.",Neutral
AMD,Back in the day you could overclock a 2600k from 3.4Ghz to 4.5Ghz on a $25 Hyper212 cooler. The performance gains were incredible as Sandy Bridge scaled very well at higher clocks.   Now days CPUs come overclocked already.,Positive
AMD,"""It's crazy to think that a cpu from 2009 can be easily overclocked.. 2.9Ghz to 4.1Ghz is crazy !""  You could overclock huge amounts on earlier generations - I used to run Pentium 4 1.6GHz chips at 3.2GHz on air-cooling, more on phase-change cooling.",Neutral
AMD,"I ran my i5 750 2.67Ghz for years at 4Ghz without any issues. I benched it some at 4.2Ghz even, but it was not fully stable.  The X58 CPU are even better tho. And even if you had insane OC potential back in the days it was not as good as it sounds, since the turboboost was higher than the stock frequency that is listed.",Negative
AMD,"Lol a 15 year old computer running Windows 11, meanwhile Microsoft telling people to upgrade 5 year old laptops for win10 being EOL.",Neutral
AMD,X5690@4.6GHz on Rampage III Extreme ðŸ˜˜,Positive
AMD,it is crazy that intel sold you same technology at downclocked speeds to make a nice model range with different prices.,Negative
AMD,Sick stuff. I still got my i7 930 at 4.2Ghz running just fine. These types of chips overclock like crazy.,Negative
AMD,Be nice. Give it another stick of ram!,Negative
AMD,Q6600 G0,Neutral
AMD,"Cool. Glad it worked for you. I have dual xeon server, maybe i should try it. But its production server dont wana break my apps. Lol",Positive
AMD,My 2500k did ~4.8 ghz and my 6950x did 5.2 ghz. Its base clock was like 3.2ghz and this was using 128GB of quad channel DDR4.  It was â€œstableâ€,Neutral
AMD,45nm is crazy in 2025,Neutral
AMD,500W power draw when,Neutral
AMD,"This subreddit is in manual approval mode, which means that **all submissions are automatically removed and must first be approved before they are visible**. Your post will only be approved if it concerns news or reviews related to Intel Corporation and its products or is a high quality discussion thread. Posts regarding purchase advice, cooling problems, technical support, etc... will not be approved. **If you are looking for purchasing advice please visit /r/buildapc. If you are looking for technical support please visit /r/techsupport or see the pinned /r/Intel megathread where Intel representatives and other users can assist you.**  *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/intel) if you have any questions or concerns.*",Neutral
AMD,"I used to run my i3-540 at 4.2GHz, air cooled on what is effectively worse than a Hyper 212 Evo. I miss the old days when I could overclock the snot out of them. These days I guess they're binned to almost their max potential out of the factory so most of the time I'm undervolting them.",Negative
AMD,Well done. Still using two H55m machines with OC (x3450 and i5 661).  They also OC decently at stock voltage keeping turbo and all power savings. My X3450 does 2.6 -> 3.3Ghz(3.8 turbo). The advantage is that it idles quite low at 50-60W.   But for gaming and rendering it's better to go all in as you did. Most chips can do anywhere from 3.8 to 4.2 all cores IME.,Positive
AMD,nah my 40 logical processors would smash through it all  x2 xeon e5-2680 v2,Neutral
AMD,"is that better? I dont need to dive into setting anymore, the CPU maker do it for me with warranty.",Neutral
AMD,"There is still more to work with, especially if one does not fossilize on static all core OC, but does 2-step TVB fueled dynamic OC, Ecores are Aldo the source of much happiness on arrow",Positive
AMD,I miss overclocking. Felt like you were getting a bargain. Now I donâ€™t even try.,Negative
AMD,"Not as big an OC as yours, but I had a pre-built from FutureShop.  It was their home brand name.  Found a BIOS for the board that wasnâ€™t theirs.  Managed to get 3.2GHz out of a 2.4GHz Pentium 4 on pre-built from FutureShop cooling.",Neutral
AMD,"Wow, soo cool",Positive
AMD,The motherboard doesn't accept other stick of ram. Only my corsair ram work,Negative
AMD,How did you even get a 6950x to boot at 5.2ghz? Most of them hit a wall around 4.3ghz,Negative
AMD,"Has its ups and downs. Now that I'm older and have less time to tweak things and mostly just want shit to be stable, I see ""pre-overclocked with maybe 5% performance left on the table"" as a pro. The con is that chipmakers just jam a ton of power through it to make it happen, and the option of buying a half-price chip and spending an entire sleepless weekend tweaking it yourself to get 95% of the more expensive chip's performance is gone.",Negative
AMD,"Same - the complexity and heat rose a lot and the gains because less significant - with multi-core chips and turbo frequencies there just isn't much headroom in them.  That and I work fixing issues with computers all day, I just want my own PC to work.",Negative
AMD,"Thats because these older CPUs were surprisingly energy efficient. Also mostly because now modern CPUs are powerful enough where overclocking is pointless. Even my i3-12100 being overclocked would be pointless, even if its only a 80 watt CPU",Negative
AMD,He couldn't without LN2.,Neutral
AMD,"It was short lived, over ~7 years I had to pull back the multiplier from 52 to 44 to keep it stable.  I retired the system this year.  It was a full open loop from EK.  2x Pascal Titan X in SLi",Neutral
AMD,"I used to overclock everything, now I undervolt everything lol",Neutral
AMD,"The most important characteristics of a laptop are battery life ( power efficiency) and screen quality. That is what sells ( non apple ) clamshells.    All the other crap they test in various reviews are mostly meaningless to the actual user. There is a very small %age of the market for high power/perf laptops and even smaller market for gaming.   Most of the reason a laptop is â€œslowâ€ is bloatware and has nothing to do with the cpu choice anyway.  And Intel is already â€œbeatingâ€ AMD in laptop cpu sales, by a substantial margin. People incorrectly assume AMD has most of the market share in all segments because of the very noisy and super-biased gaming reviewers, who mostly focus on $3000+ gaming desktop builds. Yes AMD is handily winning there.",Neutral
AMD,"I have a T14s Gen 5 Core Ultra 5 135U and recently I saw \~9h of battery life, browsing websites. It's quite nice piece of hardware so with Lunar Lake it would be just perfect. Of course not for heavy workload because for this we will have Panther Lake. I work in tech for years, not an expert in laptops area but I can assure you that new CPUs from Intel that I mentioned earlier are way, way, way better than previous generations.",Positive
AMD,"I've gotten one and honestly it's amazing, easily the best laptop I've ever used so far.   I was skeptical about the battery life claims but I've genuinely found that using it for about 8 hours straight for coding, only drains the battery maybe 50%.  I've set it to only charge up to 80% max for battery health conservation, and I've regularly coded for 12 hours straight on the medium performance profile and haven't needed to charge until I got back home.  (This is for the Ultra 7 258v cpu variant btw)  Also this is while running Fedora with KDE Plasma which makes the battery life even more impressive as it's one of the heavier distros running cutting edge hardware and I've heard that Linux has less battery optimization compared to windows.    Screen isn't anything to write home about but the 100% srgb one looks good enough and is bright, 60hz looks kind of bad but I know that it saves a lot on battery.   Keyboard feels very nice as far as laptop keyboards go, having it be easily swappable is lovely as I wore out the keys on my old laptop, and I want this thing to last.   Linux hardware compatibility is perfect so far, even the fingerprint sensor works out of the box on fedora.   My only real complaint is that the plastic it is made out of is a major grease magnet and if I touch it without having immediately washed my hands, even if my hands weren't dirty, it'll leave dark patches from oils. Also it would be nice to have swappable RAM but I think 32gb ought to last a very long time anyway.   Genuinely seems like arguably one of the, if not the, best laptops for actually getting work done. Maybe it's not as fancy or sleek, but it just works. It's like the 2001 Toyota of the laptop world, it's not winning prizes for looks, but it'll never die, gets good mileage (battery life), and is easily repairable. Maybe not the laptop you want, but definitely the one you need (excluding people who need something like a dedicated GPU or really need super high CPU performance).",Positive
AMD,"Intel beats AMD in software (drivers, firmware) â€¦ I got think pad 780M laptop by company I work for. Randomly display wonâ€™t get detected. Randomly audio device goes missing. Not fun thing to reboot your laptop and miss 10 minutes of meeting.",Negative
AMD,"Soldered RAM sucks.  Nothing beats popping out the standard 8GB stick(s) a notebook may come with, installing a couple 2x32GB sticks yourself and having it actually work.",Negative
AMD,lol. Even in the cons it says weaker multicore than AMDâ€¦.?   This article seems like AI wrote it,Negative
AMD,"Unfortunately Intel abandoned the on-package RAM after Lunar Lake again, which is the primary reason for the great efficiency and low power usage. I kind of understand why, it's expensive and not very flexible, plus apparently the market doesn't actually care that much about long battery runtimes. Only a small minority of people are ready to pay premium for this.",Negative
AMD,At work we are a Lenovo shop and recently swapped from Intel to AMD T14 laptops. Too many issues with Intel and the AMD models offer the same performance for less money.,Negative
AMD,Suck at gaming.,Negative
AMD,Try a modern mac and tell me its not the CPU holding the UX back. It's all about the cpu's.,Neutral
AMD,"That would be nice. We have a bunch of laptops with Intel's i5, 13th gen I believe it was. 2 p-cores, some e-cores. They are all slow as fuck. I mean it. The CPU is so extremely slow and goes into tdp limit right away. Most users hate them.  Battery life is ok, but they are really bad in terms of performance.  So - I wouldn't say CPU doesn't matter.",Negative
AMD,"AMD is held back in laptops by some shady deals of laptop manufacturers with Intel. It's impossible to get a 4k AMD laptop with 5090 for example, all of those are Intel (I found literally one AMD laptop like that compared to 25 from Intel). That's utterly ridiculous.",Negative
AMD,Isnâ€™t the keyboard one of the most important characteristics?,Neutral
AMD,"Yeah, so much of laptop performance is dictated by things other than the cpu. Its kinda wild.   Intel does a way better job getting good laptop designs. Amd historically has just been a cpu seller, telling oems to go wild and do whatever . . . And it always ends very badly.   The biggest sign amd is taking share is not cpu benchmarks, but will be things like having premium screens, good thermals, lack of bloatware, dual channel memory, good SSDs, good colors, etc etc. and . . . ACTUAL AVAILABILITY. I dunno how many reviews i see where they review and intel and amd parts. Usually there is some way intel has a better premium finish. And then amd just has zero ways to actually buy their model. Its the weirdest thing.",Negative
AMD,"Hey Iâ€™m looking at the exact same laptop that you have. Can you tell me about the build quality and if thereâ€™s any keyboard flex when pressing down on it? Please tell me. Iâ€™m going to use it for word, excel, reading lots of pdf files and ebooks and watch movies. Will it be enough for that?",Neutral
AMD,Omg a positive review for Intel Lunar Lake ðŸ˜­  https://www.reddit.com/r/laptops/s/RYInPJfnAd,Positive
AMD,"But haven't you heard, AMD beats Nvidia slightly at linux gaming benchmarks.  That means AMD has the best software support.",Positive
AMD,"I miss the times when laptops were far more upgradeable. I got a budget laptop for college with a low-end dual core, a spinning HDD, and 1 stick of 2GB RAM. By the time I retired it ~6 years later I've upgraded the CPU, replaced the HDD with a SSD, and added 2x4GB sticks of RAM. I also could've swapped out the network card and even the DVD drive for another SATA drive, but never got around to those.",Neutral
AMD,Soldered ram is a lot faster. So no.,Neutral
AMD,Yes but now RAM costs a ton of money,Negative
AMD,Is multicore performance the only consideration when buying a laptop?,Neutral
AMD,What kind of issues?,Neutral
AMD,What kind of issues with Intel? I thought it was the AMD that had tons of issues,Negative
AMD,It is not a gaming laptop,Neutral
AMD,"Yep. More specifically, it's mostly the single thread performance and efficiency.  It's how a MacBook Air can be fanless, run super fast, and stay cool at the same time while you're doing work with it.",Positive
AMD,It's an enterprise grade product you buffoon.,Negative
AMD,Exactly. Thinkpads are not targeting average Joes. They are targeting business and enterprise customers. Their Yoga and Ideapads are targeting the regular Joes.,Neutral
AMD,Build quality.Â    Thinkpads are solid machines that are easy to fix.Â    It's one of the few laptops that comes close to MacBook quality and everything judt working.,Positive
AMD,"So build quality will be subjective, from what I can tell, it's got very good build quality in terms of ""real"" factors such as durability. But it definitely feels less ""premium"" than similarly priced consumer grade laptops. The plastic is plastic so it will flex a little bit, but the parts all seem very well put together and it does feel ""solid"" overall.   I haven't really noticed keyboard flex, but I have noticed a slight amount of flex where my palms rest, particularly on the right side, where the smart card reader is, which makes sense as it is just a big hole in the side of the laptop. I plan on getting a dummy smart card to fill the gap and hopefully that should reduce it.   Overall whilst the internal chassis is metal, the outside is just plastic. I imagine that is good for durability, as it ought to be able to absorb shocks, but, as I said, it definitely makes it feel less ""premium"". They key press feel of the keyboard definitely does feel very nice as far as laptops go though. Obviously it's still nothing compared to a good mechanical keyboard but for a laptop it's very nice.   I bought this laptop for longevity and durability, so given that It's only just come out, I can't really say much about that, but the prestige of thinkpads of previous generations kind of speaks to their reliability. Plus it's apparent that they are still quite easy to repair and Lenovo has video guides on replacing loads of the parts.   And for your use case the battery life should be very good. It seems the Intel chip was designed to be very efficient during periods of downtime and something like viewing a PDF or editing a document has a LOT of downtime for the CPU",Positive
AMD,"Because only on Linux, Valve heavily funds AMD driver development and they also get other community contributions. The commonly used RADV vulkan driver was started as a community effort without AMD involvement.",Neutral
AMD,"I hope you're joking(sorry if you are), cos Nvidia isn't actually a good benchmark for software support on Linux. Intel is so much better at Linux software support than Nvidia",Negative
AMD,"The question is, is the soldered ram you're buying in a laptop faster than the ram you can buy and install yourself?",Neutral
AMD,All the more reason to make it upgradable,Positive
AMD,Lunar Lake isnâ€™t how Intel beats Amd lol. Panther lake will stop a lot of the bleeding for sure. AMD is so far making mostly good moves and Intel is as well with LBT. The goal for Intel over the next 3 years is stop losing customers base. I will point out Intel still has about 75% of all x86 customers.,Neutral
AMD,"I mean, the only other pro is, that you cannot get the 2.8K panel on the AMD version for some reason..... sooo",Negative
AMD,This was back when the 14th generation were having issues.,Negative
AMD,"It's $2,000 so no excuse.",Neutral
AMD,Thank you so much for this valuable and comprehensive information! I really appreciate it:),Positive
AMD,"Usually yes, soldered ram will be faster. And in case of lunar lake, it is faster and more efficient due to it being packaged with the cpu. Like Apple's unified memory.",Positive
AMD,"Lunar Lake already beat AMD, nobody buys AMD laptops",Neutral
AMD,i stopped at $2100 for a Thinkpad T14,Neutral
AMD,"Ah okay, got it thanks.",Positive
AMD,Panther Lake fixed it,Neutral
AMD,wrong  Nobody Supply AMD laptop     There fixed for u,Negative
AMD,"I do, and many of the people I know do.",Neutral
AMD,Nobody pays that much.,Negative
AMD,"Not anymore, there are plenty of AMD laptops on the market, of course - depending on region.",Neutral
AMD,Try the shunt mod,Neutral
AMD,"Cool, errr...  icy",Neutral
AMD,"I used to work in an inter chip testing lab in Ronler Acres Beaverton. We would test them in an oven, test them at room temp, and test the chips with liquid nitrogen. Cold had the highest failure rate, hot had the highest success rate.  Chips are designed to love heat.",Neutral
AMD,Great work man. Brings back the memories from the good 'ol early 2000's.   You need a power mod and more voltage.,Positive
AMD,"mine with B570, everything stock, no any mod   [https://imgur.com/a/i5wVgi4](https://imgur.com/a/i5wVgi4)",Neutral
AMD,did you use dry ice? how did you hit sub-ambient?,Neutral
AMD,I ordered a steel legend B580 and Iâ€™m going to clamp an LN2 pot to it and run it on Dice to see what happens. Probably going to shunt mod it as well because of what you did. Might as well add an Intel card to my mix and see what it does.,Neutral
AMD,Are you in the US? If so how were you able to get Maxsun?,Neutral
AMD,Oh... for sure ðŸ˜,Positive
AMD,"I know! If I could of modded the power table I would have, shunt mod is on the ""card"" for sure.",Positive
AMD,Great work dude! Only 200MHz to go ðŸ˜‰,Positive
AMD,Car coolant in the freezer ðŸ˜,Positive
AMD,That's the way! Let us all know the results.,Positive
AMD,I am in Australia.,Neutral
AMD,I di it myself but it seemed to only add like 20% more power not really the unlimited I expected.,Neutral
AMD,"Yes, but car coolant doesn't enable sub-zero. What else did you have in the freezer, how was the liquid cooled?",Neutral
AMD,Should be here in a few days and Iâ€™ll tear it down and prep it. Iâ€™ll see how it goes when itâ€™s down to -70c and do some scores and then shunt it. I think it can probably handle 30% more wattage just fine. My HWBOT is Forsaken7. Iâ€™ll let you know.,Positive
AMD,So do you have outlets in Australia where you can buy Maxsun Gpus?  Does Maxsun have an outlet in Australia where you can RMA to?  I am in the US and I want to look into getting the dual Arc card with 48gb of vram.,Neutral
AMD,"Okay, household freezers get to -18C. Water freezes at 0C, antifreeze freezes at about -25C. So, car coolant in a freezer will get to and hold -18C while staying liquid. So, that's how I did it.",Neutral
AMD,"Just be aware (from my experience anyway) when Intel crashes it doesn't just crash the driver, it crashes into a full reboot, almost every time. It's a real effing pain in the arse.",Negative
AMD,Oh! You put the car coolant to run through a freezer? Wow! Nice,Positive
