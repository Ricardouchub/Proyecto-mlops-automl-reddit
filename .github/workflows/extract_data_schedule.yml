name: Extracción Diaria de Datos de Reddit

on:
  # Disparador 1: Se ejecuta a las 05:00 UTC todos los días (puedes ajustar la hora)
  schedule:
    - cron: '0 5 * * *'
  
  # Disparador 2: Permite ejecutarlo manualmente desde la pestaña "Actions" de GitHub
  workflow_dispatch:

jobs:
  extract-and-commit:
    runs-on: ubuntu-latest

    steps:
      # 1. Clona el repositorio para tener acceso a los scripts
      - name: Checkout del repositorio
        uses: actions/checkout@v4

      # 2. Configura Python
      - name: Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # 3. Instala solo las dependencias necesarias para la extracción
      - name: Instalar dependencias
        run: pip install praw python-dotenv pandas

      # 4. Ejecuta el script de extracción de datos
      #    Las credenciales se pasan de forma segura desde los "Secrets" de GitHub
      - name: Ejecutar script de extracción
        env:
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
        run: python extract_reddit_data.py

      # 5. Configura Git y hace commit/push si el archivo de datos cambió
      - name: Hacer commit y push de los nuevos datos
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add data/reddit_comments.csv
          # El siguiente comando solo hace commit si detecta cambios en el archivo
          git diff --staged --quiet || git commit -m "📊 Datos crudos de Reddit actualizados"
          git push