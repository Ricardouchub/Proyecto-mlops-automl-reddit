name: Extracción Diaria de Datos de Reddit

on:
  # Disparador 1: Se ejecuta a las 05:00 UTC todos los días
  schedule:
    - cron: '0 5 * * *'

  # Disparador 2: Permite ejecutarlo manualmente desde la pestaña Actions de GitHub
  workflow_dispatch:

jobs:
  extract-and-commit:
    runs-on: ubuntu-latest

    steps:
      # 1. Clona tu repositorio para tener acceso a los scripts y al CSV
      - name: Checkout del repositorio
        uses: actions/checkout@v4

      # 2. Configura Python
      - name: Configurar Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # 3. Instala las dependencias necesarias
      - name: Instalar dependencias
        run: |
          python -m pip install --upgrade pip
          pip install praw python-dotenv pandas

      # 4. Ejecuta el script de extracción de datos
      #    Las credenciales se pasan como variables de entorno secretas de GitHub
      - name: Ejecutar script de extracción
        env:
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USER_AGENT: ${{ secrets.REDDIT_USER_AGENT }}
        run: python extract_reddit_data.py

      # 5. Configura Git y hace commit/push si hay cambios en el CSV
      - name: Hacer commit y push de los nuevos datos
        run: |
          git config --global user.name 'github-actions[bot]'
          git config --global user.email 'github-actions[bot]@users.noreply.github.com'
          git add reddit_comments.csv
          # El siguiente comando solo hace commit si detecta cambios en los archivos añadidos
          git diff --staged --quiet || git commit -m "Datos actualizados desde Reddit"
          git push