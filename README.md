# Pipeline de MLOps para An谩lisis de Sentimiento en Tiempo Real: Intel vs. AMD en Reddit

Este proyecto demuestra la construcci贸n de un **pipeline de MLOps de extremo a extremo**, dise帽ado para ser completamente aut贸nomo. El sistema extrae datos en vivo desde la API de Reddit, los procesa utilizando m煤ltiples modelos de NLP, entrena un modelo de Machine Learning propio con AutoML y presenta los resultados en un dashboard interactivo.

## Caracter铆sticas Principales

* **Extracci贸n de Datos Automatizada:** Un bot se conecta diariamente a la API de Reddit para buscar y recolectar nuevos comentarios sobre Intel y AMD en subreddits de tecnolog铆a.
* **Procesamiento Avanzado de NLP:** Cada comentario es enriquecido con un an谩lisis multifac茅tico:
    * **Sentimiento:** Positivo, Negativo o Neutral.
    * **Emociones:** Alegr铆a, Ira, Miedo, etc.
    * **Modelado de T贸picos:** Descubrimiento de los principales temas de conversaci贸n.
* **Entrenamiento con AutoML:** Se entrena un modelo de clasificaci贸n de sentimiento desde cero utilizando **PyCaret**, demostrando un pipeline de entrenamiento automatizado.
* **Dashboard Comparativo:** Una interfaz interactiva construida con **Gradio** que permite comparar el rendimiento del modelo propio (AutoML) contra un modelo experto de 煤ltima generaci贸n (RoBERTa), demostrando una toma de decisiones basada en datos.
* **Orquestaci贸n con GitHub Actions:** Dos pipelines de CI/CD interconectados que automatizan todo el flujo, desde la extracci贸n de datos hasta el re-entrenamiento del modelo.

## 锔 El Pipeline de MLOps en Acci贸n

Este proyecto no es solo un modelo, es un **sistema vivo y aut贸nomo**. La magia reside en la orquestaci贸n de dos bots (workflows de GitHub Actions) que trabajan en conjunto:

#### ** Bot 1: El Extractor de Datos (Diario)**

* **Activaci贸n:** Se ejecuta autom谩ticamente todos los d铆as a las 05:00 UTC.
* **Misi贸n:**
    1.  `讹` Ejecuta el script `extract_reddit_data.py`.
    2.  `` Se conecta a la API de Reddit y busca nuevos comentarios sobre Intel y AMD.
    3.  `` Actualiza el archivo `data/reddit_comments.csv` con los nuevos hallazgos.
    4.  `猬锔` Hace `commit` y `push` del archivo actualizado de vuelta al repositorio.

#### ** Bot 2: El Procesador y Entrenador (Reactivo)**

* **Activaci贸n:** Se dispara **inmediatamente despu茅s** de que el Bot 1 sube los nuevos datos.
* **Misi贸n:**
    1.  `讹` Ejecuta el script `nlp_processor.py`.
    2.  `` Toma los comentarios crudos y los enriquece con an谩lisis de sentimiento, emociones y t贸picos, guardando el resultado en `data/processed_reddit_data.csv`.
    3.  `讹` Ejecuta el script `python_train.py`.
    4.  `锔锔` Entrena un nuevo modelo de sentimiento desde cero utilizando **AutoML (PyCaret)**.
    5.  `` Guarda los artefactos del entrenamiento: el modelo (`models/sentiment_model_v2.pkl`) y el gr谩fico de importancia de caracter铆sticas.
    6.  `猬锔` Hace `commit` y `push` de todos los artefactos actualizados al repositorio.

Este ciclo asegura que el proyecto se mantenga siempre al d铆a con la conversaci贸n m谩s reciente, mejorando y adapt谩ndose sin intervenci贸n manual.

##  La Historia: AutoML vs. Modelo Experto

Uno de los hallazgos clave de este proyecto es la comparaci贸n directa entre un modelo entrenado por nosotros y un modelo pre-entrenado de 煤ltima generaci贸n (State-of-the-Art).

* **Nuestro Modelo (AutoML):** Como se puede ver en el dashboard, el modelo entrenado con PyCaret, a pesar de los esfuerzos, obtiene un rendimiento bajo. Esto demuestra emp铆ricamente que el lenguaje de Reddit es demasiado complejo y lleno de matices para los modelos de ML tradicionales basados en frecuencia de palabras.
   * **Resultados del Mejor Modelo (Ridge Classifier):**
   * **Accuracy:** `0.5489` (apenas por encima del azar para 3 clases).
   * **AUC:** `0.0000` (incapaz de discriminar entre clases).
   * **Kappa:** `0.1729` (rendimiento muy bajo por encima del azar).
* **Modelo Experto (RoBERTa):** Para la aplicaci贸n final, se toma la decisi贸n estrat茅gica de usar un modelo Transformer pre-entrenado (`cardiffnlp/twitter-roberta-base-sentiment-latest`), que ofrece una precisi贸n muy superior al entender el contexto del lenguaje.

Esta comparaci贸n no es un fallo, sino la **demostraci贸n de un proceso de MLOps maduro**: saber experimentar, analizar resultados y elegir la mejor herramienta para el producto final.


##  Estructura del Proyecto


<img width="590" height="434" alt="image" src="https://github.com/user-attachments/assets/d351cd08-88ba-4c4d-8c70-4c53c27d03f6" />
