# Pipeline de MLOps para An谩lisis de Sentimiento en Tiempo Real

### An谩lisis Competitivo Automatizado: Intel vs. AMD en Reddit

**[★ Ver Demo en Vivo](https://TU_URL_DE_RENDER.onrender.com)** (Reemplaza esta URL con la tuya)

---

Este proyecto demuestra la construcci贸n de un **pipeline de MLOps de extremo a extremo**, dise帽ado para ser completamente aut贸nomo. El sistema extrae datos en vivo desde la API de Reddit, los procesa utilizando m煤ltiples modelos de NLP, entrena un modelo de Machine Learning propio con AutoML, y despliega los resultados en un dashboard interactivo que se actualiza autom谩ticamente.

## Caracter铆sticas Principales

* **Extracci贸n de Datos Automatizada:** Un bot se conecta diariamente a Reddit para recolectar nuevos comentarios sobre Intel y AMD.
* **Procesamiento Avanzado de NLP:** Cada comentario es enriquecido con un an谩lisis multifac茅tico:
    * **Sentimiento:** Positivo, Negativo o Neutral.
    * **Emociones:** Alegr铆a, Ira, Miedo, etc.
    * **Modelado de T贸picos:** Descubrimiento de los principales temas de conversaci贸n.
* **Entrenamiento con AutoML y GPU:** Se entrena un modelo de clasificaci贸n desde cero utilizando **PyCaret**, con la opci贸n de aceleraci贸n por GPU.
* **Dashboard Comparativo:** Una interfaz interactiva construida con **Gradio** que permite comparar el rendimiento del modelo propio (AutoML) contra un modelo experto de 煤ltima generaci贸n (RoBERTa).
* **Orquestaci贸n con GitHub Actions:** M煤ltiples pipelines de CI/CD que automatizan todo el flujo, desde la extracci贸n de datos hasta el re-entrenamiento del modelo.
* **Despliegue Continuo (CI/CD) en Render:** La aplicaci贸n est谩 conectada al repositorio de GitHub, despleg谩ndose autom谩ticamente con cada nueva actualizaci贸n del modelo.

## 锔 El Pipeline de MLOps en Acci贸n

Este proyecto es un **sistema vivo y aut贸nomo**. La magia reside en la orquestaci贸n de workflows de GitHub Actions que trabajan en conjunto:

#### ** Bot 1: El Extractor de Datos (Diario)**

* **Activaci贸n:** Se ejecuta autom谩ticamente todos los d铆as a las 05:00 UTC.
* **Misi贸n:**
    1.  `讹` Ejecuta el script `extract_reddit_data.py`.
    2.  `` Se conecta a la API de Reddit y busca nuevos comentarios sobre Intel y AMD.
    3.  `` Actualiza el archivo `data/reddit_comments.csv`.
    4.  `猬锔` Hace `commit` y `push` del archivo actualizado al repositorio, **activando el siguiente bot**.

#### ** Bot 2: El Procesador y Entrenador (Reactivo)**

* **Activaci贸n:** Se dispara autom谩ticamente cuando el Bot 1 termina con 茅xito.
* **Arquitectura:** Para solucionar el problema de `No space left on device` en los runners de GitHub, este pipeline se divide en **dos trabajos secuenciales y especializados**:
    1.  **Job `process-data`:**
        * `` Instala **solo** las librer铆as de NLP y ejecuta `nlp_processor.py` para enriquecer los datos.
        * `` Guarda los datos procesados como un "artefacto" temporal.
    2.  **Job `train-model`:**
        * `` Descarga el artefacto del job anterior.
        * `锔锔` Instala **solo** las librer铆as de AutoML y ejecuta `python_train.py` para entrenar el modelo.
        * `猬锔` Hace `commit` y `push` del modelo final (`.pkl`) y el gr谩fico de importancia al repositorio, **activando el despliegue en Render.**

## La Historia: AutoML vs. Modelo Experto

Uno de los hallazgos clave de este proyecto es la comparaci贸n directa entre un modelo entrenado por nosotros y un modelo pre-entrenado de 煤ltima generaci贸n.

* **Nuestro Modelo (AutoML):** Como se ve en el dashboard, el modelo entrenado con PyCaret logra un rendimiento moderado, demostrando que ha aprendido patrones reales pero que el lenguaje de Reddit es un desaf铆o complejo.

    **Resultados del Mejor Modelo (ExtraTreesClassifier):**
    * **Accuracy:** `0.5884` (significativamente mejor que el azar del 33%).
    * **AUC:** `0.7435` (buena capacidad para discriminar entre clases).
    * **Kappa:** `0.2786` (rendimiento bajo-moderado por encima del azar).

* **Modelo Experto (RoBERTa):** Para el an谩lisis principal en el dashboard, se utiliza un modelo Transformer pre-entrenado (`cardiffnlp/twitter-roberta-base-sentiment-latest`), que ofrece una precisi贸n muy superior al entender el contexto profundo del lenguaje.

Esta comparaci贸n no es un fallo, sino la **demostraci贸n de un proceso de MLOps maduro**: saber experimentar, analizar resultados y elegir la mejor herramienta para el producto final.

